<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Updating: A Set of Bayesian Notes</title>
  <meta name="description" content="Updating: A Set of Bayesian Notes">
  <meta name="generator" content="bookdown <!--bookdown:version--> and GitBook 2.6.7">

  <meta property="og:title" content="Updating: A Set of Bayesian Notes" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://jrnold.github.io/bayesian_notes" />
  
  
  <meta name="github-repo" content="jrnold/bayesian_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Updating: A Set of Bayesian Notes" />
  <meta name="twitter:site" content="@jrnld" />
  
  

<meta name="author" content="Jeffrey B. Arnold">


<meta name="date" content="2017-02-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>



<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Updating: A Set of Bayesian Notes</h1>
<h4 class="author"><em>Jeffrey B. Arnold</em></h4>
<h4 class="date"><em>2017-02-14</em></h4>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#part-theory">(PART) Theory</a></li>
<li><a href="#bayesian-inference"><span class="toc-section-number">1</span> Bayesian Inference</a></li>
<li><a href="#part-computation">(PART) Computation</a></li>
<li><a href="#markov-chain-monte-carlo"><span class="toc-section-number">2</span> Markov Chain Monte Carlo</a><ul>
<li><a href="#monte-carlo-sampling"><span class="toc-section-number">2.1</span> Monte Carlo Sampling</a></li>
<li><a href="#markov-chain-monte-carlo-sampling"><span class="toc-section-number">2.2</span> Markov Chain Monte Carlo Sampling</a></li>
<li><a href="#references"><span class="toc-section-number">2.3</span> References</a></li>
</ul></li>
<li><a href="#mcmc-diagnostics"><span class="toc-section-number">3</span> MCMC Diagnostics</a><ul>
<li><a href="#reparameterize-models"><span class="toc-section-number">3.1</span> Reparameterize Models</a></li>
<li><a href="#convergence-diagnostics"><span class="toc-section-number">3.2</span> Convergence Diagnostics</a><ul>
<li><a href="#potential-scale-reduction-hatr"><span class="toc-section-number">3.2.1</span> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</a></li>
<li><a href="#references-1"><span class="toc-section-number">3.2.2</span> References</a></li>
</ul></li>
<li><a href="#autocorrelation-effective-sample-size-and-mcse"><span class="toc-section-number">3.3</span> Autocorrelation, Effective Sample Size, and MCSE</a><ul>
<li><a href="#effective-sample-size"><span class="toc-section-number">3.3.1</span> Effective Sample Size</a></li>
</ul></li>
<li><a href="#thinning"><span class="toc-section-number">3.4</span> Thinning</a><ul>
<li><a href="#traceplots"><span class="toc-section-number">3.4.1</span> Traceplots</a></li>
<li><a href="#monte-carlo-standard-error-mcse"><span class="toc-section-number">3.4.2</span> Monte Carlo Standard Error (MCSE)</a></li>
</ul></li>
<li><a href="#hmc-nut-specific-diagnostics"><span class="toc-section-number">3.5</span> HMC-NUT Specific Diagnostics</a><ul>
<li><a href="#divergent-transitions"><span class="toc-section-number">3.5.1</span> Divergent transitions</a></li>
<li><a href="#maximum-treedepth"><span class="toc-section-number">3.5.2</span> Maximum Treedepth</a></li>
<li><a href="#bayesian-fraction-of-missing-information"><span class="toc-section-number">3.5.3</span> Bayesian Fraction of Missing Information</a></li>
</ul></li>
</ul></li>
<li><a href="#posterior-inference"><span class="toc-section-number">4</span> Posterior Inference</a><ul>
<li><a href="#prerequisites"><span class="toc-section-number">4.1</span> Prerequisites</a></li>
<li><a href="#introduction"><span class="toc-section-number">4.2</span> Introduction</a></li>
<li><a href="#functions-of-the-posterior-distribution"><span class="toc-section-number">4.3</span> Functions of the Posterior Distribution</a></li>
<li><a href="#marginal-effects"><span class="toc-section-number">4.4</span> Marginal Effects</a><ul>
<li><a href="#example-marginal-effect-plot-for-x"><span class="toc-section-number">4.4.1</span> Example: Marginal Effect Plot for X</a></li>
</ul></li>
</ul></li>
<li><a href="#model-checking"><span class="toc-section-number">5</span> Model Checking</a><ul>
<li><a href="#why-check-models"><span class="toc-section-number">5.1</span> Why check models?</a></li>
<li><a href="#posterior-predictive-checks"><span class="toc-section-number">5.2</span> Posterior Predictive Checks</a><ul>
<li><a href="#bayesian-p-values"><span class="toc-section-number">5.2.1</span> Bayesian p-values</a></li>
<li><a href="#test-quantities"><span class="toc-section-number">5.2.2</span> Test quantities</a></li>
<li><a href="#p-values-vs.u-values"><span class="toc-section-number">5.2.3</span> p-values vs. u-values</a></li>
<li><a href="#marginal-predictive-checks"><span class="toc-section-number">5.2.4</span> Marginal predictive checks</a></li>
<li><a href="#outliers"><span class="toc-section-number">5.2.5</span> Outliers</a></li>
<li><a href="#grapical-posterior-predictive-checks"><span class="toc-section-number">5.2.6</span> Grapical Posterior Predictive Checks</a></li>
</ul></li>
<li><a href="#sources"><span class="toc-section-number">5.3</span> Sources</a></li>
</ul></li>
<li><a href="#part-models">(PART) Models</a></li>
<li><a href="#introduction-to-stan-and-linear-regression"><span class="toc-section-number">6</span> Introduction to Stan and Linear Regression</a><ul>
<li><a href="#prerequites"><span class="toc-section-number">6.1</span> Prerequites</a></li>
<li><a href="#the-statistical-model"><span class="toc-section-number">6.2</span> The Statistical Model</a><ul>
<li><a href="#sampling"><span class="toc-section-number">6.2.1</span> Sampling</a></li>
<li><a href="#convergence-diagnostics-and-model-fit"><span class="toc-section-number">6.2.2</span> Convergence Diagnostics and Model Fit</a></li>
</ul></li>
</ul></li>
<li><a href="#heteroskedasticity-and-robust-regression"><span class="toc-section-number">7</span> Heteroskedasticity and Robust Regression</a><ul>
<li><a href="#prerequisites-1"><span class="toc-section-number">7.1</span> Prerequisites</a></li>
<li><a href="#linear-regression-with-student-t-distributed-errors"><span class="toc-section-number">7.2</span> Linear Regression with Student t distributed errors</a><ul>
<li><a href="#double-exponential-laplace-errors"><span class="toc-section-number">7.2.1</span> Double Exponential (Laplace) Errors</a></li>
</ul></li>
<li><a href="#heteroskedasticity"><span class="toc-section-number">7.3</span> Heteroskedasticity</a><ul>
<li><a href="#covariates"><span class="toc-section-number">7.3.1</span> Covariates</a></li>
<li><a href="#student-t-error"><span class="toc-section-number">7.3.2</span> Student-t Error</a></li>
</ul></li>
<li><a href="#references-2"><span class="toc-section-number">7.4</span> References</a><ul>
<li><a href="#robust-regression"><span class="toc-section-number">7.4.1</span> Robust regression</a></li>
<li><a href="#heteroskedasticity-1"><span class="toc-section-number">7.4.2</span> Heteroskedasticity</a></li>
<li><a href="#qunatile-regression"><span class="toc-section-number">7.4.3</span> Qunatile regression</a></li>
</ul></li>
</ul></li>
<li><a href="#generalized-linear-models"><span class="toc-section-number">8</span> Generalized Linear Models</a><ul>
<li><a href="#generalized-linear-models-1"><span class="toc-section-number">8.1</span> Generalized Linear Models</a></li>
<li><a href="#count-models"><span class="toc-section-number">8.2</span> Count Models</a><ul>
<li><a href="#poisson"><span class="toc-section-number">8.2.1</span> Poisson</a></li>
</ul></li>
<li><a href="#example"><span class="toc-section-number">8.3</span> Example</a></li>
<li><a href="#negative-binomial"><span class="toc-section-number">8.4</span> Negative Binomial</a><ul>
<li><a href="#references-3"><span class="toc-section-number">8.4.1</span> References</a></li>
</ul></li>
<li><a href="#multinomial-categorical-models"><span class="toc-section-number">8.5</span> Multinomial / Categorical Models</a></li>
<li><a href="#gamma-regression"><span class="toc-section-number">8.6</span> Gamma Regression</a></li>
<li><a href="#beta-regression"><span class="toc-section-number">8.7</span> Beta Regression</a></li>
<li><a href="#references-4"><span class="toc-section-number">8.8</span> References</a></li>
</ul></li>
<li><a href="#binomial-models"><span class="toc-section-number">9</span> Binomial Models</a><ul>
<li><a href="#link-functions-link-function"><span class="toc-section-number">9.0.1</span> Link Functions {link-function}</a></li>
<li><a href="#stan"><span class="toc-section-number">9.0.2</span> Stan</a></li>
<li><a href="#example-vote-turnout"><span class="toc-section-number">9.0.3</span> Example: Vote Turnout</a></li>
<li><a href="#separation"><span class="toc-section-number">9.0.4</span> Separation</a></li>
<li><a href="#rare-events-logit"><span class="toc-section-number">9.1</span> Rare Events Logit</a></li>
<li><a href="#case-control"><span class="toc-section-number">9.2</span> Case Control</a><ul>
<li><a href="#references-6"><span class="toc-section-number">9.2.1</span> References</a></li>
</ul></li>
</ul></li>
<li><a href="#unbounded-count-models"><span class="toc-section-number">10</span> Unbounded Count Models</a><ul>
<li><a href="#poisson-1"><span class="toc-section-number">10.1</span> Poisson</a></li>
<li><a href="#negative-binomial-1"><span class="toc-section-number">10.2</span> Negative Binomial</a><ul>
<li><a href="#stan-1"><span class="toc-section-number">10.2.1</span> Stan</a></li>
<li><a href="#example-number-of-number-o"><span class="toc-section-number">10.2.2</span> Example: Number of Number o</a></li>
<li><a href="#references-7"><span class="toc-section-number">10.2.3</span> References</a></li>
<li><a href="#link-functions"><span class="toc-section-number">10.2.4</span> Link functions</a></li>
<li><a href="#stan-2"><span class="toc-section-number">10.2.5</span> Stan</a></li>
</ul></li>
<li><a href="#example-bilateral-sanctions"><span class="toc-section-number">10.3</span> Example: Bilateral Sanctions</a></li>
<li><a href="#negative-binomial-2"><span class="toc-section-number">10.4</span> Negative Binomial</a><ul>
<li><a href="#example-economic-sanctions-ii-ex-econ-sanctions-2"><span class="toc-section-number">10.4.1</span> Example: Economic Sanctions II {ex-econ-sanctions-2}</a></li>
<li><a href="#references-8"><span class="toc-section-number">10.4.2</span> References</a></li>
</ul></li>
</ul></li>
<li><a href="#categorical-variables"><span class="toc-section-number">11</span> Categorical Variables</a><ul>
<li><a href="#example-mexico-vote-choice"><span class="toc-section-number">11.1</span> Example: Mexico Vote Choice</a></li>
</ul></li>
<li><a href="#shrinkage-regularization"><span class="toc-section-number">12</span> Shrinkage and Regularization</a><ul>
<li><a href="#normal-linear-regression-model"><span class="toc-section-number">12.1</span> Normal Linear Regression Model</a></li>
<li><a href="#penalized-regression"><span class="toc-section-number">12.2</span> Penalized Regression</a><ul>
<li><a href="#ridge-regression"><span class="toc-section-number">12.2.1</span> Ridge Regression</a></li>
<li><a href="#lasso"><span class="toc-section-number">12.2.2</span> Lasso</a></li>
</ul></li>
<li><a href="#bayesian-shrinkage-priors"><span class="toc-section-number">12.3</span> Bayesian Shrinkage Priors</a></li>
<li><a href="#differences-between-bayesian-shrinkage-and-penalized-likelihood"><span class="toc-section-number">12.4</span> Differences between Bayesian Shrinkage and Penalized Likelihood</a></li>
<li><a href="#hierarchical-shrinkage-priors"><span class="toc-section-number">12.5</span> Hierarchical Shrinkage Priors</a></li>
<li><a href="#example-1"><span class="toc-section-number">12.6</span> Example</a><ul>
<li><a href="#double-exponential-laplace-prior"><span class="toc-section-number">12.6.1</span> Double Exponential (Laplace) Prior</a></li>
<li><a href="#hierarchical-prior-hs"><span class="toc-section-number">12.6.2</span> Hierarchical Prior (HS)</a></li>
<li><a href="#comparison"><span class="toc-section-number">12.6.3</span> Comparison</a></li>
</ul></li>
<li><a href="#shrinkage-parameters"><span class="toc-section-number">12.7</span> Shrinkage Parameters</a></li>
<li><a href="#choice-of-hyperparameter-on-tau"><span class="toc-section-number">12.8</span> Choice of Hyperparameter on <span class="math inline">\(\tau\)</span></a></li>
<li><a href="#r-implementations"><span class="toc-section-number">12.9</span> R Implementations</a></li>
<li><a href="#bayesian-model-averaging"><span class="toc-section-number">12.10</span> Bayesian Model Averaging</a><ul>
<li><a href="#zellners-g-prior"><span class="toc-section-number">12.10.1</span> Zellner’s g-prior</a></li>
</ul></li>
<li><a href="#slab-and-spike-priors"><span class="toc-section-number">12.11</span> Slab and Spike Priors</a></li>
<li><a href="#technical-notes"><span class="toc-section-number">12.12</span> Technical Notes</a></li>
<li><a href="#multiple-comparisons-and-thresholding-rules"><span class="toc-section-number">12.13</span> Multiple Comparisons and Thresholding rules</a></li>
<li><a href="#examples-of-applications-of-sensitivity-analysis"><span class="toc-section-number">12.14</span> Examples of Applications of Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#hierarchical-models"><span class="toc-section-number">13</span> Hierarchical Models</a><ul>
<li><a href="#example-baseball-hits"><span class="toc-section-number">13.1</span> Example: Baseball Hits</a><ul>
<li><a href="#other-examples"><span class="toc-section-number">13.1.1</span> Other Examples</a></li>
</ul></li>
</ul></li>
<li><a href="#multilevel-models"><span class="toc-section-number">14</span> Multilevel Models</a><ul>
<li><a href="#example-radon"><span class="toc-section-number">14.1</span> Example: Radon</a><ul>
<li><a href="#data"><span class="toc-section-number">14.1.1</span> Data</a></li>
<li><a href="#varying-intercepts-models"><span class="toc-section-number">14.1.2</span> Varying Intercepts Models</a></li>
<li><a href="#varying-intercept-model"><span class="toc-section-number">14.1.3</span> Varying Intercept Model</a></li>
<li><a href="#varying-slope-model"><span class="toc-section-number">14.1.4</span> Varying Slope Model</a></li>
<li><a href="#group-level-predictors"><span class="toc-section-number">14.1.5</span> Group Level Predictors</a></li>
<li><a href="#lme4"><span class="toc-section-number">14.1.6</span> lme4</a></li>
<li><a href="#rstanarm"><span class="toc-section-number">14.1.7</span> rstanarm</a></li>
</ul></li>
<li><a href="#pooling-of-hierarchical-parameters"><span class="toc-section-number">14.2</span> Pooling of Hierarchical Parameters</a></li>
<li><a href="#anova"><span class="toc-section-number">14.3</span> ANOVA</a></li>
<li><a href="#time-series-cross-section"><span class="toc-section-number">14.4</span> Time-Series Cross Section</a></li>
<li><a href="#extensions"><span class="toc-section-number">14.5</span> Extensions</a></li>
<li><a href="#miscellaneous"><span class="toc-section-number">14.6</span> Miscellaneous</a><ul>
<li><a href="#how-many-groups"><span class="toc-section-number">14.6.1</span> How many groups?</a></li>
<li><a href="#correlation-between-predictors-and-errors"><span class="toc-section-number">14.6.2</span> Correlation between Predictors and Errors</a></li>
</ul></li>
<li><a href="#references-9"><span class="toc-section-number">14.7</span> References</a></li>
</ul></li>
<li><a href="#part-appendix">(PART) Appendix</a><ul>
<li><a href="#parameters"><span class="toc-section-number">14.8</span> Parameters</a></li>
<li><a href="#miscellaneous-mathematical-background"><span class="toc-section-number">14.9</span> Miscellaneous Mathematical Background</a><ul>
<li><a href="#location-scale-families"><span class="toc-section-number">14.9.1</span> Location-Scale Families</a></li>
<li><a href="#scale-mixtures-of-normal-distributions"><span class="toc-section-number">14.9.2</span> Scale Mixtures of Normal Distributions</a></li>
<li><a href="#covariance-correlation-matrix-decomposition"><span class="toc-section-number">14.9.3</span> Covariance-Correlation Matrix Decomposition</a></li>
<li><a href="#qr-factorization"><span class="toc-section-number">14.9.4</span> QR Factorization</a></li>
<li><a href="#cholesky-decomposition"><span class="toc-section-number">14.9.5</span> Cholesky Decomposition</a></li>
</ul></li>
</ul></li>
<li><a href="#scaled-and-unscaled-variables"><span class="toc-section-number">15</span> Scaled and Unscaled Variables</a></li>
<li><a href="#annotated-bibliography"><span class="toc-section-number">16</span> Annotated Bibliography</a><ul>
<li><a href="#textbooks"><span class="toc-section-number">16.0.1</span> Textbooks</a></li>
<li><a href="#syllabi"><span class="toc-section-number">16.1</span> Syllabi</a></li>
<li><a href="#topics"><span class="toc-section-number">16.2</span> Topics</a></li>
<li><a href="#bayes-theorem"><span class="toc-section-number">16.3</span> Bayes’ Theorem</a></li>
<li><a href="#article-length-introductions-to-bayesian-statistics"><span class="toc-section-number">16.4</span> Article Length Introductions to Bayesian Statistics</a><ul>
<li><a href="#why-bayesian"><span class="toc-section-number">16.4.1</span> Why Bayesian</a></li>
<li><a href="#modern-statistical-workflow"><span class="toc-section-number">16.4.2</span> Modern Statistical Workflow</a></li>
<li><a href="#bayesian-philosophy"><span class="toc-section-number">16.4.3</span> Bayesian Philosophy</a></li>
<li><a href="#bayesian-hypothesis-testing"><span class="toc-section-number">16.4.4</span> Bayesian Hypothesis Testing</a></li>
<li><a href="#bayesian-frequentist-debates"><span class="toc-section-number">16.4.5</span> Bayesian Frequentist Debates</a></li>
<li><a href="#categorical"><span class="toc-section-number">16.4.6</span> Categorical</a></li>
<li><a href="#variable-selection"><span class="toc-section-number">16.4.7</span> Variable Selection</a></li>
<li><a href="#multiple-testing"><span class="toc-section-number">16.4.8</span> Multiple Testing</a></li>
<li><a href="#rare-events"><span class="toc-section-number">16.4.9</span> Rare Events</a></li>
<li><a href="#identifiability"><span class="toc-section-number">16.4.10</span> Identifiability</a></li>
<li><a href="#shrinkage"><span class="toc-section-number">16.4.11</span> Shrinkage</a></li>
<li><a href="#inference"><span class="toc-section-number">16.4.12</span> Inference</a></li>
<li><a href="#convergence"><span class="toc-section-number">16.4.13</span> Convergence</a></li>
<li><a href="#software"><span class="toc-section-number">16.4.14</span> Software</a></li>
<li><a href="#stan-3"><span class="toc-section-number">16.4.15</span> Stan</a></li>
<li><a href="#diagrams"><span class="toc-section-number">16.4.16</span> Diagrams</a></li>
<li><a href="#priors"><span class="toc-section-number">16.4.17</span> Priors</a></li>
</ul></li>
<li><a href="#bayesian-model-averaging-1"><span class="toc-section-number">16.5</span> Bayesian Model Averaging</a></li>
<li><a href="#multilevel-modeling"><span class="toc-section-number">16.6</span> Multilevel Modeling</a></li>
<li><a href="#mixture-models"><span class="toc-section-number">16.7</span> Mixture Models</a></li>
<li><a href="#inference-1"><span class="toc-section-number">16.8</span> Inference</a><ul>
<li><a href="#discussion-of-bayesian-inference"><span class="toc-section-number">16.8.1</span> Discussion of Bayesian Inference</a></li>
</ul></li>
<li><a href="#model-checking-1"><span class="toc-section-number">16.9</span> Model Checking</a><ul>
<li><a href="#posterior-predictive-checks-1"><span class="toc-section-number">16.9.1</span> Posterior Predictive Checks</a></li>
<li><a href="#prediction-criteria"><span class="toc-section-number">16.9.2</span> Prediction Criteria</a></li>
<li><a href="#software-validation"><span class="toc-section-number">16.9.3</span> Software Validation</a></li>
</ul></li>
<li><a href="#hierarchical-modeling"><span class="toc-section-number">16.10</span> Hierarchical Modeling</a></li>
<li><a href="#shrinkageregularization"><span class="toc-section-number">16.11</span> Shrinkage/Regularization</a></li>
<li><a href="#empirical-bayes"><span class="toc-section-number">16.12</span> Empirical Bayes</a></li>
<li><a href="#history-of-bayesian-statistics"><span class="toc-section-number">16.13</span> History of Bayesian Statistics</a></li>
</ul></li>
<li><a href="#sampling-difficulties"><span class="toc-section-number">17</span> Sampling Difficulties</a><ul>
<li><a href="#complicated-estimation-and-testing"><span class="toc-section-number">17.1</span> Complicated Estimation and Testing</a></li>
<li><a href="#pooling-polls"><span class="toc-section-number">17.2</span> Pooling Polls</a></li>
<li><a href="#numerical-analysis"><span class="toc-section-number">17.3</span> Numerical Analysis</a></li>
<li><a href="#visualizing-mcmc-methods"><span class="toc-section-number">17.4</span> Visualizing MCMC Methods</a></li>
<li><a href="#bayesian-point-estimation-decision"><span class="toc-section-number">17.5</span> Bayesian point estimation / Decision</a></li>
</ul></li>
<li><a href="#information-theory"><span class="toc-section-number">18</span> Information Theory</a></li>
<li><a href="#stan-modeling-language"><span class="toc-section-number">19</span> Stan Modeling Language</a><ul>
<li><a href="#lists-of-distributions"><span class="toc-section-number">19.0.1</span> Lists of Distributions</a></li>
</ul></li>
<li><a href="#references-10">References</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Updating: A Set of Bayesian Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
\[
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\RMSE}{RMSE}
\DeclareMathOperator{\sd}{sd}
\DeclareMathOperator{\se}{se}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\median}{median}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\logistic}{Logistic}
\DeclareMathOperator{\logit}{Logit}

\newcommand{\mat}[1]{\boldsymbol{#1}}
\newcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\T}{'}

% This follows BDA
\newcommand{\dunif}{\mathrm{U}}
\newcommand{\dnorm}{\mathrm{N}}
\newcommand{\dlnorm}{\mathrm{lognormal}}
\newcommand{\dmvnorm}{\mathrm{N}}
\newcommand{\dgamma}{\mathrm{Gamma}}
\newcommand{\dinvgamma}{\mathrm{Inv-Gamma}}
\newcommand{\dchisq}[1]{\chi^2_{#1}}
\newcommand{\dinvchisq}[1]{\mathrm{Inv-}\chi^2_{#1}}
\newcommand{\dexp}{\mathrm{Expon}}
\newcommand{\dlaplace}{\mathrm{Laplace}}
\newcommand{\dweibull}{\mathrm{Weibull}}
\newcommand{\dwishart}[1]{\mathrm{Wishart}_{#1}}
\newcommand{\dinvwishart}[1]{\mathrm{Inv-Wishart}_{#1}}
\newcommand{\dlkj}{\mathrm{LkjCorr}}
\newcommand{\dt}[1]{t_{#1}}
\newcommand{\dbeta}{\mathrm{Beta}}
\newcommand{\ddirichlet}{\mathrm{Dirichlet}}
\newcommand{\dlogistic}{\mathrm{Logistic}}
\newcommand{\dllogistic}{\mathrm{Log-logistic}}
\newcommand{\dpois}{\mathrm{Poisson}}
\newcommand{\dbin}{\mathrm{Bin}}
\newcommand{\dmultinom}{\mathrm{Multinom}}
\newcommand{\dnbinom}{\mathrm{Neg-bin}}
\newcommand{\dnbinomalt}{\mathrm{Neg-bin2}}
\newcommand{\dbetabinom}{\mathrm{Beta-bin}}
\newcommand{\dcauchy}{\mathrm{Cauchy}}
\newcommand{\dhalfcauchy}{\mathrm{Cauchy}^{+}}
\newcommand{\dlkjcorr}{\mathrm{LKJ}^{+}}



\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\cia}{\perp\!\!\!\perp}
\DeclareMathOperator*{\plim}{plim}
\]
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="preface" class="section level1 unnumbered">
<h1>Preface</h1>
<p>Notes on Bayesian methods - written to supplement CS&amp;SS/STAT 564: Bayesian Statistics for the Social Sciences.</p>
<p>These notes largely focus on the application and theory necessary for quantitative social scientists to successfully apply Bayesian statistical methods.</p>
<p>I also don’t hesitate to link to those who have already explained things well, and focus my efforts on places where I haven’t found good explanations (or explanations I understand), or places where I need to write notes to deepen my own understanding.</p>
<p>All these chapters will use the <strong><a href="https://cran.r-project.org/package=rstan">rstan</a></strong> package</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a></code></pre></div>
<!--chapter:end:index.Rmd-->
</div>
<div id="part-theory" class="section level1 unnumbered">
<h1>(PART) Theory</h1>
<!--chapter:end:theory.Rmd-->
</div>
<div id="bayesian-inference" class="section level1">
<h1><span class="header-section-number">1</span> Bayesian Inference</h1>
<!--chapter:end:bayesian-inference.Rmd-->
</div>
<div id="part-computation" class="section level1 unnumbered">
<h1>(PART) Computation</h1>
<!--chapter:end:computation.Rmd-->
</div>
<div id="markov-chain-monte-carlo" class="section level1">
<h1><span class="header-section-number">2</span> Markov Chain Monte Carlo</h1>
<div id="monte-carlo-sampling" class="section level2">
<h2><span class="header-section-number">2.1</span> Monte Carlo Sampling</h2>
<p>Monte Carlo methods are used to numerically approximate integrals, when the integral function is not tractable but the function being integrated is.</p>
<p>In Bayesian stats, the mean of a probability density <span class="math inline">\(p(\theta)\)</span> is
<span class="math display">\[
\mu = \int_{\Theta} \theta p(\theta) \, d \theta .
\]</span>
Except for cases in which the distribution <span class="math inline">\(p(\theta)\)</span> has a known form (not the case for most applied models) for functional form of the integral isn’t known, but <span class="math inline">\(p(\theta)\)</span> is</p>
<p>The Monte Carlo estimate of <span class="math inline">\(\mu\)</span> is.</p>
<ul>
<li>Draw <span class="math inline">\(N\)</span> independent samples, <span class="math inline">\(\theta^{(1)}, \dots, \theta^{(N)}\)</span>, from <span class="math inline">\(p(\theta)\)</span></li>
<li>Estimate <span class="math inline">\(\hat{\mu}\)</span> with,
<span class="math display">\[
  \hat{\mu} = \frac{1}{N} \sum_{n = 1}^N \theta^{(N)} .
  \]</span></li>
</ul>
<p>If <span class="math inline">\(p(\theta)\)</span> has finite mean and variance, the law of large numbers ensures that the Monte Carlo estimate converges to the true value
<span class="math display">\[
\lim_{N \to \infty} \hat\mu \to \mu
\]</span>
and the estimation error is governed by the CLT,
<span class="math display">\[
| \mu - \hat{\mu} | \propto \frac{\sigma}{\sqrt{N}}
\]</span></p>
<p><strong>Example</strong> The mean of <span class="math inline">\(Y = X^2\)</span> where <span class="math inline">\(X \sim \dnorm(0, 1)\)</span>.
Draw a sample from <span class="math inline">\(Y\)</span>,</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1024</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></a></code></pre></div>
<p>The Monte Carlo estimates of the mean is</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">mean</span>(x)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="co">#&gt; [1] 0.977</span></a></code></pre></div>
<p>with standard error,</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">sd</span>(x) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">length</span>(x))</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="co">#&gt; [1] 0.042</span></a></code></pre></div>
</div>
<div id="markov-chain-monte-carlo-sampling" class="section level2">
<h2><span class="header-section-number">2.2</span> Markov Chain Monte Carlo Sampling</h2>
<p><strong>Problem:</strong> Monte Carlo sampling requires the samples to be <strong>independent</strong>. But what if you cannot draw independent samples?</p>
<p><strong>Solution:</strong> Markov Chain Monte Carlo are a class of algorithms to sample from a distribution when independent samples cannot be drawn.
However, the samples in MCMC will be <strong>dependent</strong>.</p>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">2.3</span> References</h2>
<ul>
<li><span class="citation">Stan Development Team (2016 Ch. 28)</span></li>
</ul>
<!--chapter:end:montecarlo.Rmd-->
</div>
</div>
<div id="mcmc-diagnostics" class="section level1">
<h1><span class="header-section-number">3</span> MCMC Diagnostics</h1>
<p>There are two parts of checking a Bayesian model:</p>
<ol style="list-style-type: decimal">
<li>diagnostics: Is the sampler working? Is it adequately approximating the specified posterior distribution: <span class="math inline">\(p(\theta | D)\)</span>.</li>
<li>model fit: Does the model adequately represent the data?</li>
</ol>
<p>This chapter covers the former.</p>
<p>Also see the <strong><a href="https://cran.r-project.org/package=bayesplot">bayesplot</a></strong> vignette <a href="https://cran.r-project.org/web/packages/bayesplot/vignettes/MCMC-diagnostics.html">Visual MCMC diagnostics using the bayesplot package</a>, which though specific to the provides, provides a good overview of these diagnostics.</p>
<div id="reparameterize-models" class="section level2">
<h2><span class="header-section-number">3.1</span> Reparameterize Models</h2>
<ol style="list-style-type: decimal">
<li>Reduce correlation between parameters (e.g. see <code>mcmc_pairs</code>)</li>
<li>Put parameters on the same scale. The samplers work best when all parameters are roughly on the same scale, e.g. <span class="math inline">\(\approx 1\)</span>. Try to avoid situations where parameters are orders of magnitude different, e.g. 1e-5 and 1e+10.</li>
<li>Increase the informativeness of priors. If parameters are too uninformative, the posterior distribution may have wide tails that hamper sampling. One way of thinking about it is that the model is only “weakly identified” and requires either more data or more informative priors to estimate.</li>
</ol>
</div>
<div id="convergence-diagnostics" class="section level2">
<h2><span class="header-section-number">3.2</span> Convergence Diagnostics</h2>
<p>Under certain conditions, MCMC algorithms will draw a sample from the target posterior distribution after it has converged to equilibrium.
However, since in practice, any sample is finite, there is no guarantee about whether its converged, or is close enough to the posterior distribution.</p>
<p>In general there is no way to prove that the sampler has converged.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
However, there are several statistics that indicate that a sampler has not converged.</p>
<div id="potential-scale-reduction-hatr" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Potential Scale Reduction (<span class="math inline">\(\hat{R}\)</span>)</h3>
<p>In equilibrium, the distribution of samples from chains should be the same regardless of the initial starting
values of the chains <span class="citation">(Stan Development Team 2016, Sec 28.2)</span>.</p>
<p>One way to check this is to compare the distributions of multiple chains—in equilibrium they should all have the same mean.
Additionally, the split <span class="math inline">\(\hat{R}\)</span> tests for convergence by splitting the chain in half, and testing the hypothesis that the means are the same in each half. This tests for non-stationarity within a chain.</p>
<p>See <span class="citation">Stan Development Team (2016 Sec 28.2)</span> for the equations to calculate these.</p>
<p><strong>TODO:</strong> Examples of passing and non-passing <span class="math inline">\(\hat{R}\)</span> chains using fake data generated from known functions with a given autocorrelation.</p>
<p><strong>Rule of Thumb:</strong> The rule of thumb is that R-hat values for all less than 1.1 <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html">source</a>.
Note that <strong>all</strong> parameters must show convergence.
This is a necessary but not sufficient condition for convergence.</p>
</div>
<div id="references-1" class="section level3">
<h3><span class="header-section-number">3.2.2</span> References</h3>
<ul>
<li><span class="citation">Gelman et al. (2013, 267)</span></li>
<li><span class="citation">Stan Development Team (2016 Ch 28.)</span> for how Stan calculates Hat, autocorrelations, and ESS.</li>
<li><span class="citation">Gelman and Rubin (1992)</span> introduce the R-hat statistic</li>
</ul>
</div>
</div>
<div id="autocorrelation-effective-sample-size-and-mcse" class="section level2">
<h2><span class="header-section-number">3.3</span> Autocorrelation, Effective Sample Size, and MCSE</h2>
<p>MCMC samples are dependent. This does not effect the validity of inference on the posterior if the samplers has time to explore the posterior distribution, but it does affect the efficiency of the sampler.</p>
<p>In other words, highly correlated MCMC samplers requires more samples to produce the same level of Monte Carlo error for an estimate.</p>
<div id="effective-sample-size" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Effective Sample Size</h3>
<p>The effective sample size (ESS) measures the amount by which autocorrelation in samples increases uncertainty (standard errors) relative to an independent sample.
Suppose that the <span class="math inline">\(\rho^2_t\)</span> is the ACF function of a sample of size <span class="math inline">\(N\)</span>, the effective sample size, <span class="math inline">\(N_eff\)</span>, is
<span class="math display">\[
N_{eff} = \frac{N}{\sum_{t = -\infty}^\infty \rho_t} = \frac{N}{1 + 2 \sum_{t = -\infty}^\infty \rho_t}.
\]</span>
<strong>TODO</strong> show that if <span class="math inline">\(\rho_t = 1\)</span> for all <span class="math inline">\(t\)</span> then <span class="math inline">\(N_eff = 1\)</span>, and if <span class="math inline">\(\rho_t = 0\)</span> for all <span class="math inline">\(t\)</span> then <span class="math inline">\(N_eff = N\)</span></p>
<p>Computing the effective sample size requires calculating an autocorrelation.
A multi-chain estimate of the autocorrelation is found by computing the <em>variogram</em> with the correlations for all lags,
<span class="math display">\[
V_t = \frac{1}{m(n - t)} \sum_{j = 1}^m \sum_{i = t + 1}^n (\psi_{i,j} - \psi_{i - t,j})^2
\]</span>
The estimate of the autocorrelations <span class="math inline">\(\hat{\rho}_t\)</span> is
<span class="math display">\[
\hat{\rho}_t = 1 - \frac{V_t}{2 \widehat{\mathrm{var}}^+}
\]</span>
The estimates of the autocorrelations can be noisy, so <span class="math inline">\(\hat{\rho}_t\)</span> are summed from 0, to the last <span class="math inline">\(t\)</span> such that <span class="math inline">\(\rho\)</span> is positive (<span class="math inline">\(T\)</span>),
<span class="math display">\[
\hat{n}_{eff} = \frac{mn}{1 + 2 \sum_{t = 1}^T \hat{\rho}_t}
\]</span></p>
<ul>
<li>See also <span class="citation">Stan Development Team (2016 Sec 28.4)</span>, <span class="citation">Geyer (2011)</span>, and <span class="citation">Gelman et al. (2013 Sec 11.5)</span>.</li>
<li>This isn’t the only way to calculate the effective sample size. The <strong><a href="https://cran.r-project.org/package=coda">coda</a></strong> package function <a href="https://www.rdocumentation.org/packages/coda/topics/effectiveSize">coda</a> uses a different method. The differences are due to how the autocorrelation is calculated.</li>
</ul>
<p><strong>Example:</strong> Comparison of the effective sample sizes for data generated with various levels of autocorrelation.
The package <code>rstan</code> does not directly expose the function it uses to calculate ESS, so this <code>ess</code> function does so (for a single chain).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">ess &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">  N &lt;-<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">  V &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(<span class="kw">seq_len</span>(N <span class="op">-</span><span class="st"> </span><span class="dv">1</span>),</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">          <span class="cf">function</span>(t) {</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">             <span class="kw">mean</span>(<span class="kw">diff</span>(x, <span class="dt">lag =</span> t) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">          })</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">  rho &lt;-<span class="st"> </span><span class="kw">head_while</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>V <span class="op">/</span><span class="st"> </span><span class="kw">var</span>(x), <span class="st">`</span><span class="dt">&gt;</span><span class="st">`</span>, <span class="dt">y =</span> <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8">  N <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(rho))</a>
<a class="sourceLine" id="cb5-9" data-line-number="9">}</a>
<a class="sourceLine" id="cb5-10" data-line-number="10">n &lt;-<span class="st"> </span><span class="dv">1024</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11">sims &lt;-<span class="st"> </span><span class="kw">map_df</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="fl">0.99</span>),</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">  <span class="cf">function</span>(ar) {</a>
<a class="sourceLine" id="cb5-13" data-line-number="13">    <span class="kw">tibble</span>(<span class="dt">ar =</span> ar,</a>
<a class="sourceLine" id="cb5-14" data-line-number="14">           <span class="dt">y =</span> <span class="cf">if</span> (ar <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="kw">rnorm</span>(n) <span class="cf">else</span> <span class="kw">arima.sim</span>(<span class="kw">list</span>(<span class="dt">ar =</span> ar), n),</a>
<a class="sourceLine" id="cb5-15" data-line-number="15">           <span class="dt">x =</span> <span class="kw">seq_along</span>(y),</a>
<a class="sourceLine" id="cb5-16" data-line-number="16">           <span class="dt">n_eff =</span> <span class="kw">ess</span>(y), </a>
<a class="sourceLine" id="cb5-17" data-line-number="17">           <span class="dt">label =</span> <span class="kw">sprintf</span>(<span class="st">&quot;AR = %.2f (n_eff = %.0f)&quot;</span>, ar, n_eff))</a>
<a class="sourceLine" id="cb5-18" data-line-number="18">  }</a>
<a class="sourceLine" id="cb5-19" data-line-number="19">)</a></code></pre></div>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">ggplot</span>(sims, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>label, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<p><img src="diagnostics_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="thinning" class="section level2">
<h2><span class="header-section-number">3.4</span> Thinning</h2>
<p>Since the autocorrelation tends to decrease as the lag increases, thinning samples will reduce the final autocorrelation in the sample while also reducing the total number of samples saved.
Due to the autocorrelation, the reduction in the number of effective samples will often be less than number of samples removed in thinning.</p>
<p>Both of these will produce 1,000 samples from the posterior, but effective sample size of <span class="math inline">\(B\)</span> will be greater than the effective sample size of <span class="math inline">\(A\)</span>, since after thinning g the autocorrelation in <span class="math inline">\(B\)</span> will be lower.</p>
<ul>
<li><em>A</em> Generating 1,000 samples after convergence and save all of them</li>
<li><em>B</em> Generating 10,000 samples after convergence and save every 10th sample</li>
</ul>
<p>In this case, A produces 10,000 samples, and B produces 1,000.
The effective sample size of A will be higher than B.
However, due to autocorrelation, the proportional reduction in the effective sample size in B will be less than the thinning: <span class="math inline">\(N_{eff}(A) / N_{eff}(B) &lt; 10\)</span>.</p>
<ul>
<li><em>A</em> Generating 10,000 samples after convergence and save all of them</li>
<li><em>B</em> Generating 10,000 samples after convergence and save every 10th sample</li>
</ul>
<p>Thinning trades off sample size for memory, and due to autocorrelation in samples, loss in effective sample size is less than the loss in sample size.</p>
<p>Thinning has become less of an issue as memory has become less of a computational constraint, and samplers have become more efficient.</p>
<p>The following example simulates random values from an autocorrelated series,
and applies different levels of thinning.
Thinning is always decreasing the effective sample size.
However, the number of effective samples per sample (<code>n_eff / n</code>) increases
until the thinning is large enough that the thinned samples are uncorrelated.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">thin_ess &lt;-<span class="st"> </span><span class="cf">function</span>(thin, x) {</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">  <span class="cf">if</span> (thin <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">    <span class="co"># keep only thinned rows</span></a>
<a class="sourceLine" id="cb7-4" data-line-number="4">    x_thinned &lt;-<span class="st"> </span>x[(<span class="kw">seq_len</span>(<span class="kw">length</span>(x)) <span class="op">%%</span><span class="st"> </span>thin) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>]</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">  } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb7-6" data-line-number="6">    x_thinned &lt;-<span class="st"> </span>x</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">  }</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">  <span class="kw">tibble</span>(<span class="dt">thin =</span> thin,</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">         <span class="dt">n =</span> <span class="kw">length</span>(x_thinned),</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">         <span class="dt">n_eff =</span> <span class="kw">ess</span>(x_thinned),</a>
<a class="sourceLine" id="cb7-11" data-line-number="11">         <span class="st">`</span><span class="dt">n_eff / n</span><span class="st">`</span> =<span class="st"> </span>n_eff <span class="op">/</span><span class="st"> </span>n)</a>
<a class="sourceLine" id="cb7-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb7-13" data-line-number="13"></a>
<a class="sourceLine" id="cb7-14" data-line-number="14"><span class="kw">map_df</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>, <span class="dv">32</span>), thin_ess,</a>
<a class="sourceLine" id="cb7-15" data-line-number="15">       <span class="dt">x =</span> <span class="kw">arima.sim</span>(<span class="kw">list</span>(<span class="dt">ar =</span> <span class="fl">.9</span>), <span class="dv">4096</span>))</a>
<a class="sourceLine" id="cb7-16" data-line-number="16"><span class="co">#&gt; # A tibble: 6 × 4</span></a>
<a class="sourceLine" id="cb7-17" data-line-number="17"><span class="co">#&gt;    thin     n n_eff `n_eff / n`</span></a>
<a class="sourceLine" id="cb7-18" data-line-number="18"><span class="co">#&gt;   &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;       &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb7-19" data-line-number="19"><span class="co">#&gt; 1     1  4096  1266       0.309</span></a>
<a class="sourceLine" id="cb7-20" data-line-number="20"><span class="co">#&gt; 2     2  2048  1087       0.531</span></a>
<a class="sourceLine" id="cb7-21" data-line-number="21"><span class="co">#&gt; 3     4  1024   791       0.773</span></a>
<a class="sourceLine" id="cb7-22" data-line-number="22"><span class="co">#&gt; 4     8   512   512       1.000</span></a>
<a class="sourceLine" id="cb7-23" data-line-number="23"><span class="co">#&gt; 5    16   256   256       1.000</span></a>
<a class="sourceLine" id="cb7-24" data-line-number="24"><span class="co">#&gt; 6    32   128   128       1.000</span></a></code></pre></div>
<ul>
<li><span class="citation">Gelman et al. (2013, 282–83)</span></li>
<li><span class="citation">Stan Development Team (2016, 354–55)</span></li>
</ul>
<div id="traceplots" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Traceplots</h3>
<p>Trace plots are a time series of sampler iterations, e.g. as produced by <a href="https://www.rdocumentation.org/packages/bayesplot/topics/mcmc_trace">bayesplot</a>.</p>
<p>These can, but <strong>should not</strong>, be used to assess convergence,</p>
<ul>
<li>such visual inspection is ‘notoriously unreliable’ <span class="citation">(Gelman et al. 2013, 285)</span></li>
<li>it cannot scale to many parameters</li>
</ul>
<p>Trace plots may be useful for diagnosing convergence problems <em>after</em> <span class="math inline">\(\hat{R}\)</span> or or <span class="math inline">\(n_eff\)</span> indicates problems. Some possible issues to check in these plots are</p>
<ul>
<li>multimodality (the traceplot jumps between different distributions)</li>
<li>wide posterior tails (the traceplot shows regions where the sampler will reach and have difficulty returning to the main distribution)</li>
</ul>
</div>
<div id="monte-carlo-standard-error-mcse" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Monte Carlo Standard Error (MCSE)</h3>
<p>The Monte Carlo standard error is the uncertainty about a statistic in the sample due to sampling error.
With a independent sample of size <span class="math inline">\(N\)</span>, the MCSE for the sample mean is
<span class="math display">\[
MCSE(\bar{\theta}) = \frac{s}{\sqrt{N}}
\]</span>
where <span class="math inline">\(s\)</span> is the sample standard deviation.</p>
<p>However, MCMC are generally not independent, and the MCSE will be higher than that
of an independent sample. One way to calculate the MCSE with autocorrelated samples is to use the effective sample size instead of the sample size,
<span class="math display">\[
MCSE(\bar{\theta}) = \frac{s}{\sqrt{N_{eff}}}
\]</span></p>
<p>An MCSE estimator for the mean is
<span class="math display">\[
\mathrm{MCSE}(\hat{\theta}) = \frac{\sd(\theta)}{\sqrt{n_{neff}}}
\]</span>
An MCSE estimator for any posterior probability, where <span class="math inline">\(\hat{p} = \Pr(f(\theta))\)</span>, follows from the standard error of a proportion, but using the effective sample size,
<span class="math display">\[
MCSE(\hat{p}) = \sqrt{\hat{p} (1 - \hat{p}) / n_{eff}}
\]</span></p>
<p>See <span class="citation">Flegal, Haran, and Jones (2008)</span> and the <strong><a href="https://cran.r-project.org/package=mcmcse">mcmcse</a></strong> for methods to calculate MCMC standard errors for means and quantiles using sub-sampling methods.</p>
<p><span class="citation">Flegal, Haran, and Jones (2008)</span> argues for using ESS as a stopping rule and convergence diagnostic for Bayesian inference.</p>
<p>The estimation of standard errors for quantiles, as would be used in is more complicated. See the package <strong><a href="https://cran.r-project.org/package=mcmcse">mcmcse</a></strong> for Monte Carlo standard errors of quantiles (though calculated in a different method than <strong>rstan</strong>).</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Sec. 10.5)</span></li>
<li><span class="citation">Flegal, Haran, and Jones (2008)</span></li>
<li><a href="http://www.stat.umn.edu/geyer/mcmc/talk/mcmc.pdf">Talk by Geyer on MCSE</a></li>
</ul>
</div>
</div>
<div id="hmc-nut-specific-diagnostics" class="section level2">
<h2><span class="header-section-number">3.5</span> HMC-NUT Specific Diagnostics</h2>
<p>Hamiltonian Monte Carlo (HMC), and the No-U-Turn Sampler (HMC-NUTS) in particular, produce several diagnostics that indicate that the sampler is breaking and, thus, not sampling from the posterior distribution.
This is unusual, as most Bayesian sampling methods do not give indication of whether they are working well, and all that can be checked are the properties of the samples themselves with methods such <span class="math inline">\(\hat{R}\)</span>.</p>
<p>Three specific HMC-NUTS diagnostics are</p>
<ol style="list-style-type: decimal">
<li>divergent transitions</li>
<li>maximum treedepth</li>
<li>Bayesian fraction of missing information</li>
</ol>
<p>The general way to fix these issues is the manually adjust the HMC-NUTS sampler parameters.n</p>
<ol style="list-style-type: decimal">
<li>Stepsize: Length of the steps to take</li>
<li>Treedepth: Number of steps to take</li>
</ol>
<p>During the warmup period, Stan tunes these values, however these auto-tuned parameters may not always be optimal.
The other alternative is to reparameterize the models.</p>
<div id="divergent-transitions" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Divergent transitions</h3>
<p><strong>The problem:</strong> The details of the HMC are technical and can be found <strong>TODO</strong>. The gist of the problem is that Stan is using a discrete approximation of a continuous function when integrating.
If the step sizes are too large, the discrete approximation does not work.
Helpfully, when the approximation is poor it does not fail without any indication but will produce “divergent transitions”.</p>
<p><em>If there are too many divergent transitions, then the sampler is not drawing samples from the entire posterior and inferences will be biased</em></p>
<p><strong>The solution:</strong> Reduce the step size. This can be done by increasing the the <code>adapt_delta</code> parameter.
This is the target average proposal acceptance probability in the adaptation, which is used to determine the step size during warmup.
A higher desired acceptance probability (closer to 1) reduces the the step size. A smaller step size means that it will require more steps to explore the posterior distribution.</p>
<p>See <span class="citation">Stan Development Team (2016, 380)</span></p>
</div>
<div id="maximum-treedepth" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Maximum Treedepth</h3>
<p><strong>The problem:</strong> NUTS is an intelligent method to select the number of steps to take in each iteration. However, there is still a maximum number of steps that NUTS will try.
If the sampler is often hitting the maximum number of steps, it means that the optimal number of steps to take in each iteration is higher than the maximum.
While divergent transitions bias inference, a too-small maximum treedepth only affects efficiency.
The sampler is still exploring the posterior distribution, but the exploration will be slower and the autocorrelation higher (effective sample size lower) than if the maximum treedepth were set higher.</p>
<p><strong>The solution:</strong> Increase the maximum treedepth.</p>
</div>
<div id="bayesian-fraction-of-missing-information" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Bayesian Fraction of Missing Information</h3>
<p>This is rather technical. See <span class="citation">Betancourt (2016)</span>.</p>
<!--chapter:end:diagnostics.Rmd-->
</div>
</div>
</div>
<div id="posterior-inference" class="section level1">
<h1><span class="header-section-number">4</span> Posterior Inference</h1>
<div id="prerequisites" class="section level2">
<h2><span class="header-section-number">4.1</span> Prerequisites</h2>
<p>The <strong><a href="https://cran.r-project.org/package=haven">haven</a></strong> package is used to read Stata <code>.dta</code> files.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rubbish&quot;</span>)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;haven&quot;</span>)</a></code></pre></div>
</div>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">4.2</span> Introduction</h2>
<p>The posterior distribution is the probability distribution <span class="math inline">\(\Pr(\theta | y)\)</span>.</p>
<p>One we have the posterior distribution, or more often a sample from the posterior distribution, it is relatively easy to perform inference on any function of the posterior.</p>
<p>Common statistics used to summarize the posterior distribution:</p>
<ul>
<li>mean: <span class="math inline">\(\E(p(\theta | y)) \approx \frac{1}{S} \sum_{i = 1}^S \theta^{(s)}\)</span></li>
<li>median: <span class="math inline">\(\median(p(\theta | y)) \approx \median \theta^{(s)}\)</span></li>
<li>quantiles: 2.5%, 5%, 25%, 50%, 75%, 95%, 97.5%</li>
<li><p>credible interval:</p>
<ul>
<li>central credible interval: the interval between the p/2% and 1 - p/2% quantiles</li>
<li>highest posterior density interval: the narrowest interval containing p% of distribution</li>
</ul></li>
<li><p>marginal densities</p></li>
</ul>
</div>
<div id="functions-of-the-posterior-distribution" class="section level2">
<h2><span class="header-section-number">4.3</span> Functions of the Posterior Distribution</h2>
<p>It is also easy to conduct inference on functions of the posterior distribution.</p>
<p>Suppose <span class="math inline">\(\theta^{(1)}, \dots, \theta^{(S)}\)</span> are a sample from <span class="math inline">\(p(\theta | y)\)</span>, the
<span class="math inline">\(f(\theta^{(1)}), \dots, f(\theta^{(S)})\)</span> are a sample from <span class="math inline">\(p(f(\theta) | y)\)</span>.</p>
<p>This is not easy for methods like MLE that produce point estimates:</p>
<ul>
<li>Even in OLS, non-linear functions coefficients generally require either the Delta method or bootstrapping to calculate confidence intervals.</li>
<li><span class="citation">Berry, Golder, and Milton (2012)</span>, <span class="citation">Golder (n.d.)</span>,<span class="citation">Brambor, Clark, and Golder (2006)</span> discuss calculating confidence intervals</li>
<li>See <span class="citation">Rainey (2016b)</span> on “transformation induced bias”</li>
<li>See <span class="citation">Carpenter (2016)</span> on how reparameterization affects point estimates; this is a Stan Case study with working code</li>
</ul>
</div>
<div id="marginal-effects" class="section level2">
<h2><span class="header-section-number">4.4</span> Marginal Effects</h2>
<div id="example-marginal-effect-plot-for-x" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Example: Marginal Effect Plot for X</h3>
<p><span class="citation">Berry, Golder, and Milton (2012)</span> replicates <span class="citation">Alexseev (2006)</span> as an example of a model with an interaction between <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.
<span class="math display">\[
Y = \beta_0 + \beta_x X + \beta_z Z + \beta_{xz} X Z + \epsilon
\]</span>
In this case, the hypothesis of interest involves the marginal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>,
<span class="math display">\[
\frac{\partial \E(Y|.)}{\partial X} = \beta_z + \beta_{xz} Z
\]</span>
Since there is an interaction, the marginal effect of <span class="math inline">\(X\)</span> is not simply
the coefficient <span class="math inline">\(\beta_z\)</span>, but is a function of another predictor, <span class="math inline">\(Z\)</span>.
Point estimates of the marginal effects with interactions are relatively easy to construct, but confidence intervals for the MLE estimates quickly involve multiple terms and either the Delta method approximation or bootstrapping to calculate.</p>
<p>We will consider this problem from a Bayesian estimation perspective, and calculate point estimates (posterior mean) and credible intervals of the marginal effects.</p>
<p>The particular example is <span class="citation">Alexseev (2006)</span>, which analyzes how changes in the ethnic composition of Russian regions affected the vote share of the extreme Russian nationalist Zhirinovsky Bloc in 2003 Russian State Duma elections.[^alexseev1]</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">alexseev &lt;-<span class="st"> </span><span class="kw">read_dta</span>(<span class="st">&quot;data/alexseev.dta&quot;</span>)</a></code></pre></div>
<p>[alexseev1]: Some of the replication code and material can be found on <a href="http://mattgolder.com/interactions">Matt Golder’s website</a>.</p>
<p>One claim of <span class="citation">Alexseev (2006)</span> was that support for anti-immigrant parties depends on the percentage of the population of the dominant ethnic group (Slavic) and the change in the percentage the non-dominant share.
To test that hypothesis, <span class="citation">Alexseev (2006)</span> estimates the following model,
<span class="math display">\[
\begin{multline}
\mathtt{xenovote}_i = \beta_0 + \beta_s \mathtt{slavicshare}_i + 
\beta_{n} \mathtt{changenonslav} + \\
\beta_{sn} (\mathtt{slavicshare}_i \times \mathtt{changenonslav}_i) + 
\gamma z_{i} + \epsilon_{i},
\end{multline}
\]</span>
where <span class="math inline">\(z_i\)</span> is a vector of control variables.</p>
<ul>
<li><code>xenovote</code>: Xenophobic voting. Share of vote for the Zhironovsky Bloc.</li>
<li><code>slavicshare</code>: <em>Slavic Share.</em> Proportion Slavic in the district.</li>
<li><code>changenonslav</code>: <span class="math inline">\(\Delta\)</span> <em>non-Slavic Share</em> Change in the proprotion of non-Slavic groups in the region.</li>
</ul>
<p>The model was estimated by OLS,<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">mod_f &lt;-<span class="st"> </span>(xenovote <span class="op">~</span><span class="st"> </span>slavicshare <span class="op">*</span><span class="st"> </span>changenonslav <span class="op">+</span><span class="st"> </span>inc9903 <span class="op">+</span><span class="st"> </span>eduhi02 <span class="op">+</span><span class="st"> </span>unemp02 <span class="op">+</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">            </span>apt9200 <span class="op">+</span><span class="st"> </span>vsall03 <span class="op">+</span><span class="st"> </span>brdcont)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="kw">lm</span>(mod_f, <span class="dt">data =</span> alexseev)</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-5" data-line-number="5"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co">#&gt; lm(formula = mod_f, data = alexseev)</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb10-9" data-line-number="9"><span class="co">#&gt;               (Intercept)                slavicshare  </span></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co">#&gt;                  8.942878                   0.031486  </span></a>
<a class="sourceLine" id="cb10-11" data-line-number="11"><span class="co">#&gt;             changenonslav                    inc9903  </span></a>
<a class="sourceLine" id="cb10-12" data-line-number="12"><span class="co">#&gt;                 -0.851108                   0.000234  </span></a>
<a class="sourceLine" id="cb10-13" data-line-number="13"><span class="co">#&gt;                   eduhi02                    unemp02  </span></a>
<a class="sourceLine" id="cb10-14" data-line-number="14"><span class="co">#&gt;                 -0.039512                   1.432013  </span></a>
<a class="sourceLine" id="cb10-15" data-line-number="15"><span class="co">#&gt;                   apt9200                    vsall03  </span></a>
<a class="sourceLine" id="cb10-16" data-line-number="16"><span class="co">#&gt;                  0.030125                   0.661163  </span></a>
<a class="sourceLine" id="cb10-17" data-line-number="17"><span class="co">#&gt;                   brdcont  slavicshare:changenonslav  </span></a>
<a class="sourceLine" id="cb10-18" data-line-number="18"><span class="co">#&gt;                  2.103688                   0.008226</span></a></code></pre></div>
<p>Use the <code>lm_preprocess</code> function in the <a href="https://jrnold.github.com/rubbish">rubbish</a> package to turn the model formula into a list with relevant data.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">mod_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(mod_f, <span class="dt">data =</span> alexseev)[<span class="kw">c</span>(<span class="st">&quot;X&quot;</span>, <span class="st">&quot;y&quot;</span>)]</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"></a>
<a class="sourceLine" id="cb11-3" data-line-number="3">mod_data &lt;-<span class="st"> </span><span class="kw">within</span>(mod_data, {</a>
<a class="sourceLine" id="cb11-4" data-line-number="4">  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(X)</a>
<a class="sourceLine" id="cb11-5" data-line-number="5">  k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)</a>
<a class="sourceLine" id="cb11-6" data-line-number="6">  M &lt;-<span class="st"> </span><span class="dv">100</span></a>
<a class="sourceLine" id="cb11-7" data-line-number="7">  changenonslav &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(X[ , <span class="st">&quot;changenonslav&quot;</span>]),                               <span class="kw">max</span>(X[ , <span class="st">&quot;changenonslav&quot;</span>]),</a>
<a class="sourceLine" id="cb11-8" data-line-number="8">                       <span class="dt">length.out =</span> M)</a>
<a class="sourceLine" id="cb11-9" data-line-number="9">  idx_b_slavicshare &lt;-<span class="st"> </span><span class="kw">which</span>(<span class="kw">colnames</span>(X) <span class="op">==</span><span class="st"> &quot;slavicshare&quot;</span>)</a>
<a class="sourceLine" id="cb11-10" data-line-number="10">  idx_b_slavicshare_changenonslav &lt;-</a>
<a class="sourceLine" id="cb11-11" data-line-number="11"><span class="st">    </span><span class="kw">which</span>(<span class="kw">colnames</span>(X) <span class="op">==</span><span class="st"> &quot;slavicshare:changenonslav&quot;</span>)</a>
<a class="sourceLine" id="cb11-12" data-line-number="12">  b_loc &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb11-13" data-line-number="13">  <span class="co"># data appropriate prior</span></a>
<a class="sourceLine" id="cb11-14" data-line-number="14">  b_scale &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">apply</span>(X, <span class="dv">2</span>, sd)) <span class="op">*</span><span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb11-15" data-line-number="15">  sigma_scale &lt;-<span class="st"> </span><span class="kw">sd</span>(y)</a>
<a class="sourceLine" id="cb11-16" data-line-number="16">})</a></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">mod</a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // marfx
  // indexes of main and interaction coef
  int idx_b_slavicshare;
  int idx_b_slavicshare_changenonslav;
  int M;
  vector[M] changenonslav;
  // beta prior
  real b_loc;
  real<lower = 0.0> b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real<lower = 0.0> sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[n] mu;
  mu = X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  // likelihood
  y ~ normal(mu, sigma);
}
generated quantities {
  # hardcoded marginal effectx
  vector[M] dydx;
  dydx = b[idx_b_slavicshare] + b[idx_b_slavicshare_changenonslav] * changenonslav;

}</code>
</pre>
<p>The function <a href="https://www.rdocumentation.org/packages/rstan/topics/extract">rstan</a> extracts parameters from
the <a href="https://www.rdocumentation.org/packages/rstan/topics/stanfit">rstan</a> object as a list with an element for each parameter.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">dydx_all &lt;-</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="st">  </span>rstan<span class="op">::</span><span class="kw">extract</span>(mod_fit, <span class="dt">pars =</span> <span class="st">&quot;dydx&quot;</span>)<span class="op">$</span>dydx</a></code></pre></div>
<p>To make it easier to use with <code>ggplot</code>, convert it to a data frame with columns <code>.id</code> (number), <code>changeonslav</code> (original value of <code>changeonslav</code> passed to the sampler), and <code>value</code> (the value of the marginal effect).</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">dydx_all &lt;-</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="st">  </span>dydx_all <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="st">  </span><span class="kw">as.tibble</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">.iter =</span> <span class="kw">row_number</span>()) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-5" data-line-number="5"><span class="st">  </span><span class="kw">gather</span>(.id, value, <span class="op">-</span>.iter) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="st">  </span><span class="co"># merge with original values of changenonslav</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7"><span class="st">  </span><span class="kw">left_join</span>(<span class="kw">tibble</span>(<span class="dt">.id =</span> <span class="kw">paste0</span>(<span class="st">&quot;V&quot;</span>, <span class="kw">seq_along</span>(mod_data<span class="op">$</span>changenonslav)),</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">            <span class="dt">changenonslav =</span> mod_data<span class="op">$</span>changenonslav),</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">            <span class="dt">by =</span> <span class="st">&quot;.id&quot;</span>)</a></code></pre></div>
<p>Since values for a marginal effect line is generated for each iteration, the posterior distribution of <span class="math inline">\(\partial E(\mathtt{xenovote}|.) / \partial slavicshare\)</span> can be plotted as lines.
Since the number of lines would be too many to display effectively, plot 256 of them:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">dydx_all <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(.iter <span class="op">%in%</span><span class="st"> </span><span class="kw">sample</span>(<span class="kw">unique</span>(.iter), <span class="dv">2</span> <span class="op">^</span><span class="st"> </span><span class="dv">8</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> changenonslav, <span class="dt">y =</span> value, <span class="dt">group =</span> .iter)) <span class="op">+</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Marginal effect of slavic share&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">paste</span>(<span class="kw">expression</span>(Delta, <span class="st">&quot;non-Slavic Share&quot;</span>)))</a></code></pre></div>
<p><img src="posterior-inference_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Alternatively, we can summarize the posterior distribution of the marginal effects with a line (posterior mean) and credible interval regions (50%, 90%):</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">dydx_summary &lt;-</a>
<a class="sourceLine" id="cb16-2" data-line-number="2"><span class="st">  </span>dydx_all <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb16-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(changenonslav) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb16-4" data-line-number="4"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(value),</a>
<a class="sourceLine" id="cb16-5" data-line-number="5">            <span class="dt">q5 =</span> <span class="kw">quantile</span>(value, <span class="fl">0.05</span>),</a>
<a class="sourceLine" id="cb16-6" data-line-number="6">            <span class="dt">q25 =</span> <span class="kw">quantile</span>(value, <span class="fl">0.25</span>),</a>
<a class="sourceLine" id="cb16-7" data-line-number="7">            <span class="dt">q75 =</span> <span class="kw">quantile</span>(value, <span class="fl">0.75</span>),            </a>
<a class="sourceLine" id="cb16-8" data-line-number="8">            <span class="dt">q95 =</span> <span class="kw">quantile</span>(value, <span class="fl">0.95</span>))</a>
<a class="sourceLine" id="cb16-9" data-line-number="9"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb16-10" data-line-number="10"><span class="st">  </span>modelr<span class="op">::</span><span class="kw">geom_ref_line</span>(<span class="dt">h =</span> <span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb16-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> dydx_summary,</a>
<a class="sourceLine" id="cb16-12" data-line-number="12">              <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> changenonslav, <span class="dt">ymin =</span> q5, <span class="dt">ymax =</span> q95),</a>
<a class="sourceLine" id="cb16-13" data-line-number="13">              <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span><span class="st">  </span></a>
<a class="sourceLine" id="cb16-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> dydx_summary,</a>
<a class="sourceLine" id="cb16-15" data-line-number="15">              <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> changenonslav, <span class="dt">ymin =</span> q25, <span class="dt">ymax =</span> q75), </a>
<a class="sourceLine" id="cb16-16" data-line-number="16">              <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb16-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> dydx_summary,</a>
<a class="sourceLine" id="cb16-18" data-line-number="18">            <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> changenonslav, <span class="dt">y =</span> mean),</a>
<a class="sourceLine" id="cb16-19" data-line-number="19">            <span class="dt">colour =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb16-20" data-line-number="20"><span class="st">  </span><span class="kw">geom_rug</span>(<span class="dt">data =</span> alexseev, <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> changenonslav), <span class="dt">sides =</span> <span class="st">&quot;b&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb16-21" data-line-number="21"><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Marginal effect of slavic share&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb16-22" data-line-number="22"><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(Delta, <span class="st">&quot;non-Slavic Share&quot;</span>)))</a></code></pre></div>
<p><img src="posterior-inference_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" />
The plot above also includes a rug with the observed values of <code>changenonslav</code> in the sample.</p>
<ul>
<li><strong>Q:</strong> For each value of <code>changenonslav</code>, what is the probability that the marginal effect of <code>slavicshare</code> is greater than 0?</li>
<li><strong>Q:</strong> Reestimate the model, but calculate the marginal effect of <code>slavicshare</code> for all observed values of <code>changenonslav</code> in the sample. For each observation, calculate the probability that the marginal effect is greater than 0. What proporation of observations is the probability that the marginal effect is greater than zero.</li>
<li><strong>Q:</strong> Suppose you want to calculate the expected probability that the marginal effect of <code>slavicshare</code> is greater than zero in the sample. Let <span class="math inline">\(\theta^{S}_i\)</span> be the parameter for the marginal effect of <code>slavicshare</code> on the <code>xenovote</code>. Consider these two calculations:
<span class="math display">\[
  \frac{1}{N} \sum_{i = 1}^n \left( \frac{1}{S} \sum_{s = 1}^S I(\theta^{(s)}_i &gt; 0) \right)
  \]</span>
and
<span class="math display">\[
  \frac{1}{S} \sum_{s = 1}^S \left( \frac{1}{N} \sum_{i = 1}^N I(\theta^{(s)}_i &gt; 0) \right) .
  \]</span>
Are they the same? What are their substantive interpretations?</li>
<li><strong>Q:</strong> Construct the same plot but for Figure 5(b) in <span class="citation">Berry, Golder, and Milton (2012)</span>, which displays the marginaleffects of <span class="math inline">\(\Delta\)</span> <em>non-Slavic</em> on <em>Xenophobic</em> voting.</li>
</ul>
<!--chapter:end:posterior-inference.Rmd-->
</div>
</div>
</div>
<div id="model-checking" class="section level1">
<h1><span class="header-section-number">5</span> Model Checking</h1>
<div id="why-check-models" class="section level2">
<h2><span class="header-section-number">5.1</span> Why check models?</h2>
<ul>
<li>In theory—Bayesian model should include all relevant substantive knowledge and subsume all possible theories.</li>
<li>In practice—It won’t. We need to check how the model fits data.</li>
</ul>
<p>The question is not whether a model is “true”; it isn’t <span class="citation">(Box 1976)</span>.
The question is whether it is good enough for the purposes of the analysis.
The problem is how we can specify “good enough” criteria, and how we can check those criteria.</p>
<p>See <span class="citation">Gelman, Meng, and Stern (1996)</span>, <span class="citation">Gelman (2007)</span>, <span class="citation">Gelman (2009)</span>, <span class="citation">Gelman et al. (2013 Ch. 6)</span>, <span class="citation">Gelman and Shalizi (2012b)</span>, <span class="citation">Kruschke (2013)</span>, <span class="citation">Gelman and Shalizi (2012a)</span>, <span class="citation">Gelman (2014)</span> for more discussion of the motivation and use of posterior predictive checks.</p>
</div>
<div id="posterior-predictive-checks" class="section level2">
<h2><span class="header-section-number">5.2</span> Posterior Predictive Checks</h2>
<p>One method evaluate the fit of a model is to use <strong>posterior predictive checks</strong></p>
<ul>
<li>Fit the model to the data to get the posterior distribution of the parameters: <span class="math inline">\(p(\theta | D)\)</span></li>
<li>Simulate data from the fitted model: <span class="math inline">\(p(\tilde{D} | \theta, D)\)</span></li>
<li>Compare the simulated data (or a statistic thereof) to the observed data and a statistic thereof. The comparison between data simulated from the model can be formal or visual.</li>
</ul>
<p>Within a Stan function, this is done in the <code>generated quantities</code> block using a <code>_rng</code> distribution functions:</p>
<pre class="stan"><code>generated quantities {
  vector[n] yrep;
  for (i in 1:n) {
    yrep[i] ~ 
  }
}</code></pre>
<p>The package <strong><a href="https://cran.r-project.org/package=bayesplot">bayesplot</a></strong> includes multiple functions for posterior predictive checks; see the help for <a href="https://www.rdocumentation.org/packages/bayesplot//topics/PPC-overview">PPC-overview</a> for a summary of these functions.</p>
<div id="bayesian-p-values" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Bayesian p-values</h3>
<p>A <strong>posterior predictive p-value</strong> is a the tail posterior probability for a statistic generated from the model compared to the statistic observed in the data.
Let <span class="math inline">\(y = (y_1, \dots, y_n)\)</span> be the observed data.
Suppose the model has been fit and there is a set of simulation <span class="math inline">\(\theta^(s)\)</span>, <span class="math inline">\(s = 1, \dots, n_sims\)</span>.
In replicated dataset, <span class="math inline">\(y^{rep(s)\)</span>, has been generated from the predictive distribution
of the data, <span class="math inline">\(p(y^{(rep)} | \theta = \theta^{(s)}\)</span>.
Then the ensemble of simulated datasets, <span class="math inline">\((y^{rep(s)}, \dots, y^{rep(nsims)})\)</span>, is a sample from the posterior predictive
distribution, <span class="math inline">\(p(y^{(rep)} | y)\)</span></p>
<p>The model can be tested by means of discrepancy statistics, which are some function of the data and parameters, <span class="math inline">\(T(y, \theta)\)</span>.
If <span class="math inline">\(\theta\)</span> was known, then compare discrepancy by <span class="math inline">\(T(y^{(rep)}, \theta)\)</span>.
The statistical significance is <span class="math inline">\(p = \Pr(T(y^{(rep)}, \theta) &gt; T(y, \theta) | y, \theta)\)</span>.
If <span class="math inline">\(\theta\)</span> is unknown, then average over the posterior distribution of <span class="math inline">\(\theta\)</span>,
<span class="math display">\[
\begin{aligned}[t]
p &amp;= \Pr(T(y^{(rep)}, \theta) &gt; T(y, \theta) | y) \\
&amp;= \int Pr(T(y^{(rep)}, \theta) &gt; T(y, \theta) | y, \theta) p(\theta | y) d\,\theta ,
\end{aligned}
\]</span>
which is easily estimated from the MCMC samples as,
<span class="math display">\[
p = \frac{1}{n_{sims}}\sum_{s = 1}^{n_{sims}} 1( T(y^{rep(s)}, \theta(s)) &gt; T(y, \theta(s)))
\]</span></p>
</div>
<div id="test-quantities" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Test quantities</h3>
<p>The definition of a posterior p-value does not specify a particular test-statistic, <span class="math inline">\(T\)</span>, to use.</p>
<p>The best advice is that <span class="math inline">\(T\)</span> depends on the application.</p>
<ul>
<li><span class="citation">Gelman et al. (2013, 146)</span> Speed of light example uses the 90% interval (61st and 6th order statistics).</li>
<li><span class="citation">Gelman et al. (2013, 147)</span> binomial trial example uses the number of swicthes (0 to 1, or 1 to 0) in order to test independence.</li>
<li><p><span class="citation">Gelman et al. (2013, 148)</span> hierarchical model for adolesce smoking uses</p>
<ul>
<li>percent of adolescents in the sample who never smoked</li>
<li>percentage in the sample who smoked in all waves</li>
<li>precentage of “incident smoker”: adolescents who began the study and non-smokers and ended as smokers.</li>
</ul></li>
</ul>
</div>
<div id="p-values-vs.u-values" class="section level3">
<h3><span class="header-section-number">5.2.3</span> p-values vs. u-values</h3>
<p>A posterior predictive p-value is different than a classical p-value.</p>
<ul>
<li><p>Posterior predictive p-value</p>
<ul>
<li>distributed uniform if the <strong>model is true</strong></li>
</ul></li>
<li><p>Classical p-value</p>
<ul>
<li>distributed uniform if the <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>) is true</li>
</ul></li>
</ul>
<p>A <em>u-value</em> is any function of the data that has a <span class="math inline">\(U(0, 1)\)</span> sampling distribution <span class="citation">(Gelman et al. 2013, 151)</span></p>
<ul>
<li>a u-value can be averaged over <span class="math inline">\(\theta\)</span>, but it is not Bayesian, and is not a probability distribution</li>
<li>posterior p-value: probability statement, conditional on model and data, about future observations</li>
</ul>
</div>
<div id="marginal-predictive-checks" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Marginal predictive checks</h3>
<p>Compare statistics for each observation.</p>
<p><em>Conditional Predictive Ordinate (CPO)</em>:
The CPO (Gelfand 1996) is the leave-on-out cross-validation predictive density:
<span class="math display">\[
p(y_i | y_{-i}) = \int p(y_i | \theta) p(\theta | y_{-i}) d\,\theta
\]</span>
The pointwise predicted LOO probabilities can be calculated using PSIS-LOO or WAIC in the <strong>loo</strong> package.</p>
<!-- The sum of the logged CPOs can be an estimator of the log marginal likelihood and is called the log pseudo marginal likelihood. The ratio of PsMLs can be used as a surrogate for a Bayes Factor (pseudo Bayes Factor) (LaplaceDemon p. 20) -->
<p><strong>Predictive Concordance and Predictive QuantilesP</strong> Gelfand (1996) classifies any <span class="math inline">\(y_i\)</span> that is outside the central 95% predictive posterior of <span class="math inline">\(y^{rep}_i\)</span> is an outlier.
Let the <em>predictive quantile</em> (<span class="math inline">\(PQ_i\)</span>) be
<span class="math display">\[
PQ_i = p(y_i^{(rep)} &gt; y_i) .
\]</span>
Then the <em>predictive concordance</em> be the proportion of <span class="math inline">\(y_i\)</span> that are not outliers. Gelfand (1996) argues that the predictive concordance should match 95% - in other words that the posterior predictive distribution should have the correct coverage. (Laplace Demon p. 20)</p>
</div>
<div id="outliers" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Outliers</h3>
<p>Can be identified by the inverse-CPO.</p>
<ul>
<li>larger than 40 are possible outliers, and those higher than 70 are extreme values (Ntzoufras 2009, p. 376).</li>
<li>Congdon (2005) scales CPO by dividing each by its individual max and considers observations with scaled CPO under 0.01 as outliers.</li>
</ul>
</div>
<div id="grapical-posterior-predictive-checks" class="section level3">
<h3><span class="header-section-number">5.2.6</span> Grapical Posterior Predictive Checks</h3>
<blockquote>
<p>Visualization can surprise you, but it doesn’t scale well. Modeling scales well, but it can’t surprise you. – <a href="https://www.johndcook.com/blog/2013/02/07/visualization-modeling-and-surprises/">paraphrase of Hadley Hickham</a></p>
</blockquote>
<p>Instead of calculating posterior probabilities, plot simulated data and observed data and visually compare them. See <span class="citation">Gelman et al. (2013, 154)</span>.</p>
<ul>
<li>plot simulated data and real data <span class="citation">(Gelman et al. 2013, 154)</span>. This is similar to ideas in <span class="citation">Wickham et al. (2010)</span>.</li>
<li>plot summary statistics or inferences</li>
<li><p>residual plots</p>
<ul>
<li>Bayesian residuals have a distribution <span class="math inline">\(r_i^{(s)} = y_i - \E(y_i | \theta^{s})\)</span></li>
<li>Bayesian resdiual graph plots single realization of the residuals, or a summary of their posterior distributions</li>
<li>binned plots are best for discrete data <span class="citation">(Gelman et al. 2013, 157)</span></li>
<li></li>
</ul></li>
</ul>
<!--
## Average Predictive Comparisons

From @GelmanHill [Ch 21.4]
Let $u$ be the input of interest, and $v$ be all other inputs, so that $x = (u, v)$.
$$
b_u(u^{(lo)}, u^{(hi)}, v, \theta) = \frac{E(y | u^{(hi)}, v, \theta) - E(y | u^{(lo)}, v, \theta)}{u^{(hi)} - u^{(lo)}}
$$
the the average predictive difference per unit change in $u$ is,
$$
B_{u}(u^{(lo)}, u^{(hi)}) = \frac{1}{n} \sum_{i = 1}^n b_u(u^{(lo)}, u^{(hi)}, v_i, \theta) .
$$
This can be adjusted to use observed (weighted) differences of $u$ for each point.
See the Gelman paper on it.
-->
</div>
</div>
<div id="sources" class="section level2">
<h2><span class="header-section-number">5.3</span> Sources</h2>
<ul>
<li>See <span class="citation">Gelman and Shalizi (2012b)</span>, <span class="citation">Gelman and Shalizi (2012a)</span>, <span class="citation">Kruschke (2013)</span></li>
</ul>
<!--chapter:end:posterior-predictive.Rmd-->
</div>
</div>
<div id="part-models" class="section level1 unnumbered">
<h1>(PART) Models</h1>
<!--chapter:end:models.Rmd-->
</div>
<div id="introduction-to-stan-and-linear-regression" class="section level1">
<h1><span class="header-section-number">6</span> Introduction to Stan and Linear Regression</h1>
<p>This chapter is an introduction to writing and running a Stan model in R.
Also see the <strong>rstan</strong> <a href="https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html">vignette</a> for similar content.</p>
<div id="prerequites" class="section level2">
<h2><span class="header-section-number">6.1</span> Prerequites</h2>
<p>For this section we will use the <code>duncan</code> dataset included in the <strong>car</strong> package.
Duncan’s occupational prestige data is an example dataset used throughout the popular Fox regression text, <em>Applied Regression Analysis and Generalized Linear Models</em> <span class="citation">(Fox 2016)</span>.
It is originally from <span class="citation">Duncan (1961)</span> consists of survey data on the prestige of occupations in the US in 1950, and several predictors: type of occupation, income, and education of that</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;Duncan&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;carData&quot;</span>)</a></code></pre></div>
</div>
<div id="the-statistical-model" class="section level2">
<h2><span class="header-section-number">6.2</span> The Statistical Model</h2>
<p>The first step in running a Stan model is defining the Bayesian statistical model that will be used for inference.</p>
<p>Let’s run the regression of occupational prestige on the type of occupation, income, and education:
<span class="math display">\[
\begin{multline}
y_i = \beta_0 + \beta_1 I(\mathtt{type} = \mathtt{&quot;prof&quot;}) + \beta_2 I(\mathtt{type} = \mathtt{&quot;wc&quot;}) \\
+ \beta_3 \mathtt{income} + \beta_4 \mathtt{education} + \epsilon_i
\end{multline}
\]</span></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">duncan_lm &lt;-<span class="st"> </span><span class="kw">lm</span>(prestige <span class="op">~</span><span class="st"> </span>type <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>education,</a>
<a class="sourceLine" id="cb19-2" data-line-number="2">   <span class="dt">data =</span> Duncan)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3">duncan_lm</a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb19-5" data-line-number="5"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb19-6" data-line-number="6"><span class="co">#&gt; lm(formula = prestige ~ type + income + education, data = Duncan)</span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb19-8" data-line-number="8"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb19-9" data-line-number="9"><span class="co">#&gt; (Intercept)     typeprof       typewc       income    education  </span></a>
<a class="sourceLine" id="cb19-10" data-line-number="10"><span class="co">#&gt;      -0.185       16.658      -14.661        0.598        0.345</span></a></code></pre></div>
<p>There are <span class="math inline">\(n = 45\)</span> observations in the dataset.
Let <span class="math inline">\(y\)</span> be a <span class="math inline">\(n \times 1\)</span> vector of the values of <code>prestige</code>.
Let <span class="math inline">\(X\)</span> be the <span class="math inline">\(n \times k\)</span> design matrix of the regression.
In this case, <span class="math inline">\(k = 5\)</span>,
<span class="math display">\[
X = \begin{bmatrix}
1 &amp; \mathtt{typeprof} &amp; \mathtt{typewc} &amp; \mathtt{income} &amp; \mathtt{education}
\end{bmatrix}
\]</span></p>
<p>In OLS, we get the frequentist estimates of <span class="math inline">\(\hat{\beta}\)</span> by minimizing the squared errors,
<span class="math display">\[
\hat{\beta}_{OLS} = \argmin_{\beta} \sum_{i = 1}^n (y_i - \beta&#39; x_i)^2 = \argmin \sum_{i = 1}^n \hat{\epsilon}_i
\]</span>
For valid inference we need to make assumptions about <span class="math inline">\(\epsilon_i\)</span>, namely that they are uncorrelated with <span class="math inline">\(X\)</span>, <span class="math inline">\(\Cov(\epsilon, X) = 0\)</span>, and that they are i.i.d, <span class="math inline">\(\Cov(\epsilon_i, \epsilon_j) = 0\)</span>, <span class="math inline">\(\Var(\epsilon_i) = \sigma^2\)</span> for all <span class="math inline">\(i\)</span>.
However, no specific distributional form is or needs to be assumed for <span class="math inline">\(\epsilon\)</span> since CLT results show that, asymptotically, the sampling distribution of <span class="math inline">\(\beta\)</span> is distributed normal.
Additionally, although <span class="math inline">\(\hat\sigma^2 = \sum_{i = 1}^n \epsilon_i / (n - k - 1)\)</span> is a estimator of <span class="math inline">\(\sigma^2\)</span>, standard errors of the standard error of the regression are not directly provided.</p>
<p>In Bayesian inference, our target is the posterior distribution of the parameters, <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma\)</span>: <span class="math inline">\(p(\beta, \sigma^2 | y, X)\)</span>.
Since all uncertainty in Bayesian inference is provided via probability, we will need to explicitly provide parametric distributions for the likelihood and parameters.</p>
<p><span class="math display">\[
p(\beta, \sigma | y, X) \propto p(y | \beta, \sigma) p(\beta, \sigma)
\]</span></p>
<p>For a Bayesian linear regression model, we’ll need to specify distributions for <span class="math inline">\(p(y | \beta, \sigma)\)</span> and <span class="math inline">\(p(\beta, \sigma)\)</span>.</p>
<p><strong>Likelihood:</strong> <span class="math inline">\(p(y_i | x_i, \beta, \sigma)\)</span> suppose that the observations are distributed independent normal:
<span class="math display">\[
y_i \sim \dnorm(\beta&#39;x_i, \sigma^2)
\]</span></p>
<p><strong>Priors:</strong> The model needs to specify a prior distribution for the parameters <span class="math inline">\((\beta, \sigma)\)</span>.
Rather than specify a single distribution for <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma\)</span>, it will be easier to specify independent (separate) distributions for <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma\)</span>.
The Stan manual and … provide
For the normal distribution, assume i.i.d. normal distributions for each element of <span class="math inline">\(\beta\)</span>:
<span class="math display">\[
\beta_k \sim \dnorm(b, s)
\]</span>
For the scale parameter of the normal distribution, <span class="math inline">\(\sigma\)</span>, we will use a half-Cauchy.
The Cauchy distribution is a special case of the Student t distribution when the degrees of freedom is 1.
In Bayesian stats, it has the property that it concentrates probability mass around its median (zero), but has very wide tails, so if the prior distribution guess is wrong, the parameter can still adapt to data.
A half-Cauchy distribution is a Cauchy distribution but with support of <span class="math inline">\((0, \infty)\)</span> instead of the entire real line.
<span class="math display">\[
\sigma \sim \dhalfcauchy(0, w)
\]</span></p>
<p>Combining all the previous equations, our statistical model for linear regression is,
<span class="math display">\[
\begin{aligned}[t]
y &amp;\sim \dnorm(\mu, \sigma) \\
\mu &amp;= X \beta \\
\beta &amp;\sim \dnorm(b, s) \\
\sigma &amp;\sim \dhalfcauchy(0, w)
\end{aligned}
\]</span>
This defines a Bayesian model gives us
<span class="math display">\[
p(\beta, \sigma | y, X, b, s, w) \propto p(y | X, \beta) p(\beta | b, s) p(\sigma | w)
\]</span>
The targets of inference in this model are the two parameters: <span class="math inline">\(\beta\)</span> (regression coefficients), and <span class="math inline">\(\sigma\)</span> (standard deviation of the regression).
This is conditional on the observed or assumed quantities, which including both the data <span class="math inline">\(y\)</span> (response) and <span class="math inline">\(X\)</span> (predictors), as well the values defining the prior distributions: <span class="math inline">\(b\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(w\)</span>.</p>
<p>Now that we’ve defined a statistical model, we can write it as a Stan model.</p>
<p>Stan models are written in its own domain-specific language that focuses on declaring the statistical model (parameters, variables, distributions) while leaving the details of the sampling algorithm to Stan.</p>
<p>A Stan model consists of <em>blocks</em> which contain declarations of variables and/or statements.
Each block has a specific purpose in the model.</p>
<pre><code>functions {
    // OPTIONAL: user-defined functions
}
data {
    // read in data ...
}
transformed data {
    // Create new variables/auxiliary variables from the data
}
parameters {
    // Declare parameters that will be estimated
}
transformed parameters {
    // Create new variables/auxiliary variables from the parameters
}
model {
    // Declare your probability model: priors, hyperpriors &amp; likelihood
}
generated quantities {
    // Declare any quantities other than simulated parameters to be generated
}</code></pre>
<p>The file <code>lm.stan</code> is a Stan model for the linear regression model previously defined.</p>
<pre><code>data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // beta prior
  real b_loc;
  real&lt;lower = 0.0&gt; b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real&lt;lower = 0.0&gt; sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[n] mu;
  mu = a + X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  // likelihood
  y ~ normal(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[n] y_rep;
  for (i in 1:n) {
    y_rep[i] = normal_rng(mu[i], sigma);
  }
}</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">mod1 &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1">mod1</a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // beta prior
  real b_loc;
  real<lower = 0.0> b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real<lower = 0.0> sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[n] mu;
  mu = X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  // likelihood
  y ~ normal(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[n] y_rep;
  for (i in 1:n) {
    y_rep[i] = normal_rng(mu[i], sigma);
  }
}</code>
</pre>
<p>See the <a href="http://mc-stan.org/documentation/">Stan Modeling Language User’s Guide and Reference Manual</a> for details of the Stan Language.</p>
<p><strong>Note</strong>Since a Stan model compiles to C++ code, you may receive some warning messages such as</p>
<pre><code>/Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]
    static void set_zero_all_adjoints() {
                ^
In file included from file1d4a4d50faa.cpp:8:
In file included from /Library/Frameworks/R.framework/Versions/3.3/Resources/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</code></pre>
<p>As long as your model compiles, you can ignore these compiler warnings (On the other hard, warnings that occur during sampling should not be ignored).
If the Stan model does not give you a syntax error when parsing the model, it should compile to valid C++.[^bugs][^c-warnings]
See</p>
<p>[bugs]: In the rare case that the Stan parser transpiles the Stan model to C++ but cannot compile the C++ code, it is a bug in Stan. Follow the <a href="http://mc-stan.org/issues/">instructions</a> on how to inform the Stan developers about bugs.
[c-warnings]: The extended installation instructions for <a href="https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Mac-or-Linux">MacOS/Linux</a> and <a href="https://github.com/stan-dev/rstan/wiki/Installing-RStan-on-Windows">Windows</a> have instructions for adding compiler options to the R <a href="https://cran.r-project.org/doc/manuals/r-release/R-exts.html#Using-Makevars">Makevars</a> file.</p>
<div id="sampling" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Sampling</h3>
<p>In order to sample from the model, we need to at least give it the values for the data to use: <code>n</code>, <code>k</code>, <code>y</code>, <code>X</code>, and the data associated with the priors.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">mod1_data &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">  <span class="dt">y =</span> Duncan<span class="op">$</span>prestige,</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">  <span class="dt">n =</span> <span class="kw">nrow</span>(Duncan)</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">)</a></code></pre></div>
<p>The data types in Stan are all numeric (either integers or reals), but they include matrices and vectors.
However, there is nothing like a data frame in Stan.
Whereas in the R function <code>lm</code> we can provide a formula and a data set for where to look for objects, and the function will create the appropriate <span class="math inline">\(X\)</span> matrix for the regression, we will need to create that matrix ourselves—expanding categorical variables to indicator variables, and expanding interactions and other functions of the predictors.
However, we need to do that all manually.
The function <a href="https://www.rdocumentation.org/packages/stats/topics/model.matrix">stats</a> is the workhorse function used in <code>lm</code> and many other R functions to convert a formula into the matrix used in estimation.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(prestige <span class="op">~</span><span class="st"> </span>type <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>education, <span class="dt">data =</span> Duncan)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2">mod1_data<span class="op">$</span>X &lt;-<span class="st"> </span>X</a>
<a class="sourceLine" id="cb26-3" data-line-number="3">mod1_data<span class="op">$</span>k &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)</a></code></pre></div>
<p>We still need to provide the values for the prior distributions.
For specific values of the prior distributions, assume uninformative priors for <code>beta</code> by setting the mean to zero and the variances to large numbers.
<span class="math display">\[
\beta_k \sim \dnorm(0, 1000)
\]</span></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">mod1_data<span class="op">$</span>b_loc &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb27-2" data-line-number="2">mod1_data<span class="op">$</span>b_scale &lt;-<span class="st"> </span><span class="dv">1000</span></a></code></pre></div>
<p>For prior of the regression scale parameter <span class="math inline">\(\sigma\)</span>, use a half-Cauchy distribution with a large scale parameter, which is a good choice for the priors of scale parameters.
<!--
In this case, `prestige` has values between 0 and 100.
This is like a proportion (actually, it is a proportion x 100), so ignoring the covariates, the maximum variance of a distribution would be if `prestige = 50`, when the standard deviation would be $\sqrt{p * (1 - p)} = 50$. So a scale parameter of 50 is appropriate,
-->
<span class="math display">\[
\sigma \sim \dhalfcauchy(0, 50)
\]</span></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">mod1_data<span class="op">$</span>sigma_scale &lt;-<span class="st"> </span><span class="dv">50</span></a></code></pre></div>
<p>Now, sample from the posterior, using the function <code>sampling</code>:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1">mod1_fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod1, <span class="dt">data =</span> mod1_data)</a></code></pre></div>
</div>
<div id="convergence-diagnostics-and-model-fit" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Convergence Diagnostics and Model Fit</h3>
<ul>
<li><p><strong>Convergence Diagnostics:</strong> Is this the posterior distribution that you were looking for? These don’t directly say anything about how “good” the model is in terms representing the data, they are only evaluating how well the sampler is doing at sampling the posterior distribution of the given model. If there are problems with these, then the sample results do not represent the posterior distribution, and your inferences will be biased.</p>
<ul>
<li><code>mcse</code>:</li>
<li><code>n_eff</code>:</li>
<li><code>Rhat</code></li>
<li><code>divergences</code></li>
</ul></li>
<li><p><strong>Model fit:</strong> Is this statistical model appropriate for the data? Or better than other models?</p>
<ul>
<li>Posterior predictive checks<br />
</li>
<li><p>Information criteria:</p>
<ul>
<li>WAIC</li>
<li>Leave-one-out Cross-Validation</li>
</ul></li>
</ul></li>
</ul>
<!--chapter:end:intro-regression.Rmd-->
</div>
</div>
</div>
<div id="heteroskedasticity-and-robust-regression" class="section level1">
<h1><span class="header-section-number">7</span> Heteroskedasticity and Robust Regression</h1>
<div id="prerequisites-1" class="section level2">
<h2><span class="header-section-number">7.1</span> Prerequisites</h2>
<p><strong><a href="https://cran.r-project.org/package=VGAM">VGAM</a></strong> is needed for the Laplace distribution.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;VGAM&quot;</span>)</a></code></pre></div>
</div>
<div id="linear-regression-with-student-t-distributed-errors" class="section level2">
<h2><span class="header-section-number">7.2</span> Linear Regression with Student t distributed errors</h2>
<p>Like OLS, Bayesian linear regression with normally distributed errors is sensitive to outliers.
The normal distribution has narrow tail probabilities.</p>
<p>This plots the normal, Double Exponential (Laplace), and Student-t (df = 4) distributions all with mean 0 and scale 1, and the surprise (<span class="math inline">\(- log(p)\)</span>) at each point.
Higher surprise is a lower log-likelihood.
Both the Student-t and Double Exponential distributions have surprise values well below the normal in the ranges (-6, 6).<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>
This means that outliers impose less of a penalty on the log-posterior models using these distributions, and the regression line would need to move less to incorporate those observations since the error distribution will not consider them as unusual.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">bind_rows</span>(</a>
<a class="sourceLine" id="cb31-3" data-line-number="3">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb31-4" data-line-number="4">         <span class="dt">p =</span> <span class="kw">dnorm</span>(z, <span class="dv">0</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb31-5" data-line-number="5">         <span class="dt">distr =</span> <span class="st">&quot;Normal&quot;</span>),</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb31-7" data-line-number="7">         <span class="dt">p =</span> <span class="kw">dt</span>(z, <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb31-8" data-line-number="8">         <span class="dt">distr =</span> <span class="st">&quot;Student-t (df = 4)&quot;</span>),</a>
<a class="sourceLine" id="cb31-9" data-line-number="9">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb31-10" data-line-number="10">         <span class="dt">p =</span> VGAM<span class="op">::</span><span class="kw">dlaplace</span>(z, <span class="dv">0</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb31-11" data-line-number="11">         <span class="dt">distr =</span> <span class="st">&quot;Double Exponential&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb31-12" data-line-number="12"><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">-log(p)</span><span class="st">`</span> =<span class="st"> </span><span class="op">-</span><span class="kw">log</span>(p)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb31-13" data-line-number="13"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> z, <span class="dt">y =</span> <span class="st">`</span><span class="dt">-log(p)</span><span class="st">`</span>, <span class="dt">colour =</span> distr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb31-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_line</span>()</a>
<a class="sourceLine" id="cb31-15" data-line-number="15">      </a></code></pre></div>
<p><img src="robust_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">z &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2"><span class="kw">bind_rows</span>(</a>
<a class="sourceLine" id="cb32-3" data-line-number="3">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb32-4" data-line-number="4">         <span class="dt">p =</span> <span class="kw">dnorm</span>(z, <span class="dv">0</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb32-5" data-line-number="5">         <span class="dt">distr =</span> <span class="st">&quot;Normal&quot;</span>),</a>
<a class="sourceLine" id="cb32-6" data-line-number="6">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb32-7" data-line-number="7">         <span class="dt">p =</span> <span class="kw">dt</span>(z, <span class="dv">4</span>),</a>
<a class="sourceLine" id="cb32-8" data-line-number="8">         <span class="dt">distr =</span> <span class="st">&quot;Student-t (df = 4)&quot;</span>),</a>
<a class="sourceLine" id="cb32-9" data-line-number="9">  <span class="kw">tibble</span>(<span class="dt">z =</span> z,</a>
<a class="sourceLine" id="cb32-10" data-line-number="10">         <span class="dt">p =</span> VGAM<span class="op">::</span><span class="kw">dlaplace</span>(z, <span class="dv">0</span>, <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb32-11" data-line-number="11">         <span class="dt">distr =</span> <span class="st">&quot;Double Exponential&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb32-12" data-line-number="12"><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">-log(p)</span><span class="st">`</span> =<span class="st"> </span><span class="op">-</span><span class="kw">log</span>(p)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb32-13" data-line-number="13"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> z, <span class="dt">y =</span> p, <span class="dt">colour =</span> distr)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-14" data-line-number="14"><span class="st">  </span><span class="kw">geom_line</span>()</a>
<a class="sourceLine" id="cb32-15" data-line-number="15">      </a></code></pre></div>
<p><img src="robust_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1">mod_t</a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // beta prior
  real b_loc;
  real<lower = 0.0> b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real<lower = 0.0> sigma;
  real<lower = 1.0> nu;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[n] mu;
  mu = X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  nu ~ gamma(2, 0.1);
  // likelihood
  y ~ student_t(nu, mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[n] y_rep;
  // log-likelihood values
  vector[n] log_lik;
  for (i in 1:n) {
    y_rep[i] = student_t_rng(nu, mu[i], sigma);
    log_lik[i] = student_t_lpdf(y[i] | nu, mu[i], sigma);
  }

}</code>
</pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">unionization &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(<span class="st">&quot;data/western1995/unionization.tsv&quot;</span>,</a>
<a class="sourceLine" id="cb34-2" data-line-number="2">         <span class="dt">col_types =</span> <span class="kw">cols</span>(</a>
<a class="sourceLine" id="cb34-3" data-line-number="3">              <span class="dt">country =</span> <span class="kw">col_character</span>(),</a>
<a class="sourceLine" id="cb34-4" data-line-number="4">              <span class="dt">union_density =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb34-5" data-line-number="5">              <span class="dt">left_government =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb34-6" data-line-number="6">              <span class="dt">labor_force_size =</span> <span class="kw">col_number</span>(),</a>
<a class="sourceLine" id="cb34-7" data-line-number="7">              <span class="dt">econ_conc =</span> <span class="kw">col_double</span>()</a>
<a class="sourceLine" id="cb34-8" data-line-number="8">            ))</a>
<a class="sourceLine" id="cb34-9" data-line-number="9">mod_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(union_density <span class="op">~</span><span class="st"> </span>left_government <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(labor_force_size) <span class="op">+</span><span class="st"> </span>econ_conc, <span class="dt">data =</span> unionization)</a>
<a class="sourceLine" id="cb34-10" data-line-number="10">                                   </a>
<a class="sourceLine" id="cb34-11" data-line-number="11">mod_data &lt;-<span class="st"> </span><span class="kw">within</span>(mod_data, {</a>
<a class="sourceLine" id="cb34-12" data-line-number="12">  b_loc &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb34-13" data-line-number="13">  b_scale &lt;-<span class="st"> </span><span class="dv">1000</span></a>
<a class="sourceLine" id="cb34-14" data-line-number="14">  sigma_scale &lt;-<span class="st"> </span><span class="kw">sd</span>(y)</a>
<a class="sourceLine" id="cb34-15" data-line-number="15">})</a></code></pre></div>
<p>The <code>max_treedepth</code> parameter needed to be increased because in some runs it was hitting the maximum tree depth.
This is likely due to the wide tails of the Student t distribution.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1">mod_t_fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_t, <span class="dt">data =</span> mod_data, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">max_treedepth =</span> <span class="dv">11</span>))</a>
<a class="sourceLine" id="cb35-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-3" data-line-number="3"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm_student_t&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb35-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-5" data-line-number="5"><span class="co">#&gt; Gradient evaluation took 3.9e-05 seconds</span></a>
<a class="sourceLine" id="cb35-6" data-line-number="6"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.39 seconds.</span></a>
<a class="sourceLine" id="cb35-7" data-line-number="7"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb35-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-10" data-line-number="10"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-11" data-line-number="11"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-12" data-line-number="12"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-13" data-line-number="13"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-14" data-line-number="14"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-15" data-line-number="15"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-16" data-line-number="16"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-17" data-line-number="17"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-18" data-line-number="18"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-19" data-line-number="19"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-20" data-line-number="20"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-21" data-line-number="21"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-23" data-line-number="23"><span class="co">#&gt;  Elapsed Time: 0.924295 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb35-24" data-line-number="24"><span class="co">#&gt;                0.797333 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb35-25" data-line-number="25"><span class="co">#&gt;                1.72163 seconds (Total)</span></a>
<a class="sourceLine" id="cb35-26" data-line-number="26"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 1</span></a>
<a class="sourceLine" id="cb35-27" data-line-number="27"><span class="co">#&gt;                                                                                          count</span></a>
<a class="sourceLine" id="cb35-28" data-line-number="28"><span class="co">#&gt; Exception thrown at line 35: student_t_lpdf: Scale parameter is inf, but must be finite!     1</span></a>
<a class="sourceLine" id="cb35-29" data-line-number="29"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb35-30" data-line-number="30"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb35-31" data-line-number="31"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb35-32" data-line-number="32"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-33" data-line-number="33"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm_student_t&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb35-34" data-line-number="34"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-35" data-line-number="35"><span class="co">#&gt; Gradient evaluation took 1.3e-05 seconds</span></a>
<a class="sourceLine" id="cb35-36" data-line-number="36"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.</span></a>
<a class="sourceLine" id="cb35-37" data-line-number="37"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb35-38" data-line-number="38"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-39" data-line-number="39"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-40" data-line-number="40"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-41" data-line-number="41"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-42" data-line-number="42"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-43" data-line-number="43"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-44" data-line-number="44"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-45" data-line-number="45"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-46" data-line-number="46"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-47" data-line-number="47"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-48" data-line-number="48"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-49" data-line-number="49"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-50" data-line-number="50"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-51" data-line-number="51"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-52" data-line-number="52"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-53" data-line-number="53"><span class="co">#&gt;  Elapsed Time: 0.912943 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb35-54" data-line-number="54"><span class="co">#&gt;                0.842836 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb35-55" data-line-number="55"><span class="co">#&gt;                1.75578 seconds (Total)</span></a>
<a class="sourceLine" id="cb35-56" data-line-number="56"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 2</span></a>
<a class="sourceLine" id="cb35-57" data-line-number="57"><span class="co">#&gt;                                                                                          count</span></a>
<a class="sourceLine" id="cb35-58" data-line-number="58"><span class="co">#&gt; Exception thrown at line 35: student_t_lpdf: Scale parameter is inf, but must be finite!     1</span></a>
<a class="sourceLine" id="cb35-59" data-line-number="59"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb35-60" data-line-number="60"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb35-61" data-line-number="61"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb35-62" data-line-number="62"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-63" data-line-number="63"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm_student_t&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb35-64" data-line-number="64"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-65" data-line-number="65"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb35-66" data-line-number="66"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb35-67" data-line-number="67"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb35-68" data-line-number="68"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-69" data-line-number="69"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-70" data-line-number="70"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-71" data-line-number="71"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-72" data-line-number="72"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-73" data-line-number="73"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-74" data-line-number="74"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-75" data-line-number="75"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-76" data-line-number="76"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-77" data-line-number="77"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-78" data-line-number="78"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-79" data-line-number="79"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-80" data-line-number="80"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-81" data-line-number="81"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-82" data-line-number="82"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-83" data-line-number="83"><span class="co">#&gt;  Elapsed Time: 0.978823 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb35-84" data-line-number="84"><span class="co">#&gt;                0.815824 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb35-85" data-line-number="85"><span class="co">#&gt;                1.79465 seconds (Total)</span></a>
<a class="sourceLine" id="cb35-86" data-line-number="86"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 3</span></a>
<a class="sourceLine" id="cb35-87" data-line-number="87"><span class="co">#&gt;                                                                                     count</span></a>
<a class="sourceLine" id="cb35-88" data-line-number="88"><span class="co">#&gt; Exception thrown at line 35: student_t_lpdf: Scale parameter is 0, but must be &gt; 0!     1</span></a>
<a class="sourceLine" id="cb35-89" data-line-number="89"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb35-90" data-line-number="90"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb35-91" data-line-number="91"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb35-92" data-line-number="92"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-93" data-line-number="93"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm_student_t&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb35-94" data-line-number="94"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-95" data-line-number="95"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb35-96" data-line-number="96"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb35-97" data-line-number="97"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb35-98" data-line-number="98"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-99" data-line-number="99"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-100" data-line-number="100"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-101" data-line-number="101"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-102" data-line-number="102"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-103" data-line-number="103"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-104" data-line-number="104"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-105" data-line-number="105"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb35-106" data-line-number="106"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-107" data-line-number="107"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-108" data-line-number="108"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-109" data-line-number="109"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-110" data-line-number="110"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-111" data-line-number="111"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb35-112" data-line-number="112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb35-113" data-line-number="113"><span class="co">#&gt;  Elapsed Time: 0.903471 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb35-114" data-line-number="114"><span class="co">#&gt;                0.748265 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb35-115" data-line-number="115"><span class="co">#&gt;                1.65174 seconds (Total)</span></a>
<a class="sourceLine" id="cb35-116" data-line-number="116"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 4</span></a>
<a class="sourceLine" id="cb35-117" data-line-number="117"><span class="co">#&gt;                                                                                          count</span></a>
<a class="sourceLine" id="cb35-118" data-line-number="118"><span class="co">#&gt; Exception thrown at line 35: student_t_lpdf: Scale parameter is inf, but must be finite!     1</span></a>
<a class="sourceLine" id="cb35-119" data-line-number="119"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb35-120" data-line-number="120"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb35-121" data-line-number="121"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="kw">summary</span>(mod_t_fit, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b&quot;</span>))<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="co">#&gt;        mean se_mean     sd    2.5%    25%    50%     75%  97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb36-3" data-line-number="3"><span class="co">#&gt; b[1] 90.924 2.19841 66.781 -44.196  47.81 91.762 133.164 223.22   923    1</span></a>
<a class="sourceLine" id="cb36-4" data-line-number="4"><span class="co">#&gt; b[2]  0.273 0.00162  0.083   0.103   0.22  0.275   0.328   0.43  2626    1</span></a>
<a class="sourceLine" id="cb36-5" data-line-number="5"><span class="co">#&gt; b[3] -6.082 0.13953  4.322 -14.791  -8.92 -6.101  -3.263   2.57   959    1</span></a>
<a class="sourceLine" id="cb36-6" data-line-number="6"><span class="co">#&gt; b[4]  2.763 0.74224 22.668 -43.434 -11.60  2.445  17.292  48.50   933    1</span></a></code></pre></div>
<p>Compare those results when using a model with</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">mod_normal</a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // beta prior
  real b_loc;
  real<lower = 0.0> b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real<lower = 0.0> sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[n] mu;
  mu = X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  // likelihood
  y ~ normal(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[n] y_rep;
  // log-likelihood posterior
  vector[n] log_lik;
  for (i in 1:n) {
    y_rep[i] = normal_rng(mu[i], sigma);
    log_lik[i] = normal_lpdf(y[i] | mu[i], sigma);
  }
}</code>
</pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">mod_normal_fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_normal, <span class="dt">data =</span> mod_data)</a>
<a class="sourceLine" id="cb38-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-3" data-line-number="3"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb38-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-5" data-line-number="5"><span class="co">#&gt; Gradient evaluation took 2.9e-05 seconds</span></a>
<a class="sourceLine" id="cb38-6" data-line-number="6"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.</span></a>
<a class="sourceLine" id="cb38-7" data-line-number="7"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb38-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-10" data-line-number="10"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-11" data-line-number="11"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-12" data-line-number="12"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-13" data-line-number="13"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-14" data-line-number="14"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-15" data-line-number="15"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-16" data-line-number="16"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-17" data-line-number="17"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-18" data-line-number="18"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-19" data-line-number="19"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-20" data-line-number="20"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-21" data-line-number="21"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-23" data-line-number="23"><span class="co">#&gt;  Elapsed Time: 0.551241 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb38-24" data-line-number="24"><span class="co">#&gt;                0.482792 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb38-25" data-line-number="25"><span class="co">#&gt;                1.03403 seconds (Total)</span></a>
<a class="sourceLine" id="cb38-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-27" data-line-number="27"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-28" data-line-number="28"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb38-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-30" data-line-number="30"><span class="co">#&gt; Gradient evaluation took 9e-06 seconds</span></a>
<a class="sourceLine" id="cb38-31" data-line-number="31"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.</span></a>
<a class="sourceLine" id="cb38-32" data-line-number="32"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb38-33" data-line-number="33"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-34" data-line-number="34"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-35" data-line-number="35"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-36" data-line-number="36"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-37" data-line-number="37"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-38" data-line-number="38"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-39" data-line-number="39"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-40" data-line-number="40"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-41" data-line-number="41"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-42" data-line-number="42"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-43" data-line-number="43"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-44" data-line-number="44"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-45" data-line-number="45"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-46" data-line-number="46"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-47" data-line-number="47"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-48" data-line-number="48"><span class="co">#&gt;  Elapsed Time: 0.507048 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb38-49" data-line-number="49"><span class="co">#&gt;                0.455422 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb38-50" data-line-number="50"><span class="co">#&gt;                0.96247 seconds (Total)</span></a>
<a class="sourceLine" id="cb38-51" data-line-number="51"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-52" data-line-number="52"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-53" data-line-number="53"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb38-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-55" data-line-number="55"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb38-56" data-line-number="56"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb38-57" data-line-number="57"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb38-58" data-line-number="58"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-59" data-line-number="59"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-60" data-line-number="60"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-61" data-line-number="61"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-62" data-line-number="62"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-63" data-line-number="63"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-64" data-line-number="64"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-65" data-line-number="65"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-66" data-line-number="66"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-67" data-line-number="67"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-68" data-line-number="68"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-69" data-line-number="69"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-70" data-line-number="70"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-71" data-line-number="71"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-72" data-line-number="72"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-73" data-line-number="73"><span class="co">#&gt;  Elapsed Time: 0.493311 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb38-74" data-line-number="74"><span class="co">#&gt;                0.568471 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb38-75" data-line-number="75"><span class="co">#&gt;                1.06178 seconds (Total)</span></a>
<a class="sourceLine" id="cb38-76" data-line-number="76"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-77" data-line-number="77"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-78" data-line-number="78"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb38-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-80" data-line-number="80"><span class="co">#&gt; Gradient evaluation took 9e-06 seconds</span></a>
<a class="sourceLine" id="cb38-81" data-line-number="81"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.</span></a>
<a class="sourceLine" id="cb38-82" data-line-number="82"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb38-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-84" data-line-number="84"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-85" data-line-number="85"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-86" data-line-number="86"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-87" data-line-number="87"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-88" data-line-number="88"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-89" data-line-number="89"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-90" data-line-number="90"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb38-91" data-line-number="91"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-92" data-line-number="92"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-93" data-line-number="93"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-94" data-line-number="94"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-95" data-line-number="95"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-96" data-line-number="96"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb38-97" data-line-number="97"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb38-98" data-line-number="98"><span class="co">#&gt;  Elapsed Time: 0.511245 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb38-99" data-line-number="99"><span class="co">#&gt;                0.405449 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb38-100" data-line-number="100"><span class="co">#&gt;                0.916694 seconds (Total)</span></a></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="kw">summary</span>(mod_normal_fit, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;b&quot;</span>))<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb39-2" data-line-number="2"><span class="co">#&gt;        mean se_mean      sd     2.5%     25%    50%     75%   97.5% n_eff</span></a>
<a class="sourceLine" id="cb39-3" data-line-number="3"><span class="co">#&gt; b[1] 95.987 2.41105 63.9174 -27.7095  53.147 95.592 137.966 223.008   703</span></a>
<a class="sourceLine" id="cb39-4" data-line-number="4"><span class="co">#&gt; b[2]  0.270 0.00194  0.0842   0.0979   0.217  0.273   0.326   0.434  1891</span></a>
<a class="sourceLine" id="cb39-5" data-line-number="5"><span class="co">#&gt; b[3] -6.356 0.15521  4.2031 -14.8646  -9.116 -6.339  -3.532   1.768   733</span></a>
<a class="sourceLine" id="cb39-6" data-line-number="6"><span class="co">#&gt; b[4]  0.858 0.80219 21.5103 -41.1619 -13.309  0.972  15.252  43.658   719</span></a>
<a class="sourceLine" id="cb39-7" data-line-number="7"><span class="co">#&gt;      Rhat</span></a>
<a class="sourceLine" id="cb39-8" data-line-number="8"><span class="co">#&gt; b[1] 1.01</span></a>
<a class="sourceLine" id="cb39-9" data-line-number="9"><span class="co">#&gt; b[2] 1.00</span></a>
<a class="sourceLine" id="cb39-10" data-line-number="10"><span class="co">#&gt; b[3] 1.01</span></a>
<a class="sourceLine" id="cb39-11" data-line-number="11"><span class="co">#&gt; b[4] 1.01</span></a></code></pre></div>
<div id="double-exponential-laplace-errors" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Double Exponential (Laplace) Errors</h3>
<p>An alternative form of “robust” regression is to use the Double Exponential (Laplace) distributions for the errors.</p>
<p>This is the equivalent to least median regression, where the regression line is the median (50% quantile)</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1">mod_dbl_exp</a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int n;
  // response vector
  vector[n] y;
  // number of columns in the design matrix X
  int k;
  // design matrix X
  matrix [n, k] X;
  // beta prior
  real b_loc;
  real<lower = 0.0> b_scale;
  // sigma prior
  real sigma_scale;
}
parameters {
  // regression coefficient vector
  vector[k] b;
  // scale of the regression errors
  real<lower = 0.0> sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  vector[n] mu;
  // tau are obs-level scale params
  mu = X * b;
}
model {
  // priors
  b ~ normal(b_loc, b_scale);
  sigma ~ cauchy(0, sigma_scale);
  // likelihood
  y ~ double_exponential(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[n] y_rep;
  // log-likelihood values
  vector[n] log_lik;
  // use a single loop since both y_rep and log_lik are elementwise
  for (i in 1:n) {
    y_rep[i] = double_exponential_rng(mu[i], sigma);
    log_lik[i] = double_exponential_lpdf(y[i] | mu[i], sigma);
  }

}</code>
</pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="kw">summary</span>(mod_dbl_exp_fit, <span class="dt">par =</span> <span class="kw">c</span>(<span class="st">&quot;b&quot;</span>))<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb41-2" data-line-number="2"><span class="co">#&gt;        mean se_mean      sd    2.5%    25%    50%     75%   97.5% n_eff</span></a>
<a class="sourceLine" id="cb41-3" data-line-number="3"><span class="co">#&gt; b[1] 60.671 2.58294 72.5324 -84.418 15.896 56.321 105.938 207.022   789</span></a>
<a class="sourceLine" id="cb41-4" data-line-number="4"><span class="co">#&gt; b[2]  0.298 0.00217  0.0815   0.126  0.248  0.304   0.354   0.442  1415</span></a>
<a class="sourceLine" id="cb41-5" data-line-number="5"><span class="co">#&gt; b[3] -4.303 0.15685  4.4911 -13.482 -7.160 -4.100  -1.555   4.641   820</span></a>
<a class="sourceLine" id="cb41-6" data-line-number="6"><span class="co">#&gt; b[4] 13.381 0.91373 25.6984 -38.570 -2.215 14.588  29.270  64.348   791</span></a>
<a class="sourceLine" id="cb41-7" data-line-number="7"><span class="co">#&gt;      Rhat</span></a>
<a class="sourceLine" id="cb41-8" data-line-number="8"><span class="co">#&gt; b[1]    1</span></a>
<a class="sourceLine" id="cb41-9" data-line-number="9"><span class="co">#&gt; b[2]    1</span></a>
<a class="sourceLine" id="cb41-10" data-line-number="10"><span class="co">#&gt; b[3]    1</span></a>
<a class="sourceLine" id="cb41-11" data-line-number="11"><span class="co">#&gt; b[4]    1</span></a></code></pre></div>
<p>Model comparison</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">loo_t &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(mod_normal_fit, <span class="st">&quot;log_lik&quot;</span>))</a>
<a class="sourceLine" id="cb42-2" data-line-number="2"><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-</span></a>
<a class="sourceLine" id="cb42-3" data-line-number="3"><span class="co">#&gt; diagnostic&#39;) for details.</span></a>
<a class="sourceLine" id="cb42-4" data-line-number="4">loo_normal &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(mod_t_fit, <span class="st">&quot;log_lik&quot;</span>))</a>
<a class="sourceLine" id="cb42-5" data-line-number="5"><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-</span></a>
<a class="sourceLine" id="cb42-6" data-line-number="6"><span class="co">#&gt; diagnostic&#39;) for details.</span></a>
<a class="sourceLine" id="cb42-7" data-line-number="7">loo_dbl_exp &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(mod_dbl_exp_fit, <span class="st">&quot;log_lik&quot;</span>))</a></code></pre></div>
</div>
</div>
<div id="heteroskedasticity" class="section level2">
<h2><span class="header-section-number">7.3</span> Heteroskedasticity</h2>
<p>In applied regression, heteroskedasticity consistent (HC) or robust standard errors are often used.</p>
<p>However, there is straightforwardly direct translation of HC standard error to regression model this in a Bayesian setting. The sandwich method of estimating HC errors uses the same point estimates for the regression coefficients as OLS, but estimates the standard errors of those coefficients in a second stage from the OLS residuals.
Disregarding differences in frequentist vs. Bayesian inference, it is clear that a direct translation of that method could not be fully Bayesian since the coefficients and errors are not estimated jointly.</p>
<p>In a linear normal regression model with heteroskedasticity, each observation has its own scale parameter, <span class="math inline">\(\sigma_i\)</span>,
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(X \beta, \sigma_i) .
\end{aligned}
\]</span>
It should be clear that without proper priors this model is not identified, meaning that the posterior distribution is improper.
To estimate this model we have to apply some model to the scale terms, <span class="math inline">\(\sigma_i\)</span>.
In fact, you can think of homoskedasticity as the simplest such model; assuming that all <span class="math inline">\(\sigma_i = \sigma\)</span>.
A more general model of <span class="math inline">\(\sigma_i\)</span> should encode any information the analyst has about the scale terms.
This can be a distribution or functions of covariates for how we think observations may have different values.</p>
<div id="covariates" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Covariates</h3>
<p>A simple model of heteroskedasticity is if the observations can be split into groups. Suppose the observations are partitioned into <span class="math inline">\(k = 1, \dots, K\)</span> groups, and <span class="math inline">\(k[i]\)</span> is the group of observation <span class="math inline">\(i\)</span>,
<span class="math display">\[
\sigma_i = \sigma_{k[i]}
\]</span></p>
<p>Another choice would be to model the scale term with a regression model, for example,
<span class="math display">\[
\log(\sigma_i) \sim \dnorm(X \gamma, \tau)
\]</span></p>
</div>
<div id="student-t-error" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Student-t Error</h3>
<p>The Student-t distribution of error terms from the <a href="#robust-regression">Robust Regression</a> chapter is also model of heteroskedasticity.</p>
<p>A reparameterization that will be used quite often is to rewrite a normal distributions with unequal scale parameters as the product of a common global scale parameter (<span class="math inline">\(\sigma\)</span>), and observation specific local scale parameters, <span class="math inline">\(\lambda_i\)</span>,[^globalmixture]
<span class="math display">\[
y_i \sim \dnorm(X\beta, \lambda_i \sigma) .
\]</span>
If the local variance parameters are distributed inverse-gamma,
<span class="math display">\[
\lambda^2 \sim \dinvgamma(\nu / 2, \nu / 2)
\]</span>
then the above is equivalent to a regression with errors distributed Student-t errors with <span class="math inline">\(\nu\)</span> degrees of freedom,
<span class="math display">\[
y_i \sim \dt{\nu}(X \beta, \sigma) .
\]</span></p>
<p>[^globalmixture] See <a href="http://www.sumsar.net/blog/2013/12/t-as-a-mixture-of-normals/">this</a> for a visualization of a Student-t distribution a mixture of Normal distributions, and <a href="https://www.johndcook.com/t_normal_mixture.pdf">this</a> for a derivation of the Student t distribution as a mixture of normal distributions. This scale mixture of normal representation will also be used with shrinkage priors on the regression coefficients.</p>
<p><strong>Example:</strong> Simulate Student-t distribution with <span class="math inline">\(\nu\)</span> degrees of freedom as a scale mixture of normal. For *s in 1:S$,</p>
<ol style="list-style-type: decimal">
<li>Simulate <span class="math inline">\(z_s \sim \dgamma(\nu / 2, \nu / 2)\)</span></li>
<li><span class="math inline">\(x_s = 1 / \sqrt{z_s}2\)</span> is draw from <span class="math inline">\(\dt{\nu}(0, 1)\)</span>.</li>
</ol>
<p>When using R, ensure that you are using the correct parameterization of the gamma distribution. <strong>Left to reader</strong></p>
</div>
</div>
<div id="references-2" class="section level2">
<h2><span class="header-section-number">7.4</span> References</h2>
<div id="robust-regression" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Robust regression</h3>
<ul>
<li>See <span class="citation">Gelman and Hill (2007 sec 6.6)</span>, <span class="citation">Gelman et al. (2013 ch 17)</span></li>
<li><span class="citation">Stan Development Team (2016 Sec 8.4)</span> for the Stan example using a Student-t distribution</li>
</ul>
</div>
<div id="heteroskedasticity-1" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Heteroskedasticity</h3>
<ul>
<li><span class="citation">Gelman et al. (2013 Sec. 14.7)</span> for models with unequal variances and correlations.</li>
<li><span class="citation">Stan Development Team (2016)</span> reparameterizes the Student t distribution as a mixture of gamma distributions in Stan.</li>
</ul>
</div>
<div id="qunatile-regression" class="section level3">
<h3><span class="header-section-number">7.4.3</span> Qunatile regression</h3>
<ul>
<li><span class="citation">Benoit and Poel (2017)</span></li>
<li><span class="citation">Yu and Zhang (2005)</span> for the three-parameter asymmetric Laplace distribution</li>
</ul>
<!--chapter:end:robust.Rmd-->
</div>
</div>
</div>
<div id="generalized-linear-models" class="section level1">
<h1><span class="header-section-number">8</span> Generalized Linear Models</h1>
<div id="generalized-linear-models-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Generalized Linear Models</h2>
<p>Generalized linear models (GLMs) are a class of commonly used models.[^glm-r]
In GLMs, the mean is specified as a function of a linear model of predictors,
<span class="math display">\[
E(Y) = \mu = g^{-1}(\mat{X} \vec{\beta}) .
\]</span>
GLMs are a generalization of linear regression from an unbounded continuous outcome variable to other types of data: binary, count, categorical, bounded continuous.</p>
<p>A GLM consists of three components:</p>
<ol style="list-style-type: decimal">
<li>A <em>probability distribution</em> (<em>family</em>) specifying the conditional distribution of the response variable.
In GLMs, the distribution is in the exponential family: Normal, Binomial, Poisson, Categorical, Multinomial, Poisson, Beta.</li>
<li>A <em>linear predictor</em>, which is a linear function of the predictors,
<span class="math display">\[
 \eta = \mat{X} \vec{\beta} .
 \]</span></li>
<li>A <em>link function</em> (<span class="math inline">\(g(.)\)</span>) which maps the expected value to the the linear predictor,
<span class="math display">\[
 g(\mu) = \eta .
 \]</span>
The link function is smooth and invertible, and the <em>inverse link function</em> or <em>mean function</em> maps the linear predictor to the mean,
<span class="math display">\[
 \mu = g^{-1}(\eta) .
 \]</span>
The link function (<span class="math inline">\(g\)</span>) and its inverse ($g^{-1}) translate <span class="math inline">\(\eta\)</span> from <span class="math inline">\((\-infty, +\infty)\)</span> to the proper range for the probability distribution and back again.</li>
</ol>
<p>These models are often estimated with MLE, as with the function <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>.
These are also easily estimated in a Bayesian setting.</p>
<p>See the help for <a href="https://www.rdocumentation.org/packages/stats/topics/family">stats</a> for common probability distributions, <a href="https://www.rdocumentation.org/packages/stats/topics/make.link">stats</a> for common links, and the <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a> page for a table of common GLMs.
See the function <strong><a href="https://cran.r-project.org/package=VGAM">VGAM</a></strong> for even more examples of link functions and probability distributions.</p>
<table>
<caption>Common Link Functions and their inverses. Table derived from <span class="citation">Fox (2016, 419)</span>.</caption>
<thead>
<tr class="header">
<th align="left">Link</th>
<th align="left">Range of <span class="math inline">\(\mu_i\)</span></th>
<th align="left"><span class="math inline">\(\eta_i = g(\mu_i)\)</span></th>
<th align="left"><span class="math inline">\(\mu_i = g^{-1}(\eta)_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Identity</td>
<td align="left"><span class="math inline">\((-\infty, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i\)</span></td>
<td align="left"><span class="math inline">\(\eta_i\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse</td>
<td align="left"><span class="math inline">\((-\infty, \infty) \setminus \{0\}\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-1}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\exp(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Inverse-square</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\mu_i^{-2}\)</span></td>
<td align="left"><span class="math inline">\(\eta_i^{-1/2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Square-root</td>
<td align="left"><span class="math inline">\((0, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\sqrt{\mu_i}\)</span></td>
<td align="left"><span class="math inline">\(\eta_{i}^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Logit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(\mu / (1 - \mu_i)\)</span></td>
<td align="left"><span class="math inline">\(1 / (1 + \exp(-\eta_i))\)</span></td>
</tr>
<tr class="odd">
<td align="left">Probit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\Phi^{-1}(\mu_i)\)</span></td>
<td align="left"><span class="math inline">\(\Phi(\eta_i)\)</span></td>
</tr>
<tr class="even">
<td align="left">Cauchit</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\tan(\pi (\mu_i - 1 / 2))\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{\pi} \arctan(\eta_i) + \frac{1}{2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(-\log(-log(\mu_i))\)</span></td>
<td align="left"><span class="math inline">\(\exp(-\exp(-\eta_i))\)</span></td>
</tr>
<tr class="even">
<td align="left">Complementary Log-log</td>
<td align="left"><span class="math inline">\((0, 1)\)</span></td>
<td align="left"><span class="math inline">\(\log(-log(1 - \mu_i))\)</span></td>
<td align="left"><span class="math inline">\(1 - \exp(-\exp(\eta_i))\)</span></td>
</tr>
</tbody>
</table>
<table>
<caption>Common distributions and link functions. Table derived from <span class="citation">Fox (2016, 421)</span>, <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">Wikipedia</a>, and <a href="https://www.rdocumentation.org/packages/stats/topics/glm">stats</a>.</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Canonical Link</th>
<th align="left">Range of <span class="math inline">\(Y_i\)</span></th>
<th align="left">Other link functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">Identity</td>
<td align="left">real: <span class="math inline">\((-\infty, +\infty)\)</span></td>
<td align="left">log, inverse</td>
</tr>
<tr class="even">
<td align="left">Exponential</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="odd">
<td align="left">Gamma</td>
<td align="left">Inverse</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">identity, log</td>
</tr>
<tr class="even">
<td align="left">Inverse-Gaussian</td>
<td align="left">Inverse-squared</td>
<td align="left">real: <span class="math inline">\((0, +\infty)\)</span></td>
<td align="left">inverse, identity, log</td>
</tr>
<tr class="odd">
<td align="left">Bernoulli</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(\{0, 1\}\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="even">
<td align="left">Binomial</td>
<td align="left">Logit</td>
<td align="left">integer: <span class="math inline">\(0, 1, \dots, n_i\)</span></td>
<td align="left">probit, cauchit, log, cloglog</td>
</tr>
<tr class="odd">
<td align="left">Poisson</td>
<td align="left">Log</td>
<td align="left">integer: <span class="math inline">\(0, 1, 2, \dots\)</span></td>
<td align="left">identity, sqrt</td>
</tr>
<tr class="even">
<td align="left">Categorical</td>
<td align="left">Logit</td>
<td align="left"><span class="math inline">\(0, 1, \dots, K\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Multinomial</td>
<td align="left">Logit</td>
<td align="left">K-vector of integers, <span class="math inline">\(\{x_1, \dots, x_K\}\)</span> s.t. <span class="math inline">\(\sum_k x_k = N\)</span>.</td>
<td align="left"></td>
</tr>
</tbody>
</table>
</div>
<div id="count-models" class="section level2">
<h2><span class="header-section-number">8.2</span> Count Models</h2>
<div id="poisson" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Poisson</h3>
<p>The Poisson model is used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The outcome is modeled as a Poisson distribution
<span class="math display">\[
y_i \sim \dpois(\lambda_i)
\]</span>
with positive mean parameter <span class="math inline">\(\lambda_i \in (0, \infty)\)</span>.
Since <span class="math inline">\(\lambda_i\)</span> has to be positive, the most common link function is the log,
<span class="math display">\[
\log(\lambda_i) = \exp(\vec{x}_i&#39; \vec{\beta})
\]</span>
which has the inverse,
<span class="math display">\[
\lambda_i = \log(\vec{x}_i \vec{\beta})
\]</span></p>
<p>In Stan, the Poisson distribution has two implementations:</p>
<ul>
<li><code>poisson_lpdf</code></li>
<li><code>poisson_log_lpdf</code>: Poisson with a log link. This is for numeric stability.</li>
</ul>
<p>Also, <code>rstanarm</code> supports the <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">Poisson</a>.</p>
</div>
</div>
<div id="example" class="section level2">
<h2><span class="header-section-number">8.3</span> Example</h2>
<p>A regression model of bilateral sanctions for the period 1939 to 1983.
The outcome variable is the number of countries imposing sanctions.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;sanction&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a>
<a class="sourceLine" id="cb44-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb44-3" data-line-number="3"><span class="kw">library</span>(<span class="st">&quot;magrittr&quot;</span>)</a>
<a class="sourceLine" id="cb44-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-5" data-line-number="5"><span class="co">#&gt; Attaching package: &#39;magrittr&#39;</span></a>
<a class="sourceLine" id="cb44-6" data-line-number="6"><span class="co">#&gt; The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb44-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-8" data-line-number="8"><span class="co">#&gt;     set_names</span></a>
<a class="sourceLine" id="cb44-9" data-line-number="9"><span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb44-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-11" data-line-number="11"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb44-12" data-line-number="12"><span class="co">#&gt; The following object is masked from &#39;package:rstan&#39;:</span></a>
<a class="sourceLine" id="cb44-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-14" data-line-number="14"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb44-15" data-line-number="15"></a>
<a class="sourceLine" id="cb44-16" data-line-number="16">URL &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot;</span></a>
<a class="sourceLine" id="cb44-17" data-line-number="17"></a>
<a class="sourceLine" id="cb44-18" data-line-number="18">autoscale &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">center =</span> <span class="ot">TRUE</span>, <span class="dt">scale =</span> <span class="ot">TRUE</span>) {</a>
<a class="sourceLine" id="cb44-19" data-line-number="19">  nvals &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(x))</a>
<a class="sourceLine" id="cb44-20" data-line-number="20">  <span class="cf">if</span> (nvals <span class="op">&lt;=</span><span class="st"> </span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb44-21" data-line-number="21">    out &lt;-<span class="st"> </span>x</a>
<a class="sourceLine" id="cb44-22" data-line-number="22">  } <span class="cf">else</span> <span class="cf">if</span> (nvals <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb44-23" data-line-number="23">    out &lt;-<span class="st"> </span><span class="cf">if</span> (scale) {</a>
<a class="sourceLine" id="cb44-24" data-line-number="24">      (x <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">diff</span>(<span class="kw">range</span>(x, <span class="dt">finite =</span> <span class="ot">TRUE</span>))</a>
<a class="sourceLine" id="cb44-25" data-line-number="25">    } <span class="cf">else</span> x</a>
<a class="sourceLine" id="cb44-26" data-line-number="26">    <span class="cf">if</span> (center) {</a>
<a class="sourceLine" id="cb44-27" data-line-number="27">      out &lt;-<span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)</a>
<a class="sourceLine" id="cb44-28" data-line-number="28">    }</a>
<a class="sourceLine" id="cb44-29" data-line-number="29">  } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb44-30" data-line-number="30">    out &lt;-<span class="st"> </span><span class="cf">if</span> (center) {</a>
<a class="sourceLine" id="cb44-31" data-line-number="31">      x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb44-32" data-line-number="32">    } <span class="cf">else</span> x</a>
<a class="sourceLine" id="cb44-33" data-line-number="33">    out &lt;-<span class="st"> </span><span class="cf">if</span> (scale) out <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(out, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb44-34" data-line-number="34">  }</a>
<a class="sourceLine" id="cb44-35" data-line-number="35">  out</a>
<a class="sourceLine" id="cb44-36" data-line-number="36">}</a>
<a class="sourceLine" id="cb44-37" data-line-number="37"></a>
<a class="sourceLine" id="cb44-38" data-line-number="38"></a>
<a class="sourceLine" id="cb44-39" data-line-number="39">f &lt;-<span class="st"> </span>(oppose_expansion <span class="op">~</span><span class="st"> </span>dem_governor <span class="op">+</span><span class="st"> </span>obama_win <span class="op">+</span><span class="st"> </span>gop_leg <span class="op">+</span><span class="st"> </span>percent_uninsured <span class="op">+</span></a>
<a class="sourceLine" id="cb44-40" data-line-number="40"><span class="st">      </span>income <span class="op">+</span><span class="st"> </span>percent_nonwhite <span class="op">+</span><span class="st"> </span>percent_metro)</a>
<a class="sourceLine" id="cb44-41" data-line-number="41"></a>
<a class="sourceLine" id="cb44-42" data-line-number="42">br &lt;-<span class="st"> </span><span class="kw">read_csv</span>(URL) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-43" data-line-number="43"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">oppose_expansion =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>support_expansion,</a>
<a class="sourceLine" id="cb44-44" data-line-number="44">         <span class="dt">dem_governor =</span> <span class="dv">-1</span> <span class="op">*</span><span class="st"> </span>gop_governor,</a>
<a class="sourceLine" id="cb44-45" data-line-number="45">         <span class="dt">obama_win =</span> <span class="kw">as.integer</span>(obama_share <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb44-46" data-line-number="46">         <span class="dt">percent_nonwhite =</span> percent_black <span class="op">+</span><span class="st"> </span>percent_hispanic) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-47" data-line-number="47"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">gop_leg =</span> legGOP) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-48" data-line-number="48"><span class="st">  </span><span class="co"># keep only variables in the formula</span></a>
<a class="sourceLine" id="cb44-49" data-line-number="49"><span class="st">  </span><span class="kw">model.frame</span>(f, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-50" data-line-number="50"><span class="st">  </span><span class="co"># drop missing values (if any?)</span></a>
<a class="sourceLine" id="cb44-51" data-line-number="51"><span class="st">  </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb44-52" data-line-number="52"><span class="co">#&gt; Parsed with column specification:</span></a>
<a class="sourceLine" id="cb44-53" data-line-number="53"><span class="co">#&gt; cols(</span></a>
<a class="sourceLine" id="cb44-54" data-line-number="54"><span class="co">#&gt;   .default = col_integer(),</span></a>
<a class="sourceLine" id="cb44-55" data-line-number="55"><span class="co">#&gt;   state = col_character(),</span></a>
<a class="sourceLine" id="cb44-56" data-line-number="56"><span class="co">#&gt;   state_abbr = col_character(),</span></a>
<a class="sourceLine" id="cb44-57" data-line-number="57"><span class="co">#&gt;   house12 = col_double(),</span></a>
<a class="sourceLine" id="cb44-58" data-line-number="58"><span class="co">#&gt;   sen12 = col_double(),</span></a>
<a class="sourceLine" id="cb44-59" data-line-number="59"><span class="co">#&gt;   support_expansion_new = col_character(),</span></a>
<a class="sourceLine" id="cb44-60" data-line-number="60"><span class="co">#&gt;   percent_uninsured = col_double(),</span></a>
<a class="sourceLine" id="cb44-61" data-line-number="61"><span class="co">#&gt;   ideology = col_double(),</span></a>
<a class="sourceLine" id="cb44-62" data-line-number="62"><span class="co">#&gt;   income = col_double(),</span></a>
<a class="sourceLine" id="cb44-63" data-line-number="63"><span class="co">#&gt;   percent_black = col_double(),</span></a>
<a class="sourceLine" id="cb44-64" data-line-number="64"><span class="co">#&gt;   percent_hispanic = col_double(),</span></a>
<a class="sourceLine" id="cb44-65" data-line-number="65"><span class="co">#&gt;   percent_metro = col_double(),</span></a>
<a class="sourceLine" id="cb44-66" data-line-number="66"><span class="co">#&gt;   dsh = col_double(),</span></a>
<a class="sourceLine" id="cb44-67" data-line-number="67"><span class="co">#&gt;   obama_share = col_double()</span></a>
<a class="sourceLine" id="cb44-68" data-line-number="68"><span class="co">#&gt; )</span></a>
<a class="sourceLine" id="cb44-69" data-line-number="69"><span class="co">#&gt; See spec(...) for full column specifications.</span></a>
<a class="sourceLine" id="cb44-70" data-line-number="70"></a>
<a class="sourceLine" id="cb44-71" data-line-number="71">br_scaled &lt;-<span class="st"> </span>br <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb44-72" data-line-number="72"><span class="st">  </span><span class="co"># Autoscale all vars but response</span></a>
<a class="sourceLine" id="cb44-73" data-line-number="73"><span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(<span class="op">-</span>oppose_expansion), autoscale)</a>
<a class="sourceLine" id="cb44-74" data-line-number="74"></a>
<a class="sourceLine" id="cb44-75" data-line-number="75"><span class="kw">glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a>
<a class="sourceLine" id="cb44-76" data-line-number="76"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-77" data-line-number="77"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb44-78" data-line-number="78"><span class="co">#&gt; glm(formula = f, family = &quot;binomial&quot;, data = br)</span></a>
<a class="sourceLine" id="cb44-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-80" data-line-number="80"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb44-81" data-line-number="81"><span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span></a>
<a class="sourceLine" id="cb44-82" data-line-number="82"><span class="co">#&gt; -2.374  -0.461  -0.131   0.630   2.207  </span></a>
<a class="sourceLine" id="cb44-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-84" data-line-number="84"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb44-85" data-line-number="85"><span class="co">#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)   </span></a>
<a class="sourceLine" id="cb44-86" data-line-number="86"><span class="co">#&gt; (Intercept)         4.5103     4.5986    0.98    0.327   </span></a>
<a class="sourceLine" id="cb44-87" data-line-number="87"><span class="co">#&gt; dem_governor       -4.1556     1.4794   -2.81    0.005 **</span></a>
<a class="sourceLine" id="cb44-88" data-line-number="88"><span class="co">#&gt; obama_win          -2.1470     1.3429   -1.60    0.110   </span></a>
<a class="sourceLine" id="cb44-89" data-line-number="89"><span class="co">#&gt; gop_leg            -0.1865     1.2974   -0.14    0.886   </span></a>
<a class="sourceLine" id="cb44-90" data-line-number="90"><span class="co">#&gt; percent_uninsured  -0.3072     0.1651   -1.86    0.063 . </span></a>
<a class="sourceLine" id="cb44-91" data-line-number="91"><span class="co">#&gt; income             -0.0421     0.0776   -0.54    0.587   </span></a>
<a class="sourceLine" id="cb44-92" data-line-number="92"><span class="co">#&gt; percent_nonwhite   17.8505    48.3030    0.37    0.712   </span></a>
<a class="sourceLine" id="cb44-93" data-line-number="93"><span class="co">#&gt; percent_metro     -12.4390    32.4446   -0.38    0.701   </span></a>
<a class="sourceLine" id="cb44-94" data-line-number="94"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb44-95" data-line-number="95"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb44-96" data-line-number="96"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-97" data-line-number="97"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb44-98" data-line-number="98"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-99" data-line-number="99"><span class="co">#&gt;     Null deviance: 68.593  on 49  degrees of freedom</span></a>
<a class="sourceLine" id="cb44-100" data-line-number="100"><span class="co">#&gt; Residual deviance: 37.948  on 42  degrees of freedom</span></a>
<a class="sourceLine" id="cb44-101" data-line-number="101"><span class="co">#&gt; AIC: 53.95</span></a>
<a class="sourceLine" id="cb44-102" data-line-number="102"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-103" data-line-number="103"><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></a>
<a class="sourceLine" id="cb44-104" data-line-number="104"></a>
<a class="sourceLine" id="cb44-105" data-line-number="105"><span class="kw">library</span>(<span class="st">&quot;rstanarm&quot;</span>)</a>
<a class="sourceLine" id="cb44-106" data-line-number="106"></a>
<a class="sourceLine" id="cb44-107" data-line-number="107">fit1 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb44-108" data-line-number="108"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-109" data-line-number="109"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb44-110" data-line-number="110"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-111" data-line-number="111"><span class="co">#&gt; Gradient evaluation took 7.6e-05 seconds</span></a>
<a class="sourceLine" id="cb44-112" data-line-number="112"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.</span></a>
<a class="sourceLine" id="cb44-113" data-line-number="113"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-114" data-line-number="114"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-115" data-line-number="115"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-116" data-line-number="116"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-117" data-line-number="117"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-118" data-line-number="118"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-119" data-line-number="119"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-120" data-line-number="120"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-121" data-line-number="121"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-122" data-line-number="122"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-123" data-line-number="123"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-124" data-line-number="124"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-125" data-line-number="125"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-126" data-line-number="126"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-127" data-line-number="127"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-128" data-line-number="128"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-129" data-line-number="129"><span class="co">#&gt;  Elapsed Time: 0.227826 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-130" data-line-number="130"><span class="co">#&gt;                0.216907 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-131" data-line-number="131"><span class="co">#&gt;                0.444733 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-133" data-line-number="133"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-134" data-line-number="134"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb44-135" data-line-number="135"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-136" data-line-number="136"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb44-137" data-line-number="137"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb44-138" data-line-number="138"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-139" data-line-number="139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-140" data-line-number="140"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-141" data-line-number="141"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-142" data-line-number="142"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-143" data-line-number="143"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-144" data-line-number="144"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-145" data-line-number="145"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-146" data-line-number="146"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-147" data-line-number="147"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-148" data-line-number="148"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-149" data-line-number="149"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-150" data-line-number="150"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-151" data-line-number="151"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-152" data-line-number="152"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-153" data-line-number="153"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-154" data-line-number="154"><span class="co">#&gt;  Elapsed Time: 0.2258 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-155" data-line-number="155"><span class="co">#&gt;                0.234074 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-156" data-line-number="156"><span class="co">#&gt;                0.459874 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-158" data-line-number="158"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-159" data-line-number="159"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb44-160" data-line-number="160"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-161" data-line-number="161"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb44-162" data-line-number="162"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb44-163" data-line-number="163"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-164" data-line-number="164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-165" data-line-number="165"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-166" data-line-number="166"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-167" data-line-number="167"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-168" data-line-number="168"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-169" data-line-number="169"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-170" data-line-number="170"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-171" data-line-number="171"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-172" data-line-number="172"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-173" data-line-number="173"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-174" data-line-number="174"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-175" data-line-number="175"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-176" data-line-number="176"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-177" data-line-number="177"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-178" data-line-number="178"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-179" data-line-number="179"><span class="co">#&gt;  Elapsed Time: 0.232678 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-180" data-line-number="180"><span class="co">#&gt;                0.224351 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-181" data-line-number="181"><span class="co">#&gt;                0.457029 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-183" data-line-number="183"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-184" data-line-number="184"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb44-185" data-line-number="185"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-186" data-line-number="186"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb44-187" data-line-number="187"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb44-188" data-line-number="188"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-189" data-line-number="189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-190" data-line-number="190"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-191" data-line-number="191"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-192" data-line-number="192"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-193" data-line-number="193"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-194" data-line-number="194"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-195" data-line-number="195"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-196" data-line-number="196"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-197" data-line-number="197"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-198" data-line-number="198"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-199" data-line-number="199"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-200" data-line-number="200"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-201" data-line-number="201"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-202" data-line-number="202"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-203" data-line-number="203"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-204" data-line-number="204"><span class="co">#&gt;  Elapsed Time: 0.221657 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-205" data-line-number="205"><span class="co">#&gt;                0.224032 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-206" data-line-number="206"><span class="co">#&gt;                0.445689 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-207" data-line-number="207"></a>
<a class="sourceLine" id="cb44-208" data-line-number="208">fit2 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">prior =</span> <span class="ot">NULL</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb44-209" data-line-number="209"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-210" data-line-number="210"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb44-211" data-line-number="211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-212" data-line-number="212"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb44-213" data-line-number="213"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb44-214" data-line-number="214"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-215" data-line-number="215"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-216" data-line-number="216"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-217" data-line-number="217"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-218" data-line-number="218"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-219" data-line-number="219"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-220" data-line-number="220"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-221" data-line-number="221"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-222" data-line-number="222"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-223" data-line-number="223"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-224" data-line-number="224"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-225" data-line-number="225"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-226" data-line-number="226"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-227" data-line-number="227"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-228" data-line-number="228"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-229" data-line-number="229"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-230" data-line-number="230"><span class="co">#&gt;  Elapsed Time: 1.56167 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-231" data-line-number="231"><span class="co">#&gt;                0.243438 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-232" data-line-number="232"><span class="co">#&gt;                1.80511 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-233" data-line-number="233"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-234" data-line-number="234"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-235" data-line-number="235"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb44-236" data-line-number="236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-237" data-line-number="237"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb44-238" data-line-number="238"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb44-239" data-line-number="239"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-240" data-line-number="240"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-241" data-line-number="241"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-242" data-line-number="242"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-243" data-line-number="243"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-244" data-line-number="244"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-245" data-line-number="245"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-246" data-line-number="246"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-247" data-line-number="247"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-248" data-line-number="248"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-249" data-line-number="249"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-250" data-line-number="250"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-251" data-line-number="251"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-252" data-line-number="252"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-253" data-line-number="253"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-254" data-line-number="254"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-255" data-line-number="255"><span class="co">#&gt;  Elapsed Time: 1.37833 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-256" data-line-number="256"><span class="co">#&gt;                0.208435 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-257" data-line-number="257"><span class="co">#&gt;                1.58676 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-258" data-line-number="258"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-259" data-line-number="259"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-260" data-line-number="260"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb44-261" data-line-number="261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-262" data-line-number="262"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb44-263" data-line-number="263"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb44-264" data-line-number="264"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-265" data-line-number="265"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-266" data-line-number="266"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-267" data-line-number="267"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-268" data-line-number="268"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-269" data-line-number="269"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-270" data-line-number="270"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-271" data-line-number="271"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-272" data-line-number="272"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-273" data-line-number="273"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-274" data-line-number="274"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-275" data-line-number="275"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-276" data-line-number="276"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-277" data-line-number="277"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-278" data-line-number="278"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-279" data-line-number="279"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-280" data-line-number="280"><span class="co">#&gt;  Elapsed Time: 1.06808 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-281" data-line-number="281"><span class="co">#&gt;                0.245541 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-282" data-line-number="282"><span class="co">#&gt;                1.31363 seconds (Total)</span></a>
<a class="sourceLine" id="cb44-283" data-line-number="283"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-284" data-line-number="284"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-285" data-line-number="285"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb44-286" data-line-number="286"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-287" data-line-number="287"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb44-288" data-line-number="288"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb44-289" data-line-number="289"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb44-290" data-line-number="290"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-291" data-line-number="291"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-292" data-line-number="292"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-293" data-line-number="293"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-294" data-line-number="294"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-295" data-line-number="295"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-296" data-line-number="296"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-297" data-line-number="297"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb44-298" data-line-number="298"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-299" data-line-number="299"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-300" data-line-number="300"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-301" data-line-number="301"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-302" data-line-number="302"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-303" data-line-number="303"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb44-304" data-line-number="304"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb44-305" data-line-number="305"><span class="co">#&gt;  Elapsed Time: 1.21401 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb44-306" data-line-number="306"><span class="co">#&gt;                0.217275 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb44-307" data-line-number="307"><span class="co">#&gt;                1.43128 seconds (Total)</span></a></code></pre></div>
</div>
<div id="negative-binomial" class="section level2">
<h2><span class="header-section-number">8.4</span> Negative Binomial</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a> model is also used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The Poisson distribution has the restriction that the mean is equal to the variance, <span class="math inline">\(\E(X) = \Var(X) = \lambda\)</span>.
The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean).</p>
<p>The outcome is modeled as a negative binomial distribution,
<span class="math display">\[
y_i \sim \dbinom(\alpha_i, \beta)
\]</span>
with shape <span class="math inline">\(\alpha \in \R^{+}\)</span> and inverse scale <span class="math inline">\(\beta \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \alpha_i / \beta\)</span> and <span class="math inline">\(\Var(Y) = \frac{\alpha_i}{\beta^2}(\beta + 1)\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\alpha_i &amp;= \mu_i / \beta
\end{aligned}
\]</span></p>
<p><strong>Important</strong> The negative binomial distribution has many different parameterizations.
An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter.
<span class="math display">\[
y_i \sim \dnbinomalt(\mu_i, \phi)
\]</span>
with location parameter <span class="math inline">\(\mu \in \R^{+}\)</span> and over-dispersion parameter <span class="math inline">\(\phi \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \mu_i\)</span> and <span class="math inline">\(\Var(Y) = \mu_i + \frac{\mu_i^2}{\phi}\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\end{aligned}
\]</span></p>
<p>In Stan, there are multiple parameterizations of the</p>
<ul>
<li><code>neg_binomial_lpdf(y | alpha, beta)</code>with shape parameter <code>alpha</code> and inverse scale parameter <code>beta</code>.</li>
<li><code>neg_binomial_2_lpdf(y | mu, phi)</code> with mean <code>mu</code> and over-dispersion parameter <code>phi</code>.</li>
<li><code>neg_binomial_2_log_lpdf(y | eta, phi)</code> with log-mean <code>eta</code> and over-dispersion parameter <code>phi</code></li>
</ul>
<p>Also, <code>rstanarm</code> supports Poisson and <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">negative binomial models</a>.</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Ch 16)</span></li>
</ul>
<div id="references-3" class="section level3">
<h3><span class="header-section-number">8.4.1</span> References</h3>
<p>For general references on count models see</p>
<ul>
<li><span class="citation">Gelman and Hill (2007, 109–16)</span></li>
<li><span class="citation">McElreath (2016 Ch 10)</span></li>
<li><span class="citation">Fox (2016 Ch. 14)</span></li>
<li><span class="citation">Gelman et al. (2013 Ch. 16)</span></li>
</ul>
</div>
</div>
<div id="multinomial-categorical-models" class="section level2">
<h2><span class="header-section-number">8.5</span> Multinomial / Categorical Models</h2>
</div>
<div id="gamma-regression" class="section level2">
<h2><span class="header-section-number">8.6</span> Gamma Regression</h2>
<p>The response variable is continuous and positive.
In gamma regression, the coefficient of variation is constant rather than the variance.
<span class="math display">\[
y_i \sim \dgamma(\alpha_i, \beta)
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
\alpha_i &amp;= \mu_i / \beta \\
\mu_i &amp;= \vec{x}_i \vec{\gamma}
\end{aligned}
\]</span></p>
<p>In Stan,</p>
<ul>
<li><code>gamma(y | alpha, beta)</code> with shape parameter <span class="math inline">\(\alpha &gt; 0\)</span> and inverse scale parameter <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / \beta\)</span> and <span class="math inline">\(\Var(Y) = \alpha / \beta^2\)</span>.</li>
</ul>
</div>
<div id="beta-regression" class="section level2">
<h2><span class="header-section-number">8.7</span> Beta Regression</h2>
<p>This is for a response variable that is a proportion, <span class="math inline">\(y_i \in (0, 1)\)</span>,
<span class="math display">\[
y_i \sim \dbeta(\alpha_i, \beta_i)
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= g^{-1}(\vec{x}_i&#39; \vec{\gamma}) \\
\alpha_i &amp;= \mu_i \phi \\
\beta_i &amp;= (1 - \mu_i) \phi 
\end{aligned}
\]</span>
Additionally, the <span class="math inline">\(\phi\)</span> parameter could also be modeled.</p>
<p>In Stan:</p>
<ul>
<li><code>beta(y | alpha, beta)</code> with positive prior successes plus one, <span class="math inline">\(\alpha &gt; 0\)</span>, and negative prior failures plus one, <span class="math inline">\(\beta &gt; 0\)</span>. Then <span class="math inline">\(\E(Y) = \alpha / (\alpha + \beta)\)</span> and <span class="math inline">\(\Var(Y) = \alpha\beta / ((\alpha + \beta)^2 (\alpha + \beta + 1))\)</span>.</li>
</ul>
<p><strong>rstanarm</strong> function <a href="https://www.rdocumentation.org/packages/rstasnarm/topics/stan_betareg">rstasnarm</a></p>
<p>See:</p>
<ul>
<li><span class="citation">Ferrari and Cribari-Neto (2004)</span>, <span class="citation">Cribari-Neto and Zeileis (2010)</span>, and <span class="citation">Grün, Kosmidis, and Zeileis (2012)</span> on beta regression.</li>
<li><strong>rstanarm</strong> documentation <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/betareg.html">Modeling Rates/Proportions using Beta Regression with rstanarm</a></li>
</ul>
</div>
<div id="references-4" class="section level2">
<h2><span class="header-section-number">8.8</span> References</h2>
<p><span class="citation">Gelman et al. (2013 Ch 16)</span>, <span class="citation">Gelman and Hill (2007 Ch. 5-6)</span>, <span class="citation">McElreath (2016 Ch. 9)</span>. <span class="citation">King (1998)</span> discusses MLE estimation of many common GLM models.</p>
<p>Many econometrics/statistics textbooks, e.g. <span class="citation">Fox (2016)</span>, discuss GLMs. Though they are not derived from a Bayesian context, they can easily transferred.</p>
<!--chapter:end:generalized-linear-models.Rmd-->
</div>
</div>
<div id="binomial-models" class="section level1">
<h1><span class="header-section-number">9</span> Binomial Models</h1>
<p>Binomial models are used to an outcome that is a bounded integer,
<span class="math display">\[
y_i \in 0, 1, 2, \dots, n .
\]</span>
The outcome is distributed Binomial,
<span class="math display">\[
\begin{aligned}[t]
y_i \sim \dbin \left(n_i, \pi \right)
\end{aligned}
\]</span></p>
<p>A <em>binary outcome</em> is a common special case,
<span class="math display">\[
y_i \in \{0, 1\},
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dbin \left(1, \pi \right) &amp; \text{for all $i$} \\
\end{aligned}
\]</span></p>
<p>Depending on the <a href="#link-functions">link function</a>, these are logit and probit models that appear in the literature.</p>
<div id="link-functions-link-function" class="section level3">
<h3><span class="header-section-number">9.0.1</span> Link Functions {link-function}</h3>
<p>The parameter <span class="math inline">\(\pi \in (0, 1)\)</span> is often modeled with a link function is and a linear predictor.
<span class="math display">\[
\pi_i = g^{-1}(\vec{x}_i \vec{\beta})
\]</span></p>
<p>There are several common link functions, but they all have to map <span class="math inline">\(R \to (0, 1)\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<ul>
<li><strong>Logit:</strong> The logistic function,
<span class="math display">\[
  \pi_i = \logistic(x_i\T \beta) = \frac{1}{1 + \exp(- x_i\T\beta)} .
  \]</span>
Stan function <code>softmax</code>.</li>
<li><p><strong>Probit:</strong> The CDF of the normal distribution.
<span class="math display">\[
  \pi_i = \Phi(x_i\T \beta)
  \]</span>
Stan function <code>normal_cdf</code>.</p></li>
<li><strong>cauchit</strong>: The CDF of the Cauchy distribution. Stan function <code>cauchy_cdf</code>.</li>
<li><p><strong>cloglog</strong>: The inverse of the conditional log-log function (cloglog) is
<span class="math display">\[
  \pi_i = 1 - \exp(-\exp(x_i\T \beta)) .
  \]</span>
Stan function <code>inv_cloglog</code>.</p></li>
</ul>
<p>Of these link functions, the probit has the narrowest tails (sensitivity to outliers), followed by the logit, and cauchit.
The <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Complementary_log-log_.28cloglog.29">cloglog</a> function is different in that it is asymmetric.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>
At zero its value is above 0.5, whereas the cauchit, logit, and probit links all equal 0.5 at 0,</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="kw">make.link</span>(<span class="st">&quot;cloglog&quot;</span>)<span class="op">$</span><span class="kw">linkinv</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="co">#&gt; [1] 0.632</span></a></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw">map</span>(<span class="kw">c</span>(<span class="st">&quot;logit&quot;</span>, <span class="st">&quot;probit&quot;</span>, <span class="st">&quot;cauchit&quot;</span>, <span class="st">&quot;cloglog&quot;</span>),  make.link) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="kw">map_df</span>(</a>
<a class="sourceLine" id="cb46-3" data-line-number="3">  <span class="cf">function</span>(link) {</a>
<a class="sourceLine" id="cb46-4" data-line-number="4">    <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">101</span>),</a>
<a class="sourceLine" id="cb46-5" data-line-number="5">           <span class="dt">y =</span> link<span class="op">$</span><span class="kw">linkinv</span>(x),</a>
<a class="sourceLine" id="cb46-6" data-line-number="6">           <span class="dt">link_name =</span> link<span class="op">$</span>name)</a>
<a class="sourceLine" id="cb46-7" data-line-number="7">  }</a>
<a class="sourceLine" id="cb46-8" data-line-number="8">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb46-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">colour =</span> link_name)) <span class="op">+</span></a>
<a class="sourceLine" id="cb46-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_line</span>()</a></code></pre></div>
<p><img src="binomial_files/figure-html/unnamed-chunk-3-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="stan" class="section level3">
<h3><span class="header-section-number">9.0.2</span> Stan</h3>
<p>In Stan, the Binomial distribution has two implementations:</p>
<ul>
<li><code>binomial_lpdf</code></li>
<li><code>binomial_logit_lpdf</code>.</li>
</ul>
<p>The later implementation is for numeric stability.
Taking an exponential of a value can be numerically unstable, and <code>binomial_logit_lpdf</code> input is on the logit scale:
Whereas,
<span class="math display">\[
y_i \sim \mathsf{binomial}(1 / (1 + \exp(x_i \beta)))
\]</span>
the following is true,
<span class="math display">\[
y_i \sim \mathsf{binomial\_logit}(x_i \beta)
\]</span></p>
</div>
<div id="example-vote-turnout" class="section level3">
<h3><span class="header-section-number">9.0.3</span> Example: Vote Turnout</h3>
<p>A general Stan model for estimating logit models is:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1">mod1</a></code></pre></div>
<pre>
  <code class="stan">// Logit Model
//
// y ~ Bernoulli(p)
// p = a + X B
// b0 \sim cauchy(0, 10)
// b \sim cauchy(0, 2.5)
data {
  // number of observations
  int N;
  // response
  // vectors are only real numbers
  // need to use an array
  int<lower = 0, upper = 1> y[N];
  // number of columns in the design matrix X
  int K;
  // design matrix X
  // should not include an intercept
  matrix [N, K] X;
}
transformed data {
  # default scales same as rstanarm
  # assume data is centered and scaled
  real<lower = 0.0> a_scale;
  vector<lower = 0.0>[K] b_scale;
  a_scale = 10.0;
  b_scale = rep_vector(2.5, K);
}
parameters {
  // regression coefficient vector
  real a;
  vector[K] b;
}
transformed parameters {
  vector<lower = 0.0, upper = 1.0>[N] p;
  p = inv_logit(a + X * b);
}
model {
  // priors
  a ~ normal(0.0, a_scale);
  b ~ normal(0.0, b_scale);
  // likelihood
  y ~ binomial(1, p);
}
generated quantities {
  // simulate data from the posterior
  vector[N] y_rep;
  // log-likelihood posterior
  vector[N] log_lik;
  for (i in 1:N) {
    y_rep[i] = binomial_rng(1, p[i]);
    log_lik[i] = binomial_lpmf(y[i] | 1, p[i]);
  }
}</code>
</pre>
<p>Estimate a model of vote turnout in the 1992 from the American National Election Survey (ANES).
The data is from <a href="https://www.rdocumentation.org/packages/Zelig/topics/turnout">Zelig</a>.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;turnout&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a></code></pre></div>
<p>Vote choice (<code>vote</code>) is modeled as a function of age, income, and race.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">mod_formula &lt;-<span class="st"> </span>vote <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>educate <span class="op">+</span><span class="st"> </span>race <span class="op">-</span><span class="st"> </span><span class="dv">1</span></a></code></pre></div>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1">mod1_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(mod_formula, <span class="dt">data =</span> turnout)</a></code></pre></div>
</div>
<div id="separation" class="section level3">
<h3><span class="header-section-number">9.0.4</span> Separation</h3>
<p>*<a href="#separation">Separation</a>(<a href="https://en.wikipedia.org/wiki/Separation_(statistics)*" class="uri">https://en.wikipedia.org/wiki/Separation_(statistics)*</a> is when a predictor perfectly predicts a binary response variable <span class="citation">(Rainey 2016a, <span class="citation">@Zorn2005a</span>)</span></p>
<ul>
<li><em>complete separation:</em> the predictor perfectly predicts both 0’s and 1’s.</li>
<li><em>quasi-complete separation:</em> the predictor perfectly predicts either 0’s or 1’s.</li>
</ul>
<p>This is related and similar to identification in MLE and multicollinearity in OLS.</p>
<p>The general solution is to penalize the likelihood, which in a Bayesian context is equivalent to placing a proper prior on the coefficient of the separating variable.</p>
<p>Using a weakly informative prior such as those suggested by is sufficient to solve separation,
<span class="math display">\[
\beta_k \sim \dnorm(0, 2.5)
\]</span>
where all the columns of <span class="math inline">\(\code{x}\)</span> are assumed to mean zero, unit variance (or otherwise standardized).
The half-Cauchy prior, <span class="math inline">\(\dhalfcauchy(0, 2.5)\)</span>, suggested in <span class="citation">Gelman et al. (2008)</span> is insufficiently informative to to deal with separation <span class="citation">(J. Ghosh, Li, and Mitra 2015)</span>, but finite-variance weakly informative Student-t or Normal distributions will work.</p>
<p>These are the priors suggested by <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan</a> and used by default in <strong>rstanarm</strong> <a href="https://www.rdocumentation.org/packages/rstanarm/topics/stan_glm">rstanarm</a>.</p>
<p><span class="citation">Rainey (2016a)</span> provides a mixed MLE/Bayesian simulation based approach to apply a prior to the variable with separation, while keeping the other coefficients at their MLE values.
Since the results are highly sensitive to the prior, multiple priors should be tried (informative, skeptical, and enthusiastic).</p>
<p><span class="citation">Firth (1993)</span> suggests the Jeffreys invariant prior,
<span class="math display">\[
p(\beta_k) \propto |I(\beta)|^{\frac{1}{2}}
\]</span>
where <span class="math inline">\(|I(\beta)|\)</span> is the information matrix,
<span class="math display">\[
\begin{aligned}[t]
I(\beta) &amp;= \mat{X}\T \mat{W} \mat{X} \\
\mat{W} &amp;= \diag(\pi_i (1 - \pi_i))
\end{aligned}
\]</span>
This is the Jeffreys invariant prior. This was also recommended <span class="citation">Zorn (2005)</span>.</p>
<p><span class="citation">Greenland and Mansournia (2015)</span> suggest a log-F prior distribution which has an intuitive interpretation related to the number of observations.</p>
<div id="example-support-of-aca-medicaid-expansion" class="section level4">
<h4><span class="header-section-number">9.0.4.1</span> Example: Support of ACA Medicaid Expansion</h4>
<p>This example is from <span class="citation">Rainey (2016a)</span> from the original paper <span class="citation">Barrilleaux and Rainey (2014)</span>
with replication code <a href="https://github.com/carlislerainey/separation">here</a>.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a>
<a class="sourceLine" id="cb51-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb51-3" data-line-number="3"><span class="kw">library</span>(<span class="st">&quot;magrittr&quot;</span>)</a>
<a class="sourceLine" id="cb51-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-5" data-line-number="5"><span class="co">#&gt; Attaching package: &#39;magrittr&#39;</span></a>
<a class="sourceLine" id="cb51-6" data-line-number="6"><span class="co">#&gt; The following object is masked from &#39;package:purrr&#39;:</span></a>
<a class="sourceLine" id="cb51-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-8" data-line-number="8"><span class="co">#&gt;     set_names</span></a>
<a class="sourceLine" id="cb51-9" data-line-number="9"><span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb51-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-11" data-line-number="11"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb51-12" data-line-number="12"><span class="co">#&gt; The following object is masked from &#39;package:rstan&#39;:</span></a>
<a class="sourceLine" id="cb51-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-14" data-line-number="14"><span class="co">#&gt;     extract</span></a>
<a class="sourceLine" id="cb51-15" data-line-number="15"></a>
<a class="sourceLine" id="cb51-16" data-line-number="16">URL &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/carlislerainey/priors-for-separation/master/br-replication/data/need.csv&quot;</span></a>
<a class="sourceLine" id="cb51-17" data-line-number="17"></a>
<a class="sourceLine" id="cb51-18" data-line-number="18"></a>
<a class="sourceLine" id="cb51-19" data-line-number="19"></a>
<a class="sourceLine" id="cb51-20" data-line-number="20">f &lt;-<span class="st"> </span>(oppose_expansion <span class="op">~</span><span class="st"> </span>dem_governor <span class="op">+</span><span class="st"> </span>obama_win <span class="op">+</span><span class="st"> </span>gop_leg <span class="op">+</span><span class="st"> </span>percent_uninsured <span class="op">+</span></a>
<a class="sourceLine" id="cb51-21" data-line-number="21"><span class="st">      </span>income <span class="op">+</span><span class="st"> </span>percent_nonwhite <span class="op">+</span><span class="st"> </span>percent_metro)</a>
<a class="sourceLine" id="cb51-22" data-line-number="22"></a>
<a class="sourceLine" id="cb51-23" data-line-number="23">br &lt;-<span class="st"> </span><span class="kw">read_csv</span>(URL) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-24" data-line-number="24"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">oppose_expansion =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>support_expansion,</a>
<a class="sourceLine" id="cb51-25" data-line-number="25">         <span class="dt">dem_governor =</span> <span class="dv">-1</span> <span class="op">*</span><span class="st"> </span>gop_governor,</a>
<a class="sourceLine" id="cb51-26" data-line-number="26">         <span class="dt">obama_win =</span> <span class="kw">as.integer</span>(obama_share <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>),</a>
<a class="sourceLine" id="cb51-27" data-line-number="27">         <span class="dt">percent_nonwhite =</span> percent_black <span class="op">+</span><span class="st"> </span>percent_hispanic) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-28" data-line-number="28"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">gop_leg =</span> legGOP) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-29" data-line-number="29"><span class="st">  </span><span class="co"># keep only variables in the formula</span></a>
<a class="sourceLine" id="cb51-30" data-line-number="30"><span class="st">  </span><span class="kw">model.frame</span>(f, <span class="dt">data =</span> .) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-31" data-line-number="31"><span class="st">  </span><span class="co"># drop missing values (if any?)</span></a>
<a class="sourceLine" id="cb51-32" data-line-number="32"><span class="st">  </span><span class="kw">drop_na</span>()</a>
<a class="sourceLine" id="cb51-33" data-line-number="33"><span class="co">#&gt; Parsed with column specification:</span></a>
<a class="sourceLine" id="cb51-34" data-line-number="34"><span class="co">#&gt; cols(</span></a>
<a class="sourceLine" id="cb51-35" data-line-number="35"><span class="co">#&gt;   .default = col_integer(),</span></a>
<a class="sourceLine" id="cb51-36" data-line-number="36"><span class="co">#&gt;   state = col_character(),</span></a>
<a class="sourceLine" id="cb51-37" data-line-number="37"><span class="co">#&gt;   state_abbr = col_character(),</span></a>
<a class="sourceLine" id="cb51-38" data-line-number="38"><span class="co">#&gt;   house12 = col_double(),</span></a>
<a class="sourceLine" id="cb51-39" data-line-number="39"><span class="co">#&gt;   sen12 = col_double(),</span></a>
<a class="sourceLine" id="cb51-40" data-line-number="40"><span class="co">#&gt;   support_expansion_new = col_character(),</span></a>
<a class="sourceLine" id="cb51-41" data-line-number="41"><span class="co">#&gt;   percent_uninsured = col_double(),</span></a>
<a class="sourceLine" id="cb51-42" data-line-number="42"><span class="co">#&gt;   ideology = col_double(),</span></a>
<a class="sourceLine" id="cb51-43" data-line-number="43"><span class="co">#&gt;   income = col_double(),</span></a>
<a class="sourceLine" id="cb51-44" data-line-number="44"><span class="co">#&gt;   percent_black = col_double(),</span></a>
<a class="sourceLine" id="cb51-45" data-line-number="45"><span class="co">#&gt;   percent_hispanic = col_double(),</span></a>
<a class="sourceLine" id="cb51-46" data-line-number="46"><span class="co">#&gt;   percent_metro = col_double(),</span></a>
<a class="sourceLine" id="cb51-47" data-line-number="47"><span class="co">#&gt;   dsh = col_double(),</span></a>
<a class="sourceLine" id="cb51-48" data-line-number="48"><span class="co">#&gt;   obama_share = col_double()</span></a>
<a class="sourceLine" id="cb51-49" data-line-number="49"><span class="co">#&gt; )</span></a>
<a class="sourceLine" id="cb51-50" data-line-number="50"><span class="co">#&gt; See spec(...) for full column specifications.</span></a>
<a class="sourceLine" id="cb51-51" data-line-number="51"></a>
<a class="sourceLine" id="cb51-52" data-line-number="52">br_scaled &lt;-<span class="st"> </span>br <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb51-53" data-line-number="53"><span class="st">  </span><span class="co"># Autoscale all vars but response</span></a>
<a class="sourceLine" id="cb51-54" data-line-number="54"><span class="st">  </span><span class="kw">mutate_at</span>(<span class="kw">vars</span>(<span class="op">-</span>oppose_expansion), autoscale)</a>
<a class="sourceLine" id="cb51-55" data-line-number="55"></a>
<a class="sourceLine" id="cb51-56" data-line-number="56"><span class="kw">glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</a>
<a class="sourceLine" id="cb51-57" data-line-number="57"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-58" data-line-number="58"><span class="co">#&gt; Call:</span></a>
<a class="sourceLine" id="cb51-59" data-line-number="59"><span class="co">#&gt; glm(formula = f, family = &quot;binomial&quot;, data = br)</span></a>
<a class="sourceLine" id="cb51-60" data-line-number="60"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-61" data-line-number="61"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb51-62" data-line-number="62"><span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span></a>
<a class="sourceLine" id="cb51-63" data-line-number="63"><span class="co">#&gt; -2.374  -0.461  -0.131   0.630   2.207  </span></a>
<a class="sourceLine" id="cb51-64" data-line-number="64"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-65" data-line-number="65"><span class="co">#&gt; Coefficients:</span></a>
<a class="sourceLine" id="cb51-66" data-line-number="66"><span class="co">#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)   </span></a>
<a class="sourceLine" id="cb51-67" data-line-number="67"><span class="co">#&gt; (Intercept)         4.5103     4.5986    0.98    0.327   </span></a>
<a class="sourceLine" id="cb51-68" data-line-number="68"><span class="co">#&gt; dem_governor       -4.1556     1.4794   -2.81    0.005 **</span></a>
<a class="sourceLine" id="cb51-69" data-line-number="69"><span class="co">#&gt; obama_win          -2.1470     1.3429   -1.60    0.110   </span></a>
<a class="sourceLine" id="cb51-70" data-line-number="70"><span class="co">#&gt; gop_leg            -0.1865     1.2974   -0.14    0.886   </span></a>
<a class="sourceLine" id="cb51-71" data-line-number="71"><span class="co">#&gt; percent_uninsured  -0.3072     0.1651   -1.86    0.063 . </span></a>
<a class="sourceLine" id="cb51-72" data-line-number="72"><span class="co">#&gt; income             -0.0421     0.0776   -0.54    0.587   </span></a>
<a class="sourceLine" id="cb51-73" data-line-number="73"><span class="co">#&gt; percent_nonwhite   17.8505    48.3030    0.37    0.712   </span></a>
<a class="sourceLine" id="cb51-74" data-line-number="74"><span class="co">#&gt; percent_metro     -12.4390    32.4446   -0.38    0.701   </span></a>
<a class="sourceLine" id="cb51-75" data-line-number="75"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb51-76" data-line-number="76"><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></a>
<a class="sourceLine" id="cb51-77" data-line-number="77"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-78" data-line-number="78"><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></a>
<a class="sourceLine" id="cb51-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-80" data-line-number="80"><span class="co">#&gt;     Null deviance: 68.593  on 49  degrees of freedom</span></a>
<a class="sourceLine" id="cb51-81" data-line-number="81"><span class="co">#&gt; Residual deviance: 37.948  on 42  degrees of freedom</span></a>
<a class="sourceLine" id="cb51-82" data-line-number="82"><span class="co">#&gt; AIC: 53.95</span></a>
<a class="sourceLine" id="cb51-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-84" data-line-number="84"><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></a>
<a class="sourceLine" id="cb51-85" data-line-number="85"></a>
<a class="sourceLine" id="cb51-86" data-line-number="86">fit1 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb51-87" data-line-number="87"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-88" data-line-number="88"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb51-89" data-line-number="89"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-90" data-line-number="90"><span class="co">#&gt; Gradient evaluation took 8.5e-05 seconds</span></a>
<a class="sourceLine" id="cb51-91" data-line-number="91"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.85 seconds.</span></a>
<a class="sourceLine" id="cb51-92" data-line-number="92"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-93" data-line-number="93"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-94" data-line-number="94"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-95" data-line-number="95"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-96" data-line-number="96"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-97" data-line-number="97"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-98" data-line-number="98"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-99" data-line-number="99"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-100" data-line-number="100"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-101" data-line-number="101"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-102" data-line-number="102"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-103" data-line-number="103"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-104" data-line-number="104"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-105" data-line-number="105"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-106" data-line-number="106"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-107" data-line-number="107"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-108" data-line-number="108"><span class="co">#&gt;  Elapsed Time: 0.224432 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-109" data-line-number="109"><span class="co">#&gt;                0.210568 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-110" data-line-number="110"><span class="co">#&gt;                0.435 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-111" data-line-number="111"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-112" data-line-number="112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-113" data-line-number="113"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb51-114" data-line-number="114"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-115" data-line-number="115"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb51-116" data-line-number="116"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb51-117" data-line-number="117"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-118" data-line-number="118"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-119" data-line-number="119"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-120" data-line-number="120"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-121" data-line-number="121"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-122" data-line-number="122"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-123" data-line-number="123"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-124" data-line-number="124"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-125" data-line-number="125"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-126" data-line-number="126"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-127" data-line-number="127"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-128" data-line-number="128"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-129" data-line-number="129"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-130" data-line-number="130"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-131" data-line-number="131"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-133" data-line-number="133"><span class="co">#&gt;  Elapsed Time: 0.222537 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-134" data-line-number="134"><span class="co">#&gt;                0.231917 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-135" data-line-number="135"><span class="co">#&gt;                0.454454 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-136" data-line-number="136"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-137" data-line-number="137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-138" data-line-number="138"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb51-139" data-line-number="139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-140" data-line-number="140"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb51-141" data-line-number="141"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb51-142" data-line-number="142"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-143" data-line-number="143"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-144" data-line-number="144"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-145" data-line-number="145"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-146" data-line-number="146"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-147" data-line-number="147"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-148" data-line-number="148"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-149" data-line-number="149"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-150" data-line-number="150"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-151" data-line-number="151"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-152" data-line-number="152"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-153" data-line-number="153"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-154" data-line-number="154"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-155" data-line-number="155"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-156" data-line-number="156"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-158" data-line-number="158"><span class="co">#&gt;  Elapsed Time: 0.229284 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-159" data-line-number="159"><span class="co">#&gt;                0.221269 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-160" data-line-number="160"><span class="co">#&gt;                0.450553 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-161" data-line-number="161"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-162" data-line-number="162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-163" data-line-number="163"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb51-164" data-line-number="164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-165" data-line-number="165"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb51-166" data-line-number="166"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb51-167" data-line-number="167"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-168" data-line-number="168"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-169" data-line-number="169"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-170" data-line-number="170"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-171" data-line-number="171"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-172" data-line-number="172"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-173" data-line-number="173"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-174" data-line-number="174"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-175" data-line-number="175"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-176" data-line-number="176"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-177" data-line-number="177"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-178" data-line-number="178"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-179" data-line-number="179"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-180" data-line-number="180"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-181" data-line-number="181"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-183" data-line-number="183"><span class="co">#&gt;  Elapsed Time: 0.217782 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-184" data-line-number="184"><span class="co">#&gt;                0.220388 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-185" data-line-number="185"><span class="co">#&gt;                0.43817 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-186" data-line-number="186">fit2 &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(f, <span class="dt">data =</span> br, <span class="dt">prior =</span> <span class="ot">NULL</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb51-187" data-line-number="187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-188" data-line-number="188"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb51-189" data-line-number="189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-190" data-line-number="190"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb51-191" data-line-number="191"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb51-192" data-line-number="192"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-193" data-line-number="193"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-194" data-line-number="194"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-195" data-line-number="195"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-196" data-line-number="196"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-197" data-line-number="197"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-198" data-line-number="198"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-199" data-line-number="199"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-200" data-line-number="200"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-201" data-line-number="201"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-202" data-line-number="202"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-203" data-line-number="203"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-204" data-line-number="204"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-205" data-line-number="205"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-206" data-line-number="206"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-207" data-line-number="207"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-208" data-line-number="208"><span class="co">#&gt;  Elapsed Time: 1.55551 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-209" data-line-number="209"><span class="co">#&gt;                0.243953 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-210" data-line-number="210"><span class="co">#&gt;                1.79946 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-211" data-line-number="211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-212" data-line-number="212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-213" data-line-number="213"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb51-214" data-line-number="214"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-215" data-line-number="215"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb51-216" data-line-number="216"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb51-217" data-line-number="217"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-218" data-line-number="218"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-219" data-line-number="219"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-220" data-line-number="220"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-221" data-line-number="221"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-222" data-line-number="222"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-223" data-line-number="223"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-224" data-line-number="224"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-225" data-line-number="225"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-226" data-line-number="226"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-227" data-line-number="227"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-228" data-line-number="228"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-229" data-line-number="229"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-230" data-line-number="230"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-231" data-line-number="231"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-232" data-line-number="232"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-233" data-line-number="233"><span class="co">#&gt;  Elapsed Time: 1.39207 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-234" data-line-number="234"><span class="co">#&gt;                0.209127 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-235" data-line-number="235"><span class="co">#&gt;                1.6012 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-236" data-line-number="236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-237" data-line-number="237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-238" data-line-number="238"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb51-239" data-line-number="239"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-240" data-line-number="240"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb51-241" data-line-number="241"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb51-242" data-line-number="242"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-243" data-line-number="243"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-244" data-line-number="244"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-245" data-line-number="245"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-246" data-line-number="246"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-247" data-line-number="247"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-248" data-line-number="248"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-249" data-line-number="249"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-250" data-line-number="250"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-251" data-line-number="251"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-252" data-line-number="252"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-253" data-line-number="253"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-254" data-line-number="254"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-255" data-line-number="255"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-256" data-line-number="256"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-257" data-line-number="257"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-258" data-line-number="258"><span class="co">#&gt;  Elapsed Time: 1.06268 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-259" data-line-number="259"><span class="co">#&gt;                0.242076 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-260" data-line-number="260"><span class="co">#&gt;                1.30476 seconds (Total)</span></a>
<a class="sourceLine" id="cb51-261" data-line-number="261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-262" data-line-number="262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-263" data-line-number="263"><span class="co">#&gt; SAMPLING FOR MODEL &#39;bernoulli&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb51-264" data-line-number="264"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-265" data-line-number="265"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb51-266" data-line-number="266"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb51-267" data-line-number="267"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb51-268" data-line-number="268"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-269" data-line-number="269"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-270" data-line-number="270"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-271" data-line-number="271"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-272" data-line-number="272"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-273" data-line-number="273"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-274" data-line-number="274"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-275" data-line-number="275"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb51-276" data-line-number="276"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-277" data-line-number="277"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-278" data-line-number="278"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-279" data-line-number="279"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-280" data-line-number="280"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-281" data-line-number="281"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb51-282" data-line-number="282"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb51-283" data-line-number="283"><span class="co">#&gt;  Elapsed Time: 1.21102 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb51-284" data-line-number="284"><span class="co">#&gt;                0.217264 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb51-285" data-line-number="285"><span class="co">#&gt;                1.42828 seconds (Total)</span></a></code></pre></div>
</div>
</div>
<div id="rare-events-logit" class="section level2">
<h2><span class="header-section-number">9.1</span> Rare Events Logit</h2>
</div>
<div id="case-control" class="section level2">
<h2><span class="header-section-number">9.2</span> Case Control</h2>
<p>In binary outcome variables, sometimes it is useful to sample on the dependent variable.
For example, <span class="citation">King and Zeng (2001b)</span> and <span class="citation">King and Zeng (2001a)</span> discuss applications with respect to conflicts in international relations.
For most country-pairs, for most years, there is no conflict.
If some data are costly to gather, it may be cost efficient to get data for conflicts and then randomly select a smaller number of non-conflicts on which to gather data.
The sample will no longer be representative, but the estimates can be corrected.</p>
<p>The reason this works well, is that if there are very few 1’s, additional 0’s have little influence on the estimation (<span class="citation">King and Zeng (2001b)</span>).
This should hold more generally will unbalanced classes; in some sense, the amount of effective observations is not much more than the number in the lowest category.</p>
<p><span class="citation">King and Zeng (2001b)</span> propose two corrections:</p>
<ol style="list-style-type: decimal">
<li>Correcting the intercept (prior correction)</li>
<li>Weighting observations</li>
</ol>
<p>The <em>prior correction</em> notes that
<span class="math display">\[
\pi_i = \frac{1}{1 + \exp(-\mat{X} \vec{beta})}
\]</span></p>
<p>The unbalanced sample only affects the intercept. If <span class="math inline">\(\hat\beta_0\)</span> is the intercept from the MLE, the case-control corrected intercept <span class="math inline">\(\tilde{\beta}\)</span> is,
<span class="math display">\[
\tilde{\vec{\beta}}_0^* = \hat{\vec{\beta}}_0 - \ln \left(\frac{1 - \tau}{\tau} \frac{\bar{y}}{1 - \bar{y}} \right)
\]</span>
In an MLE setting, this can be applied after estimation, but used in any predicted values.
In a Bayesian setting, this correct should be applied within the model by adding the offset to the estimation.</p>
<p>In a Stan model, this could be implemented by directly incrementing these values</p>
<pre><code>data {
  int N;
  int y[N];
  real tau;
}
transformed data {
  real offset;
  real y_mean;
  y_mean = mean(y);
  offset = log((1 - tau) / tau * (y_mean) / (1 - y_mean));
}
parameters {
  real alpha0;
}
transformed parameters {
  real alpha;
  alpha &lt;- alpha0 - offset;
}</code></pre>
<p>If there was uncertainty about <span class="math inline">\(\tau\)</span>, then <span class="math inline">\(\tau\)</span> could be modeled as a parameter.
It may also be okay to only correct the intercept in a generated quantities block? (not sure).</p>
<p>An alternative approach is to use a <em>weighted likelihood</em>:</p>
<ul>
<li>ones are weighted by <span class="math inline">\(\tau / \bar{y}\)</span></li>
<li>zeros are weighted by <span class="math inline">\((1 - \tau) / \bar{1 - \bar{y}}\)</span></li>
</ul>
<p>The log likelihood would then be
<span class="math display">\[
\ln L_w(\beta | y) = w_1 \sum_{Y_i = 1} \ln (\pi_i) + w_0 \sum_{Y_i = 0} \ln (1 - \pi_i)
\]</span></p>
<p>In Stan, this can be implemented by directly weighting the log-posterior contributions of each observation.
For example, something like this,</p>
<pre><code>if (y[i]) {
  target += w * binomial_lpdf(1, pi[i])
} else {
  target += (1 - w) * binomial_lpdf(1, pi[i])
}</code></pre>
<p>See the example for <a href="http://docs.zeligproject.org/en/latest/zelig-relogit.html">Zelig-relogit</a></p>
<div id="references-5" class="section level4">
<h4><span class="header-section-number">9.2.0.1</span> References</h4>
<ul>
<li><span class="citation">Firth (1993)</span> proposes a penalized likelihood approach using the Jeffreys invariant prior</li>
<li><span class="citation">King and Zeng (2001a)</span> and <span class="citation">King and Zeng (2001b)</span> apply an approach similar to the penalized likelihood approach for the similar problem of rare events</li>
<li><span class="citation">Zorn (2005)</span> also suggests using the Firth logistic regression to avoid perfect separation</li>
<li><span class="citation">Rainey (2016a)</span> shows that Cauchy(0, 2.5) priors can be used</li>
<li><span class="citation">Greenland and Mansournia (2015)</span> provide another default prior to for binomial models: log F(1,1) and log F(2, 2) priors. These have the nice property that they are interpretable as additional observations.</li>
</ul>
</div>
<div id="references-6" class="section level3">
<h3><span class="header-section-number">9.2.1</span> References</h3>
<p>For general references on binomial models see <span class="citation">Stan Development Team (2016 Sec. 8.5)</span>, <span class="citation">McElreath (2016 Ch 10)</span>, <span class="citation">Gelman and Hill (2007)</span> [Ch. 5; Sec 6.4-6.5], <span class="citation">Fox (2016 Ch. 14)</span>, and <span class="citation">Gelman et al. (2013 Ch. 16)</span>.</p>
<!--chapter:end:binomial.Rmd-->
</div>
</div>
</div>
<div id="unbounded-count-models" class="section level1">
<h1><span class="header-section-number">10</span> Unbounded Count Models</h1>
<p>Unbounded count models are models in which the response is a natural number with no upper bound,
<span class="math display">\[
y_i = 0, 1, \dots, \infty .
\]</span></p>
<p>The two distributions most commonly used to model this are</p>
<ul>
<li>Poisson</li>
<li>Negative Binomial</li>
</ul>
<div id="poisson-1" class="section level2">
<h2><span class="header-section-number">10.1</span> Poisson</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>:
<span class="math display">\[
y_i \sim \dpois(\lambda_i) ,
\]</span></p>
</div>
<div id="negative-binomial-1" class="section level2">
<h2><span class="header-section-number">10.2</span> Negative Binomial</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a> model is also used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The Poisson distribution has the restriction that the mean is equal to the variance, <span class="math inline">\(\E(X) = \Var(X) = \lambda\)</span>.
The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean).</p>
<p>The outcome is modeled as a negative binomial distribution,
<span class="math display">\[
y_i \sim \dbin(\alpha_i, \beta)
\]</span>
with shape <span class="math inline">\(\alpha \in \R^{+}\)</span> and inverse scale <span class="math inline">\(\beta \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \alpha_i / \beta\)</span> and <span class="math inline">\(\Var(Y) = \frac{\alpha_i}{\beta^2}(\beta + 1)\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\alpha_i &amp;= \mu_i / \beta
\end{aligned}
\]</span></p>
<p><strong>Important</strong> The negative binomial distribution has many different parameterizations.
An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter.
<span class="math display">\[
y_i \sim \dnbinalt(\mu_i, \phi)
\]</span>
with location parameter <span class="math inline">\(\mu \in \R^{+}\)</span> and over-dispersion parameter <span class="math inline">\(\phi \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \mu_i\)</span> and <span class="math inline">\(\Var(Y) = \mu_i + \frac{\mu_i^2}{\phi}\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\end{aligned}
\]</span></p>
<div id="stan-1" class="section level3">
<h3><span class="header-section-number">10.2.1</span> Stan</h3>
<p>In Stan, there are multiple parameterizations of the</p>
<ul>
<li><code>neg_binomial_lpdf(y | alpha, beta)</code>with shape parameter <code>alpha</code> and inverse scale parameter <code>beta</code>.</li>
<li><code>neg_binomial_2_lpdf(y | mu, phi)</code> with mean <code>mu</code> and over-dispersion parameter <code>phi</code>.</li>
<li><code>neg_binomial_2_log_lpdf(y | eta, phi)</code> with log-mean <code>eta</code> and over-dispersion parameter <code>phi</code></li>
</ul>
<p>Also, <code>rstanarm</code> supports Poisson and <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">negative binomial models</a>.</p>
</div>
<div id="example-number-of-number-o" class="section level3">
<h3><span class="header-section-number">10.2.2</span> Example: Number of Number o</h3>
</div>
<div id="references-7" class="section level3">
<h3><span class="header-section-number">10.2.3</span> References</h3>
<p>For general references on count models see</p>
<ul>
<li><span class="citation">Gelman et al. (2013 Ch 16)</span></li>
<li><span class="citation">Gelman and Hill (2007, 109–16)</span></li>
<li><span class="citation">McElreath (2016 Ch 10)</span></li>
<li><span class="citation">Fox (2016 Ch. 14)</span></li>
<li><span class="citation">Gelman et al. (2013 Ch. 16)</span></li>
</ul>
<p>where <span class="math inline">\(y_i \in 0, 1, 2, \dots\)</span>.</p>
<p>The parameter <span class="math inline">\(\lambda_i \in (0, \infty)\)</span> is both the mean and variance of the distribution.</p>
</div>
<div id="link-functions" class="section level3">
<h3><span class="header-section-number">10.2.4</span> Link functions</h3>
<p>In many applications, <span class="math inline">\(\lambda\)</span>, is modeled as some function of covariates or other parameters.</p>
<p>Since <span class="math inline">\(\lambda_i\)</span> must be positive, the most common link function is the log,
<span class="math display">\[
\log(\lambda_i) = \exp(\vec{x}_i&#39; \vec{\beta})
\]</span>
which has the inverse,
<span class="math display">\[
\lambda_i = \log(\vec{x}_i \vec{\beta})
\]</span></p>
</div>
<div id="stan-2" class="section level3">
<h3><span class="header-section-number">10.2.5</span> Stan</h3>
<p>In Stan, the Poisson distribution has two implementations:</p>
<ul>
<li><code>poisson_lpdf</code></li>
<li><code>poisson_log_lpdf</code></li>
</ul>
<p>The Poisson with a log link. This is for numeric stability.</p>
<p>In <strong>rstanarm</strong> use <a href="https://www.rdocumentation.org/packages/rstanarm/topics/stan_glm">rstanarm</a> for a Poisson GLM.</p>
<ul>
<li><strong>rstanarm</strong> vignette on <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">counte models</a>.</li>
</ul>
</div>
</div>
<div id="example-bilateral-sanctions" class="section level2">
<h2><span class="header-section-number">10.3</span> Example: Bilateral Sanctions</h2>
<p>A regression model of bilateral sanctions for the period 1939 to 1983 <span class="citation">(Martin 1992)</span>.
The outcome variable is the number of countries imposing sanctions.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">mod_poisson1 &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/poisson1.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;sanction&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a>
<a class="sourceLine" id="cb55-2" data-line-number="2"></a>
<a class="sourceLine" id="cb55-3" data-line-number="3">f &lt;-<span class="st"> </span>num <span class="op">~</span><span class="st"> </span>coop <span class="op">+</span><span class="st"> </span>target <span class="op">-</span>1L</a>
<a class="sourceLine" id="cb55-4" data-line-number="4">reg_model_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(f, <span class="dt">data =</span> sanction)</a>
<a class="sourceLine" id="cb55-5" data-line-number="5"></a>
<a class="sourceLine" id="cb55-6" data-line-number="6">sanction_data &lt;-</a>
<a class="sourceLine" id="cb55-7" data-line-number="7"><span class="st">  </span><span class="kw">list</span>(<span class="dt">X =</span> <span class="kw">autoscale</span>(reg_model_data<span class="op">$</span>X),</a>
<a class="sourceLine" id="cb55-8" data-line-number="8">       <span class="dt">y =</span> reg_model_data<span class="op">$</span>y)</a>
<a class="sourceLine" id="cb55-9" data-line-number="9">sanction_data<span class="op">$</span>N &lt;-<span class="st"> </span><span class="kw">nrow</span>(sanction_data<span class="op">$</span>X)</a>
<a class="sourceLine" id="cb55-10" data-line-number="10">sanction_data<span class="op">$</span>K &lt;-<span class="st"> </span><span class="kw">ncol</span>(sanction_data<span class="op">$</span>X)</a></code></pre></div>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1">fit_sanction_pois &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_poisson1, <span class="dt">data =</span> sanction_data)</a>
<a class="sourceLine" id="cb56-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-3" data-line-number="3"><span class="co">#&gt; SAMPLING FOR MODEL &#39;poisson1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb56-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-5" data-line-number="5"><span class="co">#&gt; Gradient evaluation took 4.3e-05 seconds</span></a>
<a class="sourceLine" id="cb56-6" data-line-number="6"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.43 seconds.</span></a>
<a class="sourceLine" id="cb56-7" data-line-number="7"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb56-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-10" data-line-number="10"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-11" data-line-number="11"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-12" data-line-number="12"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-13" data-line-number="13"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-14" data-line-number="14"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-15" data-line-number="15"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-16" data-line-number="16"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-17" data-line-number="17"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-18" data-line-number="18"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-19" data-line-number="19"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-20" data-line-number="20"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-21" data-line-number="21"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-23" data-line-number="23"><span class="co">#&gt;  Elapsed Time: 0.09828 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb56-24" data-line-number="24"><span class="co">#&gt;                0.095359 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb56-25" data-line-number="25"><span class="co">#&gt;                0.193639 seconds (Total)</span></a>
<a class="sourceLine" id="cb56-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-27" data-line-number="27"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-28" data-line-number="28"><span class="co">#&gt; SAMPLING FOR MODEL &#39;poisson1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb56-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-30" data-line-number="30"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb56-31" data-line-number="31"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb56-32" data-line-number="32"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb56-33" data-line-number="33"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-34" data-line-number="34"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-35" data-line-number="35"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-36" data-line-number="36"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-37" data-line-number="37"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-38" data-line-number="38"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-39" data-line-number="39"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-40" data-line-number="40"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-41" data-line-number="41"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-42" data-line-number="42"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-43" data-line-number="43"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-44" data-line-number="44"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-45" data-line-number="45"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-46" data-line-number="46"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-47" data-line-number="47"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-48" data-line-number="48"><span class="co">#&gt;  Elapsed Time: 0.101347 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb56-49" data-line-number="49"><span class="co">#&gt;                0.103472 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb56-50" data-line-number="50"><span class="co">#&gt;                0.204819 seconds (Total)</span></a>
<a class="sourceLine" id="cb56-51" data-line-number="51"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-52" data-line-number="52"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-53" data-line-number="53"><span class="co">#&gt; SAMPLING FOR MODEL &#39;poisson1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb56-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-55" data-line-number="55"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb56-56" data-line-number="56"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb56-57" data-line-number="57"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb56-58" data-line-number="58"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-59" data-line-number="59"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-60" data-line-number="60"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-61" data-line-number="61"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-62" data-line-number="62"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-63" data-line-number="63"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-64" data-line-number="64"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-65" data-line-number="65"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-66" data-line-number="66"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-67" data-line-number="67"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-68" data-line-number="68"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-69" data-line-number="69"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-70" data-line-number="70"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-71" data-line-number="71"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-72" data-line-number="72"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-73" data-line-number="73"><span class="co">#&gt;  Elapsed Time: 0.101324 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb56-74" data-line-number="74"><span class="co">#&gt;                0.107138 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb56-75" data-line-number="75"><span class="co">#&gt;                0.208462 seconds (Total)</span></a>
<a class="sourceLine" id="cb56-76" data-line-number="76"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-77" data-line-number="77"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-78" data-line-number="78"><span class="co">#&gt; SAMPLING FOR MODEL &#39;poisson1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb56-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-80" data-line-number="80"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb56-81" data-line-number="81"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb56-82" data-line-number="82"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb56-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-84" data-line-number="84"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-85" data-line-number="85"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-86" data-line-number="86"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-87" data-line-number="87"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-88" data-line-number="88"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-89" data-line-number="89"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-90" data-line-number="90"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb56-91" data-line-number="91"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-92" data-line-number="92"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-93" data-line-number="93"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-94" data-line-number="94"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-95" data-line-number="95"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-96" data-line-number="96"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb56-97" data-line-number="97"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb56-98" data-line-number="98"><span class="co">#&gt;  Elapsed Time: 0.10045 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb56-99" data-line-number="99"><span class="co">#&gt;                0.093848 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb56-100" data-line-number="100"><span class="co">#&gt;                0.194298 seconds (Total)</span></a></code></pre></div>
</div>
<div id="negative-binomial-2" class="section level2">
<h2><span class="header-section-number">10.4</span> Negative Binomial</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a> model is also used for unbounded count data,
<span class="math display">\[
Y = 0, 1, \dots, \infty
\]</span>
The Poisson distribution has the restriction that the mean is equal to the variance, <span class="math inline">\(\E(X) = \Var(X) = \lambda\)</span>.
The Negative Binomial distribution has an additional parameter that allows the variance to vary (though it is always larger than the mean).</p>
<p>The outcome is modeled as a negative binomial distribution,
<span class="math display">\[
y_i \sim \dnegbinom(\alpha_i, \beta)
\]</span>
with shape <span class="math inline">\(\alpha \in \R^{+}\)</span> and inverse scale <span class="math inline">\(\beta \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \alpha_i / \beta\)</span> and <span class="math inline">\(\Var(Y) = \frac{\alpha_i}{\beta^2}(\beta + 1)\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\alpha_i &amp;= \mu_i / \beta
\end{aligned}
\]</span></p>
<p><strong>Important</strong> The negative binomial distribution has many different parameterizations.
An alternative parameterization of the negative binomial uses the mean and a over-dispersion parameter.
<span class="math display">\[
y_i \sim \dnbinomalt(\mu_i, \phi)
\]</span>
with location parameter <span class="math inline">\(\mu \in \R^{+}\)</span> and over-dispersion parameter <span class="math inline">\(\phi \in \R^{+}\)</span>, and <span class="math inline">\(\E(y) = \mu_i\)</span> and <span class="math inline">\(\Var(Y) = \mu_i + \frac{\mu_i^2}{\phi}\)</span>.
Then the mean can be modeled and transformed to the
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;= \log( \vec{x}_i \vec{\gamma} ) \\
\end{aligned}
\]</span></p>
<p>In Stan, there are multiple parameterizations of the</p>
<ul>
<li><code>neg_binomial_lpdf(y | alpha, beta)</code>with shape parameter <code>alpha</code> and inverse scale parameter <code>beta</code>.</li>
<li><code>neg_binomial_2_lpdf(y | mu, phi)</code> with mean <code>mu</code> and over-dispersion parameter <code>phi</code>.</li>
<li><code>neg_binomial_2_log_lpdf(y | eta, phi)</code> with log-mean <code>eta</code> and over-dispersion parameter <code>phi</code></li>
</ul>
<p>Also, <code>rstanarm</code> supports Poisson and <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html">negative binomial models</a>.</p>
<div id="example-economic-sanctions-ii-ex-econ-sanctions-2" class="section level3">
<h3><span class="header-section-number">10.4.1</span> Example: Economic Sanctions II {ex-econ-sanctions-2}</h3>
<p>Continuing the <a href="#ex-econ-sanctions-2">economic sanctions example</a> of <span class="citation">Martin (1992)</span>.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1">mod_negbin1 &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/negbin1.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1">fit_sanction_nb &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_negbin1, <span class="dt">data =</span> sanction_data, <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta  =</span> <span class="fl">0.95</span>))</a>
<a class="sourceLine" id="cb58-2" data-line-number="2"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb58-3" data-line-number="3"><span class="co">#&gt; SAMPLING FOR MODEL &#39;negbin1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb58-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb58-5" data-line-number="5"><span class="co">#&gt; Gradient evaluation took 7.6e-05 seconds</span></a>
<a class="sourceLine" id="cb58-6" data-line-number="6"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.76 seconds.</span></a>
<a class="sourceLine" id="cb58-7" data-line-number="7"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb58-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb58-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb58-10" data-line-number="10"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb58-11" data-line-number="11"><span class="co">#&gt; [1] &quot;Error in sampler$call_sampler(args_list[[i]]) : &quot;                                                                                                    </span></a>
<a class="sourceLine" id="cb58-12" data-line-number="12"><span class="co">#&gt; [2] &quot;  Exception thrown at line 48: neg_binomial_2_rng: Random number that came from gamma distribution is 4.11693e+10, but must be less than 1.07374e+09&quot;</span></a>
<a class="sourceLine" id="cb58-13" data-line-number="13"><span class="co">#&gt; error occurred during calling the sampler; sampling not done</span></a></code></pre></div>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb59-1" data-line-number="1"><span class="kw">summary</span>(fit_sanction_nb, <span class="dt">par =</span> <span class="kw">c</span>(<span class="st">&quot;a&quot;</span>, <span class="st">&quot;b&quot;</span>, <span class="st">&quot;phi&quot;</span>))<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb59-2" data-line-number="2"><span class="co">#&gt; Stan model &#39;negbin1&#39; does not contain samples.</span></a>
<a class="sourceLine" id="cb59-3" data-line-number="3"><span class="co">#&gt; NULL</span></a></code></pre></div>
<p>We can compare the</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1">loo_sanction_pois &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit_sanction_pois, <span class="st">&quot;log_lik&quot;</span>))</a>
<a class="sourceLine" id="cb60-2" data-line-number="2"><span class="co">#&gt; Warning: Some Pareto k diagnostic values are too high. See help(&#39;pareto-k-</span></a>
<a class="sourceLine" id="cb60-3" data-line-number="3"><span class="co">#&gt; diagnostic&#39;) for details.</span></a>
<a class="sourceLine" id="cb60-4" data-line-number="4"><span class="co"># loo_sanction_nb &lt;- loo(extract_log_lik(fit_sanction_nb, &quot;log_lik&quot;))</span></a></code></pre></div>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1"><span class="co"># loo::compare(loo_sanction_pois, loo_sanction_nb)</span></a></code></pre></div>
</div>
<div id="references-8" class="section level3">
<h3><span class="header-section-number">10.4.2</span> References</h3>
<p>For general references on count models see <span class="citation">Gelman and Hill (2007, 109–16)</span>, <span class="citation">McElreath (2016 Ch 10)</span>, <span class="citation">Fox (2016 Ch. 14)</span>, and <span class="citation">Gelman et al. (2013 Ch. 16)</span>.</p>
<!--chapter:end:counts.Rmd-->
</div>
</div>
</div>
<div id="categorical-variables" class="section level1">
<h1><span class="header-section-number">11</span> Categorical Variables</h1>
<div id="example-mexico-vote-choice" class="section level2">
<h2><span class="header-section-number">11.1</span> Example: Mexico Vote Choice</h2>
<p>This example from <a href="http://docs.zeligproject.org/en/latest/zeligchoice-mlogit.html">Zelig</a> uses a multinomial model</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;mexico&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;Zelig&quot;</span>)</a></code></pre></div>
<!--chapter:end:categorical.Rmd-->
</div>
</div>
<div id="shrinkage-regularization" class="section level1">
<h1><span class="header-section-number">12</span> Shrinkage and Regularization</h1>
<p><em>Shrinkage estimation</em> deliberately introduces biases into the model to improve overall performance, often at the cost of individual estimates <span class="citation">(Efron and Hastie 2016, 91)</span>.</p>
<p>This is opposed to MLE, which produces unbiased estimates (asymptotically, given certain regularity conditions). Likewise, the Bayesian estimates with non- or weakly-informative priors will produce estimates similar to the MLE.
With shrinkage, the priors are used to produce estimates <em>different</em> than the MLE case.</p>
<p><em>Regularization</em> describes any method that reduces variability in high dimensional estimation or prediction problems <span class="citation">(Efron and Hastie 2016)</span>.</p>
<div id="normal-linear-regression-model" class="section level2">
<h2><span class="header-section-number">12.1</span> Normal Linear Regression Model</h2>
<p>Consider the single output linear Gaussian regression model with several input variables, given by
<span class="math display">\[
\begin{aligned}[t]
y_i \sim \dnorm(\vec{x}_i&#39; \vec{\beta}, \sigma^2)
\end{aligned}
\]</span>
where <span class="math inline">\(\vec{x}\)</span> is a <span class="math inline">\(k\)</span>-vector of predictors, and <span class="math inline">\(\vec{\beta}\)</span> are the coefficients.</p>
<p>What priors do we put on <span class="math inline">\(\beta\)</span>?</p>
<ul>
<li><strong>Improproper priors:</strong> <span class="math inline">\(\beta_k \propto 1\)</span> This produces the equivalent of MLE estimates.</li>
<li><strong>Non-informative priors:</strong> These are priors which have such wide variance that they have little influence on the posterior, e.g. <span class="math inline">\(\beta_k \sim \dnorm(0, 1e6)\)</span>. The primary reason for these (as opposed to simply using an improper prior) is that some MCMC methods, e.g. Gibbs sampling as used in JAGS or BUGS, require proper prior distributions for all parameters.</li>
</ul>
<p><strong>Shrinkage priors</strong> have a couple characteristics</p>
<ul>
<li>they push <span class="math inline">\(\beta_k \to 0\)</span></li>
<li>while in the other cases, the scale of the prior on <span class="math inline">\(\beta\)</span> is fixed, in shrinkage priors there is often a hyperprior on it. E.g. <span class="math inline">\(\beta_k \sim \dnorm(0, \tau)\)</span>, where <span class="math inline">\(\tau\)</span> is also a parameter to be estimated.</li>
</ul>
</div>
<div id="penalized-regression" class="section level2">
<h2><span class="header-section-number">12.2</span> Penalized Regression</h2>
<p>Penalized regressions are regressions of the form:
<span class="math display">\[
\hat{\beta}_{penalized} = \argmin_{\beta} \sum_{i = 1}^n (\vec{x}_i\T \vec{\beta} - y_i)^2 + f(\beta)
\]</span>
where <span class="math inline">\(f\)</span> is some sort of penalty function on <span class="math inline">\(\beta\)</span> that penalizes larger (in magnitude) values of <span class="math inline">\(\beta\)</span>.</p>
<p>Two common forms</p>
<ul>
<li>Ridge: uses an <span class="math inline">\(\ell_2\)</span> penalty: <span class="math inline">\(\vec{beta}^2\)</span></li>
<li>Lasso: uses an <span class="math inline">\(\ell_1\)</span> penalty: <span class="math inline">\(|\vec{\beta}|\)</span></li>
</ul>
<div id="ridge-regression" class="section level3">
<h3><span class="header-section-number">12.2.1</span> Ridge Regression</h3>
<p>Ridge regression uses the following penalty <span class="citation">(Hoerl and Kennard 1970)</span>:
<span class="math display">\[
\hat{\beta}_{\text{ridge}} = \argmin_{\beta} \sum_{i = 1}^n (\vec{x}_i\T \vec{\beta} - y_i)^2 + \lambda \sum_{k} \beta_k^2
\]</span>
This penalty produces smaller in magnitude coefficients, <span class="math inline">\(|\hat{\beta}_{ridge}| &lt; |\hat{\beta}_{OLS}|\)</span>.
However, this “bias” in the coefficients can be offset by a lower variance, better MSE, and better out-of-sample performance than the OLS estimates.</p>
<p>The point estimate for ridge regression coefficients is:
<span class="math display">\[
\hat{\vec{\beta}}_{\text{ridge}} = {(\mat{X}\T \mat{X} + \lambda \mat{I}_p)}^{-1} \mat{X}\T \vec{y}
\]</span>
The variance-covariance matrix of the point estimate is,
<span class="math display">\[
\mathrm{df}(\lambda) = \tr(\mat{X}(\mat{X}\T \mat{X} + \lambda \mat{I}_p)^{-1} \mat{X}\T) = \sum_{j = 1}^p \frac{d_j^2}{d_j^2 + \lambda}
\]</span>
where <span class="math inline">\(d_j\)</span> are the singular values of <span class="math inline">\(X\)</span></p>
<p>Some implications:</p>
<ul>
<li><span class="math inline">\(\hat{\vec{\beta}}\)</span> exists even if <span class="math inline">\(\hat{\vec{\beta}}_{\text{OLS}}\)</span> (<span class="math inline">\((\mat{X}\T\mat{X})^{-1}\)</span>), i.e. cases of <span class="math inline">\(n &gt; p\)</span> and collinearity, does not exist.</li>
<li>If <span class="math inline">\(\mat{X}\)</span> is orthogonal (mean 0, unit variance, zero correlation), <span class="math inline">\(\mat{X}\T \mat{X} = n \mat{I}_p\)</span> then
<span class="math display">\[
\hat{\vec{\beta}}_{\text{ridge}} = \frac{n}{n + \lambda} \hat{\vec{\beta}}_{\text{ols}}
\]</span>
meaning
<span class="math display">\[
|\hat{\vec{\beta}}_{\text{ols}}| &gt; 
|\hat{\vec{\beta}}_{\text{ridge}}| \geq 0
\]</span></li>
<li>Ridge does not produce sparse estimates, since <span class="math inline">\((n / (n + \lambda)) \vec{\vec{\beta}}_{ols} = 0\)</span> iff <span class="math inline">\(\vec{\vec{\beta}}_{ols} = 0\)</span></li>
<li><span class="math inline">\(\lambda = 0\)</span>, then there is no shrinkage</li>
<li><span class="math inline">\(\lambda \to \infty\)</span>, then there is complete shrinkage and all coefficients are tend to 0.</li>
</ul>
</div>
<div id="lasso" class="section level3">
<h3><span class="header-section-number">12.2.2</span> Lasso</h3>
<p>The Lasso or LASSO (least absolute shrinkage and selection operator) replaces squared the penalty on <span class="math inline">\(\beta\)</span> with an absolute value penalty <span class="citation">(Tibshirani 1996)</span>:
<span class="math display">\[
\hat{\beta}_{\text{lasso}} = \argmin_{\beta} \frac{1}{2 \sigma} \sum_{i = 1}^n (\vec{x}_i\T \vec{\beta} - y_i)^2 + \lambda \sum_{k} |\beta_k|
\]</span>
The absolute value penalty will put some <span class="math inline">\(\hat{\beta}_k = 0\)</span>, producing a “sparse” solution.</p>
<p>Properties:</p>
<ul>
<li>Unlike ridge regression, it sets some coefficients to exactly 0</li>
<li>If variables are perfectly correlated, there is no unique solution (unlike the ridge regression)</li>
<li>Used as the best convex approximation of the “best subset selection” regression problem, which finds the number of nonzero entries in a vector.</li>
</ul>
</div>
</div>
<div id="bayesian-shrinkage-priors" class="section level2">
<h2><span class="header-section-number">12.3</span> Bayesian Shrinkage Priors</h2>
<p><span class="math display">\[
\log p(\theta|y, x) \propto \frac{1}{2 \sigma} \sum_{i = 1}^n (\vec{x}_i\T \vec{\beta} - y_i)^2 + \lambda \sum_{k} \beta_k^2
\]</span>
In the first case, the log density of a normal distribution is,
<span class="math display">\[
\log p(y | \mu, x) \propto \frac{1}{2 \sigma} (x - \mu)^2
\]</span>
The first regression term is the produce of normal distributions (sum of their log probabilities),
<span class="math display">\[
y_i \sim \dnorm(\vec{x}_i\T \vec{\beta}, \sigma) 
\]</span>
The second term, <span class="math inline">\(\lambda \sum_{k} \beta_k^2\)</span> is also the sum of the log of densities of i.i.d. normal densities, with mean 0, and scale <span class="math inline">\(\tau = 1 / 2 \lambda\)</span>,
<span class="math display">\[
\beta_k \sim \dnorm(0, \tau^2)
\]</span></p>
<p>The only difference in the LASSO is the penalty term, which uses an absolute value penalty for <span class="math inline">\(\beta_k\)</span>.
That term corresponds to a sum of log densities of i.i.d. double exponential (Laplace) distributions.
The double exponential distribution density is similar to a normal distribution,
<span class="math display">\[
\log p(y | \mu, \sigma) \propto - \frac{|y - \mu|}{\sigma}
\]</span>
So the LASSO penalty is equivalent to the log density of a double exponential distribution with location <span class="math inline">\(0\)</span>, and scale <span class="math inline">\(1 / \lambda\)</span>.
<span class="math display">\[
\beta_k \sim \dlaplace(0, \tau)
\]</span></p>
</div>
<div id="differences-between-bayesian-shrinkage-and-penalized-likelihood" class="section level2">
<h2><span class="header-section-number">12.4</span> Differences between Bayesian Shrinkage and Penalized Likelihood</h2>
<p>There are several differences between Bayesian approaches to shrinkage and penalized ML approaches.</p>
<p>The point estimates:</p>
<ul>
<li>ML: mode</li>
<li>Bayesian: posterior mean (or median)</li>
</ul>
<p>In Lasso</p>
<ul>
<li>ML: the mode produces exact zeros and sparsity</li>
<li>Bayesian: posterior mean is not sparse (zero)</li>
</ul>
<p>Choosing the shrinkage penalty:</p>
<ul>
<li>ML: cross-validation</li>
<li>Bayesian: a prior is placed on the shrinkage penalty, and it is estimated as part of the posterior.</li>
</ul>
</div>
<div id="hierarchical-shrinkage-priors" class="section level2">
<h2><span class="header-section-number">12.5</span> Hierarchical Shrinkage Priors</h2>
<p><span class="math display">\[
\begin{aligned}
\beta_k &amp;\sim \dnorm(0, \lambda_i^2 \tau^2) \\
\lambda_i &amp;\sim \dt{\nu}^{+}(0, 1)
\end{aligned}
\]</span>
If <span class="math inline">\(\nu = 1\)</span>, then this is the Horseshoe prior
<span class="citation">(Carvalho, Polson, and Scott 2010, <span class="citation">@CarvalhoPolsonScott2009a</span>, <span class="citation">@PasKleijnVaart2014a</span>, <span class="citation">@DattaGhosh2013a</span>, <span class="citation">@PolsonScott2011a</span>, <span class="citation">@PiironenVehtari2016a</span>)</span></p>
<p>Hierarchical Shrinkage Plus (HS-<span class="math inline">\(t_{\nu}\)</span>+)</p>
<p><span class="math display">\[
\begin{aligned}
\beta_k &amp;\sim \dnorm(0, \lambda_i^2 \eta_i^2 \tau^2) \\
\lambda_i &amp;\sim \dt{\nu}^{+}(0, 1) \\
\eta_i &amp;\sim \dt{\nu}^{+}(0, 1)
\end{aligned}
\]</span>
This induces even more shrinkage towards zero than the</p>
<p>If <span class="math inline">\(\nu = 1\)</span>, then this is the Horseshoe+ prior as introduced by <span class="citation">Bhadra et al. (2015)</span>.</p>
<p>In linear regression
<span class="math display">\[
\begin{aligned}[t]
p(\beta | \Lambda, \tau, \sigma^2, D) &amp;= \dnorm(\beta, \bar{\beta}, \Sigma) \\
\bar{\beta} &amp;= \tau^2 \Lambda (\tau^2 \Lambda + \sigma^2 (X&#39;X)^{-1})^{-1} \hat{\beta} \\
\Sigma &amp;= (\tau^{-2} \Lambda^{-1} + \frac{1}{\sigma^2} X&#39;X)^{-1}
\end{aligned}
\]</span>
where <span class="math inline">\(\Lambda = \diag(\lambda_1^2, \dots, \lambda_D^2)\)</span>, and <span class="math inline">\(\hat{\beta}\)</span> is the MLE estimate, <span class="math inline">\((X&#39;X)^{-1} X&#39; y\)</span>.
If predictors are uncorrelated with mean zero and unit variance, then
<span class="math display">\[
X&#39;X \approx n I
\]</span>
and
<span class="math display">\[
\bar{\beta}_j = (1 - \kappa_j) \hat{\beta}_j
\]</span>
where
<span class="math display">\[
\kappa_j = \frac{1}{1 + n \sigma^{-2} \tau^2 \lambda_j^2}
\]</span>
where <span class="math inline">\(\kappa_j\)</span> is the <em>shrinkage factor</em> for the coefficient <span class="math inline">\(\beta_j\)</span>, which is how much it is shrunk towards zero from the MLE.
<span class="math inline">\(\kappa_j = 1\)</span> is complete shrinkage, and <span class="math inline">\(\kappa_j = 0\)</span> is no shrinkage.
So <span class="math inline">\(\bar{\beta} \to 0\)</span> as <span class="math inline">\(\tau \to 0\)</span> and <span class="math inline">\(\bar{\beta} \to \hat{\beta}\)</span> as <span class="math inline">\(\tau \to \infty\)</span>.</p>
<p>Using a plug-in estimate of <span class="math inline">\(\tau\)</span> using cross-validation or the maximum marginal likelihood.
The danger is that <span class="math inline">\(\hat{\tau} = 0\)</span> if it is very sparse.</p>
<p>van de Pas et al (2014) show that the optimal value (up to a log factor) in terms of MSE and posterior contraction rates compared to the true <span class="math inline">\(\beta^*\)</span> is
<span class="math display">\[
\tau^* = \frac{p^*}{n}
\]</span>
where <span class="math inline">\(p^*\)</span> is the number of non-zero coefficients in the true coefficient vector <span class="math inline">\(\beta^*\)</span>.</p>
<p>The effective number of nonzero coefficients is,
<span class="math display">\[
m_{\mathrm{eff}} = \sum_{j = 1}^D (1 - \kappa_j)
\]</span></p>
<p>Some other notes</p>
<p>To calculate the distribution of <span class="math inline">\(\kappa_j\)</span> given a distribution of <span class="math inline">\(\lambda\)</span>.
Note that
<span class="math display">\[
\kappa_j(\lambda_j) = \frac{1}{1 + n \sigma^{-2} \tau^2 \lambda_j^2}
\]</span>
is monotonically decreasing in <span class="math inline">\(\lambda_j\)</span>.
It is also invertible,
<span class="math display">\[
\lambda_j(\kappa_j) = \sqrt{\frac{1}{(1 + n \sigma^{-2} \tau^2) \kappa_j}}
\]</span>
The derivative of this with respect to <span class="math inline">\(\kappa_j\)</span> is
<span class="math display">\[
\frac{\partial \lambda_j(\kappa_j)}{\partial \kappa_j} = - \sqrt{\frac{1}{(1 + n \sigma^{-2} \tau^2)}} \kappa_j^{-\frac{3}{2}}
\]</span>
The distribution of <span class="math inline">\(\kappa\)</span>, given the distribution <span class="math inline">\(f_\lambda\)</span> for lambda is,
<span class="math display">\[
\begin{aligned}[t]
f_\kappa(\kappa_j) &amp;= f_\lambda(\lambda_j(\kappa_j)) \left| \frac{\partial \lambda_j(\kappa_j)}{\partial \kappa_j} \right| \\
&amp;= f_\lambda\left(\sqrt{\frac{1}{(1 + n \sigma^{-2} \tau^2) \kappa_j}}\right) \left| (1 + n \sigma^{-2} \tau^2)^{-\frac{1}{2}} \kappa_j^{-\frac{3}{2}} \right| \\
\end{aligned}
\]</span></p>
<p>Suppose that the distribution is given for precision, <span class="math inline">\(\lambda_j^{-2}\)</span>.
Then the inverse is,
<span class="math display">\[
\lambda_j^{-2}(\kappa_j) = (1 + n \sigma^{-2} \tau^2) \kappa_j
\]</span>
with derivative,
<span class="math display">\[
\frac{\partial \lambda_j^{-2}(\kappa_j)}{\partial \kappa_j} = (1 + n \sigma^{-2} \tau^2)
\]</span>
Thus,
<span class="math display">\[
\begin{aligned}[t]
f_\kappa(\kappa_j) &amp;= f_{\lambda^{-2}}(\lambda_j^{-2}(\kappa_j)) \left| \frac{\partial \lambda_j^{-2}(\kappa_j)}{\partial \kappa_j} \right| \\
&amp;= f_{\lambda^{-2}}\left((1 + n \sigma^{-2} \tau^2) \kappa_j \right) \left| (1 + n \sigma^{-2} \tau^2)  \right| \\
\end{aligned}
\]</span></p>
<p>Suppose that the distribution is given for variance <span class="math inline">\(\lambda_j^2\)</span>.
Then the inverse is,
<span class="math display">\[
\lambda_j^2(\kappa_j) = \frac{1}{(1 + n \sigma^{-2} \tau^2) \kappa_j}
\]</span>
with derivative,
<span class="math display">\[
\frac{\partial \lambda_j^2(\kappa_j)}{\partial \kappa_j} = -(1 + n \sigma^{-2} \tau^2)^{-1} \kappa_j^{-2}
\]</span>
Thus,
<span class="math display">\[
\begin{aligned}[t]
f_\kappa(\kappa_j) &amp;= f_{\lambda^2}(\lambda_j^2(\kappa_j)) \left| \frac{\partial \lambda_j^2(\kappa_j)}{\partial \kappa_j} \right| \\
&amp;= f_{\lambda^2}\left(\frac{1}{(1 + n \sigma^{-2} \tau^2) \kappa_j}\right) \left| (1 + n \sigma^{-2} \tau^2)^{-1} \kappa_j^{-2} \right| \\
\end{aligned}
\]</span></p>
<p>I may also be useful to consider the distribution of <span class="math inline">\(\kappa\)</span> given the distribution of <span class="math inline">\(\tau\)</span>.
Note that
<span class="math display">\[
\kappa_j(\tau) = \frac{1}{1 + n \sigma^{-2} \tau^2 \lambda_j^2}
\]</span>
is monotonically decreasing in <span class="math inline">\(\tau\)</span>.
It is also invertible,
<span class="math display">\[
\tau(\kappa_j) = \sqrt{\frac{1}{(1 + n \sigma^{-2} \lambda_j^2) \kappa_j}}
\]</span>
The derivative of this with respect to <span class="math inline">\(\kappa_j\)</span> is
<span class="math display">\[
\frac{\partial \tau(\kappa_j)}{\partial \kappa_j} = - {(1 + n \sigma^{-2} \lambda_j^2)}^{-\frac{1}{2}} \kappa_j^{-\frac{3}{2}}
\]</span>
The distribution of <span class="math inline">\(\kappa\)</span>, given the distribution <span class="math inline">\(f_\lambda\)</span> for lambda is,
<span class="math display">\[
\begin{aligned}[t]
f_\kappa(\kappa_j) &amp;= f_\tau(\tau(\kappa_j)) \left| \frac{\partial \tau(\kappa_j)}{\partial \kappa_j} \right| \\
&amp;= f_\tau\left(\frac{1}{(1 + n \sigma^{-2} \lambda_j^2) \kappa_j} \right) \left| {(1 + n \sigma^{-2} \lambda_j^2)}^{-\frac{1}{2}} \kappa_j^{-\frac{3}{2}} \right| \\
\end{aligned}
\]</span></p>
<ul>
<li>Allan Riddell. <a href="https://www.ariddell.org/horseshoe-prior-with-stan.html">Epistemology of the corral: regression and variable selection with Stan and the Horseshoe prior</a> March 10, 2014.</li>
</ul>
</div>
<div id="example-1" class="section level2">
<h2><span class="header-section-number">12.6</span> Example</h2>
<p>See the <a href="https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.info.txt">documentation</a>.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rstan&quot;</span>)</a>
<a class="sourceLine" id="cb63-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;loo&quot;</span>)</a>
<a class="sourceLine" id="cb63-3" data-line-number="3"><span class="kw">library</span>(<span class="st">&quot;glmnet&quot;</span>)</a>
<a class="sourceLine" id="cb63-4" data-line-number="4"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb63-5" data-line-number="5"><span class="kw">library</span>(<span class="st">&quot;forcats&quot;</span>)</a>
<a class="sourceLine" id="cb63-6" data-line-number="6"><span class="kw">library</span>(<span class="st">&quot;rubbish&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1">URL &lt;-<span class="st"> &quot;https://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data&quot;</span></a>
<a class="sourceLine" id="cb64-2" data-line-number="2"></a>
<a class="sourceLine" id="cb64-3" data-line-number="3">col_types &lt;-<span class="st"> </span><span class="kw">cols</span>(</a>
<a class="sourceLine" id="cb64-4" data-line-number="4">  <span class="dt">X1 =</span> <span class="kw">col_integer</span>(),</a>
<a class="sourceLine" id="cb64-5" data-line-number="5">  <span class="dt">lcavol =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb64-6" data-line-number="6">  <span class="dt">lweight =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb64-7" data-line-number="7">  <span class="dt">age =</span> <span class="kw">col_integer</span>(),</a>
<a class="sourceLine" id="cb64-8" data-line-number="8">  <span class="dt">lbph =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb64-9" data-line-number="9">  <span class="dt">svi =</span> <span class="kw">col_integer</span>(),</a>
<a class="sourceLine" id="cb64-10" data-line-number="10">  <span class="dt">lcp =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb64-11" data-line-number="11">  <span class="dt">gleason =</span> <span class="kw">col_integer</span>(),</a>
<a class="sourceLine" id="cb64-12" data-line-number="12">  <span class="dt">pgg45 =</span> <span class="kw">col_integer</span>(),</a>
<a class="sourceLine" id="cb64-13" data-line-number="13">  <span class="dt">lpsa =</span> <span class="kw">col_double</span>(),</a>
<a class="sourceLine" id="cb64-14" data-line-number="14">  <span class="dt">train =</span> <span class="kw">col_logical</span>()</a>
<a class="sourceLine" id="cb64-15" data-line-number="15">)</a>
<a class="sourceLine" id="cb64-16" data-line-number="16">prostate &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(URL, <span class="dt">col_types =</span> col_types,</a>
<a class="sourceLine" id="cb64-17" data-line-number="17">                     <span class="dt">skip =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb64-18" data-line-number="18">                     <span class="dt">col_names =</span> <span class="kw">names</span>(col_types<span class="op">$</span>cols))</a></code></pre></div>
<p>Recall the prostate data example: we are interested in the level of prostate-specific antigen (PSA), elevated in men who have prostate cancer.
The data <code>prostate</code> has data on on the level of prostate-specific antigen (PSA), which is elevated in men with prostate cancer, for 97 men with
prostate cancer, and clinical predictors.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1">f &lt;-<span class="st"> </span>lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>lbph <span class="op">+</span><span class="st"> </span>svi <span class="op">+</span><span class="st"> </span>lcp <span class="op">+</span><span class="st"> </span>gleason <span class="op">+</span><span class="st"> </span>pgg45 <span class="op">-</span><span class="st"> </span>1L</a></code></pre></div>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1">prostate_data &lt;-<span class="st"> </span><span class="kw">lm_preprocess</span>(f, <span class="dt">data =</span> prostate)[<span class="kw">c</span>(<span class="st">&quot;y&quot;</span>, <span class="st">&quot;X&quot;</span>)] <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb66-2" data-line-number="2"><span class="st">  </span><span class="kw">within</span>({</a>
<a class="sourceLine" id="cb66-3" data-line-number="3">    X &lt;-<span class="st"> </span><span class="kw">scale</span>(X)</a>
<a class="sourceLine" id="cb66-4" data-line-number="4">    K &lt;-<span class="st"> </span><span class="kw">ncol</span>(X)</a>
<a class="sourceLine" id="cb66-5" data-line-number="5">    N &lt;-<span class="st"> </span><span class="kw">nrow</span>(X)  </a>
<a class="sourceLine" id="cb66-6" data-line-number="6">  })</a></code></pre></div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1">run_with_tau &lt;-<span class="st"> </span><span class="cf">function</span>(tau, mod, data, ...) {</a>
<a class="sourceLine" id="cb67-2" data-line-number="2">  <span class="kw">cat</span>(<span class="st">&quot;Tau = &quot;</span>, tau)</a>
<a class="sourceLine" id="cb67-3" data-line-number="3">  data<span class="op">$</span>tau &lt;-<span class="st"> </span>tau</a>
<a class="sourceLine" id="cb67-4" data-line-number="4">  fit &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod, <span class="dt">data =</span> data, <span class="dt">refresh =</span> <span class="dv">-1</span>, <span class="dt">verbose =</span> <span class="ot">FALSE</span>, ...)</a>
<a class="sourceLine" id="cb67-5" data-line-number="5">  out &lt;-<span class="st"> </span><span class="kw">list</span>()</a>
<a class="sourceLine" id="cb67-6" data-line-number="6">  out<span class="op">$</span>summary &lt;-<span class="st"> </span><span class="kw">summary</span>(fit, <span class="dt">par =</span> <span class="st">&quot;b&quot;</span>)<span class="op">$</span>summary <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb67-7" data-line-number="7"><span class="st">    </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb67-8" data-line-number="8"><span class="st">    </span><span class="kw">rownames_to_column</span>(<span class="st">&quot;parameter&quot;</span>)</a>
<a class="sourceLine" id="cb67-9" data-line-number="9">  </a>
<a class="sourceLine" id="cb67-10" data-line-number="10">  ## calculate posterior modes</a>
<a class="sourceLine" id="cb67-11" data-line-number="11">  out<span class="op">$</span>summary<span class="op">$</span>mode &lt;-<span class="st"> </span><span class="kw">apply</span>(rstan<span class="op">::</span><span class="kw">extract</span>(fit, <span class="st">&quot;b&quot;</span>)[[<span class="dv">1</span>]], <span class="dv">2</span>, LaplacesDemon<span class="op">::</span>Mode)</a>
<a class="sourceLine" id="cb67-12" data-line-number="12">  </a>
<a class="sourceLine" id="cb67-13" data-line-number="13">  out<span class="op">$</span>summary<span class="op">$</span>tau &lt;-<span class="st"> </span>tau</a>
<a class="sourceLine" id="cb67-14" data-line-number="14">  out<span class="op">$</span>loo &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit))</a>
<a class="sourceLine" id="cb67-15" data-line-number="15">  out<span class="op">$</span>lppd &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">extract_log_lik</span>(fit))</a>
<a class="sourceLine" id="cb67-16" data-line-number="16">  out<span class="op">$</span>tau &lt;-<span class="st"> </span>tau</a>
<a class="sourceLine" id="cb67-17" data-line-number="17">  out</a>
<a class="sourceLine" id="cb67-18" data-line-number="18">}</a></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1">mod_lm_coef_normal_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-normal-1.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1">mod_lm_coef_normal_<span class="dv">1</span></a></code></pre></div>
<pre>
  <code class="stan">data {
  // number of observations
  int N;
  // response vector
  vector[N] y;
  // number of columns in the design matrix X
  int K;
  // design matrix X
  matrix [N, K] X;
  //
  real<lower = 0.> tau;
}
transformed data {
  real<lower = 0.> y_sd;
  real a_pr_scale;
  real sigma_pr_scale;
  real tau_pr_scale;
  y_sd = sd(y);
  sigma_pr_scale = y_sd * 5.;
  a_pr_scale = 10.;
}
parameters {
  // regression coefficient vector
  real a;
  vector[K] b;
  // scale of the regression errors
  real<lower = 0.> sigma;
}
transformed parameters {
  // mu is the observation fitted/predicted value
  // also called yhat
  vector[N] mu;
  mu = X * b;
}
model {
  // priors
  a ~ normal(0., a_pr_scale);
  b ~ normal(0., tau);
  sigma ~ cauchy(0., sigma_pr_scale);
  // likelihood
  y ~ normal(mu, sigma);
}
generated quantities {
  // simulate data from the posterior
  vector[N] y_rep;
  // log-likelihood posterior
  vector[N] log_lik;
  // mean log likelihood
  for (n in 1:N) {
    y_rep[n] = normal_rng(mu[n], sigma);
    log_lik[n] = normal_lpdf(y[n] | mu[n], sigma);
  }
}</code>
</pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1">tau_values &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">^</span><span class="st"> </span><span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">-5</span>, <span class="dt">by =</span> <span class="fl">-.5</span>)</a>
<a class="sourceLine" id="cb70-2" data-line-number="2">coefpath_normal &lt;-</a>
<a class="sourceLine" id="cb70-3" data-line-number="3"><span class="st">  </span><span class="kw">map</span>(tau_values, run_with_tau,</a>
<a class="sourceLine" id="cb70-4" data-line-number="4">      <span class="dt">mod =</span> mod_lm_coef_normal_<span class="dv">1</span>, <span class="dt">data =</span> prostate_data)</a>
<a class="sourceLine" id="cb70-5" data-line-number="5"><span class="co">#&gt; Tau =  4</span></a>
<a class="sourceLine" id="cb70-6" data-line-number="6"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-8" data-line-number="8"><span class="co">#&gt; Gradient evaluation took 5.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-9" data-line-number="9"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds.</span></a>
<a class="sourceLine" id="cb70-10" data-line-number="10"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-13" data-line-number="13"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-14" data-line-number="14"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-15" data-line-number="15"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-16" data-line-number="16"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-17" data-line-number="17"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-18" data-line-number="18"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-19" data-line-number="19"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-20" data-line-number="20"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-21" data-line-number="21"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-22" data-line-number="22"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-23" data-line-number="23"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-24" data-line-number="24"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-26" data-line-number="26"><span class="co">#&gt;  Elapsed Time: 0.17799 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-27" data-line-number="27"><span class="co">#&gt;                0.126119 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-28" data-line-number="28"><span class="co">#&gt;                0.304109 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-31" data-line-number="31"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-32" data-line-number="32"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-33" data-line-number="33"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-34" data-line-number="34"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-35" data-line-number="35"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-36" data-line-number="36"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-38" data-line-number="38"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-39" data-line-number="39"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-40" data-line-number="40"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-41" data-line-number="41"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-42" data-line-number="42"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-43" data-line-number="43"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-44" data-line-number="44"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-45" data-line-number="45"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-46" data-line-number="46"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-47" data-line-number="47"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-48" data-line-number="48"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-49" data-line-number="49"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-50" data-line-number="50"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-51" data-line-number="51"><span class="co">#&gt;  Elapsed Time: 0.153112 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-52" data-line-number="52"><span class="co">#&gt;                0.128688 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-53" data-line-number="53"><span class="co">#&gt;                0.2818 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-55" data-line-number="55"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-56" data-line-number="56"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-57" data-line-number="57"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-58" data-line-number="58"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-59" data-line-number="59"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-60" data-line-number="60"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-61" data-line-number="61"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-62" data-line-number="62"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-63" data-line-number="63"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-64" data-line-number="64"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-65" data-line-number="65"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-66" data-line-number="66"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-67" data-line-number="67"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-68" data-line-number="68"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-69" data-line-number="69"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-70" data-line-number="70"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-71" data-line-number="71"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-72" data-line-number="72"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-73" data-line-number="73"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-74" data-line-number="74"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-75" data-line-number="75"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-76" data-line-number="76"><span class="co">#&gt;  Elapsed Time: 0.172674 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-77" data-line-number="77"><span class="co">#&gt;                0.138926 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-78" data-line-number="78"><span class="co">#&gt;                0.3116 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-80" data-line-number="80"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-81" data-line-number="81"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-82" data-line-number="82"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-83" data-line-number="83"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-84" data-line-number="84"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-85" data-line-number="85"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-86" data-line-number="86"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-87" data-line-number="87"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-88" data-line-number="88"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-89" data-line-number="89"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-90" data-line-number="90"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-91" data-line-number="91"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-92" data-line-number="92"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-93" data-line-number="93"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-94" data-line-number="94"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-95" data-line-number="95"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-96" data-line-number="96"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-97" data-line-number="97"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-98" data-line-number="98"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-99" data-line-number="99"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-100" data-line-number="100"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-101" data-line-number="101"><span class="co">#&gt;  Elapsed Time: 0.168585 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-102" data-line-number="102"><span class="co">#&gt;                0.13534 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-103" data-line-number="103"><span class="co">#&gt;                0.303925 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-104" data-line-number="104"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-105" data-line-number="105"><span class="co">#&gt; Tau =  2.83</span></a>
<a class="sourceLine" id="cb70-106" data-line-number="106"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-107" data-line-number="107"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-108" data-line-number="108"><span class="co">#&gt; Gradient evaluation took 3.2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-109" data-line-number="109"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.</span></a>
<a class="sourceLine" id="cb70-110" data-line-number="110"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-111" data-line-number="111"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-112" data-line-number="112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-113" data-line-number="113"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-114" data-line-number="114"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-115" data-line-number="115"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-116" data-line-number="116"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-117" data-line-number="117"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-118" data-line-number="118"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-119" data-line-number="119"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-120" data-line-number="120"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-121" data-line-number="121"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-122" data-line-number="122"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-123" data-line-number="123"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-124" data-line-number="124"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-125" data-line-number="125"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-126" data-line-number="126"><span class="co">#&gt;  Elapsed Time: 0.168349 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-127" data-line-number="127"><span class="co">#&gt;                0.137366 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-128" data-line-number="128"><span class="co">#&gt;                0.305715 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-129" data-line-number="129"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-130" data-line-number="130"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-131" data-line-number="131"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-133" data-line-number="133"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-134" data-line-number="134"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-135" data-line-number="135"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-136" data-line-number="136"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-137" data-line-number="137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-138" data-line-number="138"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-139" data-line-number="139"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-140" data-line-number="140"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-141" data-line-number="141"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-142" data-line-number="142"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-143" data-line-number="143"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-144" data-line-number="144"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-145" data-line-number="145"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-146" data-line-number="146"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-147" data-line-number="147"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-148" data-line-number="148"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-149" data-line-number="149"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-150" data-line-number="150"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-151" data-line-number="151"><span class="co">#&gt;  Elapsed Time: 0.166031 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-152" data-line-number="152"><span class="co">#&gt;                0.139874 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-153" data-line-number="153"><span class="co">#&gt;                0.305905 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-154" data-line-number="154"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-155" data-line-number="155"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-156" data-line-number="156"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-158" data-line-number="158"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-159" data-line-number="159"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-160" data-line-number="160"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-161" data-line-number="161"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-162" data-line-number="162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-163" data-line-number="163"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-164" data-line-number="164"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-165" data-line-number="165"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-166" data-line-number="166"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-167" data-line-number="167"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-168" data-line-number="168"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-169" data-line-number="169"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-170" data-line-number="170"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-171" data-line-number="171"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-172" data-line-number="172"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-173" data-line-number="173"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-174" data-line-number="174"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-175" data-line-number="175"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-176" data-line-number="176"><span class="co">#&gt;  Elapsed Time: 0.162088 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-177" data-line-number="177"><span class="co">#&gt;                0.127644 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-178" data-line-number="178"><span class="co">#&gt;                0.289732 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-179" data-line-number="179"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-180" data-line-number="180"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-181" data-line-number="181"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-183" data-line-number="183"><span class="co">#&gt; Gradient evaluation took 3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-184" data-line-number="184"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.</span></a>
<a class="sourceLine" id="cb70-185" data-line-number="185"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-186" data-line-number="186"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-187" data-line-number="187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-188" data-line-number="188"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-189" data-line-number="189"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-190" data-line-number="190"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-191" data-line-number="191"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-192" data-line-number="192"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-193" data-line-number="193"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-194" data-line-number="194"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-195" data-line-number="195"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-196" data-line-number="196"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-197" data-line-number="197"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-198" data-line-number="198"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-199" data-line-number="199"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-200" data-line-number="200"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-201" data-line-number="201"><span class="co">#&gt;  Elapsed Time: 0.177064 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-202" data-line-number="202"><span class="co">#&gt;                0.131347 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-203" data-line-number="203"><span class="co">#&gt;                0.308411 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-204" data-line-number="204"><span class="co">#&gt; Warning: Some Pareto k diagnostic values are slightly high. See</span></a>
<a class="sourceLine" id="cb70-205" data-line-number="205"><span class="co">#&gt; help(&#39;pareto-k-diagnostic&#39;) for details.</span></a>
<a class="sourceLine" id="cb70-206" data-line-number="206"><span class="co">#&gt; Tau =  2</span></a>
<a class="sourceLine" id="cb70-207" data-line-number="207"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-208" data-line-number="208"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-209" data-line-number="209"><span class="co">#&gt; Gradient evaluation took 3.2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-210" data-line-number="210"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.</span></a>
<a class="sourceLine" id="cb70-211" data-line-number="211"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-212" data-line-number="212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-213" data-line-number="213"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-214" data-line-number="214"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-215" data-line-number="215"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-216" data-line-number="216"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-217" data-line-number="217"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-218" data-line-number="218"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-219" data-line-number="219"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-220" data-line-number="220"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-221" data-line-number="221"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-222" data-line-number="222"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-223" data-line-number="223"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-224" data-line-number="224"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-225" data-line-number="225"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-226" data-line-number="226"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-227" data-line-number="227"><span class="co">#&gt;  Elapsed Time: 0.157295 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-228" data-line-number="228"><span class="co">#&gt;                0.12598 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-229" data-line-number="229"><span class="co">#&gt;                0.283275 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-230" data-line-number="230"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-231" data-line-number="231"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-232" data-line-number="232"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-233" data-line-number="233"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-234" data-line-number="234"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-235" data-line-number="235"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-236" data-line-number="236"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-237" data-line-number="237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-238" data-line-number="238"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-239" data-line-number="239"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-240" data-line-number="240"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-241" data-line-number="241"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-242" data-line-number="242"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-243" data-line-number="243"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-244" data-line-number="244"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-245" data-line-number="245"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-246" data-line-number="246"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-247" data-line-number="247"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-248" data-line-number="248"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-249" data-line-number="249"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-250" data-line-number="250"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-251" data-line-number="251"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-252" data-line-number="252"><span class="co">#&gt;  Elapsed Time: 0.165807 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-253" data-line-number="253"><span class="co">#&gt;                0.128247 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-254" data-line-number="254"><span class="co">#&gt;                0.294054 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-255" data-line-number="255"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-256" data-line-number="256"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-257" data-line-number="257"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-258" data-line-number="258"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-259" data-line-number="259"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-260" data-line-number="260"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-261" data-line-number="261"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-262" data-line-number="262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-263" data-line-number="263"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-264" data-line-number="264"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-265" data-line-number="265"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-266" data-line-number="266"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-267" data-line-number="267"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-268" data-line-number="268"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-269" data-line-number="269"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-270" data-line-number="270"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-271" data-line-number="271"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-272" data-line-number="272"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-273" data-line-number="273"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-274" data-line-number="274"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-275" data-line-number="275"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-276" data-line-number="276"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-277" data-line-number="277"><span class="co">#&gt;  Elapsed Time: 0.17434 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-278" data-line-number="278"><span class="co">#&gt;                0.137339 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-279" data-line-number="279"><span class="co">#&gt;                0.311679 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-280" data-line-number="280"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-281" data-line-number="281"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-282" data-line-number="282"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-283" data-line-number="283"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-284" data-line-number="284"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-285" data-line-number="285"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-286" data-line-number="286"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-287" data-line-number="287"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-288" data-line-number="288"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-289" data-line-number="289"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-290" data-line-number="290"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-291" data-line-number="291"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-292" data-line-number="292"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-293" data-line-number="293"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-294" data-line-number="294"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-295" data-line-number="295"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-296" data-line-number="296"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-297" data-line-number="297"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-298" data-line-number="298"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-299" data-line-number="299"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-300" data-line-number="300"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-301" data-line-number="301"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-302" data-line-number="302"><span class="co">#&gt;  Elapsed Time: 0.155348 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-303" data-line-number="303"><span class="co">#&gt;                0.12996 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-304" data-line-number="304"><span class="co">#&gt;                0.285308 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-305" data-line-number="305"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-306" data-line-number="306"><span class="co">#&gt; Tau =  1.41</span></a>
<a class="sourceLine" id="cb70-307" data-line-number="307"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-308" data-line-number="308"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-309" data-line-number="309"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb70-310" data-line-number="310"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb70-311" data-line-number="311"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-312" data-line-number="312"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-313" data-line-number="313"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-314" data-line-number="314"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-315" data-line-number="315"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-316" data-line-number="316"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-317" data-line-number="317"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-318" data-line-number="318"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-319" data-line-number="319"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-320" data-line-number="320"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-321" data-line-number="321"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-322" data-line-number="322"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-323" data-line-number="323"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-324" data-line-number="324"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-325" data-line-number="325"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-326" data-line-number="326"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-327" data-line-number="327"><span class="co">#&gt;  Elapsed Time: 0.151035 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-328" data-line-number="328"><span class="co">#&gt;                0.122661 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-329" data-line-number="329"><span class="co">#&gt;                0.273696 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-330" data-line-number="330"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-331" data-line-number="331"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-332" data-line-number="332"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-333" data-line-number="333"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-334" data-line-number="334"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-335" data-line-number="335"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-336" data-line-number="336"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-337" data-line-number="337"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-338" data-line-number="338"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-339" data-line-number="339"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-340" data-line-number="340"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-341" data-line-number="341"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-342" data-line-number="342"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-343" data-line-number="343"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-344" data-line-number="344"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-345" data-line-number="345"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-346" data-line-number="346"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-347" data-line-number="347"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-348" data-line-number="348"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-349" data-line-number="349"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-350" data-line-number="350"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-351" data-line-number="351"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-352" data-line-number="352"><span class="co">#&gt;  Elapsed Time: 0.168477 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-353" data-line-number="353"><span class="co">#&gt;                0.138765 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-354" data-line-number="354"><span class="co">#&gt;                0.307242 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-355" data-line-number="355"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-356" data-line-number="356"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-357" data-line-number="357"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-358" data-line-number="358"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-359" data-line-number="359"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-360" data-line-number="360"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-361" data-line-number="361"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-362" data-line-number="362"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-363" data-line-number="363"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-364" data-line-number="364"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-365" data-line-number="365"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-366" data-line-number="366"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-367" data-line-number="367"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-368" data-line-number="368"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-369" data-line-number="369"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-370" data-line-number="370"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-371" data-line-number="371"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-372" data-line-number="372"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-373" data-line-number="373"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-374" data-line-number="374"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-375" data-line-number="375"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-376" data-line-number="376"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-377" data-line-number="377"><span class="co">#&gt;  Elapsed Time: 0.166347 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-378" data-line-number="378"><span class="co">#&gt;                0.119069 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-379" data-line-number="379"><span class="co">#&gt;                0.285416 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-380" data-line-number="380"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-381" data-line-number="381"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-382" data-line-number="382"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-383" data-line-number="383"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-384" data-line-number="384"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-385" data-line-number="385"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-386" data-line-number="386"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-387" data-line-number="387"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-388" data-line-number="388"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-389" data-line-number="389"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-390" data-line-number="390"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-391" data-line-number="391"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-392" data-line-number="392"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-393" data-line-number="393"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-394" data-line-number="394"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-395" data-line-number="395"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-396" data-line-number="396"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-397" data-line-number="397"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-398" data-line-number="398"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-399" data-line-number="399"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-400" data-line-number="400"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-401" data-line-number="401"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-402" data-line-number="402"><span class="co">#&gt;  Elapsed Time: 0.165977 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-403" data-line-number="403"><span class="co">#&gt;                0.13783 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-404" data-line-number="404"><span class="co">#&gt;                0.303807 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-405" data-line-number="405"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-406" data-line-number="406"><span class="co">#&gt; Tau =  1</span></a>
<a class="sourceLine" id="cb70-407" data-line-number="407"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-408" data-line-number="408"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-409" data-line-number="409"><span class="co">#&gt; Gradient evaluation took 2.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-410" data-line-number="410"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.</span></a>
<a class="sourceLine" id="cb70-411" data-line-number="411"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-412" data-line-number="412"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-413" data-line-number="413"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-414" data-line-number="414"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-415" data-line-number="415"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-416" data-line-number="416"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-417" data-line-number="417"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-418" data-line-number="418"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-419" data-line-number="419"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-420" data-line-number="420"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-421" data-line-number="421"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-422" data-line-number="422"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-423" data-line-number="423"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-424" data-line-number="424"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-425" data-line-number="425"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-426" data-line-number="426"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-427" data-line-number="427"><span class="co">#&gt;  Elapsed Time: 0.155363 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-428" data-line-number="428"><span class="co">#&gt;                0.135929 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-429" data-line-number="429"><span class="co">#&gt;                0.291292 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-430" data-line-number="430"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-431" data-line-number="431"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-432" data-line-number="432"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-433" data-line-number="433"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-434" data-line-number="434"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb70-435" data-line-number="435"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb70-436" data-line-number="436"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-437" data-line-number="437"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-438" data-line-number="438"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-439" data-line-number="439"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-440" data-line-number="440"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-441" data-line-number="441"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-442" data-line-number="442"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-443" data-line-number="443"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-444" data-line-number="444"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-445" data-line-number="445"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-446" data-line-number="446"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-447" data-line-number="447"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-448" data-line-number="448"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-449" data-line-number="449"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-450" data-line-number="450"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-451" data-line-number="451"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-452" data-line-number="452"><span class="co">#&gt;  Elapsed Time: 0.156522 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-453" data-line-number="453"><span class="co">#&gt;                0.12641 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-454" data-line-number="454"><span class="co">#&gt;                0.282932 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-455" data-line-number="455"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-456" data-line-number="456"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-457" data-line-number="457"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-458" data-line-number="458"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-459" data-line-number="459"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-460" data-line-number="460"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb70-461" data-line-number="461"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-462" data-line-number="462"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-463" data-line-number="463"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-464" data-line-number="464"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-465" data-line-number="465"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-466" data-line-number="466"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-467" data-line-number="467"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-468" data-line-number="468"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-469" data-line-number="469"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-470" data-line-number="470"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-471" data-line-number="471"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-472" data-line-number="472"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-473" data-line-number="473"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-474" data-line-number="474"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-475" data-line-number="475"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-476" data-line-number="476"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-477" data-line-number="477"><span class="co">#&gt;  Elapsed Time: 0.152098 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-478" data-line-number="478"><span class="co">#&gt;                0.117134 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-479" data-line-number="479"><span class="co">#&gt;                0.269232 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-480" data-line-number="480"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-481" data-line-number="481"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-482" data-line-number="482"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-483" data-line-number="483"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-484" data-line-number="484"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-485" data-line-number="485"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-486" data-line-number="486"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-487" data-line-number="487"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-488" data-line-number="488"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-489" data-line-number="489"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-490" data-line-number="490"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-491" data-line-number="491"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-492" data-line-number="492"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-493" data-line-number="493"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-494" data-line-number="494"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-495" data-line-number="495"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-496" data-line-number="496"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-497" data-line-number="497"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-498" data-line-number="498"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-499" data-line-number="499"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-500" data-line-number="500"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-501" data-line-number="501"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-502" data-line-number="502"><span class="co">#&gt;  Elapsed Time: 0.169239 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-503" data-line-number="503"><span class="co">#&gt;                0.126917 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-504" data-line-number="504"><span class="co">#&gt;                0.296156 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-505" data-line-number="505"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-506" data-line-number="506"><span class="co">#&gt; Tau =  0.707</span></a>
<a class="sourceLine" id="cb70-507" data-line-number="507"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-508" data-line-number="508"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-509" data-line-number="509"><span class="co">#&gt; Gradient evaluation took 2.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-510" data-line-number="510"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.</span></a>
<a class="sourceLine" id="cb70-511" data-line-number="511"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-512" data-line-number="512"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-513" data-line-number="513"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-514" data-line-number="514"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-515" data-line-number="515"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-516" data-line-number="516"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-517" data-line-number="517"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-518" data-line-number="518"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-519" data-line-number="519"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-520" data-line-number="520"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-521" data-line-number="521"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-522" data-line-number="522"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-523" data-line-number="523"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-524" data-line-number="524"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-525" data-line-number="525"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-526" data-line-number="526"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-527" data-line-number="527"><span class="co">#&gt;  Elapsed Time: 0.144612 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-528" data-line-number="528"><span class="co">#&gt;                0.125574 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-529" data-line-number="529"><span class="co">#&gt;                0.270186 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-530" data-line-number="530"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-531" data-line-number="531"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-532" data-line-number="532"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-533" data-line-number="533"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-534" data-line-number="534"><span class="co">#&gt; Gradient evaluation took 1.2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-535" data-line-number="535"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.</span></a>
<a class="sourceLine" id="cb70-536" data-line-number="536"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-537" data-line-number="537"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-538" data-line-number="538"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-539" data-line-number="539"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-540" data-line-number="540"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-541" data-line-number="541"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-542" data-line-number="542"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-543" data-line-number="543"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-544" data-line-number="544"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-545" data-line-number="545"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-546" data-line-number="546"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-547" data-line-number="547"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-548" data-line-number="548"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-549" data-line-number="549"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-550" data-line-number="550"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-551" data-line-number="551"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-552" data-line-number="552"><span class="co">#&gt;  Elapsed Time: 0.141649 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-553" data-line-number="553"><span class="co">#&gt;                0.119192 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-554" data-line-number="554"><span class="co">#&gt;                0.260841 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-555" data-line-number="555"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-556" data-line-number="556"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-557" data-line-number="557"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-558" data-line-number="558"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-559" data-line-number="559"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-560" data-line-number="560"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-561" data-line-number="561"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-562" data-line-number="562"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-563" data-line-number="563"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-564" data-line-number="564"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-565" data-line-number="565"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-566" data-line-number="566"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-567" data-line-number="567"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-568" data-line-number="568"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-569" data-line-number="569"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-570" data-line-number="570"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-571" data-line-number="571"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-572" data-line-number="572"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-573" data-line-number="573"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-574" data-line-number="574"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-575" data-line-number="575"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-576" data-line-number="576"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-577" data-line-number="577"><span class="co">#&gt;  Elapsed Time: 0.152489 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-578" data-line-number="578"><span class="co">#&gt;                0.131134 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-579" data-line-number="579"><span class="co">#&gt;                0.283623 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-580" data-line-number="580"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-581" data-line-number="581"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-582" data-line-number="582"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-583" data-line-number="583"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-584" data-line-number="584"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-585" data-line-number="585"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-586" data-line-number="586"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-587" data-line-number="587"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-588" data-line-number="588"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-589" data-line-number="589"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-590" data-line-number="590"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-591" data-line-number="591"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-592" data-line-number="592"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-593" data-line-number="593"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-594" data-line-number="594"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-595" data-line-number="595"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-596" data-line-number="596"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-597" data-line-number="597"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-598" data-line-number="598"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-599" data-line-number="599"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-600" data-line-number="600"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-601" data-line-number="601"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-602" data-line-number="602"><span class="co">#&gt;  Elapsed Time: 0.161852 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-603" data-line-number="603"><span class="co">#&gt;                0.13558 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-604" data-line-number="604"><span class="co">#&gt;                0.297432 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-605" data-line-number="605"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-606" data-line-number="606"><span class="co">#&gt; Tau =  0.5</span></a>
<a class="sourceLine" id="cb70-607" data-line-number="607"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-608" data-line-number="608"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-609" data-line-number="609"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb70-610" data-line-number="610"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb70-611" data-line-number="611"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-612" data-line-number="612"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-613" data-line-number="613"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-614" data-line-number="614"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-615" data-line-number="615"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-616" data-line-number="616"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-617" data-line-number="617"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-618" data-line-number="618"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-619" data-line-number="619"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-620" data-line-number="620"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-621" data-line-number="621"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-622" data-line-number="622"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-623" data-line-number="623"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-624" data-line-number="624"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-625" data-line-number="625"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-626" data-line-number="626"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-627" data-line-number="627"><span class="co">#&gt;  Elapsed Time: 0.132697 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-628" data-line-number="628"><span class="co">#&gt;                0.101804 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-629" data-line-number="629"><span class="co">#&gt;                0.234501 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-630" data-line-number="630"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-631" data-line-number="631"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-632" data-line-number="632"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-633" data-line-number="633"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-634" data-line-number="634"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-635" data-line-number="635"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-636" data-line-number="636"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-637" data-line-number="637"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-638" data-line-number="638"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-639" data-line-number="639"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-640" data-line-number="640"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-641" data-line-number="641"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-642" data-line-number="642"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-643" data-line-number="643"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-644" data-line-number="644"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-645" data-line-number="645"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-646" data-line-number="646"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-647" data-line-number="647"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-648" data-line-number="648"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-649" data-line-number="649"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-650" data-line-number="650"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-651" data-line-number="651"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-652" data-line-number="652"><span class="co">#&gt;  Elapsed Time: 0.141479 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-653" data-line-number="653"><span class="co">#&gt;                0.124046 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-654" data-line-number="654"><span class="co">#&gt;                0.265525 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-655" data-line-number="655"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-656" data-line-number="656"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-657" data-line-number="657"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-658" data-line-number="658"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-659" data-line-number="659"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb70-660" data-line-number="660"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb70-661" data-line-number="661"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-662" data-line-number="662"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-663" data-line-number="663"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-664" data-line-number="664"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-665" data-line-number="665"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-666" data-line-number="666"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-667" data-line-number="667"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-668" data-line-number="668"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-669" data-line-number="669"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-670" data-line-number="670"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-671" data-line-number="671"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-672" data-line-number="672"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-673" data-line-number="673"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-674" data-line-number="674"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-675" data-line-number="675"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-676" data-line-number="676"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-677" data-line-number="677"><span class="co">#&gt;  Elapsed Time: 0.145724 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-678" data-line-number="678"><span class="co">#&gt;                0.107125 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-679" data-line-number="679"><span class="co">#&gt;                0.252849 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-680" data-line-number="680"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-681" data-line-number="681"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-682" data-line-number="682"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-683" data-line-number="683"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-684" data-line-number="684"><span class="co">#&gt; Gradient evaluation took 1.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-685" data-line-number="685"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.</span></a>
<a class="sourceLine" id="cb70-686" data-line-number="686"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-687" data-line-number="687"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-688" data-line-number="688"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-689" data-line-number="689"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-690" data-line-number="690"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-691" data-line-number="691"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-692" data-line-number="692"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-693" data-line-number="693"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-694" data-line-number="694"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-695" data-line-number="695"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-696" data-line-number="696"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-697" data-line-number="697"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-698" data-line-number="698"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-699" data-line-number="699"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-700" data-line-number="700"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-701" data-line-number="701"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-702" data-line-number="702"><span class="co">#&gt;  Elapsed Time: 0.138335 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-703" data-line-number="703"><span class="co">#&gt;                0.0871 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-704" data-line-number="704"><span class="co">#&gt;                0.225435 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-705" data-line-number="705"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-706" data-line-number="706"><span class="co">#&gt; Tau =  0.354</span></a>
<a class="sourceLine" id="cb70-707" data-line-number="707"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-708" data-line-number="708"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-709" data-line-number="709"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb70-710" data-line-number="710"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb70-711" data-line-number="711"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-712" data-line-number="712"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-713" data-line-number="713"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-714" data-line-number="714"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-715" data-line-number="715"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-716" data-line-number="716"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-717" data-line-number="717"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-718" data-line-number="718"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-719" data-line-number="719"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-720" data-line-number="720"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-721" data-line-number="721"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-722" data-line-number="722"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-723" data-line-number="723"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-724" data-line-number="724"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-725" data-line-number="725"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-726" data-line-number="726"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-727" data-line-number="727"><span class="co">#&gt;  Elapsed Time: 0.137622 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-728" data-line-number="728"><span class="co">#&gt;                0.085612 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-729" data-line-number="729"><span class="co">#&gt;                0.223234 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-730" data-line-number="730"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-731" data-line-number="731"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-732" data-line-number="732"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-733" data-line-number="733"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-734" data-line-number="734"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb70-735" data-line-number="735"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb70-736" data-line-number="736"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-737" data-line-number="737"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-738" data-line-number="738"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-739" data-line-number="739"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-740" data-line-number="740"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-741" data-line-number="741"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-742" data-line-number="742"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-743" data-line-number="743"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-744" data-line-number="744"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-745" data-line-number="745"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-746" data-line-number="746"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-747" data-line-number="747"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-748" data-line-number="748"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-749" data-line-number="749"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-750" data-line-number="750"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-751" data-line-number="751"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-752" data-line-number="752"><span class="co">#&gt;  Elapsed Time: 0.132972 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-753" data-line-number="753"><span class="co">#&gt;                0.106316 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-754" data-line-number="754"><span class="co">#&gt;                0.239288 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-755" data-line-number="755"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-756" data-line-number="756"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-757" data-line-number="757"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-758" data-line-number="758"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-759" data-line-number="759"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-760" data-line-number="760"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-761" data-line-number="761"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-762" data-line-number="762"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-763" data-line-number="763"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-764" data-line-number="764"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-765" data-line-number="765"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-766" data-line-number="766"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-767" data-line-number="767"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-768" data-line-number="768"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-769" data-line-number="769"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-770" data-line-number="770"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-771" data-line-number="771"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-772" data-line-number="772"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-773" data-line-number="773"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-774" data-line-number="774"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-775" data-line-number="775"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-776" data-line-number="776"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-777" data-line-number="777"><span class="co">#&gt;  Elapsed Time: 0.124177 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-778" data-line-number="778"><span class="co">#&gt;                0.087221 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-779" data-line-number="779"><span class="co">#&gt;                0.211398 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-780" data-line-number="780"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-781" data-line-number="781"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-782" data-line-number="782"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-783" data-line-number="783"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-784" data-line-number="784"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-785" data-line-number="785"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-786" data-line-number="786"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-787" data-line-number="787"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-788" data-line-number="788"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-789" data-line-number="789"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-790" data-line-number="790"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-791" data-line-number="791"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-792" data-line-number="792"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-793" data-line-number="793"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-794" data-line-number="794"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-795" data-line-number="795"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-796" data-line-number="796"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-797" data-line-number="797"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-798" data-line-number="798"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-799" data-line-number="799"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-800" data-line-number="800"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-801" data-line-number="801"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-802" data-line-number="802"><span class="co">#&gt;  Elapsed Time: 0.141065 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-803" data-line-number="803"><span class="co">#&gt;                0.090947 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-804" data-line-number="804"><span class="co">#&gt;                0.232012 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-805" data-line-number="805"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-806" data-line-number="806"><span class="co">#&gt; Tau =  0.25</span></a>
<a class="sourceLine" id="cb70-807" data-line-number="807"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-808" data-line-number="808"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-809" data-line-number="809"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb70-810" data-line-number="810"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb70-811" data-line-number="811"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-812" data-line-number="812"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-813" data-line-number="813"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-814" data-line-number="814"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-815" data-line-number="815"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-816" data-line-number="816"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-817" data-line-number="817"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-818" data-line-number="818"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-819" data-line-number="819"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-820" data-line-number="820"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-821" data-line-number="821"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-822" data-line-number="822"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-823" data-line-number="823"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-824" data-line-number="824"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-825" data-line-number="825"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-826" data-line-number="826"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-827" data-line-number="827"><span class="co">#&gt;  Elapsed Time: 0.123187 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-828" data-line-number="828"><span class="co">#&gt;                0.085269 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-829" data-line-number="829"><span class="co">#&gt;                0.208456 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-830" data-line-number="830"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-831" data-line-number="831"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-832" data-line-number="832"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-833" data-line-number="833"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-834" data-line-number="834"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-835" data-line-number="835"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-836" data-line-number="836"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-837" data-line-number="837"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-838" data-line-number="838"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-839" data-line-number="839"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-840" data-line-number="840"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-841" data-line-number="841"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-842" data-line-number="842"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-843" data-line-number="843"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-844" data-line-number="844"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-845" data-line-number="845"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-846" data-line-number="846"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-847" data-line-number="847"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-848" data-line-number="848"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-849" data-line-number="849"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-850" data-line-number="850"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-851" data-line-number="851"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-852" data-line-number="852"><span class="co">#&gt;  Elapsed Time: 0.116354 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-853" data-line-number="853"><span class="co">#&gt;                0.084139 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-854" data-line-number="854"><span class="co">#&gt;                0.200493 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-855" data-line-number="855"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-856" data-line-number="856"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-857" data-line-number="857"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-858" data-line-number="858"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-859" data-line-number="859"><span class="co">#&gt; Gradient evaluation took 1.2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-860" data-line-number="860"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.</span></a>
<a class="sourceLine" id="cb70-861" data-line-number="861"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-862" data-line-number="862"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-863" data-line-number="863"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-864" data-line-number="864"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-865" data-line-number="865"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-866" data-line-number="866"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-867" data-line-number="867"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-868" data-line-number="868"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-869" data-line-number="869"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-870" data-line-number="870"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-871" data-line-number="871"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-872" data-line-number="872"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-873" data-line-number="873"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-874" data-line-number="874"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-875" data-line-number="875"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-876" data-line-number="876"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-877" data-line-number="877"><span class="co">#&gt;  Elapsed Time: 0.123148 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-878" data-line-number="878"><span class="co">#&gt;                0.08502 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-879" data-line-number="879"><span class="co">#&gt;                0.208168 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-880" data-line-number="880"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-881" data-line-number="881"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-882" data-line-number="882"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-883" data-line-number="883"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-884" data-line-number="884"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-885" data-line-number="885"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-886" data-line-number="886"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-887" data-line-number="887"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-888" data-line-number="888"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-889" data-line-number="889"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-890" data-line-number="890"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-891" data-line-number="891"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-892" data-line-number="892"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-893" data-line-number="893"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-894" data-line-number="894"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-895" data-line-number="895"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-896" data-line-number="896"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-897" data-line-number="897"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-898" data-line-number="898"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-899" data-line-number="899"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-900" data-line-number="900"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-901" data-line-number="901"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-902" data-line-number="902"><span class="co">#&gt;  Elapsed Time: 0.129021 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-903" data-line-number="903"><span class="co">#&gt;                0.087296 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-904" data-line-number="904"><span class="co">#&gt;                0.216317 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-905" data-line-number="905"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-906" data-line-number="906"><span class="co">#&gt; Tau =  0.177</span></a>
<a class="sourceLine" id="cb70-907" data-line-number="907"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-908" data-line-number="908"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-909" data-line-number="909"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb70-910" data-line-number="910"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb70-911" data-line-number="911"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-912" data-line-number="912"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-913" data-line-number="913"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-914" data-line-number="914"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-915" data-line-number="915"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-916" data-line-number="916"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-917" data-line-number="917"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-918" data-line-number="918"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-919" data-line-number="919"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-920" data-line-number="920"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-921" data-line-number="921"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-922" data-line-number="922"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-923" data-line-number="923"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-924" data-line-number="924"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-925" data-line-number="925"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-926" data-line-number="926"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-927" data-line-number="927"><span class="co">#&gt;  Elapsed Time: 0.146875 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-928" data-line-number="928"><span class="co">#&gt;                0.084014 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-929" data-line-number="929"><span class="co">#&gt;                0.230889 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-930" data-line-number="930"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-931" data-line-number="931"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-932" data-line-number="932"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-933" data-line-number="933"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-934" data-line-number="934"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-935" data-line-number="935"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-936" data-line-number="936"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-937" data-line-number="937"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-938" data-line-number="938"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-939" data-line-number="939"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-940" data-line-number="940"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-941" data-line-number="941"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-942" data-line-number="942"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-943" data-line-number="943"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-944" data-line-number="944"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-945" data-line-number="945"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-946" data-line-number="946"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-947" data-line-number="947"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-948" data-line-number="948"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-949" data-line-number="949"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-950" data-line-number="950"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-951" data-line-number="951"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-952" data-line-number="952"><span class="co">#&gt;  Elapsed Time: 0.114281 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-953" data-line-number="953"><span class="co">#&gt;                0.082986 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-954" data-line-number="954"><span class="co">#&gt;                0.197267 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-955" data-line-number="955"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-956" data-line-number="956"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-957" data-line-number="957"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-958" data-line-number="958"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-959" data-line-number="959"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-960" data-line-number="960"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-961" data-line-number="961"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-962" data-line-number="962"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-963" data-line-number="963"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-964" data-line-number="964"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-965" data-line-number="965"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-966" data-line-number="966"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-967" data-line-number="967"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-968" data-line-number="968"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-969" data-line-number="969"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-970" data-line-number="970"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-971" data-line-number="971"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-972" data-line-number="972"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-973" data-line-number="973"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-974" data-line-number="974"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-975" data-line-number="975"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-976" data-line-number="976"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-977" data-line-number="977"><span class="co">#&gt;  Elapsed Time: 0.124388 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-978" data-line-number="978"><span class="co">#&gt;                0.085893 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-979" data-line-number="979"><span class="co">#&gt;                0.210281 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-980" data-line-number="980"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-981" data-line-number="981"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-982" data-line-number="982"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-983" data-line-number="983"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-984" data-line-number="984"><span class="co">#&gt; Gradient evaluation took 1.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-985" data-line-number="985"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.</span></a>
<a class="sourceLine" id="cb70-986" data-line-number="986"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-987" data-line-number="987"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-988" data-line-number="988"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-989" data-line-number="989"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-990" data-line-number="990"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-991" data-line-number="991"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-992" data-line-number="992"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-993" data-line-number="993"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-994" data-line-number="994"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-995" data-line-number="995"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-996" data-line-number="996"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-997" data-line-number="997"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-998" data-line-number="998"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-999" data-line-number="999"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1000" data-line-number="1000"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1001" data-line-number="1001"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1002" data-line-number="1002"><span class="co">#&gt;  Elapsed Time: 0.127223 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1003" data-line-number="1003"><span class="co">#&gt;                0.081284 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1004" data-line-number="1004"><span class="co">#&gt;                0.208507 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1005" data-line-number="1005"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1006" data-line-number="1006"><span class="co">#&gt; Tau =  0.125</span></a>
<a class="sourceLine" id="cb70-1007" data-line-number="1007"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-1008" data-line-number="1008"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1009" data-line-number="1009"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1010" data-line-number="1010"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb70-1011" data-line-number="1011"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1012" data-line-number="1012"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1013" data-line-number="1013"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1014" data-line-number="1014"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1015" data-line-number="1015"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1016" data-line-number="1016"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1017" data-line-number="1017"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1018" data-line-number="1018"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1019" data-line-number="1019"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1020" data-line-number="1020"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1021" data-line-number="1021"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1022" data-line-number="1022"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1023" data-line-number="1023"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1024" data-line-number="1024"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1025" data-line-number="1025"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1026" data-line-number="1026"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1027" data-line-number="1027"><span class="co">#&gt;  Elapsed Time: 0.130665 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1028" data-line-number="1028"><span class="co">#&gt;                0.082034 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1029" data-line-number="1029"><span class="co">#&gt;                0.212699 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1030" data-line-number="1030"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1031" data-line-number="1031"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1032" data-line-number="1032"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-1033" data-line-number="1033"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1034" data-line-number="1034"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1035" data-line-number="1035"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-1036" data-line-number="1036"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1037" data-line-number="1037"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1038" data-line-number="1038"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1039" data-line-number="1039"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1040" data-line-number="1040"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1041" data-line-number="1041"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1042" data-line-number="1042"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1043" data-line-number="1043"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1044" data-line-number="1044"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1045" data-line-number="1045"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1046" data-line-number="1046"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1047" data-line-number="1047"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1048" data-line-number="1048"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1049" data-line-number="1049"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1050" data-line-number="1050"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1051" data-line-number="1051"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1052" data-line-number="1052"><span class="co">#&gt;  Elapsed Time: 0.122393 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1053" data-line-number="1053"><span class="co">#&gt;                0.083755 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1054" data-line-number="1054"><span class="co">#&gt;                0.206148 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1055" data-line-number="1055"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1056" data-line-number="1056"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1057" data-line-number="1057"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-1058" data-line-number="1058"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1059" data-line-number="1059"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1060" data-line-number="1060"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-1061" data-line-number="1061"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1062" data-line-number="1062"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1063" data-line-number="1063"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1064" data-line-number="1064"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1065" data-line-number="1065"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1066" data-line-number="1066"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1067" data-line-number="1067"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1068" data-line-number="1068"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1069" data-line-number="1069"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1070" data-line-number="1070"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1071" data-line-number="1071"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1072" data-line-number="1072"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1073" data-line-number="1073"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1074" data-line-number="1074"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1075" data-line-number="1075"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1076" data-line-number="1076"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1077" data-line-number="1077"><span class="co">#&gt;  Elapsed Time: 0.117707 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1078" data-line-number="1078"><span class="co">#&gt;                0.08409 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1079" data-line-number="1079"><span class="co">#&gt;                0.201797 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1080" data-line-number="1080"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1081" data-line-number="1081"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1082" data-line-number="1082"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-1083" data-line-number="1083"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1084" data-line-number="1084"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1085" data-line-number="1085"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-1086" data-line-number="1086"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1087" data-line-number="1087"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1088" data-line-number="1088"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1089" data-line-number="1089"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1090" data-line-number="1090"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1091" data-line-number="1091"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1092" data-line-number="1092"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1093" data-line-number="1093"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1094" data-line-number="1094"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1095" data-line-number="1095"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1096" data-line-number="1096"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1097" data-line-number="1097"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1098" data-line-number="1098"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1099" data-line-number="1099"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1100" data-line-number="1100"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1101" data-line-number="1101"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1102" data-line-number="1102"><span class="co">#&gt;  Elapsed Time: 0.11971 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1103" data-line-number="1103"><span class="co">#&gt;                0.081726 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1104" data-line-number="1104"><span class="co">#&gt;                0.201436 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1105" data-line-number="1105"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1106" data-line-number="1106"><span class="co">#&gt; Tau =  0.0884</span></a>
<a class="sourceLine" id="cb70-1107" data-line-number="1107"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-1108" data-line-number="1108"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1109" data-line-number="1109"><span class="co">#&gt; Gradient evaluation took 2.9e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1110" data-line-number="1110"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.</span></a>
<a class="sourceLine" id="cb70-1111" data-line-number="1111"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1112" data-line-number="1112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1113" data-line-number="1113"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1114" data-line-number="1114"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1115" data-line-number="1115"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1116" data-line-number="1116"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1117" data-line-number="1117"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1118" data-line-number="1118"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1119" data-line-number="1119"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1120" data-line-number="1120"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1121" data-line-number="1121"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1122" data-line-number="1122"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1123" data-line-number="1123"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1124" data-line-number="1124"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1125" data-line-number="1125"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1126" data-line-number="1126"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1127" data-line-number="1127"><span class="co">#&gt;  Elapsed Time: 0.130868 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1128" data-line-number="1128"><span class="co">#&gt;                0.083027 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1129" data-line-number="1129"><span class="co">#&gt;                0.213895 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1130" data-line-number="1130"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1131" data-line-number="1131"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1132" data-line-number="1132"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-1133" data-line-number="1133"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1134" data-line-number="1134"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1135" data-line-number="1135"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb70-1136" data-line-number="1136"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1137" data-line-number="1137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1138" data-line-number="1138"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1139" data-line-number="1139"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1140" data-line-number="1140"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1141" data-line-number="1141"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1142" data-line-number="1142"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1143" data-line-number="1143"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1144" data-line-number="1144"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1145" data-line-number="1145"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1146" data-line-number="1146"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1147" data-line-number="1147"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1148" data-line-number="1148"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1149" data-line-number="1149"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1150" data-line-number="1150"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1151" data-line-number="1151"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1152" data-line-number="1152"><span class="co">#&gt;  Elapsed Time: 0.121938 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1153" data-line-number="1153"><span class="co">#&gt;                0.082334 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1154" data-line-number="1154"><span class="co">#&gt;                0.204272 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1155" data-line-number="1155"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1156" data-line-number="1156"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1157" data-line-number="1157"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-1158" data-line-number="1158"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1159" data-line-number="1159"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1160" data-line-number="1160"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb70-1161" data-line-number="1161"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1162" data-line-number="1162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1163" data-line-number="1163"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1164" data-line-number="1164"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1165" data-line-number="1165"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1166" data-line-number="1166"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1167" data-line-number="1167"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1168" data-line-number="1168"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1169" data-line-number="1169"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1170" data-line-number="1170"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1171" data-line-number="1171"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1172" data-line-number="1172"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1173" data-line-number="1173"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1174" data-line-number="1174"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1175" data-line-number="1175"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1176" data-line-number="1176"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1177" data-line-number="1177"><span class="co">#&gt;  Elapsed Time: 0.134972 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1178" data-line-number="1178"><span class="co">#&gt;                0.085134 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1179" data-line-number="1179"><span class="co">#&gt;                0.220106 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1180" data-line-number="1180"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1181" data-line-number="1181"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1182" data-line-number="1182"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-1183" data-line-number="1183"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1184" data-line-number="1184"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1185" data-line-number="1185"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-1186" data-line-number="1186"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1187" data-line-number="1187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1188" data-line-number="1188"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1189" data-line-number="1189"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1190" data-line-number="1190"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1191" data-line-number="1191"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1192" data-line-number="1192"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1193" data-line-number="1193"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1194" data-line-number="1194"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1195" data-line-number="1195"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1196" data-line-number="1196"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1197" data-line-number="1197"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1198" data-line-number="1198"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1199" data-line-number="1199"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1200" data-line-number="1200"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1201" data-line-number="1201"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1202" data-line-number="1202"><span class="co">#&gt;  Elapsed Time: 0.12292 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1203" data-line-number="1203"><span class="co">#&gt;                0.079876 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1204" data-line-number="1204"><span class="co">#&gt;                0.202796 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1205" data-line-number="1205"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1206" data-line-number="1206"><span class="co">#&gt; Tau =  0.0625</span></a>
<a class="sourceLine" id="cb70-1207" data-line-number="1207"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-1208" data-line-number="1208"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1209" data-line-number="1209"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1210" data-line-number="1210"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb70-1211" data-line-number="1211"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1212" data-line-number="1212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1213" data-line-number="1213"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1214" data-line-number="1214"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1215" data-line-number="1215"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1216" data-line-number="1216"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1217" data-line-number="1217"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1218" data-line-number="1218"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1219" data-line-number="1219"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1220" data-line-number="1220"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1221" data-line-number="1221"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1222" data-line-number="1222"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1223" data-line-number="1223"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1224" data-line-number="1224"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1225" data-line-number="1225"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1226" data-line-number="1226"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1227" data-line-number="1227"><span class="co">#&gt;  Elapsed Time: 0.141243 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1228" data-line-number="1228"><span class="co">#&gt;                0.080644 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1229" data-line-number="1229"><span class="co">#&gt;                0.221887 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1230" data-line-number="1230"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1231" data-line-number="1231"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1232" data-line-number="1232"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-1233" data-line-number="1233"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1234" data-line-number="1234"><span class="co">#&gt; Gradient evaluation took 1.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1235" data-line-number="1235"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.</span></a>
<a class="sourceLine" id="cb70-1236" data-line-number="1236"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1237" data-line-number="1237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1238" data-line-number="1238"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1239" data-line-number="1239"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1240" data-line-number="1240"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1241" data-line-number="1241"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1242" data-line-number="1242"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1243" data-line-number="1243"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1244" data-line-number="1244"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1245" data-line-number="1245"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1246" data-line-number="1246"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1247" data-line-number="1247"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1248" data-line-number="1248"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1249" data-line-number="1249"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1250" data-line-number="1250"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1251" data-line-number="1251"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1252" data-line-number="1252"><span class="co">#&gt;  Elapsed Time: 0.147777 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1253" data-line-number="1253"><span class="co">#&gt;                0.080076 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1254" data-line-number="1254"><span class="co">#&gt;                0.227853 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1255" data-line-number="1255"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1256" data-line-number="1256"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1257" data-line-number="1257"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-1258" data-line-number="1258"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1259" data-line-number="1259"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1260" data-line-number="1260"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb70-1261" data-line-number="1261"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1262" data-line-number="1262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1263" data-line-number="1263"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1264" data-line-number="1264"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1265" data-line-number="1265"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1266" data-line-number="1266"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1267" data-line-number="1267"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1268" data-line-number="1268"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1269" data-line-number="1269"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1270" data-line-number="1270"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1271" data-line-number="1271"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1272" data-line-number="1272"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1273" data-line-number="1273"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1274" data-line-number="1274"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1275" data-line-number="1275"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1276" data-line-number="1276"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1277" data-line-number="1277"><span class="co">#&gt;  Elapsed Time: 0.14366 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1278" data-line-number="1278"><span class="co">#&gt;                0.079912 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1279" data-line-number="1279"><span class="co">#&gt;                0.223572 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1280" data-line-number="1280"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1281" data-line-number="1281"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1282" data-line-number="1282"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-1283" data-line-number="1283"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1284" data-line-number="1284"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1285" data-line-number="1285"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb70-1286" data-line-number="1286"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1287" data-line-number="1287"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1288" data-line-number="1288"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1289" data-line-number="1289"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1290" data-line-number="1290"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1291" data-line-number="1291"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1292" data-line-number="1292"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1293" data-line-number="1293"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1294" data-line-number="1294"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1295" data-line-number="1295"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1296" data-line-number="1296"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1297" data-line-number="1297"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1298" data-line-number="1298"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1299" data-line-number="1299"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1300" data-line-number="1300"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1301" data-line-number="1301"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1302" data-line-number="1302"><span class="co">#&gt;  Elapsed Time: 0.12876 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1303" data-line-number="1303"><span class="co">#&gt;                0.079623 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1304" data-line-number="1304"><span class="co">#&gt;                0.208383 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1305" data-line-number="1305"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1306" data-line-number="1306"><span class="co">#&gt; Tau =  0.0442</span></a>
<a class="sourceLine" id="cb70-1307" data-line-number="1307"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-1308" data-line-number="1308"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1309" data-line-number="1309"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1310" data-line-number="1310"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb70-1311" data-line-number="1311"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1312" data-line-number="1312"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1313" data-line-number="1313"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1314" data-line-number="1314"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1315" data-line-number="1315"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1316" data-line-number="1316"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1317" data-line-number="1317"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1318" data-line-number="1318"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1319" data-line-number="1319"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1320" data-line-number="1320"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1321" data-line-number="1321"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1322" data-line-number="1322"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1323" data-line-number="1323"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1324" data-line-number="1324"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1325" data-line-number="1325"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1326" data-line-number="1326"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1327" data-line-number="1327"><span class="co">#&gt;  Elapsed Time: 0.135554 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1328" data-line-number="1328"><span class="co">#&gt;                0.080896 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1329" data-line-number="1329"><span class="co">#&gt;                0.21645 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1330" data-line-number="1330"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1331" data-line-number="1331"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1332" data-line-number="1332"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-1333" data-line-number="1333"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1334" data-line-number="1334"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1335" data-line-number="1335"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb70-1336" data-line-number="1336"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1337" data-line-number="1337"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1338" data-line-number="1338"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1339" data-line-number="1339"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1340" data-line-number="1340"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1341" data-line-number="1341"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1342" data-line-number="1342"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1343" data-line-number="1343"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1344" data-line-number="1344"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1345" data-line-number="1345"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1346" data-line-number="1346"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1347" data-line-number="1347"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1348" data-line-number="1348"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1349" data-line-number="1349"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1350" data-line-number="1350"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1351" data-line-number="1351"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1352" data-line-number="1352"><span class="co">#&gt;  Elapsed Time: 0.138415 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1353" data-line-number="1353"><span class="co">#&gt;                0.082123 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1354" data-line-number="1354"><span class="co">#&gt;                0.220538 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1355" data-line-number="1355"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1356" data-line-number="1356"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1357" data-line-number="1357"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-1358" data-line-number="1358"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1359" data-line-number="1359"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1360" data-line-number="1360"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-1361" data-line-number="1361"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1362" data-line-number="1362"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1363" data-line-number="1363"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1364" data-line-number="1364"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1365" data-line-number="1365"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1366" data-line-number="1366"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1367" data-line-number="1367"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1368" data-line-number="1368"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1369" data-line-number="1369"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1370" data-line-number="1370"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1371" data-line-number="1371"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1372" data-line-number="1372"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1373" data-line-number="1373"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1374" data-line-number="1374"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1375" data-line-number="1375"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1376" data-line-number="1376"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1377" data-line-number="1377"><span class="co">#&gt;  Elapsed Time: 0.143854 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1378" data-line-number="1378"><span class="co">#&gt;                0.079031 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1379" data-line-number="1379"><span class="co">#&gt;                0.222885 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1380" data-line-number="1380"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1381" data-line-number="1381"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1382" data-line-number="1382"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-1383" data-line-number="1383"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1384" data-line-number="1384"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1385" data-line-number="1385"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb70-1386" data-line-number="1386"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1387" data-line-number="1387"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1388" data-line-number="1388"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1389" data-line-number="1389"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1390" data-line-number="1390"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1391" data-line-number="1391"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1392" data-line-number="1392"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1393" data-line-number="1393"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1394" data-line-number="1394"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1395" data-line-number="1395"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1396" data-line-number="1396"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1397" data-line-number="1397"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1398" data-line-number="1398"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1399" data-line-number="1399"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1400" data-line-number="1400"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1401" data-line-number="1401"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1402" data-line-number="1402"><span class="co">#&gt;  Elapsed Time: 0.140652 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1403" data-line-number="1403"><span class="co">#&gt;                0.222103 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1404" data-line-number="1404"><span class="co">#&gt;                0.362755 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1405" data-line-number="1405"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1406" data-line-number="1406"><span class="co">#&gt; Tau =  0.0312</span></a>
<a class="sourceLine" id="cb70-1407" data-line-number="1407"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb70-1408" data-line-number="1408"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1409" data-line-number="1409"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1410" data-line-number="1410"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb70-1411" data-line-number="1411"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1412" data-line-number="1412"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1413" data-line-number="1413"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1414" data-line-number="1414"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1415" data-line-number="1415"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1416" data-line-number="1416"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1417" data-line-number="1417"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1418" data-line-number="1418"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1419" data-line-number="1419"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1420" data-line-number="1420"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1421" data-line-number="1421"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1422" data-line-number="1422"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1423" data-line-number="1423"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1424" data-line-number="1424"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1425" data-line-number="1425"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1426" data-line-number="1426"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1427" data-line-number="1427"><span class="co">#&gt;  Elapsed Time: 0.152801 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1428" data-line-number="1428"><span class="co">#&gt;                0.082293 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1429" data-line-number="1429"><span class="co">#&gt;                0.235094 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1430" data-line-number="1430"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1431" data-line-number="1431"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1432" data-line-number="1432"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb70-1433" data-line-number="1433"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1434" data-line-number="1434"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1435" data-line-number="1435"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb70-1436" data-line-number="1436"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1437" data-line-number="1437"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1438" data-line-number="1438"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1439" data-line-number="1439"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1440" data-line-number="1440"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1441" data-line-number="1441"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1442" data-line-number="1442"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1443" data-line-number="1443"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1444" data-line-number="1444"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1445" data-line-number="1445"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1446" data-line-number="1446"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1447" data-line-number="1447"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1448" data-line-number="1448"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1449" data-line-number="1449"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1450" data-line-number="1450"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1451" data-line-number="1451"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1452" data-line-number="1452"><span class="co">#&gt;  Elapsed Time: 0.187366 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1453" data-line-number="1453"><span class="co">#&gt;                0.082302 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1454" data-line-number="1454"><span class="co">#&gt;                0.269668 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1455" data-line-number="1455"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1456" data-line-number="1456"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1457" data-line-number="1457"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb70-1458" data-line-number="1458"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1459" data-line-number="1459"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1460" data-line-number="1460"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb70-1461" data-line-number="1461"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1462" data-line-number="1462"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1463" data-line-number="1463"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1464" data-line-number="1464"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1465" data-line-number="1465"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1466" data-line-number="1466"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1467" data-line-number="1467"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1468" data-line-number="1468"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1469" data-line-number="1469"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1470" data-line-number="1470"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1471" data-line-number="1471"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1472" data-line-number="1472"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1473" data-line-number="1473"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1474" data-line-number="1474"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1475" data-line-number="1475"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1476" data-line-number="1476"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1477" data-line-number="1477"><span class="co">#&gt;  Elapsed Time: 0.191033 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1478" data-line-number="1478"><span class="co">#&gt;                0.085223 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1479" data-line-number="1479"><span class="co">#&gt;                0.276256 seconds (Total)</span></a>
<a class="sourceLine" id="cb70-1480" data-line-number="1480"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1481" data-line-number="1481"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1482" data-line-number="1482"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-normal-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb70-1483" data-line-number="1483"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1484" data-line-number="1484"><span class="co">#&gt; Gradient evaluation took 3.3e-05 seconds</span></a>
<a class="sourceLine" id="cb70-1485" data-line-number="1485"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.</span></a>
<a class="sourceLine" id="cb70-1486" data-line-number="1486"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb70-1487" data-line-number="1487"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1488" data-line-number="1488"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1489" data-line-number="1489"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1490" data-line-number="1490"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1491" data-line-number="1491"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1492" data-line-number="1492"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1493" data-line-number="1493"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1494" data-line-number="1494"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb70-1495" data-line-number="1495"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1496" data-line-number="1496"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1497" data-line-number="1497"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1498" data-line-number="1498"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1499" data-line-number="1499"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1500" data-line-number="1500"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb70-1501" data-line-number="1501"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb70-1502" data-line-number="1502"><span class="co">#&gt;  Elapsed Time: 0.188981 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb70-1503" data-line-number="1503"><span class="co">#&gt;                0.081884 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb70-1504" data-line-number="1504"><span class="co">#&gt;                0.270865 seconds (Total)</span></a></code></pre></div>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1">plot_coefpaths &lt;-<span class="st"> </span><span class="cf">function</span>(coefpaths, <span class="dt">stat =</span> <span class="st">&quot;mean&quot;</span>) {</a>
<a class="sourceLine" id="cb71-2" data-line-number="2">  <span class="kw">ggplot</span>(<span class="kw">map_df</span>(coefpaths, <span class="st">&quot;summary&quot;</span>), <span class="kw">aes_string</span>(<span class="dt">x =</span> <span class="st">&quot;log2(tau)&quot;</span>, <span class="dt">y =</span> stat,</a>
<a class="sourceLine" id="cb71-3" data-line-number="3">                       <span class="dt">colour =</span> <span class="st">&quot;fct_reorder2(parameter, tau, mean)&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;parameter&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb71-4" data-line-number="4"><span class="st">    </span>modelr<span class="op">::</span><span class="kw">geom_ref_line</span>(<span class="dt">h =</span> <span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb71-5" data-line-number="5"><span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb71-6" data-line-number="6"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Parameter&quot;</span>)  </a>
<a class="sourceLine" id="cb71-7" data-line-number="7">}</a></code></pre></div>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1"><span class="kw">plot_coefpaths</span>(coefpath_normal)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1">plot_coefpath_loo &lt;-<span class="st"> </span><span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb73-2" data-line-number="2">  <span class="kw">map_df</span>(x,</a>
<a class="sourceLine" id="cb73-3" data-line-number="3">       <span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb73-4" data-line-number="4">         <span class="kw">tibble</span>(<span class="dt">tau =</span> x<span class="op">$</span>tau,</a>
<a class="sourceLine" id="cb73-5" data-line-number="5">                <span class="dt">elpd =</span> x<span class="op">$</span>loo<span class="op">$</span>elpd_loo,</a>
<a class="sourceLine" id="cb73-6" data-line-number="6">                <span class="dt">lppd =</span> x<span class="op">$</span>lppd,</a>
<a class="sourceLine" id="cb73-7" data-line-number="7">                <span class="dt">p =</span> x<span class="op">$</span>loo<span class="op">$</span>p_loo)</a>
<a class="sourceLine" id="cb73-8" data-line-number="8">       }) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb73-9" data-line-number="9"><span class="st">    </span><span class="kw">gather</span>(parameter, value, <span class="op">-</span>tau) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb73-10" data-line-number="10"><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tau, <span class="dt">y =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb73-11" data-line-number="11"><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb73-12" data-line-number="12"><span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb73-13" data-line-number="13"><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter, <span class="dt">scale =</span> <span class="st">&quot;free_y&quot;</span>, <span class="dt">ncol =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb73-14" data-line-number="14">}</a></code></pre></div>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1"><span class="kw">plot_coefpath_loo</span>(coefpath_normal)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Which is the “best” <span class="math inline">\(tau\)</span>?</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1">get_best_tau &lt;-<span class="st"> </span><span class="cf">function</span>(coefpath) {</a>
<a class="sourceLine" id="cb75-2" data-line-number="2">  <span class="kw">map_df</span>(coefpath,</a>
<a class="sourceLine" id="cb75-3" data-line-number="3">       <span class="cf">function</span>(x) {</a>
<a class="sourceLine" id="cb75-4" data-line-number="4">         <span class="kw">tibble</span>(<span class="dt">tau =</span> x<span class="op">$</span>tau,</a>
<a class="sourceLine" id="cb75-5" data-line-number="5">                <span class="dt">elpd =</span> x<span class="op">$</span>loo<span class="op">$</span>elpd_loo,</a>
<a class="sourceLine" id="cb75-6" data-line-number="6">                <span class="dt">p =</span> x<span class="op">$</span>loo<span class="op">$</span>p_loo)</a>
<a class="sourceLine" id="cb75-7" data-line-number="7">       }) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb75-8" data-line-number="8"><span class="st">    </span><span class="kw">filter</span>(elpd <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(elpd)) </a>
<a class="sourceLine" id="cb75-9" data-line-number="9">}</a></code></pre></div>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1"><span class="kw">get_best_tau</span>(coefpath_normal)</a>
<a class="sourceLine" id="cb76-2" data-line-number="2"><span class="co">#&gt; # A tibble: 1 × 3</span></a>
<a class="sourceLine" id="cb76-3" data-line-number="3"><span class="co">#&gt;     tau  elpd     p</span></a>
<a class="sourceLine" id="cb76-4" data-line-number="4"><span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb76-5" data-line-number="5"><span class="co">#&gt; 1 0.177  -234   2.3</span></a></code></pre></div>
<p>The mean estimate of <span class="math inline">\(\tau\)</span> is higher than the best estimate, and there is some uncertainty over it.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1">mod_lm_coef_normal_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-normal-2.stan&quot;</span>)</a>
<a class="sourceLine" id="cb77-2" data-line-number="2"><span class="co">#&gt; In file included from file278426df96ec.cpp:8:</span></a>
<a class="sourceLine" id="cb77-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb77-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb77-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb77-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb77-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb77-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb77-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb77-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb77-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb77-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb77-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb77-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb77-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb77-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb77-17" data-line-number="17"><span class="co">#&gt; In file included from file278426df96ec.cpp:8:</span></a>
<a class="sourceLine" id="cb77-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb77-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb77-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb77-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb77-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb77-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb77-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb77-25" data-line-number="25"><span class="co">#&gt; In file included from file278426df96ec.cpp:8:</span></a>
<a class="sourceLine" id="cb77-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb77-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb77-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb77-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb77-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb77-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb77-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb77-33" data-line-number="33"><span class="co">#&gt; In file included from file278426df96ec.cpp:8:</span></a>
<a class="sourceLine" id="cb77-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb77-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb77-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb77-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb77-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb77-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb77-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb77-41" data-line-number="41"><span class="co">#&gt; In file included from file278426df96ec.cpp:8:</span></a>
<a class="sourceLine" id="cb77-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb77-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb77-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb77-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb77-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb77-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb77-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb77-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb77-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb77-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb77-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb77-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb77-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb77-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb77-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb77-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb77-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb77-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb77-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb77-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb77-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb77-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb77-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">fit_normal &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_lm_coef_normal_<span class="dv">2</span>, <span class="dt">data =</span> prostate_data, <span class="dt">refresh =</span> <span class="dv">-1</span>,</a>
<a class="sourceLine" id="cb78-2" data-line-number="2">                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>))</a>
<a class="sourceLine" id="cb78-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-4" data-line-number="4"><span class="co">#&gt; Gradient evaluation took 3.3e-05 seconds</span></a>
<a class="sourceLine" id="cb78-5" data-line-number="5"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.33 seconds.</span></a>
<a class="sourceLine" id="cb78-6" data-line-number="6"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb78-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-10" data-line-number="10"><span class="co">#&gt;  Elapsed Time: 0.377087 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb78-11" data-line-number="11"><span class="co">#&gt;                0.244246 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb78-12" data-line-number="12"><span class="co">#&gt;                0.621333 seconds (Total)</span></a>
<a class="sourceLine" id="cb78-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-14" data-line-number="14"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-15" data-line-number="15"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb78-16" data-line-number="16"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb78-17" data-line-number="17"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb78-18" data-line-number="18"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-19" data-line-number="19"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-20" data-line-number="20"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-21" data-line-number="21"><span class="co">#&gt;  Elapsed Time: 0.395013 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb78-22" data-line-number="22"><span class="co">#&gt;                0.219145 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb78-23" data-line-number="23"><span class="co">#&gt;                0.614158 seconds (Total)</span></a>
<a class="sourceLine" id="cb78-24" data-line-number="24"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-26" data-line-number="26"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb78-27" data-line-number="27"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb78-28" data-line-number="28"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb78-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-31" data-line-number="31"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-32" data-line-number="32"><span class="co">#&gt;  Elapsed Time: 0.290592 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb78-33" data-line-number="33"><span class="co">#&gt;                0.233561 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb78-34" data-line-number="34"><span class="co">#&gt;                0.524153 seconds (Total)</span></a>
<a class="sourceLine" id="cb78-35" data-line-number="35"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-36" data-line-number="36"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-37" data-line-number="37"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb78-38" data-line-number="38"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb78-39" data-line-number="39"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb78-40" data-line-number="40"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-41" data-line-number="41"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-42" data-line-number="42"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb78-43" data-line-number="43"><span class="co">#&gt;  Elapsed Time: 0.411155 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb78-44" data-line-number="44"><span class="co">#&gt;                0.273809 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb78-45" data-line-number="45"><span class="co">#&gt;                0.684964 seconds (Total)</span></a></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" data-line-number="1"><span class="kw">summary</span>(fit_normal, <span class="st">&quot;tau&quot;</span>)<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb79-2" data-line-number="2"><span class="co">#&gt;      mean se_mean    sd   2.5%   25%   50%   75% 97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb79-3" data-line-number="3"><span class="co">#&gt; tau 0.265 0.00519 0.139 0.0542 0.167 0.245 0.339 0.603   718    1</span></a></code></pre></div>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit_normal))</a>
<a class="sourceLine" id="cb80-2" data-line-number="2"><span class="co">#&gt; Computed from 4000 by 97 log-likelihood matrix</span></a>
<a class="sourceLine" id="cb80-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb80-4" data-line-number="4"><span class="co">#&gt;          Estimate  SE</span></a>
<a class="sourceLine" id="cb80-5" data-line-number="5"><span class="co">#&gt; elpd_loo   -234.6 3.0</span></a>
<a class="sourceLine" id="cb80-6" data-line-number="6"><span class="co">#&gt; p_loo         3.8 0.4</span></a>
<a class="sourceLine" id="cb80-7" data-line-number="7"><span class="co">#&gt; looic       469.2 6.0</span></a>
<a class="sourceLine" id="cb80-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb80-9" data-line-number="9"><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5)</span></a>
<a class="sourceLine" id="cb80-10" data-line-number="10"><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></a></code></pre></div>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_normal), <span class="st">&quot;tau&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-17-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_normal), <span class="dt">regex_pars =</span> <span class="st">&quot;^b&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div id="double-exponential-laplace-prior" class="section level3">
<h3><span class="header-section-number">12.6.1</span> Double Exponential (Laplace) Prior</h3>
<p>A second prior to consider for <span class="math inline">\(\vec\beta\)</span> is the Double Exponential.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1">mod_lasso_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-lasso-1.stan&quot;</span>)</a>
<a class="sourceLine" id="cb83-2" data-line-number="2"><span class="co">#&gt; In file included from file278426ec8e21.cpp:8:</span></a>
<a class="sourceLine" id="cb83-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb83-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb83-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb83-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb83-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb83-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb83-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb83-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb83-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb83-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb83-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb83-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb83-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb83-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb83-17" data-line-number="17"><span class="co">#&gt; In file included from file278426ec8e21.cpp:8:</span></a>
<a class="sourceLine" id="cb83-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb83-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb83-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb83-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb83-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb83-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb83-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb83-25" data-line-number="25"><span class="co">#&gt; In file included from file278426ec8e21.cpp:8:</span></a>
<a class="sourceLine" id="cb83-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb83-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb83-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb83-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb83-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb83-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb83-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb83-33" data-line-number="33"><span class="co">#&gt; In file included from file278426ec8e21.cpp:8:</span></a>
<a class="sourceLine" id="cb83-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb83-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb83-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb83-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb83-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb83-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb83-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb83-41" data-line-number="41"><span class="co">#&gt; In file included from file278426ec8e21.cpp:8:</span></a>
<a class="sourceLine" id="cb83-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb83-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb83-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb83-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb83-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb83-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb83-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb83-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb83-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb83-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb83-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb83-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb83-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb83-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb83-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb83-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb83-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb83-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb83-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb83-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb83-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb83-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb83-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1">coefpath_lasso &lt;-<span class="st"> </span><span class="kw">map</span>(tau_values,</a>
<a class="sourceLine" id="cb84-2" data-line-number="2">                      run_with_tau,</a>
<a class="sourceLine" id="cb84-3" data-line-number="3">                   <span class="dt">mod =</span> mod_lasso_<span class="dv">1</span>,</a>
<a class="sourceLine" id="cb84-4" data-line-number="4">                   <span class="dt">data =</span> prostate_data)</a>
<a class="sourceLine" id="cb84-5" data-line-number="5"><span class="co">#&gt; Tau =  4</span></a>
<a class="sourceLine" id="cb84-6" data-line-number="6"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-8" data-line-number="8"><span class="co">#&gt; Gradient evaluation took 3.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-9" data-line-number="9"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.</span></a>
<a class="sourceLine" id="cb84-10" data-line-number="10"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-13" data-line-number="13"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-14" data-line-number="14"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-15" data-line-number="15"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-16" data-line-number="16"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-17" data-line-number="17"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-18" data-line-number="18"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-19" data-line-number="19"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-20" data-line-number="20"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-21" data-line-number="21"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-22" data-line-number="22"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-23" data-line-number="23"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-24" data-line-number="24"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-26" data-line-number="26"><span class="co">#&gt;  Elapsed Time: 0.169471 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-27" data-line-number="27"><span class="co">#&gt;                0.136615 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-28" data-line-number="28"><span class="co">#&gt;                0.306086 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-29" data-line-number="29"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-31" data-line-number="31"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-32" data-line-number="32"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-33" data-line-number="33"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-34" data-line-number="34"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-35" data-line-number="35"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-36" data-line-number="36"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-38" data-line-number="38"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-39" data-line-number="39"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-40" data-line-number="40"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-41" data-line-number="41"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-42" data-line-number="42"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-43" data-line-number="43"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-44" data-line-number="44"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-45" data-line-number="45"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-46" data-line-number="46"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-47" data-line-number="47"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-48" data-line-number="48"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-49" data-line-number="49"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-50" data-line-number="50"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-51" data-line-number="51"><span class="co">#&gt;  Elapsed Time: 0.160739 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-52" data-line-number="52"><span class="co">#&gt;                0.132459 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-53" data-line-number="53"><span class="co">#&gt;                0.293198 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-55" data-line-number="55"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-56" data-line-number="56"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-57" data-line-number="57"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-58" data-line-number="58"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-59" data-line-number="59"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-60" data-line-number="60"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-61" data-line-number="61"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-62" data-line-number="62"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-63" data-line-number="63"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-64" data-line-number="64"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-65" data-line-number="65"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-66" data-line-number="66"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-67" data-line-number="67"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-68" data-line-number="68"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-69" data-line-number="69"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-70" data-line-number="70"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-71" data-line-number="71"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-72" data-line-number="72"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-73" data-line-number="73"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-74" data-line-number="74"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-75" data-line-number="75"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-76" data-line-number="76"><span class="co">#&gt;  Elapsed Time: 0.163054 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-77" data-line-number="77"><span class="co">#&gt;                0.119725 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-78" data-line-number="78"><span class="co">#&gt;                0.282779 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-79" data-line-number="79"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-80" data-line-number="80"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-81" data-line-number="81"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-82" data-line-number="82"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-83" data-line-number="83"><span class="co">#&gt; Gradient evaluation took 3.8e-05 seconds</span></a>
<a class="sourceLine" id="cb84-84" data-line-number="84"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.</span></a>
<a class="sourceLine" id="cb84-85" data-line-number="85"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-86" data-line-number="86"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-87" data-line-number="87"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-88" data-line-number="88"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-89" data-line-number="89"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-90" data-line-number="90"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-91" data-line-number="91"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-92" data-line-number="92"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-93" data-line-number="93"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-94" data-line-number="94"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-95" data-line-number="95"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-96" data-line-number="96"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-97" data-line-number="97"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-98" data-line-number="98"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-99" data-line-number="99"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-100" data-line-number="100"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-101" data-line-number="101"><span class="co">#&gt;  Elapsed Time: 0.156085 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-102" data-line-number="102"><span class="co">#&gt;                0.13623 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-103" data-line-number="103"><span class="co">#&gt;                0.292315 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-104" data-line-number="104"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-105" data-line-number="105"><span class="co">#&gt; Tau =  2.83</span></a>
<a class="sourceLine" id="cb84-106" data-line-number="106"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-107" data-line-number="107"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-108" data-line-number="108"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-109" data-line-number="109"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb84-110" data-line-number="110"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-111" data-line-number="111"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-112" data-line-number="112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-113" data-line-number="113"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-114" data-line-number="114"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-115" data-line-number="115"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-116" data-line-number="116"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-117" data-line-number="117"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-118" data-line-number="118"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-119" data-line-number="119"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-120" data-line-number="120"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-121" data-line-number="121"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-122" data-line-number="122"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-123" data-line-number="123"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-124" data-line-number="124"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-125" data-line-number="125"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-126" data-line-number="126"><span class="co">#&gt;  Elapsed Time: 0.16491 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-127" data-line-number="127"><span class="co">#&gt;                0.131669 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-128" data-line-number="128"><span class="co">#&gt;                0.296579 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-129" data-line-number="129"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-130" data-line-number="130"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-131" data-line-number="131"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-133" data-line-number="133"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-134" data-line-number="134"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-135" data-line-number="135"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-136" data-line-number="136"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-137" data-line-number="137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-138" data-line-number="138"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-139" data-line-number="139"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-140" data-line-number="140"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-141" data-line-number="141"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-142" data-line-number="142"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-143" data-line-number="143"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-144" data-line-number="144"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-145" data-line-number="145"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-146" data-line-number="146"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-147" data-line-number="147"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-148" data-line-number="148"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-149" data-line-number="149"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-150" data-line-number="150"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-151" data-line-number="151"><span class="co">#&gt;  Elapsed Time: 0.15949 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-152" data-line-number="152"><span class="co">#&gt;                0.122812 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-153" data-line-number="153"><span class="co">#&gt;                0.282302 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-154" data-line-number="154"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-155" data-line-number="155"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-156" data-line-number="156"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-158" data-line-number="158"><span class="co">#&gt; Gradient evaluation took 3.1e-05 seconds</span></a>
<a class="sourceLine" id="cb84-159" data-line-number="159"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.</span></a>
<a class="sourceLine" id="cb84-160" data-line-number="160"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-161" data-line-number="161"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-162" data-line-number="162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-163" data-line-number="163"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-164" data-line-number="164"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-165" data-line-number="165"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-166" data-line-number="166"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-167" data-line-number="167"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-168" data-line-number="168"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-169" data-line-number="169"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-170" data-line-number="170"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-171" data-line-number="171"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-172" data-line-number="172"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-173" data-line-number="173"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-174" data-line-number="174"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-175" data-line-number="175"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-176" data-line-number="176"><span class="co">#&gt;  Elapsed Time: 0.158244 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-177" data-line-number="177"><span class="co">#&gt;                0.128231 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-178" data-line-number="178"><span class="co">#&gt;                0.286475 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-179" data-line-number="179"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-180" data-line-number="180"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-181" data-line-number="181"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-183" data-line-number="183"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-184" data-line-number="184"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-185" data-line-number="185"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-186" data-line-number="186"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-187" data-line-number="187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-188" data-line-number="188"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-189" data-line-number="189"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-190" data-line-number="190"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-191" data-line-number="191"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-192" data-line-number="192"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-193" data-line-number="193"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-194" data-line-number="194"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-195" data-line-number="195"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-196" data-line-number="196"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-197" data-line-number="197"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-198" data-line-number="198"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-199" data-line-number="199"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-200" data-line-number="200"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-201" data-line-number="201"><span class="co">#&gt;  Elapsed Time: 0.144683 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-202" data-line-number="202"><span class="co">#&gt;                0.127824 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-203" data-line-number="203"><span class="co">#&gt;                0.272507 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-204" data-line-number="204"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-205" data-line-number="205"><span class="co">#&gt; Tau =  2</span></a>
<a class="sourceLine" id="cb84-206" data-line-number="206"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-207" data-line-number="207"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-208" data-line-number="208"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-209" data-line-number="209"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-210" data-line-number="210"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-211" data-line-number="211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-212" data-line-number="212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-213" data-line-number="213"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-214" data-line-number="214"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-215" data-line-number="215"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-216" data-line-number="216"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-217" data-line-number="217"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-218" data-line-number="218"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-219" data-line-number="219"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-220" data-line-number="220"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-221" data-line-number="221"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-222" data-line-number="222"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-223" data-line-number="223"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-224" data-line-number="224"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-225" data-line-number="225"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-226" data-line-number="226"><span class="co">#&gt;  Elapsed Time: 0.154439 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-227" data-line-number="227"><span class="co">#&gt;                0.123893 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-228" data-line-number="228"><span class="co">#&gt;                0.278332 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-229" data-line-number="229"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-230" data-line-number="230"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-231" data-line-number="231"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-232" data-line-number="232"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-233" data-line-number="233"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-234" data-line-number="234"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-235" data-line-number="235"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-236" data-line-number="236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-237" data-line-number="237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-238" data-line-number="238"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-239" data-line-number="239"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-240" data-line-number="240"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-241" data-line-number="241"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-242" data-line-number="242"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-243" data-line-number="243"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-244" data-line-number="244"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-245" data-line-number="245"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-246" data-line-number="246"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-247" data-line-number="247"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-248" data-line-number="248"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-249" data-line-number="249"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-250" data-line-number="250"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-251" data-line-number="251"><span class="co">#&gt;  Elapsed Time: 0.151097 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-252" data-line-number="252"><span class="co">#&gt;                0.132078 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-253" data-line-number="253"><span class="co">#&gt;                0.283175 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-254" data-line-number="254"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-255" data-line-number="255"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-256" data-line-number="256"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-257" data-line-number="257"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-258" data-line-number="258"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-259" data-line-number="259"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-260" data-line-number="260"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-261" data-line-number="261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-262" data-line-number="262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-263" data-line-number="263"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-264" data-line-number="264"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-265" data-line-number="265"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-266" data-line-number="266"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-267" data-line-number="267"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-268" data-line-number="268"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-269" data-line-number="269"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-270" data-line-number="270"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-271" data-line-number="271"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-272" data-line-number="272"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-273" data-line-number="273"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-274" data-line-number="274"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-275" data-line-number="275"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-276" data-line-number="276"><span class="co">#&gt;  Elapsed Time: 0.165071 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-277" data-line-number="277"><span class="co">#&gt;                0.128108 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-278" data-line-number="278"><span class="co">#&gt;                0.293179 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-279" data-line-number="279"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-280" data-line-number="280"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-281" data-line-number="281"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-282" data-line-number="282"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-283" data-line-number="283"><span class="co">#&gt; Gradient evaluation took 2.9e-05 seconds</span></a>
<a class="sourceLine" id="cb84-284" data-line-number="284"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.</span></a>
<a class="sourceLine" id="cb84-285" data-line-number="285"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-286" data-line-number="286"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-287" data-line-number="287"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-288" data-line-number="288"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-289" data-line-number="289"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-290" data-line-number="290"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-291" data-line-number="291"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-292" data-line-number="292"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-293" data-line-number="293"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-294" data-line-number="294"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-295" data-line-number="295"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-296" data-line-number="296"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-297" data-line-number="297"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-298" data-line-number="298"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-299" data-line-number="299"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-300" data-line-number="300"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-301" data-line-number="301"><span class="co">#&gt;  Elapsed Time: 0.165049 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-302" data-line-number="302"><span class="co">#&gt;                0.11433 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-303" data-line-number="303"><span class="co">#&gt;                0.279379 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-304" data-line-number="304"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-305" data-line-number="305"><span class="co">#&gt; Tau =  1.41</span></a>
<a class="sourceLine" id="cb84-306" data-line-number="306"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-307" data-line-number="307"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-308" data-line-number="308"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-309" data-line-number="309"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-310" data-line-number="310"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-311" data-line-number="311"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-312" data-line-number="312"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-313" data-line-number="313"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-314" data-line-number="314"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-315" data-line-number="315"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-316" data-line-number="316"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-317" data-line-number="317"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-318" data-line-number="318"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-319" data-line-number="319"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-320" data-line-number="320"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-321" data-line-number="321"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-322" data-line-number="322"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-323" data-line-number="323"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-324" data-line-number="324"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-325" data-line-number="325"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-326" data-line-number="326"><span class="co">#&gt;  Elapsed Time: 0.151507 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-327" data-line-number="327"><span class="co">#&gt;                0.128273 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-328" data-line-number="328"><span class="co">#&gt;                0.27978 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-329" data-line-number="329"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-330" data-line-number="330"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-331" data-line-number="331"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-332" data-line-number="332"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-333" data-line-number="333"><span class="co">#&gt; Gradient evaluation took 1.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-334" data-line-number="334"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.</span></a>
<a class="sourceLine" id="cb84-335" data-line-number="335"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-336" data-line-number="336"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-337" data-line-number="337"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-338" data-line-number="338"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-339" data-line-number="339"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-340" data-line-number="340"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-341" data-line-number="341"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-342" data-line-number="342"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-343" data-line-number="343"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-344" data-line-number="344"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-345" data-line-number="345"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-346" data-line-number="346"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-347" data-line-number="347"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-348" data-line-number="348"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-349" data-line-number="349"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-350" data-line-number="350"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-351" data-line-number="351"><span class="co">#&gt;  Elapsed Time: 0.153933 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-352" data-line-number="352"><span class="co">#&gt;                0.114526 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-353" data-line-number="353"><span class="co">#&gt;                0.268459 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-354" data-line-number="354"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-355" data-line-number="355"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-356" data-line-number="356"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-357" data-line-number="357"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-358" data-line-number="358"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-359" data-line-number="359"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-360" data-line-number="360"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-361" data-line-number="361"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-362" data-line-number="362"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-363" data-line-number="363"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-364" data-line-number="364"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-365" data-line-number="365"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-366" data-line-number="366"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-367" data-line-number="367"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-368" data-line-number="368"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-369" data-line-number="369"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-370" data-line-number="370"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-371" data-line-number="371"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-372" data-line-number="372"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-373" data-line-number="373"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-374" data-line-number="374"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-375" data-line-number="375"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-376" data-line-number="376"><span class="co">#&gt;  Elapsed Time: 0.148666 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-377" data-line-number="377"><span class="co">#&gt;                0.13089 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-378" data-line-number="378"><span class="co">#&gt;                0.279556 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-379" data-line-number="379"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-380" data-line-number="380"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-381" data-line-number="381"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-382" data-line-number="382"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-383" data-line-number="383"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb84-384" data-line-number="384"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb84-385" data-line-number="385"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-386" data-line-number="386"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-387" data-line-number="387"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-388" data-line-number="388"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-389" data-line-number="389"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-390" data-line-number="390"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-391" data-line-number="391"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-392" data-line-number="392"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-393" data-line-number="393"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-394" data-line-number="394"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-395" data-line-number="395"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-396" data-line-number="396"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-397" data-line-number="397"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-398" data-line-number="398"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-399" data-line-number="399"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-400" data-line-number="400"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-401" data-line-number="401"><span class="co">#&gt;  Elapsed Time: 0.157489 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-402" data-line-number="402"><span class="co">#&gt;                0.133079 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-403" data-line-number="403"><span class="co">#&gt;                0.290568 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-404" data-line-number="404"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-405" data-line-number="405"><span class="co">#&gt; Tau =  1</span></a>
<a class="sourceLine" id="cb84-406" data-line-number="406"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-407" data-line-number="407"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-408" data-line-number="408"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-409" data-line-number="409"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb84-410" data-line-number="410"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-411" data-line-number="411"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-412" data-line-number="412"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-413" data-line-number="413"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-414" data-line-number="414"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-415" data-line-number="415"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-416" data-line-number="416"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-417" data-line-number="417"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-418" data-line-number="418"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-419" data-line-number="419"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-420" data-line-number="420"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-421" data-line-number="421"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-422" data-line-number="422"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-423" data-line-number="423"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-424" data-line-number="424"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-425" data-line-number="425"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-426" data-line-number="426"><span class="co">#&gt;  Elapsed Time: 0.157807 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-427" data-line-number="427"><span class="co">#&gt;                0.119827 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-428" data-line-number="428"><span class="co">#&gt;                0.277634 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-429" data-line-number="429"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-430" data-line-number="430"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-431" data-line-number="431"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-432" data-line-number="432"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-433" data-line-number="433"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-434" data-line-number="434"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb84-435" data-line-number="435"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-436" data-line-number="436"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-437" data-line-number="437"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-438" data-line-number="438"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-439" data-line-number="439"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-440" data-line-number="440"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-441" data-line-number="441"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-442" data-line-number="442"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-443" data-line-number="443"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-444" data-line-number="444"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-445" data-line-number="445"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-446" data-line-number="446"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-447" data-line-number="447"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-448" data-line-number="448"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-449" data-line-number="449"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-450" data-line-number="450"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-451" data-line-number="451"><span class="co">#&gt;  Elapsed Time: 0.152256 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-452" data-line-number="452"><span class="co">#&gt;                0.129752 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-453" data-line-number="453"><span class="co">#&gt;                0.282008 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-454" data-line-number="454"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-455" data-line-number="455"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-456" data-line-number="456"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-457" data-line-number="457"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-458" data-line-number="458"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-459" data-line-number="459"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-460" data-line-number="460"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-461" data-line-number="461"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-462" data-line-number="462"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-463" data-line-number="463"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-464" data-line-number="464"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-465" data-line-number="465"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-466" data-line-number="466"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-467" data-line-number="467"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-468" data-line-number="468"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-469" data-line-number="469"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-470" data-line-number="470"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-471" data-line-number="471"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-472" data-line-number="472"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-473" data-line-number="473"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-474" data-line-number="474"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-475" data-line-number="475"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-476" data-line-number="476"><span class="co">#&gt;  Elapsed Time: 0.152488 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-477" data-line-number="477"><span class="co">#&gt;                0.115369 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-478" data-line-number="478"><span class="co">#&gt;                0.267857 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-479" data-line-number="479"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-480" data-line-number="480"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-481" data-line-number="481"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-482" data-line-number="482"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-483" data-line-number="483"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-484" data-line-number="484"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb84-485" data-line-number="485"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-486" data-line-number="486"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-487" data-line-number="487"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-488" data-line-number="488"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-489" data-line-number="489"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-490" data-line-number="490"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-491" data-line-number="491"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-492" data-line-number="492"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-493" data-line-number="493"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-494" data-line-number="494"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-495" data-line-number="495"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-496" data-line-number="496"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-497" data-line-number="497"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-498" data-line-number="498"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-499" data-line-number="499"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-500" data-line-number="500"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-501" data-line-number="501"><span class="co">#&gt;  Elapsed Time: 0.138709 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-502" data-line-number="502"><span class="co">#&gt;                0.119415 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-503" data-line-number="503"><span class="co">#&gt;                0.258124 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-504" data-line-number="504"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-505" data-line-number="505"><span class="co">#&gt; Tau =  0.707</span></a>
<a class="sourceLine" id="cb84-506" data-line-number="506"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-507" data-line-number="507"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-508" data-line-number="508"><span class="co">#&gt; Gradient evaluation took 2.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-509" data-line-number="509"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.</span></a>
<a class="sourceLine" id="cb84-510" data-line-number="510"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-511" data-line-number="511"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-512" data-line-number="512"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-513" data-line-number="513"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-514" data-line-number="514"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-515" data-line-number="515"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-516" data-line-number="516"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-517" data-line-number="517"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-518" data-line-number="518"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-519" data-line-number="519"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-520" data-line-number="520"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-521" data-line-number="521"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-522" data-line-number="522"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-523" data-line-number="523"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-524" data-line-number="524"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-525" data-line-number="525"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-526" data-line-number="526"><span class="co">#&gt;  Elapsed Time: 0.148239 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-527" data-line-number="527"><span class="co">#&gt;                0.130681 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-528" data-line-number="528"><span class="co">#&gt;                0.27892 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-529" data-line-number="529"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-530" data-line-number="530"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-531" data-line-number="531"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-532" data-line-number="532"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-533" data-line-number="533"><span class="co">#&gt; Gradient evaluation took 1.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-534" data-line-number="534"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.</span></a>
<a class="sourceLine" id="cb84-535" data-line-number="535"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-536" data-line-number="536"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-537" data-line-number="537"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-538" data-line-number="538"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-539" data-line-number="539"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-540" data-line-number="540"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-541" data-line-number="541"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-542" data-line-number="542"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-543" data-line-number="543"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-544" data-line-number="544"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-545" data-line-number="545"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-546" data-line-number="546"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-547" data-line-number="547"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-548" data-line-number="548"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-549" data-line-number="549"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-550" data-line-number="550"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-551" data-line-number="551"><span class="co">#&gt;  Elapsed Time: 0.159341 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-552" data-line-number="552"><span class="co">#&gt;                0.13126 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-553" data-line-number="553"><span class="co">#&gt;                0.290601 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-554" data-line-number="554"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-555" data-line-number="555"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-556" data-line-number="556"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-557" data-line-number="557"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-558" data-line-number="558"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-559" data-line-number="559"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-560" data-line-number="560"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-561" data-line-number="561"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-562" data-line-number="562"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-563" data-line-number="563"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-564" data-line-number="564"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-565" data-line-number="565"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-566" data-line-number="566"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-567" data-line-number="567"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-568" data-line-number="568"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-569" data-line-number="569"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-570" data-line-number="570"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-571" data-line-number="571"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-572" data-line-number="572"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-573" data-line-number="573"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-574" data-line-number="574"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-575" data-line-number="575"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-576" data-line-number="576"><span class="co">#&gt;  Elapsed Time: 0.150785 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-577" data-line-number="577"><span class="co">#&gt;                0.132919 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-578" data-line-number="578"><span class="co">#&gt;                0.283704 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-579" data-line-number="579"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-580" data-line-number="580"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-581" data-line-number="581"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-582" data-line-number="582"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-583" data-line-number="583"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb84-584" data-line-number="584"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb84-585" data-line-number="585"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-586" data-line-number="586"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-587" data-line-number="587"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-588" data-line-number="588"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-589" data-line-number="589"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-590" data-line-number="590"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-591" data-line-number="591"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-592" data-line-number="592"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-593" data-line-number="593"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-594" data-line-number="594"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-595" data-line-number="595"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-596" data-line-number="596"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-597" data-line-number="597"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-598" data-line-number="598"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-599" data-line-number="599"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-600" data-line-number="600"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-601" data-line-number="601"><span class="co">#&gt;  Elapsed Time: 0.140309 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-602" data-line-number="602"><span class="co">#&gt;                0.1175 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-603" data-line-number="603"><span class="co">#&gt;                0.257809 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-604" data-line-number="604"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-605" data-line-number="605"><span class="co">#&gt; Tau =  0.5</span></a>
<a class="sourceLine" id="cb84-606" data-line-number="606"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-607" data-line-number="607"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-608" data-line-number="608"><span class="co">#&gt; Gradient evaluation took 3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-609" data-line-number="609"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.3 seconds.</span></a>
<a class="sourceLine" id="cb84-610" data-line-number="610"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-611" data-line-number="611"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-612" data-line-number="612"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-613" data-line-number="613"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-614" data-line-number="614"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-615" data-line-number="615"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-616" data-line-number="616"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-617" data-line-number="617"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-618" data-line-number="618"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-619" data-line-number="619"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-620" data-line-number="620"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-621" data-line-number="621"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-622" data-line-number="622"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-623" data-line-number="623"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-624" data-line-number="624"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-625" data-line-number="625"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-626" data-line-number="626"><span class="co">#&gt;  Elapsed Time: 0.168461 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-627" data-line-number="627"><span class="co">#&gt;                0.137516 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-628" data-line-number="628"><span class="co">#&gt;                0.305977 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-629" data-line-number="629"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-630" data-line-number="630"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-631" data-line-number="631"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-632" data-line-number="632"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-633" data-line-number="633"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-634" data-line-number="634"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb84-635" data-line-number="635"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-636" data-line-number="636"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-637" data-line-number="637"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-638" data-line-number="638"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-639" data-line-number="639"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-640" data-line-number="640"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-641" data-line-number="641"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-642" data-line-number="642"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-643" data-line-number="643"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-644" data-line-number="644"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-645" data-line-number="645"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-646" data-line-number="646"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-647" data-line-number="647"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-648" data-line-number="648"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-649" data-line-number="649"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-650" data-line-number="650"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-651" data-line-number="651"><span class="co">#&gt;  Elapsed Time: 0.178259 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-652" data-line-number="652"><span class="co">#&gt;                0.13673 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-653" data-line-number="653"><span class="co">#&gt;                0.314989 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-654" data-line-number="654"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-655" data-line-number="655"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-656" data-line-number="656"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-657" data-line-number="657"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-658" data-line-number="658"><span class="co">#&gt; Gradient evaluation took 1.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-659" data-line-number="659"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.</span></a>
<a class="sourceLine" id="cb84-660" data-line-number="660"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-661" data-line-number="661"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-662" data-line-number="662"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-663" data-line-number="663"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-664" data-line-number="664"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-665" data-line-number="665"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-666" data-line-number="666"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-667" data-line-number="667"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-668" data-line-number="668"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-669" data-line-number="669"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-670" data-line-number="670"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-671" data-line-number="671"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-672" data-line-number="672"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-673" data-line-number="673"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-674" data-line-number="674"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-675" data-line-number="675"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-676" data-line-number="676"><span class="co">#&gt;  Elapsed Time: 0.163207 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-677" data-line-number="677"><span class="co">#&gt;                0.12666 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-678" data-line-number="678"><span class="co">#&gt;                0.289867 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-679" data-line-number="679"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-680" data-line-number="680"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-681" data-line-number="681"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-682" data-line-number="682"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-683" data-line-number="683"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb84-684" data-line-number="684"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb84-685" data-line-number="685"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-686" data-line-number="686"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-687" data-line-number="687"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-688" data-line-number="688"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-689" data-line-number="689"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-690" data-line-number="690"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-691" data-line-number="691"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-692" data-line-number="692"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-693" data-line-number="693"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-694" data-line-number="694"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-695" data-line-number="695"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-696" data-line-number="696"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-697" data-line-number="697"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-698" data-line-number="698"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-699" data-line-number="699"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-700" data-line-number="700"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-701" data-line-number="701"><span class="co">#&gt;  Elapsed Time: 0.148402 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-702" data-line-number="702"><span class="co">#&gt;                0.118888 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-703" data-line-number="703"><span class="co">#&gt;                0.26729 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-704" data-line-number="704"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-705" data-line-number="705"><span class="co">#&gt; Tau =  0.354</span></a>
<a class="sourceLine" id="cb84-706" data-line-number="706"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-707" data-line-number="707"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-708" data-line-number="708"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-709" data-line-number="709"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-710" data-line-number="710"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-711" data-line-number="711"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-712" data-line-number="712"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-713" data-line-number="713"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-714" data-line-number="714"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-715" data-line-number="715"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-716" data-line-number="716"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-717" data-line-number="717"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-718" data-line-number="718"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-719" data-line-number="719"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-720" data-line-number="720"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-721" data-line-number="721"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-722" data-line-number="722"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-723" data-line-number="723"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-724" data-line-number="724"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-725" data-line-number="725"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-726" data-line-number="726"><span class="co">#&gt;  Elapsed Time: 0.162557 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-727" data-line-number="727"><span class="co">#&gt;                0.138546 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-728" data-line-number="728"><span class="co">#&gt;                0.301103 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-729" data-line-number="729"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-730" data-line-number="730"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-731" data-line-number="731"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-732" data-line-number="732"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-733" data-line-number="733"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-734" data-line-number="734"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-735" data-line-number="735"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-736" data-line-number="736"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-737" data-line-number="737"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-738" data-line-number="738"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-739" data-line-number="739"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-740" data-line-number="740"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-741" data-line-number="741"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-742" data-line-number="742"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-743" data-line-number="743"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-744" data-line-number="744"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-745" data-line-number="745"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-746" data-line-number="746"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-747" data-line-number="747"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-748" data-line-number="748"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-749" data-line-number="749"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-750" data-line-number="750"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-751" data-line-number="751"><span class="co">#&gt;  Elapsed Time: 0.167166 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-752" data-line-number="752"><span class="co">#&gt;                0.097878 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-753" data-line-number="753"><span class="co">#&gt;                0.265044 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-754" data-line-number="754"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-755" data-line-number="755"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-756" data-line-number="756"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-757" data-line-number="757"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-758" data-line-number="758"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-759" data-line-number="759"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-760" data-line-number="760"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-761" data-line-number="761"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-762" data-line-number="762"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-763" data-line-number="763"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-764" data-line-number="764"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-765" data-line-number="765"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-766" data-line-number="766"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-767" data-line-number="767"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-768" data-line-number="768"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-769" data-line-number="769"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-770" data-line-number="770"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-771" data-line-number="771"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-772" data-line-number="772"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-773" data-line-number="773"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-774" data-line-number="774"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-775" data-line-number="775"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-776" data-line-number="776"><span class="co">#&gt;  Elapsed Time: 0.155406 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-777" data-line-number="777"><span class="co">#&gt;                0.10972 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-778" data-line-number="778"><span class="co">#&gt;                0.265126 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-779" data-line-number="779"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-780" data-line-number="780"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-781" data-line-number="781"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-782" data-line-number="782"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-783" data-line-number="783"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-784" data-line-number="784"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-785" data-line-number="785"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-786" data-line-number="786"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-787" data-line-number="787"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-788" data-line-number="788"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-789" data-line-number="789"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-790" data-line-number="790"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-791" data-line-number="791"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-792" data-line-number="792"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-793" data-line-number="793"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-794" data-line-number="794"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-795" data-line-number="795"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-796" data-line-number="796"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-797" data-line-number="797"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-798" data-line-number="798"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-799" data-line-number="799"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-800" data-line-number="800"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-801" data-line-number="801"><span class="co">#&gt;  Elapsed Time: 0.156223 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-802" data-line-number="802"><span class="co">#&gt;                0.136394 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-803" data-line-number="803"><span class="co">#&gt;                0.292617 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-804" data-line-number="804"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-805" data-line-number="805"><span class="co">#&gt; Tau =  0.25</span></a>
<a class="sourceLine" id="cb84-806" data-line-number="806"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-807" data-line-number="807"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-808" data-line-number="808"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-809" data-line-number="809"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb84-810" data-line-number="810"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-811" data-line-number="811"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-812" data-line-number="812"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-813" data-line-number="813"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-814" data-line-number="814"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-815" data-line-number="815"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-816" data-line-number="816"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-817" data-line-number="817"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-818" data-line-number="818"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-819" data-line-number="819"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-820" data-line-number="820"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-821" data-line-number="821"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-822" data-line-number="822"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-823" data-line-number="823"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-824" data-line-number="824"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-825" data-line-number="825"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-826" data-line-number="826"><span class="co">#&gt;  Elapsed Time: 0.176802 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-827" data-line-number="827"><span class="co">#&gt;                0.129965 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-828" data-line-number="828"><span class="co">#&gt;                0.306767 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-829" data-line-number="829"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-830" data-line-number="830"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-831" data-line-number="831"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-832" data-line-number="832"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-833" data-line-number="833"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb84-834" data-line-number="834"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb84-835" data-line-number="835"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-836" data-line-number="836"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-837" data-line-number="837"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-838" data-line-number="838"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-839" data-line-number="839"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-840" data-line-number="840"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-841" data-line-number="841"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-842" data-line-number="842"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-843" data-line-number="843"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-844" data-line-number="844"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-845" data-line-number="845"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-846" data-line-number="846"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-847" data-line-number="847"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-848" data-line-number="848"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-849" data-line-number="849"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-850" data-line-number="850"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-851" data-line-number="851"><span class="co">#&gt;  Elapsed Time: 0.183236 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-852" data-line-number="852"><span class="co">#&gt;                0.141074 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-853" data-line-number="853"><span class="co">#&gt;                0.32431 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-854" data-line-number="854"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-855" data-line-number="855"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-856" data-line-number="856"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-857" data-line-number="857"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-858" data-line-number="858"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-859" data-line-number="859"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-860" data-line-number="860"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-861" data-line-number="861"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-862" data-line-number="862"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-863" data-line-number="863"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-864" data-line-number="864"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-865" data-line-number="865"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-866" data-line-number="866"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-867" data-line-number="867"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-868" data-line-number="868"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-869" data-line-number="869"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-870" data-line-number="870"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-871" data-line-number="871"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-872" data-line-number="872"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-873" data-line-number="873"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-874" data-line-number="874"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-875" data-line-number="875"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-876" data-line-number="876"><span class="co">#&gt;  Elapsed Time: 0.163929 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-877" data-line-number="877"><span class="co">#&gt;                0.137625 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-878" data-line-number="878"><span class="co">#&gt;                0.301554 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-879" data-line-number="879"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-880" data-line-number="880"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-881" data-line-number="881"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-882" data-line-number="882"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-883" data-line-number="883"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-884" data-line-number="884"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb84-885" data-line-number="885"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-886" data-line-number="886"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-887" data-line-number="887"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-888" data-line-number="888"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-889" data-line-number="889"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-890" data-line-number="890"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-891" data-line-number="891"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-892" data-line-number="892"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-893" data-line-number="893"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-894" data-line-number="894"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-895" data-line-number="895"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-896" data-line-number="896"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-897" data-line-number="897"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-898" data-line-number="898"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-899" data-line-number="899"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-900" data-line-number="900"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-901" data-line-number="901"><span class="co">#&gt;  Elapsed Time: 0.208815 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-902" data-line-number="902"><span class="co">#&gt;                0.138363 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-903" data-line-number="903"><span class="co">#&gt;                0.347178 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-904" data-line-number="904"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-905" data-line-number="905"><span class="co">#&gt; Tau =  0.177</span></a>
<a class="sourceLine" id="cb84-906" data-line-number="906"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-907" data-line-number="907"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-908" data-line-number="908"><span class="co">#&gt; Gradient evaluation took 3.1e-05 seconds</span></a>
<a class="sourceLine" id="cb84-909" data-line-number="909"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.</span></a>
<a class="sourceLine" id="cb84-910" data-line-number="910"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-911" data-line-number="911"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-912" data-line-number="912"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-913" data-line-number="913"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-914" data-line-number="914"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-915" data-line-number="915"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-916" data-line-number="916"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-917" data-line-number="917"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-918" data-line-number="918"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-919" data-line-number="919"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-920" data-line-number="920"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-921" data-line-number="921"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-922" data-line-number="922"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-923" data-line-number="923"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-924" data-line-number="924"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-925" data-line-number="925"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-926" data-line-number="926"><span class="co">#&gt;  Elapsed Time: 0.202964 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-927" data-line-number="927"><span class="co">#&gt;                0.144704 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-928" data-line-number="928"><span class="co">#&gt;                0.347668 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-929" data-line-number="929"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-930" data-line-number="930"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-931" data-line-number="931"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-932" data-line-number="932"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-933" data-line-number="933"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-934" data-line-number="934"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-935" data-line-number="935"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-936" data-line-number="936"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-937" data-line-number="937"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-938" data-line-number="938"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-939" data-line-number="939"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-940" data-line-number="940"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-941" data-line-number="941"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-942" data-line-number="942"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-943" data-line-number="943"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-944" data-line-number="944"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-945" data-line-number="945"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-946" data-line-number="946"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-947" data-line-number="947"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-948" data-line-number="948"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-949" data-line-number="949"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-950" data-line-number="950"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-951" data-line-number="951"><span class="co">#&gt;  Elapsed Time: 0.183398 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-952" data-line-number="952"><span class="co">#&gt;                0.133954 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-953" data-line-number="953"><span class="co">#&gt;                0.317352 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-954" data-line-number="954"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-955" data-line-number="955"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-956" data-line-number="956"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-957" data-line-number="957"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-958" data-line-number="958"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-959" data-line-number="959"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-960" data-line-number="960"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-961" data-line-number="961"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-962" data-line-number="962"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-963" data-line-number="963"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-964" data-line-number="964"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-965" data-line-number="965"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-966" data-line-number="966"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-967" data-line-number="967"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-968" data-line-number="968"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-969" data-line-number="969"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-970" data-line-number="970"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-971" data-line-number="971"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-972" data-line-number="972"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-973" data-line-number="973"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-974" data-line-number="974"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-975" data-line-number="975"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-976" data-line-number="976"><span class="co">#&gt;  Elapsed Time: 0.207131 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-977" data-line-number="977"><span class="co">#&gt;                0.144178 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-978" data-line-number="978"><span class="co">#&gt;                0.351309 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-979" data-line-number="979"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-980" data-line-number="980"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-981" data-line-number="981"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-982" data-line-number="982"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-983" data-line-number="983"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb84-984" data-line-number="984"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb84-985" data-line-number="985"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-986" data-line-number="986"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-987" data-line-number="987"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-988" data-line-number="988"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-989" data-line-number="989"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-990" data-line-number="990"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-991" data-line-number="991"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-992" data-line-number="992"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-993" data-line-number="993"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-994" data-line-number="994"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-995" data-line-number="995"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-996" data-line-number="996"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-997" data-line-number="997"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-998" data-line-number="998"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-999" data-line-number="999"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1000" data-line-number="1000"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1001" data-line-number="1001"><span class="co">#&gt;  Elapsed Time: 0.189636 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1002" data-line-number="1002"><span class="co">#&gt;                0.147323 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1003" data-line-number="1003"><span class="co">#&gt;                0.336959 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1004" data-line-number="1004"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1005" data-line-number="1005"><span class="co">#&gt; Tau =  0.125</span></a>
<a class="sourceLine" id="cb84-1006" data-line-number="1006"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-1007" data-line-number="1007"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1008" data-line-number="1008"><span class="co">#&gt; Gradient evaluation took 2.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1009" data-line-number="1009"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.</span></a>
<a class="sourceLine" id="cb84-1010" data-line-number="1010"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1011" data-line-number="1011"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1012" data-line-number="1012"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1013" data-line-number="1013"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1014" data-line-number="1014"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1015" data-line-number="1015"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1016" data-line-number="1016"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1017" data-line-number="1017"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1018" data-line-number="1018"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1019" data-line-number="1019"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1020" data-line-number="1020"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1021" data-line-number="1021"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1022" data-line-number="1022"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1023" data-line-number="1023"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1024" data-line-number="1024"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1025" data-line-number="1025"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1026" data-line-number="1026"><span class="co">#&gt;  Elapsed Time: 0.216855 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1027" data-line-number="1027"><span class="co">#&gt;                0.152283 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1028" data-line-number="1028"><span class="co">#&gt;                0.369138 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1029" data-line-number="1029"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1030" data-line-number="1030"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1031" data-line-number="1031"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-1032" data-line-number="1032"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1033" data-line-number="1033"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1034" data-line-number="1034"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-1035" data-line-number="1035"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1036" data-line-number="1036"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1037" data-line-number="1037"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1038" data-line-number="1038"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1039" data-line-number="1039"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1040" data-line-number="1040"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1041" data-line-number="1041"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1042" data-line-number="1042"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1043" data-line-number="1043"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1044" data-line-number="1044"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1045" data-line-number="1045"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1046" data-line-number="1046"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1047" data-line-number="1047"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1048" data-line-number="1048"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1049" data-line-number="1049"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1050" data-line-number="1050"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1051" data-line-number="1051"><span class="co">#&gt;  Elapsed Time: 0.240154 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1052" data-line-number="1052"><span class="co">#&gt;                0.153379 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1053" data-line-number="1053"><span class="co">#&gt;                0.393533 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1054" data-line-number="1054"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1055" data-line-number="1055"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1056" data-line-number="1056"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-1057" data-line-number="1057"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1058" data-line-number="1058"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1059" data-line-number="1059"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb84-1060" data-line-number="1060"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1061" data-line-number="1061"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1062" data-line-number="1062"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1063" data-line-number="1063"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1064" data-line-number="1064"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1065" data-line-number="1065"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1066" data-line-number="1066"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1067" data-line-number="1067"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1068" data-line-number="1068"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1069" data-line-number="1069"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1070" data-line-number="1070"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1071" data-line-number="1071"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1072" data-line-number="1072"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1073" data-line-number="1073"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1074" data-line-number="1074"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1075" data-line-number="1075"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1076" data-line-number="1076"><span class="co">#&gt;  Elapsed Time: 0.241622 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1077" data-line-number="1077"><span class="co">#&gt;                0.163411 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1078" data-line-number="1078"><span class="co">#&gt;                0.405033 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1079" data-line-number="1079"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1080" data-line-number="1080"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1081" data-line-number="1081"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-1082" data-line-number="1082"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1083" data-line-number="1083"><span class="co">#&gt; Gradient evaluation took 2.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1084" data-line-number="1084"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.</span></a>
<a class="sourceLine" id="cb84-1085" data-line-number="1085"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1086" data-line-number="1086"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1087" data-line-number="1087"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1088" data-line-number="1088"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1089" data-line-number="1089"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1090" data-line-number="1090"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1091" data-line-number="1091"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1092" data-line-number="1092"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1093" data-line-number="1093"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1094" data-line-number="1094"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1095" data-line-number="1095"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1096" data-line-number="1096"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1097" data-line-number="1097"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1098" data-line-number="1098"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1099" data-line-number="1099"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1100" data-line-number="1100"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1101" data-line-number="1101"><span class="co">#&gt;  Elapsed Time: 0.276523 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1102" data-line-number="1102"><span class="co">#&gt;                0.172288 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1103" data-line-number="1103"><span class="co">#&gt;                0.448811 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1104" data-line-number="1104"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1105" data-line-number="1105"><span class="co">#&gt; Tau =  0.0884</span></a>
<a class="sourceLine" id="cb84-1106" data-line-number="1106"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-1107" data-line-number="1107"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1108" data-line-number="1108"><span class="co">#&gt; Gradient evaluation took 2.8e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1109" data-line-number="1109"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.</span></a>
<a class="sourceLine" id="cb84-1110" data-line-number="1110"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1111" data-line-number="1111"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1112" data-line-number="1112"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1113" data-line-number="1113"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1114" data-line-number="1114"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1115" data-line-number="1115"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1116" data-line-number="1116"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1117" data-line-number="1117"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1118" data-line-number="1118"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1119" data-line-number="1119"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1120" data-line-number="1120"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1121" data-line-number="1121"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1122" data-line-number="1122"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1123" data-line-number="1123"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1124" data-line-number="1124"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1125" data-line-number="1125"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1126" data-line-number="1126"><span class="co">#&gt;  Elapsed Time: 0.26097 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1127" data-line-number="1127"><span class="co">#&gt;                0.168084 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1128" data-line-number="1128"><span class="co">#&gt;                0.429054 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1129" data-line-number="1129"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1130" data-line-number="1130"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1131" data-line-number="1131"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-1132" data-line-number="1132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1133" data-line-number="1133"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1134" data-line-number="1134"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-1135" data-line-number="1135"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1136" data-line-number="1136"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1137" data-line-number="1137"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1138" data-line-number="1138"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1139" data-line-number="1139"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1140" data-line-number="1140"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1141" data-line-number="1141"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1142" data-line-number="1142"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1143" data-line-number="1143"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1144" data-line-number="1144"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1145" data-line-number="1145"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1146" data-line-number="1146"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1147" data-line-number="1147"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1148" data-line-number="1148"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1149" data-line-number="1149"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1150" data-line-number="1150"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1151" data-line-number="1151"><span class="co">#&gt;  Elapsed Time: 0.24219 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1152" data-line-number="1152"><span class="co">#&gt;                0.170399 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1153" data-line-number="1153"><span class="co">#&gt;                0.412589 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1154" data-line-number="1154"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1155" data-line-number="1155"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1156" data-line-number="1156"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-1157" data-line-number="1157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1158" data-line-number="1158"><span class="co">#&gt; Gradient evaluation took 2.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1159" data-line-number="1159"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.24 seconds.</span></a>
<a class="sourceLine" id="cb84-1160" data-line-number="1160"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1161" data-line-number="1161"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1162" data-line-number="1162"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1163" data-line-number="1163"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1164" data-line-number="1164"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1165" data-line-number="1165"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1166" data-line-number="1166"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1167" data-line-number="1167"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1168" data-line-number="1168"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1169" data-line-number="1169"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1170" data-line-number="1170"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1171" data-line-number="1171"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1172" data-line-number="1172"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1173" data-line-number="1173"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1174" data-line-number="1174"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1175" data-line-number="1175"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1176" data-line-number="1176"><span class="co">#&gt;  Elapsed Time: 0.236765 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1177" data-line-number="1177"><span class="co">#&gt;                0.161416 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1178" data-line-number="1178"><span class="co">#&gt;                0.398181 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1179" data-line-number="1179"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1180" data-line-number="1180"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1181" data-line-number="1181"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-1182" data-line-number="1182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1183" data-line-number="1183"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1184" data-line-number="1184"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-1185" data-line-number="1185"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1186" data-line-number="1186"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1187" data-line-number="1187"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1188" data-line-number="1188"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1189" data-line-number="1189"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1190" data-line-number="1190"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1191" data-line-number="1191"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1192" data-line-number="1192"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1193" data-line-number="1193"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1194" data-line-number="1194"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1195" data-line-number="1195"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1196" data-line-number="1196"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1197" data-line-number="1197"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1198" data-line-number="1198"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1199" data-line-number="1199"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1200" data-line-number="1200"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1201" data-line-number="1201"><span class="co">#&gt;  Elapsed Time: 0.27547 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1202" data-line-number="1202"><span class="co">#&gt;                0.160869 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1203" data-line-number="1203"><span class="co">#&gt;                0.436339 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1204" data-line-number="1204"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1205" data-line-number="1205"><span class="co">#&gt; Tau =  0.0625</span></a>
<a class="sourceLine" id="cb84-1206" data-line-number="1206"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-1207" data-line-number="1207"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1208" data-line-number="1208"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1209" data-line-number="1209"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-1210" data-line-number="1210"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1211" data-line-number="1211"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1212" data-line-number="1212"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1213" data-line-number="1213"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1214" data-line-number="1214"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1215" data-line-number="1215"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1216" data-line-number="1216"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1217" data-line-number="1217"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1218" data-line-number="1218"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1219" data-line-number="1219"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1220" data-line-number="1220"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1221" data-line-number="1221"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1222" data-line-number="1222"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1223" data-line-number="1223"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1224" data-line-number="1224"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1225" data-line-number="1225"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1226" data-line-number="1226"><span class="co">#&gt;  Elapsed Time: 0.296557 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1227" data-line-number="1227"><span class="co">#&gt;                0.23422 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1228" data-line-number="1228"><span class="co">#&gt;                0.530777 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1229" data-line-number="1229"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1230" data-line-number="1230"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1231" data-line-number="1231"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-1232" data-line-number="1232"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1233" data-line-number="1233"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1234" data-line-number="1234"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-1235" data-line-number="1235"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1236" data-line-number="1236"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1237" data-line-number="1237"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1238" data-line-number="1238"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1239" data-line-number="1239"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1240" data-line-number="1240"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1241" data-line-number="1241"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1242" data-line-number="1242"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1243" data-line-number="1243"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1244" data-line-number="1244"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1245" data-line-number="1245"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1246" data-line-number="1246"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1247" data-line-number="1247"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1248" data-line-number="1248"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1249" data-line-number="1249"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1250" data-line-number="1250"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1251" data-line-number="1251"><span class="co">#&gt;  Elapsed Time: 0.259157 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1252" data-line-number="1252"><span class="co">#&gt;                0.201577 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1253" data-line-number="1253"><span class="co">#&gt;                0.460734 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1254" data-line-number="1254"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1255" data-line-number="1255"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1256" data-line-number="1256"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-1257" data-line-number="1257"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1258" data-line-number="1258"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1259" data-line-number="1259"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb84-1260" data-line-number="1260"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1261" data-line-number="1261"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1262" data-line-number="1262"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1263" data-line-number="1263"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1264" data-line-number="1264"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1265" data-line-number="1265"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1266" data-line-number="1266"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1267" data-line-number="1267"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1268" data-line-number="1268"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1269" data-line-number="1269"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1270" data-line-number="1270"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1271" data-line-number="1271"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1272" data-line-number="1272"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1273" data-line-number="1273"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1274" data-line-number="1274"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1275" data-line-number="1275"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1276" data-line-number="1276"><span class="co">#&gt;  Elapsed Time: 0.388088 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1277" data-line-number="1277"><span class="co">#&gt;                0.18296 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1278" data-line-number="1278"><span class="co">#&gt;                0.571048 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1279" data-line-number="1279"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1280" data-line-number="1280"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1281" data-line-number="1281"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-1282" data-line-number="1282"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1283" data-line-number="1283"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1284" data-line-number="1284"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb84-1285" data-line-number="1285"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1286" data-line-number="1286"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1287" data-line-number="1287"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1288" data-line-number="1288"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1289" data-line-number="1289"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1290" data-line-number="1290"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1291" data-line-number="1291"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1292" data-line-number="1292"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1293" data-line-number="1293"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1294" data-line-number="1294"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1295" data-line-number="1295"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1296" data-line-number="1296"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1297" data-line-number="1297"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1298" data-line-number="1298"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1299" data-line-number="1299"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1300" data-line-number="1300"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1301" data-line-number="1301"><span class="co">#&gt;  Elapsed Time: 0.282283 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1302" data-line-number="1302"><span class="co">#&gt;                0.212218 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1303" data-line-number="1303"><span class="co">#&gt;                0.494501 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1304" data-line-number="1304"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1305" data-line-number="1305"><span class="co">#&gt; Tau =  0.0442</span></a>
<a class="sourceLine" id="cb84-1306" data-line-number="1306"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-1307" data-line-number="1307"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1308" data-line-number="1308"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1309" data-line-number="1309"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb84-1310" data-line-number="1310"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1311" data-line-number="1311"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1312" data-line-number="1312"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1313" data-line-number="1313"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1314" data-line-number="1314"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1315" data-line-number="1315"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1316" data-line-number="1316"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1317" data-line-number="1317"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1318" data-line-number="1318"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1319" data-line-number="1319"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1320" data-line-number="1320"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1321" data-line-number="1321"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1322" data-line-number="1322"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1323" data-line-number="1323"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1324" data-line-number="1324"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1325" data-line-number="1325"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1326" data-line-number="1326"><span class="co">#&gt;  Elapsed Time: 0.283107 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1327" data-line-number="1327"><span class="co">#&gt;                0.203368 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1328" data-line-number="1328"><span class="co">#&gt;                0.486475 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1329" data-line-number="1329"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1330" data-line-number="1330"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1331" data-line-number="1331"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-1332" data-line-number="1332"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1333" data-line-number="1333"><span class="co">#&gt; Gradient evaluation took 1.4e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1334" data-line-number="1334"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.</span></a>
<a class="sourceLine" id="cb84-1335" data-line-number="1335"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1336" data-line-number="1336"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1337" data-line-number="1337"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1338" data-line-number="1338"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1339" data-line-number="1339"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1340" data-line-number="1340"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1341" data-line-number="1341"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1342" data-line-number="1342"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1343" data-line-number="1343"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1344" data-line-number="1344"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1345" data-line-number="1345"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1346" data-line-number="1346"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1347" data-line-number="1347"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1348" data-line-number="1348"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1349" data-line-number="1349"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1350" data-line-number="1350"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1351" data-line-number="1351"><span class="co">#&gt;  Elapsed Time: 0.319521 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1352" data-line-number="1352"><span class="co">#&gt;                0.175834 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1353" data-line-number="1353"><span class="co">#&gt;                0.495355 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1354" data-line-number="1354"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1355" data-line-number="1355"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1356" data-line-number="1356"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-1357" data-line-number="1357"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1358" data-line-number="1358"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1359" data-line-number="1359"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-1360" data-line-number="1360"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1361" data-line-number="1361"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1362" data-line-number="1362"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1363" data-line-number="1363"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1364" data-line-number="1364"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1365" data-line-number="1365"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1366" data-line-number="1366"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1367" data-line-number="1367"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1368" data-line-number="1368"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1369" data-line-number="1369"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1370" data-line-number="1370"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1371" data-line-number="1371"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1372" data-line-number="1372"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1373" data-line-number="1373"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1374" data-line-number="1374"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1375" data-line-number="1375"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1376" data-line-number="1376"><span class="co">#&gt;  Elapsed Time: 0.314637 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1377" data-line-number="1377"><span class="co">#&gt;                0.222073 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1378" data-line-number="1378"><span class="co">#&gt;                0.53671 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1379" data-line-number="1379"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1380" data-line-number="1380"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1381" data-line-number="1381"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-1382" data-line-number="1382"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1383" data-line-number="1383"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1384" data-line-number="1384"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-1385" data-line-number="1385"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1386" data-line-number="1386"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1387" data-line-number="1387"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1388" data-line-number="1388"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1389" data-line-number="1389"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1390" data-line-number="1390"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1391" data-line-number="1391"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1392" data-line-number="1392"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1393" data-line-number="1393"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1394" data-line-number="1394"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1395" data-line-number="1395"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1396" data-line-number="1396"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1397" data-line-number="1397"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1398" data-line-number="1398"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1399" data-line-number="1399"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1400" data-line-number="1400"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1401" data-line-number="1401"><span class="co">#&gt;  Elapsed Time: 0.309884 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1402" data-line-number="1402"><span class="co">#&gt;                0.174977 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1403" data-line-number="1403"><span class="co">#&gt;                0.484861 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1404" data-line-number="1404"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1405" data-line-number="1405"><span class="co">#&gt; Tau =  0.0312</span></a>
<a class="sourceLine" id="cb84-1406" data-line-number="1406"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb84-1407" data-line-number="1407"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1408" data-line-number="1408"><span class="co">#&gt; Gradient evaluation took 2.3e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1409" data-line-number="1409"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.</span></a>
<a class="sourceLine" id="cb84-1410" data-line-number="1410"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1411" data-line-number="1411"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1412" data-line-number="1412"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1413" data-line-number="1413"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1414" data-line-number="1414"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1415" data-line-number="1415"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1416" data-line-number="1416"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1417" data-line-number="1417"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1418" data-line-number="1418"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1419" data-line-number="1419"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1420" data-line-number="1420"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1421" data-line-number="1421"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1422" data-line-number="1422"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1423" data-line-number="1423"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1424" data-line-number="1424"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1425" data-line-number="1425"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1426" data-line-number="1426"><span class="co">#&gt;  Elapsed Time: 0.336272 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1427" data-line-number="1427"><span class="co">#&gt;                0.205675 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1428" data-line-number="1428"><span class="co">#&gt;                0.541947 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1429" data-line-number="1429"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1430" data-line-number="1430"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1431" data-line-number="1431"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb84-1432" data-line-number="1432"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1433" data-line-number="1433"><span class="co">#&gt; Gradient evaluation took 2.5e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1434" data-line-number="1434"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.</span></a>
<a class="sourceLine" id="cb84-1435" data-line-number="1435"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1436" data-line-number="1436"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1437" data-line-number="1437"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1438" data-line-number="1438"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1439" data-line-number="1439"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1440" data-line-number="1440"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1441" data-line-number="1441"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1442" data-line-number="1442"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1443" data-line-number="1443"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1444" data-line-number="1444"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1445" data-line-number="1445"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1446" data-line-number="1446"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1447" data-line-number="1447"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1448" data-line-number="1448"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1449" data-line-number="1449"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1450" data-line-number="1450"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1451" data-line-number="1451"><span class="co">#&gt;  Elapsed Time: 0.314891 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1452" data-line-number="1452"><span class="co">#&gt;                0.192009 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1453" data-line-number="1453"><span class="co">#&gt;                0.5069 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1454" data-line-number="1454"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1455" data-line-number="1455"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1456" data-line-number="1456"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb84-1457" data-line-number="1457"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1458" data-line-number="1458"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1459" data-line-number="1459"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb84-1460" data-line-number="1460"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1461" data-line-number="1461"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1462" data-line-number="1462"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1463" data-line-number="1463"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1464" data-line-number="1464"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1465" data-line-number="1465"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1466" data-line-number="1466"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1467" data-line-number="1467"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1468" data-line-number="1468"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1469" data-line-number="1469"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1470" data-line-number="1470"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1471" data-line-number="1471"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1472" data-line-number="1472"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1473" data-line-number="1473"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1474" data-line-number="1474"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1475" data-line-number="1475"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1476" data-line-number="1476"><span class="co">#&gt;  Elapsed Time: 0.354932 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1477" data-line-number="1477"><span class="co">#&gt;                0.219093 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1478" data-line-number="1478"><span class="co">#&gt;                0.574025 seconds (Total)</span></a>
<a class="sourceLine" id="cb84-1479" data-line-number="1479"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1480" data-line-number="1480"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1481" data-line-number="1481"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-lasso-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb84-1482" data-line-number="1482"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1483" data-line-number="1483"><span class="co">#&gt; Gradient evaluation took 4.1e-05 seconds</span></a>
<a class="sourceLine" id="cb84-1484" data-line-number="1484"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.</span></a>
<a class="sourceLine" id="cb84-1485" data-line-number="1485"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb84-1486" data-line-number="1486"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1487" data-line-number="1487"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1488" data-line-number="1488"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1489" data-line-number="1489"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1490" data-line-number="1490"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1491" data-line-number="1491"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1492" data-line-number="1492"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1493" data-line-number="1493"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb84-1494" data-line-number="1494"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1495" data-line-number="1495"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1496" data-line-number="1496"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1497" data-line-number="1497"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1498" data-line-number="1498"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1499" data-line-number="1499"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb84-1500" data-line-number="1500"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb84-1501" data-line-number="1501"><span class="co">#&gt;  Elapsed Time: 0.281833 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb84-1502" data-line-number="1502"><span class="co">#&gt;                0.195115 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb84-1503" data-line-number="1503"><span class="co">#&gt;                0.476948 seconds (Total)</span></a></code></pre></div>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1"><span class="kw">plot_coefpaths</span>(coefpath_lasso)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-21-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="kw">plot_coefpaths</span>(coefpath_lasso, <span class="st">&quot;mode&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-22-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1">plot_coefpath_pars &lt;-<span class="st"> </span><span class="cf">function</span>(coefpath) {</a>
<a class="sourceLine" id="cb87-2" data-line-number="2">  <span class="kw">ggplot</span>(<span class="kw">map_df</span>(coefpath, <span class="st">&quot;summary&quot;</span>), <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log10</span>(tau), <span class="dt">y =</span> mean)) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-3" data-line-number="3"><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-4" data-line-number="4"><span class="st">    </span>modelr<span class="op">::</span><span class="kw">geom_ref_line</span>(<span class="dt">h =</span> <span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-5" data-line-number="5"><span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> <span class="st">`</span><span class="dt">25%</span><span class="st">`</span>, <span class="dt">ymax =</span> <span class="st">`</span><span class="dt">75%</span><span class="st">`</span>), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-6" data-line-number="6"><span class="st">    </span><span class="kw">geom_line</span>()  </a>
<a class="sourceLine" id="cb87-7" data-line-number="7">}</a>
<a class="sourceLine" id="cb87-8" data-line-number="8"><span class="kw">plot_coefpath_pars</span>(coefpath_lasso)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-23-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Which is the “best” <span class="math inline">\(tau\)</span>?</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1"><span class="kw">get_best_tau</span>(coefpath_lasso)</a>
<a class="sourceLine" id="cb88-2" data-line-number="2"><span class="co">#&gt; # A tibble: 1 × 3</span></a>
<a class="sourceLine" id="cb88-3" data-line-number="3"><span class="co">#&gt;     tau  elpd     p</span></a>
<a class="sourceLine" id="cb88-4" data-line-number="4"><span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb88-5" data-line-number="5"><span class="co">#&gt; 1 0.125  -234  2.47</span></a></code></pre></div>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1">mod_lasso_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-lasso-2.stan&quot;</span>)</a>
<a class="sourceLine" id="cb89-2" data-line-number="2"><span class="co">#&gt; In file included from file27846d0ff3da.cpp:8:</span></a>
<a class="sourceLine" id="cb89-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb89-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb89-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb89-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb89-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb89-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb89-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb89-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb89-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb89-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb89-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb89-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb89-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb89-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb89-17" data-line-number="17"><span class="co">#&gt; In file included from file27846d0ff3da.cpp:8:</span></a>
<a class="sourceLine" id="cb89-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb89-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb89-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb89-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb89-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb89-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb89-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb89-25" data-line-number="25"><span class="co">#&gt; In file included from file27846d0ff3da.cpp:8:</span></a>
<a class="sourceLine" id="cb89-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb89-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb89-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb89-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb89-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb89-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb89-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb89-33" data-line-number="33"><span class="co">#&gt; In file included from file27846d0ff3da.cpp:8:</span></a>
<a class="sourceLine" id="cb89-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb89-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb89-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb89-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb89-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb89-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb89-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb89-41" data-line-number="41"><span class="co">#&gt; In file included from file27846d0ff3da.cpp:8:</span></a>
<a class="sourceLine" id="cb89-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb89-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb89-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb89-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb89-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb89-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb89-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb89-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb89-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb89-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb89-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb89-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb89-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb89-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb89-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb89-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb89-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb89-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb89-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb89-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb89-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb89-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb89-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1">fit_lasso &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_lasso_<span class="dv">2</span>, </a>
<a class="sourceLine" id="cb90-2" data-line-number="2">                      <span class="dt">data =</span> prostate_data, </a>
<a class="sourceLine" id="cb90-3" data-line-number="3">                      <span class="dt">refresh =</span> <span class="dv">-1</span>,</a>
<a class="sourceLine" id="cb90-4" data-line-number="4">                      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.9</span>))</a>
<a class="sourceLine" id="cb90-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-6" data-line-number="6"><span class="co">#&gt; Gradient evaluation took 3.5e-05 seconds</span></a>
<a class="sourceLine" id="cb90-7" data-line-number="7"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.</span></a>
<a class="sourceLine" id="cb90-8" data-line-number="8"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb90-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-12" data-line-number="12"><span class="co">#&gt;  Elapsed Time: 0.520379 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb90-13" data-line-number="13"><span class="co">#&gt;                0.239833 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb90-14" data-line-number="14"><span class="co">#&gt;                0.760212 seconds (Total)</span></a>
<a class="sourceLine" id="cb90-15" data-line-number="15"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-16" data-line-number="16"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-17" data-line-number="17"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb90-18" data-line-number="18"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb90-19" data-line-number="19"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb90-20" data-line-number="20"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-21" data-line-number="21"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-22" data-line-number="22"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-23" data-line-number="23"><span class="co">#&gt;  Elapsed Time: 0.578325 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb90-24" data-line-number="24"><span class="co">#&gt;                0.270174 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb90-25" data-line-number="25"><span class="co">#&gt;                0.848499 seconds (Total)</span></a>
<a class="sourceLine" id="cb90-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-27" data-line-number="27"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-28" data-line-number="28"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb90-29" data-line-number="29"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb90-30" data-line-number="30"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb90-31" data-line-number="31"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-32" data-line-number="32"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-33" data-line-number="33"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-34" data-line-number="34"><span class="co">#&gt;  Elapsed Time: 0.413246 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb90-35" data-line-number="35"><span class="co">#&gt;                0.223016 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb90-36" data-line-number="36"><span class="co">#&gt;                0.636262 seconds (Total)</span></a>
<a class="sourceLine" id="cb90-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-38" data-line-number="38"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-39" data-line-number="39"><span class="co">#&gt; Gradient evaluation took 1.2e-05 seconds</span></a>
<a class="sourceLine" id="cb90-40" data-line-number="40"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.</span></a>
<a class="sourceLine" id="cb90-41" data-line-number="41"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb90-42" data-line-number="42"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-43" data-line-number="43"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-44" data-line-number="44"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb90-45" data-line-number="45"><span class="co">#&gt;  Elapsed Time: 0.470348 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb90-46" data-line-number="46"><span class="co">#&gt;                0.246839 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb90-47" data-line-number="47"><span class="co">#&gt;                0.717187 seconds (Total)</span></a>
<a class="sourceLine" id="cb90-48" data-line-number="48"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 4</span></a>
<a class="sourceLine" id="cb90-49" data-line-number="49"><span class="co">#&gt;                                                                                                   count</span></a>
<a class="sourceLine" id="cb90-50" data-line-number="50"><span class="co">#&gt; Exception thrown at line 38: double_exponential_lpdf: Scale parameter is inf, but must be finite!     1</span></a>
<a class="sourceLine" id="cb90-51" data-line-number="51"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb90-52" data-line-number="52"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb90-53" data-line-number="53"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb90-54" data-line-number="54"><span class="co">#&gt; Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See</span></a>
<a class="sourceLine" id="cb90-55" data-line-number="55"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#bfmi-low</span></a>
<a class="sourceLine" id="cb90-56" data-line-number="56"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a></code></pre></div>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1"><span class="kw">summary</span>(fit_lasso, <span class="st">&quot;tau&quot;</span>)<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb91-2" data-line-number="2"><span class="co">#&gt;      mean se_mean    sd   2.5%  25%   50%   75% 97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb91-3" data-line-number="3"><span class="co">#&gt; tau 0.216 0.00859 0.146 0.0173 0.12 0.193 0.282 0.576   288 1.01</span></a></code></pre></div>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1"><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit_lasso))</a>
<a class="sourceLine" id="cb92-2" data-line-number="2"><span class="co">#&gt; Computed from 4000 by 97 log-likelihood matrix</span></a>
<a class="sourceLine" id="cb92-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb92-4" data-line-number="4"><span class="co">#&gt;          Estimate  SE</span></a>
<a class="sourceLine" id="cb92-5" data-line-number="5"><span class="co">#&gt; elpd_loo   -234.6 3.0</span></a>
<a class="sourceLine" id="cb92-6" data-line-number="6"><span class="co">#&gt; p_loo         3.7 0.4</span></a>
<a class="sourceLine" id="cb92-7" data-line-number="7"><span class="co">#&gt; looic       469.2 6.0</span></a>
<a class="sourceLine" id="cb92-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb92-9" data-line-number="9"><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5)</span></a>
<a class="sourceLine" id="cb92-10" data-line-number="10"><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></a></code></pre></div>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_lasso), <span class="st">&quot;tau&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-29-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_lasso), <span class="dt">regex_pars =</span> <span class="st">&quot;^b&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-30-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="hierarchical-prior-hs" class="section level3">
<h3><span class="header-section-number">12.6.2</span> Hierarchical Prior (HS)</h3>
<p>The Hierarchical or Horseshoe Prior is defined as as a scale mixture of normal distributions,
<span class="math display">\[
\begin{aligned}[t]
\lambda_i &amp;\sim \dt{\nu}(0, 1) \\
\end{aligned}
\]</span>
In the original formulation <span class="citation">(Carvalho, Polson, and Scott 2009,<span class="citation">@CarvalhoPolsonScott2010a</span>)</span> use a half-Cauchy (<span class="math inline">\(\nu = 1\)</span>), but Stan suggests and <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> uses
a Student-t with <span class="math inline">\(\nu = 3\)</span>, finding that it has better sampling performance than the half-Cauchy.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1">mod_lm_coef_hs_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-hs-1.stan&quot;</span>)</a>
<a class="sourceLine" id="cb95-2" data-line-number="2"><span class="co">#&gt; In file included from file278478b1328d.cpp:8:</span></a>
<a class="sourceLine" id="cb95-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb95-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb95-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb95-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb95-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb95-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb95-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb95-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb95-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb95-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb95-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb95-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb95-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb95-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb95-17" data-line-number="17"><span class="co">#&gt; In file included from file278478b1328d.cpp:8:</span></a>
<a class="sourceLine" id="cb95-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb95-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb95-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb95-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb95-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb95-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb95-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb95-25" data-line-number="25"><span class="co">#&gt; In file included from file278478b1328d.cpp:8:</span></a>
<a class="sourceLine" id="cb95-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb95-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb95-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb95-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb95-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb95-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb95-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb95-33" data-line-number="33"><span class="co">#&gt; In file included from file278478b1328d.cpp:8:</span></a>
<a class="sourceLine" id="cb95-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb95-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb95-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb95-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb95-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb95-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb95-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb95-41" data-line-number="41"><span class="co">#&gt; In file included from file278478b1328d.cpp:8:</span></a>
<a class="sourceLine" id="cb95-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb95-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb95-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb95-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb95-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb95-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb95-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb95-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb95-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb95-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb95-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb95-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb95-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb95-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb95-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb95-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb95-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb95-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb95-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb95-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb95-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb95-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb95-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1">coefpath_hs &lt;-<span class="st"> </span><span class="kw">map</span>(tau_values,</a>
<a class="sourceLine" id="cb96-2" data-line-number="2">                   run_with_tau, </a>
<a class="sourceLine" id="cb96-3" data-line-number="3">                   <span class="dt">mod =</span> mod_lm_coef_hs_<span class="dv">1</span>,</a>
<a class="sourceLine" id="cb96-4" data-line-number="4">                   <span class="dt">data =</span> <span class="kw">c</span>(prostate_data, <span class="kw">list</span>(<span class="dt">df_local =</span> <span class="dv">3</span>)),</a>
<a class="sourceLine" id="cb96-5" data-line-number="5">                   <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.999</span>, <span class="dt">max_treedepth =</span> <span class="dv">12</span>))</a>
<a class="sourceLine" id="cb96-6" data-line-number="6"><span class="co">#&gt; Tau =  4</span></a>
<a class="sourceLine" id="cb96-7" data-line-number="7"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-9" data-line-number="9"><span class="co">#&gt; Gradient evaluation took 3.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-10" data-line-number="10"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.</span></a>
<a class="sourceLine" id="cb96-11" data-line-number="11"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-12" data-line-number="12"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-13" data-line-number="13"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-14" data-line-number="14"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-15" data-line-number="15"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-16" data-line-number="16"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-17" data-line-number="17"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-18" data-line-number="18"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-19" data-line-number="19"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-20" data-line-number="20"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-21" data-line-number="21"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-22" data-line-number="22"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-23" data-line-number="23"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-24" data-line-number="24"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-25" data-line-number="25"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-27" data-line-number="27"><span class="co">#&gt;  Elapsed Time: 2.87611 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-28" data-line-number="28"><span class="co">#&gt;                6.20805 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-29" data-line-number="29"><span class="co">#&gt;                9.08416 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-30" data-line-number="30"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-31" data-line-number="31"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-32" data-line-number="32"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-33" data-line-number="33"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-34" data-line-number="34"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-35" data-line-number="35"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-36" data-line-number="36"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-38" data-line-number="38"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-39" data-line-number="39"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-40" data-line-number="40"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-41" data-line-number="41"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-42" data-line-number="42"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-43" data-line-number="43"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-44" data-line-number="44"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-45" data-line-number="45"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-46" data-line-number="46"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-47" data-line-number="47"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-48" data-line-number="48"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-49" data-line-number="49"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-50" data-line-number="50"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-51" data-line-number="51"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-52" data-line-number="52"><span class="co">#&gt;  Elapsed Time: 3.52193 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-53" data-line-number="53"><span class="co">#&gt;                1.54883 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-54" data-line-number="54"><span class="co">#&gt;                5.07076 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-55" data-line-number="55"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-56" data-line-number="56"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-57" data-line-number="57"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-58" data-line-number="58"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-59" data-line-number="59"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-60" data-line-number="60"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb96-61" data-line-number="61"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-62" data-line-number="62"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-63" data-line-number="63"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-64" data-line-number="64"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-65" data-line-number="65"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-66" data-line-number="66"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-67" data-line-number="67"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-68" data-line-number="68"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-69" data-line-number="69"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-70" data-line-number="70"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-71" data-line-number="71"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-72" data-line-number="72"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-73" data-line-number="73"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-74" data-line-number="74"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-75" data-line-number="75"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-76" data-line-number="76"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-77" data-line-number="77"><span class="co">#&gt;  Elapsed Time: 2.86541 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-78" data-line-number="78"><span class="co">#&gt;                2.61092 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-79" data-line-number="79"><span class="co">#&gt;                5.47633 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-80" data-line-number="80"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-81" data-line-number="81"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-82" data-line-number="82"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-83" data-line-number="83"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-84" data-line-number="84"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-85" data-line-number="85"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-86" data-line-number="86"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-87" data-line-number="87"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-88" data-line-number="88"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-89" data-line-number="89"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-90" data-line-number="90"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-91" data-line-number="91"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-92" data-line-number="92"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-93" data-line-number="93"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-94" data-line-number="94"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-95" data-line-number="95"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-96" data-line-number="96"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-97" data-line-number="97"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-98" data-line-number="98"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-99" data-line-number="99"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-100" data-line-number="100"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-101" data-line-number="101"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-102" data-line-number="102"><span class="co">#&gt;  Elapsed Time: 2.47924 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-103" data-line-number="103"><span class="co">#&gt;                3.56892 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-104" data-line-number="104"><span class="co">#&gt;                6.04816 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-105" data-line-number="105"><span class="co">#&gt; Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta above 0.999 may help. See</span></a>
<a class="sourceLine" id="cb96-106" data-line-number="106"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</span></a>
<a class="sourceLine" id="cb96-107" data-line-number="107"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a>
<a class="sourceLine" id="cb96-108" data-line-number="108"><span class="co">#&gt; Tau =  2.83</span></a>
<a class="sourceLine" id="cb96-109" data-line-number="109"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-110" data-line-number="110"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-111" data-line-number="111"><span class="co">#&gt; Gradient evaluation took 2.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-112" data-line-number="112"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.</span></a>
<a class="sourceLine" id="cb96-113" data-line-number="113"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-114" data-line-number="114"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-115" data-line-number="115"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-116" data-line-number="116"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-117" data-line-number="117"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-118" data-line-number="118"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-119" data-line-number="119"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-120" data-line-number="120"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-121" data-line-number="121"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-122" data-line-number="122"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-123" data-line-number="123"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-124" data-line-number="124"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-125" data-line-number="125"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-126" data-line-number="126"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-127" data-line-number="127"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-128" data-line-number="128"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-129" data-line-number="129"><span class="co">#&gt;  Elapsed Time: 2.55465 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-130" data-line-number="130"><span class="co">#&gt;                5.27214 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-131" data-line-number="131"><span class="co">#&gt;                7.82679 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-132" data-line-number="132"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-133" data-line-number="133"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-134" data-line-number="134"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-135" data-line-number="135"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-136" data-line-number="136"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb96-137" data-line-number="137"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb96-138" data-line-number="138"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-139" data-line-number="139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-140" data-line-number="140"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-141" data-line-number="141"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-142" data-line-number="142"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-143" data-line-number="143"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-144" data-line-number="144"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-145" data-line-number="145"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-146" data-line-number="146"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-147" data-line-number="147"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-148" data-line-number="148"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-149" data-line-number="149"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-150" data-line-number="150"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-151" data-line-number="151"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-152" data-line-number="152"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-153" data-line-number="153"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-154" data-line-number="154"><span class="co">#&gt;  Elapsed Time: 2.32708 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-155" data-line-number="155"><span class="co">#&gt;                1.8418 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-156" data-line-number="156"><span class="co">#&gt;                4.16887 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-157" data-line-number="157"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-158" data-line-number="158"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-159" data-line-number="159"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-160" data-line-number="160"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-161" data-line-number="161"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb96-162" data-line-number="162"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb96-163" data-line-number="163"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-164" data-line-number="164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-165" data-line-number="165"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-166" data-line-number="166"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-167" data-line-number="167"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-168" data-line-number="168"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-169" data-line-number="169"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-170" data-line-number="170"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-171" data-line-number="171"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-172" data-line-number="172"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-173" data-line-number="173"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-174" data-line-number="174"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-175" data-line-number="175"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-176" data-line-number="176"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-177" data-line-number="177"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-178" data-line-number="178"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-179" data-line-number="179"><span class="co">#&gt;  Elapsed Time: 2.59388 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-180" data-line-number="180"><span class="co">#&gt;                2.63362 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-181" data-line-number="181"><span class="co">#&gt;                5.2275 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-182" data-line-number="182"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-183" data-line-number="183"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-184" data-line-number="184"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-185" data-line-number="185"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-186" data-line-number="186"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-187" data-line-number="187"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-188" data-line-number="188"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-189" data-line-number="189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-190" data-line-number="190"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-191" data-line-number="191"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-192" data-line-number="192"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-193" data-line-number="193"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-194" data-line-number="194"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-195" data-line-number="195"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-196" data-line-number="196"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-197" data-line-number="197"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-198" data-line-number="198"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-199" data-line-number="199"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-200" data-line-number="200"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-201" data-line-number="201"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-202" data-line-number="202"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-203" data-line-number="203"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-204" data-line-number="204"><span class="co">#&gt;  Elapsed Time: 2.16754 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-205" data-line-number="205"><span class="co">#&gt;                3.22175 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-206" data-line-number="206"><span class="co">#&gt;                5.38929 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-207" data-line-number="207"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-208" data-line-number="208"><span class="co">#&gt; Tau =  2</span></a>
<a class="sourceLine" id="cb96-209" data-line-number="209"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-210" data-line-number="210"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-211" data-line-number="211"><span class="co">#&gt; Gradient evaluation took 3.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-212" data-line-number="212"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.</span></a>
<a class="sourceLine" id="cb96-213" data-line-number="213"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-214" data-line-number="214"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-215" data-line-number="215"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-216" data-line-number="216"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-217" data-line-number="217"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-218" data-line-number="218"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-219" data-line-number="219"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-220" data-line-number="220"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-221" data-line-number="221"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-222" data-line-number="222"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-223" data-line-number="223"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-224" data-line-number="224"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-225" data-line-number="225"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-226" data-line-number="226"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-227" data-line-number="227"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-228" data-line-number="228"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-229" data-line-number="229"><span class="co">#&gt;  Elapsed Time: 2.41352 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-230" data-line-number="230"><span class="co">#&gt;                1.06254 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-231" data-line-number="231"><span class="co">#&gt;                3.47605 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-232" data-line-number="232"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-233" data-line-number="233"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-234" data-line-number="234"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-235" data-line-number="235"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-236" data-line-number="236"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-237" data-line-number="237"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-238" data-line-number="238"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-239" data-line-number="239"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-240" data-line-number="240"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-241" data-line-number="241"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-242" data-line-number="242"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-243" data-line-number="243"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-244" data-line-number="244"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-245" data-line-number="245"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-246" data-line-number="246"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-247" data-line-number="247"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-248" data-line-number="248"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-249" data-line-number="249"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-250" data-line-number="250"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-251" data-line-number="251"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-252" data-line-number="252"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-253" data-line-number="253"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-254" data-line-number="254"><span class="co">#&gt;  Elapsed Time: 1.79026 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-255" data-line-number="255"><span class="co">#&gt;                1.07781 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-256" data-line-number="256"><span class="co">#&gt;                2.86808 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-257" data-line-number="257"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-258" data-line-number="258"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-259" data-line-number="259"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-260" data-line-number="260"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-261" data-line-number="261"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-262" data-line-number="262"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-263" data-line-number="263"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-264" data-line-number="264"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-265" data-line-number="265"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-266" data-line-number="266"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-267" data-line-number="267"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-268" data-line-number="268"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-269" data-line-number="269"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-270" data-line-number="270"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-271" data-line-number="271"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-272" data-line-number="272"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-273" data-line-number="273"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-274" data-line-number="274"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-275" data-line-number="275"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-276" data-line-number="276"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-277" data-line-number="277"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-278" data-line-number="278"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-279" data-line-number="279"><span class="co">#&gt;  Elapsed Time: 1.83395 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-280" data-line-number="280"><span class="co">#&gt;                2.11641 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-281" data-line-number="281"><span class="co">#&gt;                3.95036 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-282" data-line-number="282"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-283" data-line-number="283"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-284" data-line-number="284"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-285" data-line-number="285"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-286" data-line-number="286"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-287" data-line-number="287"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-288" data-line-number="288"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-289" data-line-number="289"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-290" data-line-number="290"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-291" data-line-number="291"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-292" data-line-number="292"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-293" data-line-number="293"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-294" data-line-number="294"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-295" data-line-number="295"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-296" data-line-number="296"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-297" data-line-number="297"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-298" data-line-number="298"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-299" data-line-number="299"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-300" data-line-number="300"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-301" data-line-number="301"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-302" data-line-number="302"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-303" data-line-number="303"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-304" data-line-number="304"><span class="co">#&gt;  Elapsed Time: 1.791 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-305" data-line-number="305"><span class="co">#&gt;                1.14265 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-306" data-line-number="306"><span class="co">#&gt;                2.93365 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-307" data-line-number="307"><span class="co">#&gt; Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta above 0.999 may help. See</span></a>
<a class="sourceLine" id="cb96-308" data-line-number="308"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</span></a>
<a class="sourceLine" id="cb96-309" data-line-number="309"></a>
<a class="sourceLine" id="cb96-310" data-line-number="310"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a>
<a class="sourceLine" id="cb96-311" data-line-number="311"><span class="co">#&gt; Tau =  1.41</span></a>
<a class="sourceLine" id="cb96-312" data-line-number="312"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-313" data-line-number="313"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-314" data-line-number="314"><span class="co">#&gt; Gradient evaluation took 4.2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-315" data-line-number="315"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.</span></a>
<a class="sourceLine" id="cb96-316" data-line-number="316"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-317" data-line-number="317"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-318" data-line-number="318"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-319" data-line-number="319"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-320" data-line-number="320"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-321" data-line-number="321"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-322" data-line-number="322"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-323" data-line-number="323"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-324" data-line-number="324"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-325" data-line-number="325"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-326" data-line-number="326"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-327" data-line-number="327"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-328" data-line-number="328"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-329" data-line-number="329"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-330" data-line-number="330"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-331" data-line-number="331"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-332" data-line-number="332"><span class="co">#&gt;  Elapsed Time: 1.25397 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-333" data-line-number="333"><span class="co">#&gt;                1.20778 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-334" data-line-number="334"><span class="co">#&gt;                2.46175 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-335" data-line-number="335"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-336" data-line-number="336"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-337" data-line-number="337"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-338" data-line-number="338"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-339" data-line-number="339"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-340" data-line-number="340"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-341" data-line-number="341"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-342" data-line-number="342"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-343" data-line-number="343"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-344" data-line-number="344"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-345" data-line-number="345"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-346" data-line-number="346"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-347" data-line-number="347"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-348" data-line-number="348"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-349" data-line-number="349"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-350" data-line-number="350"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-351" data-line-number="351"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-352" data-line-number="352"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-353" data-line-number="353"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-354" data-line-number="354"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-355" data-line-number="355"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-356" data-line-number="356"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-357" data-line-number="357"><span class="co">#&gt;  Elapsed Time: 1.78616 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-358" data-line-number="358"><span class="co">#&gt;                1.15518 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-359" data-line-number="359"><span class="co">#&gt;                2.94134 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-360" data-line-number="360"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-361" data-line-number="361"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-362" data-line-number="362"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-363" data-line-number="363"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-364" data-line-number="364"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb96-365" data-line-number="365"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb96-366" data-line-number="366"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-367" data-line-number="367"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-368" data-line-number="368"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-369" data-line-number="369"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-370" data-line-number="370"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-371" data-line-number="371"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-372" data-line-number="372"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-373" data-line-number="373"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-374" data-line-number="374"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-375" data-line-number="375"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-376" data-line-number="376"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-377" data-line-number="377"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-378" data-line-number="378"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-379" data-line-number="379"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-380" data-line-number="380"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-381" data-line-number="381"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-382" data-line-number="382"><span class="co">#&gt;  Elapsed Time: 2.0846 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-383" data-line-number="383"><span class="co">#&gt;                0.736958 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-384" data-line-number="384"><span class="co">#&gt;                2.82156 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-385" data-line-number="385"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-386" data-line-number="386"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-387" data-line-number="387"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-388" data-line-number="388"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-389" data-line-number="389"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-390" data-line-number="390"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-391" data-line-number="391"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-392" data-line-number="392"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-393" data-line-number="393"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-394" data-line-number="394"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-395" data-line-number="395"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-396" data-line-number="396"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-397" data-line-number="397"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-398" data-line-number="398"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-399" data-line-number="399"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-400" data-line-number="400"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-401" data-line-number="401"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-402" data-line-number="402"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-403" data-line-number="403"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-404" data-line-number="404"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-405" data-line-number="405"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-406" data-line-number="406"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-407" data-line-number="407"><span class="co">#&gt;  Elapsed Time: 2.22619 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-408" data-line-number="408"><span class="co">#&gt;                0.638367 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-409" data-line-number="409"><span class="co">#&gt;                2.86456 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-410" data-line-number="410"><span class="co">#&gt; Warning: There were 3 divergent transitions after warmup. Increasing adapt_delta above 0.999 may help. See</span></a>
<a class="sourceLine" id="cb96-411" data-line-number="411"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</span></a>
<a class="sourceLine" id="cb96-412" data-line-number="412"></a>
<a class="sourceLine" id="cb96-413" data-line-number="413"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a>
<a class="sourceLine" id="cb96-414" data-line-number="414"><span class="co">#&gt; Tau =  1</span></a>
<a class="sourceLine" id="cb96-415" data-line-number="415"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-416" data-line-number="416"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-417" data-line-number="417"><span class="co">#&gt; Gradient evaluation took 2.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-418" data-line-number="418"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.</span></a>
<a class="sourceLine" id="cb96-419" data-line-number="419"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-420" data-line-number="420"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-421" data-line-number="421"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-422" data-line-number="422"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-423" data-line-number="423"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-424" data-line-number="424"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-425" data-line-number="425"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-426" data-line-number="426"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-427" data-line-number="427"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-428" data-line-number="428"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-429" data-line-number="429"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-430" data-line-number="430"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-431" data-line-number="431"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-432" data-line-number="432"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-433" data-line-number="433"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-434" data-line-number="434"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-435" data-line-number="435"><span class="co">#&gt;  Elapsed Time: 1.15944 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-436" data-line-number="436"><span class="co">#&gt;                1.33754 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-437" data-line-number="437"><span class="co">#&gt;                2.49697 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-438" data-line-number="438"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-439" data-line-number="439"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-440" data-line-number="440"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-441" data-line-number="441"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-442" data-line-number="442"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-443" data-line-number="443"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-444" data-line-number="444"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-445" data-line-number="445"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-446" data-line-number="446"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-447" data-line-number="447"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-448" data-line-number="448"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-449" data-line-number="449"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-450" data-line-number="450"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-451" data-line-number="451"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-452" data-line-number="452"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-453" data-line-number="453"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-454" data-line-number="454"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-455" data-line-number="455"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-456" data-line-number="456"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-457" data-line-number="457"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-458" data-line-number="458"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-459" data-line-number="459"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-460" data-line-number="460"><span class="co">#&gt;  Elapsed Time: 1.18318 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-461" data-line-number="461"><span class="co">#&gt;                1.75236 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-462" data-line-number="462"><span class="co">#&gt;                2.93555 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-463" data-line-number="463"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-464" data-line-number="464"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-465" data-line-number="465"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-466" data-line-number="466"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-467" data-line-number="467"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-468" data-line-number="468"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-469" data-line-number="469"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-470" data-line-number="470"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-471" data-line-number="471"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-472" data-line-number="472"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-473" data-line-number="473"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-474" data-line-number="474"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-475" data-line-number="475"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-476" data-line-number="476"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-477" data-line-number="477"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-478" data-line-number="478"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-479" data-line-number="479"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-480" data-line-number="480"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-481" data-line-number="481"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-482" data-line-number="482"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-483" data-line-number="483"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-484" data-line-number="484"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-485" data-line-number="485"><span class="co">#&gt;  Elapsed Time: 1.11993 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-486" data-line-number="486"><span class="co">#&gt;                0.755497 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-487" data-line-number="487"><span class="co">#&gt;                1.87542 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-488" data-line-number="488"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-489" data-line-number="489"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-490" data-line-number="490"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-491" data-line-number="491"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-492" data-line-number="492"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-493" data-line-number="493"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-494" data-line-number="494"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-495" data-line-number="495"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-496" data-line-number="496"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-497" data-line-number="497"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-498" data-line-number="498"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-499" data-line-number="499"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-500" data-line-number="500"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-501" data-line-number="501"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-502" data-line-number="502"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-503" data-line-number="503"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-504" data-line-number="504"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-505" data-line-number="505"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-506" data-line-number="506"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-507" data-line-number="507"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-508" data-line-number="508"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-509" data-line-number="509"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-510" data-line-number="510"><span class="co">#&gt;  Elapsed Time: 1.63862 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-511" data-line-number="511"><span class="co">#&gt;                1.18794 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-512" data-line-number="512"><span class="co">#&gt;                2.82656 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-513" data-line-number="513"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-514" data-line-number="514"><span class="co">#&gt; Tau =  0.707</span></a>
<a class="sourceLine" id="cb96-515" data-line-number="515"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-516" data-line-number="516"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-517" data-line-number="517"><span class="co">#&gt; Gradient evaluation took 3.5e-05 seconds</span></a>
<a class="sourceLine" id="cb96-518" data-line-number="518"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.35 seconds.</span></a>
<a class="sourceLine" id="cb96-519" data-line-number="519"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-520" data-line-number="520"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-521" data-line-number="521"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-522" data-line-number="522"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-523" data-line-number="523"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-524" data-line-number="524"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-525" data-line-number="525"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-526" data-line-number="526"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-527" data-line-number="527"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-528" data-line-number="528"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-529" data-line-number="529"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-530" data-line-number="530"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-531" data-line-number="531"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-532" data-line-number="532"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-533" data-line-number="533"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-534" data-line-number="534"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-535" data-line-number="535"><span class="co">#&gt;  Elapsed Time: 1.13553 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-536" data-line-number="536"><span class="co">#&gt;                1.44398 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-537" data-line-number="537"><span class="co">#&gt;                2.57951 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-538" data-line-number="538"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-539" data-line-number="539"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-540" data-line-number="540"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-541" data-line-number="541"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-542" data-line-number="542"><span class="co">#&gt; Gradient evaluation took 1.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-543" data-line-number="543"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.</span></a>
<a class="sourceLine" id="cb96-544" data-line-number="544"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-545" data-line-number="545"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-546" data-line-number="546"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-547" data-line-number="547"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-548" data-line-number="548"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-549" data-line-number="549"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-550" data-line-number="550"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-551" data-line-number="551"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-552" data-line-number="552"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-553" data-line-number="553"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-554" data-line-number="554"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-555" data-line-number="555"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-556" data-line-number="556"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-557" data-line-number="557"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-558" data-line-number="558"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-559" data-line-number="559"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-560" data-line-number="560"><span class="co">#&gt;  Elapsed Time: 1.22404 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-561" data-line-number="561"><span class="co">#&gt;                1.56945 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-562" data-line-number="562"><span class="co">#&gt;                2.79349 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-563" data-line-number="563"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-564" data-line-number="564"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-565" data-line-number="565"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-566" data-line-number="566"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-567" data-line-number="567"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-568" data-line-number="568"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-569" data-line-number="569"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-570" data-line-number="570"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-571" data-line-number="571"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-572" data-line-number="572"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-573" data-line-number="573"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-574" data-line-number="574"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-575" data-line-number="575"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-576" data-line-number="576"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-577" data-line-number="577"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-578" data-line-number="578"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-579" data-line-number="579"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-580" data-line-number="580"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-581" data-line-number="581"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-582" data-line-number="582"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-583" data-line-number="583"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-584" data-line-number="584"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-585" data-line-number="585"><span class="co">#&gt;  Elapsed Time: 0.908564 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-586" data-line-number="586"><span class="co">#&gt;                0.78698 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-587" data-line-number="587"><span class="co">#&gt;                1.69554 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-588" data-line-number="588"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-589" data-line-number="589"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-590" data-line-number="590"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-591" data-line-number="591"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-592" data-line-number="592"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-593" data-line-number="593"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-594" data-line-number="594"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-595" data-line-number="595"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-596" data-line-number="596"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-597" data-line-number="597"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-598" data-line-number="598"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-599" data-line-number="599"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-600" data-line-number="600"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-601" data-line-number="601"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-602" data-line-number="602"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-603" data-line-number="603"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-604" data-line-number="604"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-605" data-line-number="605"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-606" data-line-number="606"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-607" data-line-number="607"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-608" data-line-number="608"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-609" data-line-number="609"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-610" data-line-number="610"><span class="co">#&gt;  Elapsed Time: 1.45544 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-611" data-line-number="611"><span class="co">#&gt;                0.707461 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-612" data-line-number="612"><span class="co">#&gt;                2.1629 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-613" data-line-number="613"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-614" data-line-number="614"><span class="co">#&gt; Tau =  0.5</span></a>
<a class="sourceLine" id="cb96-615" data-line-number="615"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-616" data-line-number="616"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-617" data-line-number="617"><span class="co">#&gt; Gradient evaluation took 3.2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-618" data-line-number="618"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.</span></a>
<a class="sourceLine" id="cb96-619" data-line-number="619"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-620" data-line-number="620"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-621" data-line-number="621"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-622" data-line-number="622"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-623" data-line-number="623"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-624" data-line-number="624"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-625" data-line-number="625"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-626" data-line-number="626"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-627" data-line-number="627"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-628" data-line-number="628"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-629" data-line-number="629"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-630" data-line-number="630"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-631" data-line-number="631"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-632" data-line-number="632"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-633" data-line-number="633"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-634" data-line-number="634"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-635" data-line-number="635"><span class="co">#&gt;  Elapsed Time: 0.873706 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-636" data-line-number="636"><span class="co">#&gt;                0.612853 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-637" data-line-number="637"><span class="co">#&gt;                1.48656 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-638" data-line-number="638"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-639" data-line-number="639"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-640" data-line-number="640"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-641" data-line-number="641"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-642" data-line-number="642"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb96-643" data-line-number="643"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb96-644" data-line-number="644"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-645" data-line-number="645"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-646" data-line-number="646"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-647" data-line-number="647"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-648" data-line-number="648"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-649" data-line-number="649"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-650" data-line-number="650"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-651" data-line-number="651"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-652" data-line-number="652"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-653" data-line-number="653"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-654" data-line-number="654"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-655" data-line-number="655"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-656" data-line-number="656"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-657" data-line-number="657"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-658" data-line-number="658"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-659" data-line-number="659"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-660" data-line-number="660"><span class="co">#&gt;  Elapsed Time: 0.821891 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-661" data-line-number="661"><span class="co">#&gt;                0.668755 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-662" data-line-number="662"><span class="co">#&gt;                1.49065 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-663" data-line-number="663"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-664" data-line-number="664"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-665" data-line-number="665"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-666" data-line-number="666"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-667" data-line-number="667"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-668" data-line-number="668"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-669" data-line-number="669"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-670" data-line-number="670"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-671" data-line-number="671"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-672" data-line-number="672"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-673" data-line-number="673"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-674" data-line-number="674"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-675" data-line-number="675"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-676" data-line-number="676"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-677" data-line-number="677"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-678" data-line-number="678"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-679" data-line-number="679"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-680" data-line-number="680"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-681" data-line-number="681"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-682" data-line-number="682"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-683" data-line-number="683"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-684" data-line-number="684"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-685" data-line-number="685"><span class="co">#&gt;  Elapsed Time: 1.4445 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-686" data-line-number="686"><span class="co">#&gt;                0.50983 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-687" data-line-number="687"><span class="co">#&gt;                1.95433 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-688" data-line-number="688"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-689" data-line-number="689"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-690" data-line-number="690"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-691" data-line-number="691"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-692" data-line-number="692"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-693" data-line-number="693"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-694" data-line-number="694"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-695" data-line-number="695"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-696" data-line-number="696"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-697" data-line-number="697"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-698" data-line-number="698"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-699" data-line-number="699"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-700" data-line-number="700"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-701" data-line-number="701"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-702" data-line-number="702"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-703" data-line-number="703"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-704" data-line-number="704"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-705" data-line-number="705"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-706" data-line-number="706"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-707" data-line-number="707"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-708" data-line-number="708"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-709" data-line-number="709"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-710" data-line-number="710"><span class="co">#&gt;  Elapsed Time: 0.882806 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-711" data-line-number="711"><span class="co">#&gt;                0.749524 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-712" data-line-number="712"><span class="co">#&gt;                1.63233 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-713" data-line-number="713"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-714" data-line-number="714"><span class="co">#&gt; Tau =  0.354</span></a>
<a class="sourceLine" id="cb96-715" data-line-number="715"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-716" data-line-number="716"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-717" data-line-number="717"><span class="co">#&gt; Gradient evaluation took 2.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-718" data-line-number="718"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.</span></a>
<a class="sourceLine" id="cb96-719" data-line-number="719"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-720" data-line-number="720"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-721" data-line-number="721"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-722" data-line-number="722"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-723" data-line-number="723"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-724" data-line-number="724"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-725" data-line-number="725"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-726" data-line-number="726"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-727" data-line-number="727"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-728" data-line-number="728"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-729" data-line-number="729"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-730" data-line-number="730"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-731" data-line-number="731"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-732" data-line-number="732"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-733" data-line-number="733"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-734" data-line-number="734"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-735" data-line-number="735"><span class="co">#&gt;  Elapsed Time: 0.904845 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-736" data-line-number="736"><span class="co">#&gt;                1.21261 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-737" data-line-number="737"><span class="co">#&gt;                2.11746 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-738" data-line-number="738"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-739" data-line-number="739"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-740" data-line-number="740"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-741" data-line-number="741"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-742" data-line-number="742"><span class="co">#&gt; Gradient evaluation took 2.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-743" data-line-number="743"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.</span></a>
<a class="sourceLine" id="cb96-744" data-line-number="744"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-745" data-line-number="745"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-746" data-line-number="746"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-747" data-line-number="747"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-748" data-line-number="748"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-749" data-line-number="749"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-750" data-line-number="750"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-751" data-line-number="751"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-752" data-line-number="752"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-753" data-line-number="753"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-754" data-line-number="754"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-755" data-line-number="755"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-756" data-line-number="756"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-757" data-line-number="757"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-758" data-line-number="758"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-759" data-line-number="759"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-760" data-line-number="760"><span class="co">#&gt;  Elapsed Time: 0.967748 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-761" data-line-number="761"><span class="co">#&gt;                1.14564 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-762" data-line-number="762"><span class="co">#&gt;                2.11338 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-763" data-line-number="763"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-764" data-line-number="764"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-765" data-line-number="765"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-766" data-line-number="766"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-767" data-line-number="767"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-768" data-line-number="768"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-769" data-line-number="769"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-770" data-line-number="770"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-771" data-line-number="771"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-772" data-line-number="772"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-773" data-line-number="773"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-774" data-line-number="774"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-775" data-line-number="775"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-776" data-line-number="776"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-777" data-line-number="777"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-778" data-line-number="778"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-779" data-line-number="779"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-780" data-line-number="780"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-781" data-line-number="781"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-782" data-line-number="782"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-783" data-line-number="783"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-784" data-line-number="784"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-785" data-line-number="785"><span class="co">#&gt;  Elapsed Time: 0.824583 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-786" data-line-number="786"><span class="co">#&gt;                0.614315 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-787" data-line-number="787"><span class="co">#&gt;                1.4389 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-788" data-line-number="788"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-789" data-line-number="789"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-790" data-line-number="790"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-791" data-line-number="791"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-792" data-line-number="792"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-793" data-line-number="793"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-794" data-line-number="794"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-795" data-line-number="795"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-796" data-line-number="796"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-797" data-line-number="797"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-798" data-line-number="798"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-799" data-line-number="799"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-800" data-line-number="800"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-801" data-line-number="801"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-802" data-line-number="802"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-803" data-line-number="803"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-804" data-line-number="804"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-805" data-line-number="805"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-806" data-line-number="806"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-807" data-line-number="807"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-808" data-line-number="808"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-809" data-line-number="809"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-810" data-line-number="810"><span class="co">#&gt;  Elapsed Time: 0.751391 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-811" data-line-number="811"><span class="co">#&gt;                0.580313 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-812" data-line-number="812"><span class="co">#&gt;                1.3317 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-813" data-line-number="813"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-814" data-line-number="814"><span class="co">#&gt; Tau =  0.25</span></a>
<a class="sourceLine" id="cb96-815" data-line-number="815"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-816" data-line-number="816"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-817" data-line-number="817"><span class="co">#&gt; Gradient evaluation took 2.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-818" data-line-number="818"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.28 seconds.</span></a>
<a class="sourceLine" id="cb96-819" data-line-number="819"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-820" data-line-number="820"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-821" data-line-number="821"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-822" data-line-number="822"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-823" data-line-number="823"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-824" data-line-number="824"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-825" data-line-number="825"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-826" data-line-number="826"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-827" data-line-number="827"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-828" data-line-number="828"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-829" data-line-number="829"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-830" data-line-number="830"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-831" data-line-number="831"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-832" data-line-number="832"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-833" data-line-number="833"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-834" data-line-number="834"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-835" data-line-number="835"><span class="co">#&gt;  Elapsed Time: 0.958892 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-836" data-line-number="836"><span class="co">#&gt;                0.630532 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-837" data-line-number="837"><span class="co">#&gt;                1.58942 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-838" data-line-number="838"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-839" data-line-number="839"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-840" data-line-number="840"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-841" data-line-number="841"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-842" data-line-number="842"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-843" data-line-number="843"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-844" data-line-number="844"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-845" data-line-number="845"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-846" data-line-number="846"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-847" data-line-number="847"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-848" data-line-number="848"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-849" data-line-number="849"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-850" data-line-number="850"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-851" data-line-number="851"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-852" data-line-number="852"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-853" data-line-number="853"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-854" data-line-number="854"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-855" data-line-number="855"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-856" data-line-number="856"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-857" data-line-number="857"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-858" data-line-number="858"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-859" data-line-number="859"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-860" data-line-number="860"><span class="co">#&gt;  Elapsed Time: 0.819902 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-861" data-line-number="861"><span class="co">#&gt;                0.632382 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-862" data-line-number="862"><span class="co">#&gt;                1.45228 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-863" data-line-number="863"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-864" data-line-number="864"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-865" data-line-number="865"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-866" data-line-number="866"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-867" data-line-number="867"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-868" data-line-number="868"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-869" data-line-number="869"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-870" data-line-number="870"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-871" data-line-number="871"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-872" data-line-number="872"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-873" data-line-number="873"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-874" data-line-number="874"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-875" data-line-number="875"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-876" data-line-number="876"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-877" data-line-number="877"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-878" data-line-number="878"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-879" data-line-number="879"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-880" data-line-number="880"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-881" data-line-number="881"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-882" data-line-number="882"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-883" data-line-number="883"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-884" data-line-number="884"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-885" data-line-number="885"><span class="co">#&gt;  Elapsed Time: 0.707015 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-886" data-line-number="886"><span class="co">#&gt;                0.607349 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-887" data-line-number="887"><span class="co">#&gt;                1.31436 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-888" data-line-number="888"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-889" data-line-number="889"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-890" data-line-number="890"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-891" data-line-number="891"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-892" data-line-number="892"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-893" data-line-number="893"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-894" data-line-number="894"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-895" data-line-number="895"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-896" data-line-number="896"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-897" data-line-number="897"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-898" data-line-number="898"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-899" data-line-number="899"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-900" data-line-number="900"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-901" data-line-number="901"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-902" data-line-number="902"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-903" data-line-number="903"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-904" data-line-number="904"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-905" data-line-number="905"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-906" data-line-number="906"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-907" data-line-number="907"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-908" data-line-number="908"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-909" data-line-number="909"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-910" data-line-number="910"><span class="co">#&gt;  Elapsed Time: 0.792171 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-911" data-line-number="911"><span class="co">#&gt;                0.603033 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-912" data-line-number="912"><span class="co">#&gt;                1.3952 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-913" data-line-number="913"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-914" data-line-number="914"><span class="co">#&gt; Tau =  0.177</span></a>
<a class="sourceLine" id="cb96-915" data-line-number="915"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-916" data-line-number="916"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-917" data-line-number="917"><span class="co">#&gt; Gradient evaluation took 3.2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-918" data-line-number="918"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.32 seconds.</span></a>
<a class="sourceLine" id="cb96-919" data-line-number="919"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-920" data-line-number="920"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-921" data-line-number="921"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-922" data-line-number="922"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-923" data-line-number="923"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-924" data-line-number="924"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-925" data-line-number="925"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-926" data-line-number="926"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-927" data-line-number="927"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-928" data-line-number="928"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-929" data-line-number="929"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-930" data-line-number="930"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-931" data-line-number="931"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-932" data-line-number="932"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-933" data-line-number="933"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-934" data-line-number="934"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-935" data-line-number="935"><span class="co">#&gt;  Elapsed Time: 1.37449 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-936" data-line-number="936"><span class="co">#&gt;                0.360441 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-937" data-line-number="937"><span class="co">#&gt;                1.73493 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-938" data-line-number="938"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-939" data-line-number="939"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-940" data-line-number="940"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-941" data-line-number="941"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-942" data-line-number="942"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-943" data-line-number="943"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb96-944" data-line-number="944"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-945" data-line-number="945"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-946" data-line-number="946"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-947" data-line-number="947"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-948" data-line-number="948"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-949" data-line-number="949"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-950" data-line-number="950"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-951" data-line-number="951"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-952" data-line-number="952"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-953" data-line-number="953"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-954" data-line-number="954"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-955" data-line-number="955"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-956" data-line-number="956"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-957" data-line-number="957"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-958" data-line-number="958"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-959" data-line-number="959"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-960" data-line-number="960"><span class="co">#&gt;  Elapsed Time: 0.710186 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-961" data-line-number="961"><span class="co">#&gt;                0.748483 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-962" data-line-number="962"><span class="co">#&gt;                1.45867 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-963" data-line-number="963"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-964" data-line-number="964"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-965" data-line-number="965"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-966" data-line-number="966"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-967" data-line-number="967"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-968" data-line-number="968"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-969" data-line-number="969"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-970" data-line-number="970"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-971" data-line-number="971"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-972" data-line-number="972"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-973" data-line-number="973"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-974" data-line-number="974"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-975" data-line-number="975"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-976" data-line-number="976"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-977" data-line-number="977"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-978" data-line-number="978"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-979" data-line-number="979"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-980" data-line-number="980"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-981" data-line-number="981"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-982" data-line-number="982"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-983" data-line-number="983"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-984" data-line-number="984"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-985" data-line-number="985"><span class="co">#&gt;  Elapsed Time: 1.33735 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-986" data-line-number="986"><span class="co">#&gt;                1.07732 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-987" data-line-number="987"><span class="co">#&gt;                2.41467 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-988" data-line-number="988"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-989" data-line-number="989"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-990" data-line-number="990"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-991" data-line-number="991"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-992" data-line-number="992"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-993" data-line-number="993"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-994" data-line-number="994"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-995" data-line-number="995"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-996" data-line-number="996"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-997" data-line-number="997"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-998" data-line-number="998"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-999" data-line-number="999"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1000" data-line-number="1000"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1001" data-line-number="1001"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1002" data-line-number="1002"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1003" data-line-number="1003"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1004" data-line-number="1004"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1005" data-line-number="1005"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1006" data-line-number="1006"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1007" data-line-number="1007"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1008" data-line-number="1008"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1009" data-line-number="1009"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1010" data-line-number="1010"><span class="co">#&gt;  Elapsed Time: 0.661162 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1011" data-line-number="1011"><span class="co">#&gt;                0.730974 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1012" data-line-number="1012"><span class="co">#&gt;                1.39214 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1013" data-line-number="1013"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1014" data-line-number="1014"><span class="co">#&gt; Tau =  0.125</span></a>
<a class="sourceLine" id="cb96-1015" data-line-number="1015"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-1016" data-line-number="1016"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1017" data-line-number="1017"><span class="co">#&gt; Gradient evaluation took 2.6e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1018" data-line-number="1018"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.</span></a>
<a class="sourceLine" id="cb96-1019" data-line-number="1019"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1020" data-line-number="1020"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1021" data-line-number="1021"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1022" data-line-number="1022"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1023" data-line-number="1023"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1024" data-line-number="1024"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1025" data-line-number="1025"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1026" data-line-number="1026"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1027" data-line-number="1027"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1028" data-line-number="1028"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1029" data-line-number="1029"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1030" data-line-number="1030"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1031" data-line-number="1031"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1032" data-line-number="1032"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1033" data-line-number="1033"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1034" data-line-number="1034"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1035" data-line-number="1035"><span class="co">#&gt;  Elapsed Time: 1.25579 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1036" data-line-number="1036"><span class="co">#&gt;                0.4392 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1037" data-line-number="1037"><span class="co">#&gt;                1.69499 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1038" data-line-number="1038"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1039" data-line-number="1039"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1040" data-line-number="1040"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-1041" data-line-number="1041"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1042" data-line-number="1042"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1043" data-line-number="1043"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-1044" data-line-number="1044"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1045" data-line-number="1045"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1046" data-line-number="1046"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1047" data-line-number="1047"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1048" data-line-number="1048"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1049" data-line-number="1049"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1050" data-line-number="1050"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1051" data-line-number="1051"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1052" data-line-number="1052"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1053" data-line-number="1053"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1054" data-line-number="1054"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1055" data-line-number="1055"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1056" data-line-number="1056"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1057" data-line-number="1057"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1058" data-line-number="1058"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1059" data-line-number="1059"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1060" data-line-number="1060"><span class="co">#&gt;  Elapsed Time: 0.78691 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1061" data-line-number="1061"><span class="co">#&gt;                0.378782 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1062" data-line-number="1062"><span class="co">#&gt;                1.16569 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1063" data-line-number="1063"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1064" data-line-number="1064"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1065" data-line-number="1065"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-1066" data-line-number="1066"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1067" data-line-number="1067"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1068" data-line-number="1068"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb96-1069" data-line-number="1069"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1070" data-line-number="1070"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1071" data-line-number="1071"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1072" data-line-number="1072"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1073" data-line-number="1073"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1074" data-line-number="1074"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1075" data-line-number="1075"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1076" data-line-number="1076"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1077" data-line-number="1077"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1078" data-line-number="1078"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1079" data-line-number="1079"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1080" data-line-number="1080"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1081" data-line-number="1081"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1082" data-line-number="1082"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1083" data-line-number="1083"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1084" data-line-number="1084"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1085" data-line-number="1085"><span class="co">#&gt;  Elapsed Time: 0.868063 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1086" data-line-number="1086"><span class="co">#&gt;                0.598435 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1087" data-line-number="1087"><span class="co">#&gt;                1.4665 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1088" data-line-number="1088"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1089" data-line-number="1089"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1090" data-line-number="1090"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-1091" data-line-number="1091"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1092" data-line-number="1092"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1093" data-line-number="1093"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-1094" data-line-number="1094"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1095" data-line-number="1095"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1096" data-line-number="1096"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1097" data-line-number="1097"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1098" data-line-number="1098"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1099" data-line-number="1099"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1100" data-line-number="1100"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1101" data-line-number="1101"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1102" data-line-number="1102"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1103" data-line-number="1103"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1104" data-line-number="1104"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1105" data-line-number="1105"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1106" data-line-number="1106"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1107" data-line-number="1107"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1108" data-line-number="1108"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1109" data-line-number="1109"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1110" data-line-number="1110"><span class="co">#&gt;  Elapsed Time: 0.95026 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1111" data-line-number="1111"><span class="co">#&gt;                0.914547 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1112" data-line-number="1112"><span class="co">#&gt;                1.86481 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1113" data-line-number="1113"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1114" data-line-number="1114"><span class="co">#&gt; Tau =  0.0884</span></a>
<a class="sourceLine" id="cb96-1115" data-line-number="1115"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-1116" data-line-number="1116"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1117" data-line-number="1117"><span class="co">#&gt; Gradient evaluation took 4.1e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1118" data-line-number="1118"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.</span></a>
<a class="sourceLine" id="cb96-1119" data-line-number="1119"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1120" data-line-number="1120"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1121" data-line-number="1121"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1122" data-line-number="1122"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1123" data-line-number="1123"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1124" data-line-number="1124"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1125" data-line-number="1125"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1126" data-line-number="1126"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1127" data-line-number="1127"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1128" data-line-number="1128"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1129" data-line-number="1129"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1130" data-line-number="1130"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1131" data-line-number="1131"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1132" data-line-number="1132"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1133" data-line-number="1133"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1134" data-line-number="1134"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1135" data-line-number="1135"><span class="co">#&gt;  Elapsed Time: 0.898391 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1136" data-line-number="1136"><span class="co">#&gt;                0.627058 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1137" data-line-number="1137"><span class="co">#&gt;                1.52545 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1138" data-line-number="1138"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1139" data-line-number="1139"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1140" data-line-number="1140"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-1141" data-line-number="1141"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1142" data-line-number="1142"><span class="co">#&gt; Gradient evaluation took 1.5e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1143" data-line-number="1143"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.</span></a>
<a class="sourceLine" id="cb96-1144" data-line-number="1144"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1145" data-line-number="1145"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1146" data-line-number="1146"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1147" data-line-number="1147"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1148" data-line-number="1148"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1149" data-line-number="1149"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1150" data-line-number="1150"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1151" data-line-number="1151"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1152" data-line-number="1152"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1153" data-line-number="1153"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1154" data-line-number="1154"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1155" data-line-number="1155"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1156" data-line-number="1156"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1157" data-line-number="1157"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1158" data-line-number="1158"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1159" data-line-number="1159"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1160" data-line-number="1160"><span class="co">#&gt;  Elapsed Time: 0.590551 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1161" data-line-number="1161"><span class="co">#&gt;                0.639761 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1162" data-line-number="1162"><span class="co">#&gt;                1.23031 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1163" data-line-number="1163"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1164" data-line-number="1164"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1165" data-line-number="1165"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-1166" data-line-number="1166"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1167" data-line-number="1167"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1168" data-line-number="1168"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-1169" data-line-number="1169"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1170" data-line-number="1170"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1171" data-line-number="1171"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1172" data-line-number="1172"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1173" data-line-number="1173"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1174" data-line-number="1174"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1175" data-line-number="1175"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1176" data-line-number="1176"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1177" data-line-number="1177"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1178" data-line-number="1178"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1179" data-line-number="1179"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1180" data-line-number="1180"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1181" data-line-number="1181"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1182" data-line-number="1182"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1183" data-line-number="1183"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1184" data-line-number="1184"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1185" data-line-number="1185"><span class="co">#&gt;  Elapsed Time: 0.632818 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1186" data-line-number="1186"><span class="co">#&gt;                0.425219 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1187" data-line-number="1187"><span class="co">#&gt;                1.05804 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1188" data-line-number="1188"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1189" data-line-number="1189"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1190" data-line-number="1190"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-1191" data-line-number="1191"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1192" data-line-number="1192"><span class="co">#&gt; Gradient evaluation took 2.2e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1193" data-line-number="1193"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.</span></a>
<a class="sourceLine" id="cb96-1194" data-line-number="1194"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1195" data-line-number="1195"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1196" data-line-number="1196"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1197" data-line-number="1197"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1198" data-line-number="1198"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1199" data-line-number="1199"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1200" data-line-number="1200"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1201" data-line-number="1201"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1202" data-line-number="1202"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1203" data-line-number="1203"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1204" data-line-number="1204"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1205" data-line-number="1205"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1206" data-line-number="1206"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1207" data-line-number="1207"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1208" data-line-number="1208"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1209" data-line-number="1209"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1210" data-line-number="1210"><span class="co">#&gt;  Elapsed Time: 0.72216 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1211" data-line-number="1211"><span class="co">#&gt;                0.629402 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1212" data-line-number="1212"><span class="co">#&gt;                1.35156 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1213" data-line-number="1213"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1214" data-line-number="1214"><span class="co">#&gt; Tau =  0.0625</span></a>
<a class="sourceLine" id="cb96-1215" data-line-number="1215"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-1216" data-line-number="1216"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1217" data-line-number="1217"><span class="co">#&gt; Gradient evaluation took 2.6e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1218" data-line-number="1218"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.26 seconds.</span></a>
<a class="sourceLine" id="cb96-1219" data-line-number="1219"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1220" data-line-number="1220"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1221" data-line-number="1221"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1222" data-line-number="1222"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1223" data-line-number="1223"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1224" data-line-number="1224"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1225" data-line-number="1225"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1226" data-line-number="1226"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1227" data-line-number="1227"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1228" data-line-number="1228"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1229" data-line-number="1229"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1230" data-line-number="1230"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1231" data-line-number="1231"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1232" data-line-number="1232"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1233" data-line-number="1233"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1234" data-line-number="1234"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1235" data-line-number="1235"><span class="co">#&gt;  Elapsed Time: 0.586961 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1236" data-line-number="1236"><span class="co">#&gt;                1.1543 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1237" data-line-number="1237"><span class="co">#&gt;                1.74126 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1238" data-line-number="1238"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1239" data-line-number="1239"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1240" data-line-number="1240"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-1241" data-line-number="1241"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1242" data-line-number="1242"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1243" data-line-number="1243"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-1244" data-line-number="1244"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1245" data-line-number="1245"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1246" data-line-number="1246"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1247" data-line-number="1247"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1248" data-line-number="1248"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1249" data-line-number="1249"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1250" data-line-number="1250"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1251" data-line-number="1251"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1252" data-line-number="1252"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1253" data-line-number="1253"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1254" data-line-number="1254"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1255" data-line-number="1255"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1256" data-line-number="1256"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1257" data-line-number="1257"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1258" data-line-number="1258"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1259" data-line-number="1259"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1260" data-line-number="1260"><span class="co">#&gt;  Elapsed Time: 0.61856 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1261" data-line-number="1261"><span class="co">#&gt;                0.32033 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1262" data-line-number="1262"><span class="co">#&gt;                0.93889 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1263" data-line-number="1263"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1264" data-line-number="1264"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1265" data-line-number="1265"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-1266" data-line-number="1266"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1267" data-line-number="1267"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1268" data-line-number="1268"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb96-1269" data-line-number="1269"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1270" data-line-number="1270"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1271" data-line-number="1271"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1272" data-line-number="1272"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1273" data-line-number="1273"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1274" data-line-number="1274"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1275" data-line-number="1275"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1276" data-line-number="1276"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1277" data-line-number="1277"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1278" data-line-number="1278"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1279" data-line-number="1279"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1280" data-line-number="1280"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1281" data-line-number="1281"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1282" data-line-number="1282"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1283" data-line-number="1283"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1284" data-line-number="1284"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1285" data-line-number="1285"><span class="co">#&gt;  Elapsed Time: 0.607866 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1286" data-line-number="1286"><span class="co">#&gt;                0.625017 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1287" data-line-number="1287"><span class="co">#&gt;                1.23288 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1288" data-line-number="1288"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1289" data-line-number="1289"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1290" data-line-number="1290"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-1291" data-line-number="1291"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1292" data-line-number="1292"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1293" data-line-number="1293"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-1294" data-line-number="1294"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1295" data-line-number="1295"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1296" data-line-number="1296"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1297" data-line-number="1297"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1298" data-line-number="1298"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1299" data-line-number="1299"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1300" data-line-number="1300"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1301" data-line-number="1301"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1302" data-line-number="1302"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1303" data-line-number="1303"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1304" data-line-number="1304"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1305" data-line-number="1305"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1306" data-line-number="1306"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1307" data-line-number="1307"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1308" data-line-number="1308"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1309" data-line-number="1309"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1310" data-line-number="1310"><span class="co">#&gt;  Elapsed Time: 0.515886 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1311" data-line-number="1311"><span class="co">#&gt;                0.443247 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1312" data-line-number="1312"><span class="co">#&gt;                0.959133 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1313" data-line-number="1313"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1314" data-line-number="1314"><span class="co">#&gt; Tau =  0.0442</span></a>
<a class="sourceLine" id="cb96-1315" data-line-number="1315"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-1316" data-line-number="1316"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1317" data-line-number="1317"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1318" data-line-number="1318"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb96-1319" data-line-number="1319"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1320" data-line-number="1320"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1321" data-line-number="1321"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1322" data-line-number="1322"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1323" data-line-number="1323"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1324" data-line-number="1324"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1325" data-line-number="1325"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1326" data-line-number="1326"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1327" data-line-number="1327"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1328" data-line-number="1328"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1329" data-line-number="1329"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1330" data-line-number="1330"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1331" data-line-number="1331"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1332" data-line-number="1332"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1333" data-line-number="1333"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1334" data-line-number="1334"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1335" data-line-number="1335"><span class="co">#&gt;  Elapsed Time: 1.00163 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1336" data-line-number="1336"><span class="co">#&gt;                0.45284 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1337" data-line-number="1337"><span class="co">#&gt;                1.45447 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1338" data-line-number="1338"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1339" data-line-number="1339"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1340" data-line-number="1340"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-1341" data-line-number="1341"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1342" data-line-number="1342"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1343" data-line-number="1343"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb96-1344" data-line-number="1344"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1345" data-line-number="1345"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1346" data-line-number="1346"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1347" data-line-number="1347"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1348" data-line-number="1348"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1349" data-line-number="1349"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1350" data-line-number="1350"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1351" data-line-number="1351"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1352" data-line-number="1352"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1353" data-line-number="1353"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1354" data-line-number="1354"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1355" data-line-number="1355"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1356" data-line-number="1356"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1357" data-line-number="1357"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1358" data-line-number="1358"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1359" data-line-number="1359"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1360" data-line-number="1360"><span class="co">#&gt;  Elapsed Time: 0.489896 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1361" data-line-number="1361"><span class="co">#&gt;                0.544579 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1362" data-line-number="1362"><span class="co">#&gt;                1.03448 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1363" data-line-number="1363"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1364" data-line-number="1364"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1365" data-line-number="1365"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-1366" data-line-number="1366"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1367" data-line-number="1367"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1368" data-line-number="1368"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-1369" data-line-number="1369"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1370" data-line-number="1370"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1371" data-line-number="1371"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1372" data-line-number="1372"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1373" data-line-number="1373"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1374" data-line-number="1374"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1375" data-line-number="1375"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1376" data-line-number="1376"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1377" data-line-number="1377"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1378" data-line-number="1378"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1379" data-line-number="1379"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1380" data-line-number="1380"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1381" data-line-number="1381"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1382" data-line-number="1382"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1383" data-line-number="1383"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1384" data-line-number="1384"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1385" data-line-number="1385"><span class="co">#&gt;  Elapsed Time: 0.54948 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1386" data-line-number="1386"><span class="co">#&gt;                0.589965 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1387" data-line-number="1387"><span class="co">#&gt;                1.13944 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1388" data-line-number="1388"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1389" data-line-number="1389"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1390" data-line-number="1390"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-1391" data-line-number="1391"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1392" data-line-number="1392"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1393" data-line-number="1393"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb96-1394" data-line-number="1394"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1395" data-line-number="1395"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1396" data-line-number="1396"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1397" data-line-number="1397"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1398" data-line-number="1398"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1399" data-line-number="1399"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1400" data-line-number="1400"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1401" data-line-number="1401"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1402" data-line-number="1402"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1403" data-line-number="1403"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1404" data-line-number="1404"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1405" data-line-number="1405"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1406" data-line-number="1406"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1407" data-line-number="1407"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1408" data-line-number="1408"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1409" data-line-number="1409"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1410" data-line-number="1410"><span class="co">#&gt;  Elapsed Time: 0.562241 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1411" data-line-number="1411"><span class="co">#&gt;                0.527688 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1412" data-line-number="1412"><span class="co">#&gt;                1.08993 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1413" data-line-number="1413"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1414" data-line-number="1414"><span class="co">#&gt; Tau =  0.0312</span></a>
<a class="sourceLine" id="cb96-1415" data-line-number="1415"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 1).</span></a>
<a class="sourceLine" id="cb96-1416" data-line-number="1416"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1417" data-line-number="1417"><span class="co">#&gt; Gradient evaluation took 2.7e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1418" data-line-number="1418"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.</span></a>
<a class="sourceLine" id="cb96-1419" data-line-number="1419"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1420" data-line-number="1420"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1421" data-line-number="1421"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1422" data-line-number="1422"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1423" data-line-number="1423"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1424" data-line-number="1424"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1425" data-line-number="1425"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1426" data-line-number="1426"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1427" data-line-number="1427"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1428" data-line-number="1428"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1429" data-line-number="1429"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1430" data-line-number="1430"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1431" data-line-number="1431"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1432" data-line-number="1432"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1433" data-line-number="1433"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1434" data-line-number="1434"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1435" data-line-number="1435"><span class="co">#&gt;  Elapsed Time: 0.897725 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1436" data-line-number="1436"><span class="co">#&gt;                0.414058 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1437" data-line-number="1437"><span class="co">#&gt;                1.31178 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1438" data-line-number="1438"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1439" data-line-number="1439"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1440" data-line-number="1440"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 2).</span></a>
<a class="sourceLine" id="cb96-1441" data-line-number="1441"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1442" data-line-number="1442"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1443" data-line-number="1443"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb96-1444" data-line-number="1444"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1445" data-line-number="1445"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1446" data-line-number="1446"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1447" data-line-number="1447"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1448" data-line-number="1448"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1449" data-line-number="1449"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1450" data-line-number="1450"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1451" data-line-number="1451"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1452" data-line-number="1452"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1453" data-line-number="1453"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1454" data-line-number="1454"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1455" data-line-number="1455"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1456" data-line-number="1456"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1457" data-line-number="1457"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1458" data-line-number="1458"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1459" data-line-number="1459"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1460" data-line-number="1460"><span class="co">#&gt;  Elapsed Time: 0.697267 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1461" data-line-number="1461"><span class="co">#&gt;                0.458762 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1462" data-line-number="1462"><span class="co">#&gt;                1.15603 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1463" data-line-number="1463"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1464" data-line-number="1464"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1465" data-line-number="1465"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 3).</span></a>
<a class="sourceLine" id="cb96-1466" data-line-number="1466"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1467" data-line-number="1467"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1468" data-line-number="1468"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb96-1469" data-line-number="1469"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1470" data-line-number="1470"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1471" data-line-number="1471"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1472" data-line-number="1472"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1473" data-line-number="1473"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1474" data-line-number="1474"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1475" data-line-number="1475"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1476" data-line-number="1476"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1477" data-line-number="1477"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1478" data-line-number="1478"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1479" data-line-number="1479"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1480" data-line-number="1480"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1481" data-line-number="1481"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1482" data-line-number="1482"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1483" data-line-number="1483"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1484" data-line-number="1484"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1485" data-line-number="1485"><span class="co">#&gt;  Elapsed Time: 0.605598 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1486" data-line-number="1486"><span class="co">#&gt;                0.328416 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1487" data-line-number="1487"><span class="co">#&gt;                0.934014 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1488" data-line-number="1488"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1489" data-line-number="1489"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1490" data-line-number="1490"><span class="co">#&gt; SAMPLING FOR MODEL &#39;lm-coef-hs-1&#39; NOW (CHAIN 4).</span></a>
<a class="sourceLine" id="cb96-1491" data-line-number="1491"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1492" data-line-number="1492"><span class="co">#&gt; Gradient evaluation took 1.8e-05 seconds</span></a>
<a class="sourceLine" id="cb96-1493" data-line-number="1493"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.</span></a>
<a class="sourceLine" id="cb96-1494" data-line-number="1494"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb96-1495" data-line-number="1495"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1496" data-line-number="1496"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1497" data-line-number="1497"><span class="co">#&gt; Iteration:    1 / 2000 [  0%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1498" data-line-number="1498"><span class="co">#&gt; Iteration:  200 / 2000 [ 10%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1499" data-line-number="1499"><span class="co">#&gt; Iteration:  400 / 2000 [ 20%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1500" data-line-number="1500"><span class="co">#&gt; Iteration:  600 / 2000 [ 30%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1501" data-line-number="1501"><span class="co">#&gt; Iteration:  800 / 2000 [ 40%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1502" data-line-number="1502"><span class="co">#&gt; Iteration: 1000 / 2000 [ 50%]  (Warmup)</span></a>
<a class="sourceLine" id="cb96-1503" data-line-number="1503"><span class="co">#&gt; Iteration: 1001 / 2000 [ 50%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1504" data-line-number="1504"><span class="co">#&gt; Iteration: 1200 / 2000 [ 60%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1505" data-line-number="1505"><span class="co">#&gt; Iteration: 1400 / 2000 [ 70%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1506" data-line-number="1506"><span class="co">#&gt; Iteration: 1600 / 2000 [ 80%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1507" data-line-number="1507"><span class="co">#&gt; Iteration: 1800 / 2000 [ 90%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1508" data-line-number="1508"><span class="co">#&gt; Iteration: 2000 / 2000 [100%]  (Sampling)</span></a>
<a class="sourceLine" id="cb96-1509" data-line-number="1509"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb96-1510" data-line-number="1510"><span class="co">#&gt;  Elapsed Time: 0.576019 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb96-1511" data-line-number="1511"><span class="co">#&gt;                0.642967 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb96-1512" data-line-number="1512"><span class="co">#&gt;                1.21899 seconds (Total)</span></a>
<a class="sourceLine" id="cb96-1513" data-line-number="1513"><span class="co">#&gt; Warning: Some Pareto k diagnostic values are slightly high. See</span></a>
<a class="sourceLine" id="cb96-1514" data-line-number="1514"><span class="co">#&gt; help(&#39;pareto-k-diagnostic&#39;) for details.</span></a></code></pre></div>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" data-line-number="1"><span class="kw">plot_coefpaths</span>(coefpath_hs)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-33-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" data-line-number="1"><span class="kw">plot_coefpaths</span>(coefpath_hs, <span class="st">&quot;mode&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-34-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" data-line-number="1"><span class="kw">get_best_tau</span>(coefpath_hs)</a>
<a class="sourceLine" id="cb99-2" data-line-number="2"><span class="co">#&gt; # A tibble: 1 × 3</span></a>
<a class="sourceLine" id="cb99-3" data-line-number="3"><span class="co">#&gt;     tau  elpd     p</span></a>
<a class="sourceLine" id="cb99-4" data-line-number="4"><span class="co">#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb99-5" data-line-number="5"><span class="co">#&gt; 1 0.125  -234  2.51</span></a></code></pre></div>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" data-line-number="1"><span class="kw">plot_coefpath_loo</span>(coefpath_hs)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-36-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" data-line-number="1">mod_lm_coef_hs_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-hs-2.stan&quot;</span>)</a>
<a class="sourceLine" id="cb101-2" data-line-number="2"><span class="co">#&gt; In file included from file27845219544d.cpp:8:</span></a>
<a class="sourceLine" id="cb101-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb101-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb101-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb101-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb101-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb101-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb101-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb101-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb101-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb101-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb101-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb101-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb101-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb101-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb101-17" data-line-number="17"><span class="co">#&gt; In file included from file27845219544d.cpp:8:</span></a>
<a class="sourceLine" id="cb101-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb101-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb101-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb101-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb101-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb101-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb101-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb101-25" data-line-number="25"><span class="co">#&gt; In file included from file27845219544d.cpp:8:</span></a>
<a class="sourceLine" id="cb101-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb101-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb101-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb101-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb101-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb101-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb101-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb101-33" data-line-number="33"><span class="co">#&gt; In file included from file27845219544d.cpp:8:</span></a>
<a class="sourceLine" id="cb101-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb101-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb101-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb101-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb101-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb101-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb101-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb101-41" data-line-number="41"><span class="co">#&gt; In file included from file27845219544d.cpp:8:</span></a>
<a class="sourceLine" id="cb101-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb101-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb101-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb101-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb101-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb101-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb101-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb101-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb101-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb101-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb101-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb101-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb101-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb101-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb101-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb101-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb101-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb101-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb101-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb101-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb101-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb101-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb101-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1">fit_hs &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_lm_coef_hs_<span class="dv">2</span>, <span class="dt">refresh =</span> <span class="dv">-1</span>,</a>
<a class="sourceLine" id="cb102-2" data-line-number="2">                   <span class="dt">data =</span> <span class="kw">c</span>(prostate_data, <span class="kw">list</span>(<span class="dt">df_local =</span> <span class="dv">3</span>, <span class="dt">df_global =</span> <span class="dv">3</span>)),</a>
<a class="sourceLine" id="cb102-3" data-line-number="3">                 <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.995</span>))</a>
<a class="sourceLine" id="cb102-4" data-line-number="4"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-5" data-line-number="5"><span class="co">#&gt; Gradient evaluation took 4.1e-05 seconds</span></a>
<a class="sourceLine" id="cb102-6" data-line-number="6"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.</span></a>
<a class="sourceLine" id="cb102-7" data-line-number="7"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb102-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-11" data-line-number="11"><span class="co">#&gt;  Elapsed Time: 1.00399 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb102-12" data-line-number="12"><span class="co">#&gt;                0.582382 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb102-13" data-line-number="13"><span class="co">#&gt;                1.58637 seconds (Total)</span></a>
<a class="sourceLine" id="cb102-14" data-line-number="14"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 1</span></a>
<a class="sourceLine" id="cb102-15" data-line-number="15"><span class="co">#&gt;                                                                          count</span></a>
<a class="sourceLine" id="cb102-16" data-line-number="16"><span class="co">#&gt; Exception thrown at line 39: multiply: B[1] is nan, but must not be nan!     2</span></a>
<a class="sourceLine" id="cb102-17" data-line-number="17"><span class="co">#&gt; Exception thrown at line 39: multiply: B[8] is nan, but must not be nan!     1</span></a>
<a class="sourceLine" id="cb102-18" data-line-number="18"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb102-19" data-line-number="19"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb102-20" data-line-number="20"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb102-21" data-line-number="21"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-22" data-line-number="22"><span class="co">#&gt; Gradient evaluation took 2e-05 seconds</span></a>
<a class="sourceLine" id="cb102-23" data-line-number="23"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.2 seconds.</span></a>
<a class="sourceLine" id="cb102-24" data-line-number="24"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb102-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-27" data-line-number="27"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-28" data-line-number="28"><span class="co">#&gt;  Elapsed Time: 0.988918 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb102-29" data-line-number="29"><span class="co">#&gt;                0.412526 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb102-30" data-line-number="30"><span class="co">#&gt;                1.40144 seconds (Total)</span></a>
<a class="sourceLine" id="cb102-31" data-line-number="31"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 2</span></a>
<a class="sourceLine" id="cb102-32" data-line-number="32"><span class="co">#&gt;                                                                          count</span></a>
<a class="sourceLine" id="cb102-33" data-line-number="33"><span class="co">#&gt; Exception thrown at line 39: multiply: B[1] is nan, but must not be nan!     5</span></a>
<a class="sourceLine" id="cb102-34" data-line-number="34"><span class="co">#&gt; Exception thrown at line 39: multiply: B[5] is nan, but must not be nan!     1</span></a>
<a class="sourceLine" id="cb102-35" data-line-number="35"><span class="co">#&gt; Exception thrown at line 39: multiply: B[7] is nan, but must not be nan!     1</span></a>
<a class="sourceLine" id="cb102-36" data-line-number="36"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb102-37" data-line-number="37"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb102-38" data-line-number="38"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb102-39" data-line-number="39"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-40" data-line-number="40"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb102-41" data-line-number="41"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb102-42" data-line-number="42"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb102-43" data-line-number="43"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-44" data-line-number="44"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-45" data-line-number="45"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-46" data-line-number="46"><span class="co">#&gt;  Elapsed Time: 1.15877 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb102-47" data-line-number="47"><span class="co">#&gt;                1.16426 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb102-48" data-line-number="48"><span class="co">#&gt;                2.32303 seconds (Total)</span></a>
<a class="sourceLine" id="cb102-49" data-line-number="49"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-50" data-line-number="50"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-51" data-line-number="51"><span class="co">#&gt; Gradient evaluation took 1.6e-05 seconds</span></a>
<a class="sourceLine" id="cb102-52" data-line-number="52"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.</span></a>
<a class="sourceLine" id="cb102-53" data-line-number="53"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb102-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-55" data-line-number="55"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-56" data-line-number="56"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb102-57" data-line-number="57"><span class="co">#&gt;  Elapsed Time: 0.90871 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb102-58" data-line-number="58"><span class="co">#&gt;                0.473369 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb102-59" data-line-number="59"><span class="co">#&gt;                1.38208 seconds (Total)</span></a>
<a class="sourceLine" id="cb102-60" data-line-number="60"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 4</span></a>
<a class="sourceLine" id="cb102-61" data-line-number="61"><span class="co">#&gt;                                                                          count</span></a>
<a class="sourceLine" id="cb102-62" data-line-number="62"><span class="co">#&gt; Exception thrown at line 39: multiply: B[1] is nan, but must not be nan!     1</span></a>
<a class="sourceLine" id="cb102-63" data-line-number="63"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb102-64" data-line-number="64"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb102-65" data-line-number="65"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a></code></pre></div>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" data-line-number="1"><span class="kw">summary</span>(fit_hs, <span class="st">&quot;tau&quot;</span>)<span class="op">$</span>summary</a>
<a class="sourceLine" id="cb103-2" data-line-number="2"><span class="co">#&gt;      mean se_mean    sd   2.5%   25%  50%   75% 97.5% n_eff Rhat</span></a>
<a class="sourceLine" id="cb103-3" data-line-number="3"><span class="co">#&gt; tau 0.298 0.00459 0.223 0.0361 0.147 0.24 0.382 0.885  2359    1</span></a></code></pre></div>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1"><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit_hs))</a>
<a class="sourceLine" id="cb104-2" data-line-number="2"><span class="co">#&gt; Computed from 4000 by 97 log-likelihood matrix</span></a>
<a class="sourceLine" id="cb104-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb104-4" data-line-number="4"><span class="co">#&gt;          Estimate  SE</span></a>
<a class="sourceLine" id="cb104-5" data-line-number="5"><span class="co">#&gt; elpd_loo   -234.5 3.0</span></a>
<a class="sourceLine" id="cb104-6" data-line-number="6"><span class="co">#&gt; p_loo         3.7 0.4</span></a>
<a class="sourceLine" id="cb104-7" data-line-number="7"><span class="co">#&gt; looic       469.0 5.9</span></a>
<a class="sourceLine" id="cb104-8" data-line-number="8"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb104-9" data-line-number="9"><span class="co">#&gt; All Pareto k estimates are good (k &lt; 0.5)</span></a>
<a class="sourceLine" id="cb104-10" data-line-number="10"><span class="co">#&gt; See help(&#39;pareto-k-diagnostic&#39;) for details.</span></a></code></pre></div>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_hs), <span class="st">&quot;tau&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-41-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" data-line-number="1"><span class="kw">mcmc_dens</span>(<span class="kw">as.array</span>(fit_hs), <span class="dt">regex_pars =</span> <span class="st">&quot;^b</span><span class="ch">\\</span><span class="st">[</span><span class="ch">\\</span><span class="st">d+</span><span class="ch">\\</span><span class="st">]$&quot;</span>)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-42-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" data-line-number="1">mod_lm_coef_hs_<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/lm-coef-hs-3.stan&quot;</span>)</a>
<a class="sourceLine" id="cb107-2" data-line-number="2"><span class="co">#&gt; In file included from file278473f93038.cpp:8:</span></a>
<a class="sourceLine" id="cb107-3" data-line-number="3"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb107-4" data-line-number="4"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb107-5" data-line-number="5"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb107-6" data-line-number="6"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:12:</span></a>
<a class="sourceLine" id="cb107-7" data-line-number="7"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/gevv_vvv_vari.hpp:5:</span></a>
<a class="sourceLine" id="cb107-8" data-line-number="8"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/var.hpp:7:</span></a>
<a class="sourceLine" id="cb107-9" data-line-number="9"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/math/tools/config.hpp:13:</span></a>
<a class="sourceLine" id="cb107-10" data-line-number="10"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/config.hpp:39:</span></a>
<a class="sourceLine" id="cb107-11" data-line-number="11"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/config/compiler/clang.hpp:196:11: warning: &#39;BOOST_NO_CXX11_RVALUE_REFERENCES&#39; macro redefined [-Wmacro-redefined]</span></a>
<a class="sourceLine" id="cb107-12" data-line-number="12"><span class="co">#&gt; #  define BOOST_NO_CXX11_RVALUE_REFERENCES</span></a>
<a class="sourceLine" id="cb107-13" data-line-number="13"><span class="co">#&gt;           ^</span></a>
<a class="sourceLine" id="cb107-14" data-line-number="14"><span class="co">#&gt; &lt;command line&gt;:6:9: note: previous definition is here</span></a>
<a class="sourceLine" id="cb107-15" data-line-number="15"><span class="co">#&gt; #define BOOST_NO_CXX11_RVALUE_REFERENCES 1</span></a>
<a class="sourceLine" id="cb107-16" data-line-number="16"><span class="co">#&gt;         ^</span></a>
<a class="sourceLine" id="cb107-17" data-line-number="17"><span class="co">#&gt; In file included from file278473f93038.cpp:8:</span></a>
<a class="sourceLine" id="cb107-18" data-line-number="18"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb107-19" data-line-number="19"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb107-20" data-line-number="20"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb107-21" data-line-number="21"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:42:</span></a>
<a class="sourceLine" id="cb107-22" data-line-number="22"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints.hpp:14:17: warning: unused function &#39;set_zero_all_adjoints&#39; [-Wunused-function]</span></a>
<a class="sourceLine" id="cb107-23" data-line-number="23"><span class="co">#&gt;     static void set_zero_all_adjoints() {</span></a>
<a class="sourceLine" id="cb107-24" data-line-number="24"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb107-25" data-line-number="25"><span class="co">#&gt; In file included from file278473f93038.cpp:8:</span></a>
<a class="sourceLine" id="cb107-26" data-line-number="26"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb107-27" data-line-number="27"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb107-28" data-line-number="28"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:4:</span></a>
<a class="sourceLine" id="cb107-29" data-line-number="29"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core.hpp:43:</span></a>
<a class="sourceLine" id="cb107-30" data-line-number="30"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/core/set_zero_all_adjoints_nested.hpp:17:17: warning: &#39;static&#39; function &#39;set_zero_all_adjoints_nested&#39; declared in header file should be declared &#39;static inline&#39; [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb107-31" data-line-number="31"><span class="co">#&gt;     static void set_zero_all_adjoints_nested() {</span></a>
<a class="sourceLine" id="cb107-32" data-line-number="32"><span class="co">#&gt;                 ^</span></a>
<a class="sourceLine" id="cb107-33" data-line-number="33"><span class="co">#&gt; In file included from file278473f93038.cpp:8:</span></a>
<a class="sourceLine" id="cb107-34" data-line-number="34"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb107-35" data-line-number="35"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb107-36" data-line-number="36"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb107-37" data-line-number="37"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:59:</span></a>
<a class="sourceLine" id="cb107-38" data-line-number="38"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat/fun/autocorrelation.hpp:17:14: warning: function &#39;fft_next_good_size&#39; is not needed and will not be emitted [-Wunneeded-internal-declaration]</span></a>
<a class="sourceLine" id="cb107-39" data-line-number="39"><span class="co">#&gt;       size_t fft_next_good_size(size_t N) {</span></a>
<a class="sourceLine" id="cb107-40" data-line-number="40"><span class="co">#&gt;              ^</span></a>
<a class="sourceLine" id="cb107-41" data-line-number="41"><span class="co">#&gt; In file included from file278473f93038.cpp:8:</span></a>
<a class="sourceLine" id="cb107-42" data-line-number="42"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/src/stan/model/model_header.hpp:4:</span></a>
<a class="sourceLine" id="cb107-43" data-line-number="43"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math.hpp:4:</span></a>
<a class="sourceLine" id="cb107-44" data-line-number="44"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/rev/mat.hpp:11:</span></a>
<a class="sourceLine" id="cb107-45" data-line-number="45"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/mat.hpp:298:</span></a>
<a class="sourceLine" id="cb107-46" data-line-number="46"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr.hpp:39:</span></a>
<a class="sourceLine" id="cb107-47" data-line-number="47"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/StanHeaders/include/stan/math/prim/arr/functor/integrate_ode_rk45.hpp:13:</span></a>
<a class="sourceLine" id="cb107-48" data-line-number="48"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint.hpp:61:</span></a>
<a class="sourceLine" id="cb107-49" data-line-number="49"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/numeric/odeint/util/multi_array_adaption.hpp:29:</span></a>
<a class="sourceLine" id="cb107-50" data-line-number="50"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array.hpp:21:</span></a>
<a class="sourceLine" id="cb107-51" data-line-number="51"><span class="co">#&gt; In file included from /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/base.hpp:28:</span></a>
<a class="sourceLine" id="cb107-52" data-line-number="52"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:42:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb107-53" data-line-number="53"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb107-54" data-line-number="54"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb107-55" data-line-number="55"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:43:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb107-56" data-line-number="56"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb107-57" data-line-number="57"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb107-58" data-line-number="58"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:53:43: warning: unused typedef &#39;index_range&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb107-59" data-line-number="59"><span class="co">#&gt;       typedef typename Array::index_range index_range;</span></a>
<a class="sourceLine" id="cb107-60" data-line-number="60"><span class="co">#&gt;                                           ^</span></a>
<a class="sourceLine" id="cb107-61" data-line-number="61"><span class="co">#&gt; /Users/jrnold/Library/R/3.4/library/BH/include/boost/multi_array/concept_checks.hpp:54:37: warning: unused typedef &#39;index&#39; [-Wunused-local-typedef]</span></a>
<a class="sourceLine" id="cb107-62" data-line-number="62"><span class="co">#&gt;       typedef typename Array::index index;</span></a>
<a class="sourceLine" id="cb107-63" data-line-number="63"><span class="co">#&gt;                                     ^</span></a>
<a class="sourceLine" id="cb107-64" data-line-number="64"><span class="co">#&gt; 8 warnings generated.</span></a></code></pre></div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1">fit_hs3 &lt;-<span class="st"> </span><span class="kw">sampling</span>(mod_lm_coef_hs_<span class="dv">3</span>,</a>
<a class="sourceLine" id="cb108-2" data-line-number="2">                    <span class="dt">refresh =</span> <span class="dv">-1</span>,</a>
<a class="sourceLine" id="cb108-3" data-line-number="3">                    <span class="dt">data =</span> <span class="kw">c</span>(prostate_data, <span class="kw">list</span>(<span class="dt">df_local =</span> <span class="dv">3</span>, <span class="dt">df_global =</span> <span class="dv">3</span>, <span class="dt">p0 =</span> <span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb108-4" data-line-number="4">                    <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.995</span>))</a>
<a class="sourceLine" id="cb108-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-6" data-line-number="6"><span class="co">#&gt; Gradient evaluation took 3.8e-05 seconds</span></a>
<a class="sourceLine" id="cb108-7" data-line-number="7"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.38 seconds.</span></a>
<a class="sourceLine" id="cb108-8" data-line-number="8"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb108-9" data-line-number="9"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-10" data-line-number="10"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-12" data-line-number="12"><span class="co">#&gt;  Elapsed Time: 7.08115 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb108-13" data-line-number="13"><span class="co">#&gt;                9.70287 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb108-14" data-line-number="14"><span class="co">#&gt;                16.784 seconds (Total)</span></a>
<a class="sourceLine" id="cb108-15" data-line-number="15"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 1</span></a>
<a class="sourceLine" id="cb108-16" data-line-number="16"><span class="co">#&gt;                                                                                          count</span></a>
<a class="sourceLine" id="cb108-17" data-line-number="17"><span class="co">#&gt; Exception thrown at line 51: student_t_lpdf: Scale parameter is inf, but must be finite!     4</span></a>
<a class="sourceLine" id="cb108-18" data-line-number="18"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb108-19" data-line-number="19"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb108-20" data-line-number="20"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb108-21" data-line-number="21"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-22" data-line-number="22"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb108-23" data-line-number="23"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb108-24" data-line-number="24"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb108-25" data-line-number="25"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-26" data-line-number="26"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-27" data-line-number="27"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-28" data-line-number="28"><span class="co">#&gt;  Elapsed Time: 5.45486 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb108-29" data-line-number="29"><span class="co">#&gt;                9.76004 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb108-30" data-line-number="30"><span class="co">#&gt;                15.2149 seconds (Total)</span></a>
<a class="sourceLine" id="cb108-31" data-line-number="31"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-32" data-line-number="32"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-33" data-line-number="33"><span class="co">#&gt; Gradient evaluation took 1.9e-05 seconds</span></a>
<a class="sourceLine" id="cb108-34" data-line-number="34"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.19 seconds.</span></a>
<a class="sourceLine" id="cb108-35" data-line-number="35"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb108-36" data-line-number="36"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-38" data-line-number="38"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-39" data-line-number="39"><span class="co">#&gt;  Elapsed Time: 9.2612 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb108-40" data-line-number="40"><span class="co">#&gt;                9.87074 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb108-41" data-line-number="41"><span class="co">#&gt;                19.1319 seconds (Total)</span></a>
<a class="sourceLine" id="cb108-42" data-line-number="42"><span class="co">#&gt; The following numerical problems occurred the indicated number of times on chain 3</span></a>
<a class="sourceLine" id="cb108-43" data-line-number="43"><span class="co">#&gt;                                                                                          count</span></a>
<a class="sourceLine" id="cb108-44" data-line-number="44"><span class="co">#&gt; Exception thrown at line 44: multiply: B[1] is nan, but must not be nan!                     1</span></a>
<a class="sourceLine" id="cb108-45" data-line-number="45"><span class="co">#&gt; Exception thrown at line 51: student_t_lpdf: Scale parameter is inf, but must be finite!     1</span></a>
<a class="sourceLine" id="cb108-46" data-line-number="46"><span class="co">#&gt; When a numerical problem occurs, the Hamiltonian proposal gets rejected.</span></a>
<a class="sourceLine" id="cb108-47" data-line-number="47"><span class="co">#&gt; See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected</span></a>
<a class="sourceLine" id="cb108-48" data-line-number="48"><span class="co">#&gt; If the number in the &#39;count&#39; column is small, there is no need to ask about this message on stan-users.</span></a>
<a class="sourceLine" id="cb108-49" data-line-number="49"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-50" data-line-number="50"><span class="co">#&gt; Gradient evaluation took 2.1e-05 seconds</span></a>
<a class="sourceLine" id="cb108-51" data-line-number="51"><span class="co">#&gt; 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.</span></a>
<a class="sourceLine" id="cb108-52" data-line-number="52"><span class="co">#&gt; Adjust your expectations accordingly!</span></a>
<a class="sourceLine" id="cb108-53" data-line-number="53"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-54" data-line-number="54"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-55" data-line-number="55"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb108-56" data-line-number="56"><span class="co">#&gt;  Elapsed Time: 2.91756 seconds (Warm-up)</span></a>
<a class="sourceLine" id="cb108-57" data-line-number="57"><span class="co">#&gt;                5.69903 seconds (Sampling)</span></a>
<a class="sourceLine" id="cb108-58" data-line-number="58"><span class="co">#&gt;                8.61659 seconds (Total)</span></a>
<a class="sourceLine" id="cb108-59" data-line-number="59"><span class="co">#&gt; Warning: There were 531 divergent transitions after warmup. Increasing adapt_delta above 0.995 may help. See</span></a>
<a class="sourceLine" id="cb108-60" data-line-number="60"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</span></a>
<a class="sourceLine" id="cb108-61" data-line-number="61"><span class="co">#&gt; Warning: There were 3342 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See</span></a>
<a class="sourceLine" id="cb108-62" data-line-number="62"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded</span></a>
<a class="sourceLine" id="cb108-63" data-line-number="63"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a></code></pre></div>
</div>
<div id="comparison" class="section level3">
<h3><span class="header-section-number">12.6.3</span> Comparison</h3>
<p>Let’s compare the various coefficient paths:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" data-line-number="1">all_coefpaths &lt;-</a>
<a class="sourceLine" id="cb109-2" data-line-number="2"><span class="st">  </span><span class="kw">bind_rows</span>(<span class="kw">mutate</span>(<span class="kw">map_df</span>(coefpath_normal, <span class="st">&quot;summary&quot;</span>), <span class="dt">model =</span> <span class="st">&quot;normal&quot;</span>),</a>
<a class="sourceLine" id="cb109-3" data-line-number="3">          <span class="kw">mutate</span>(<span class="kw">map_df</span>(coefpath_lasso, <span class="st">&quot;summary&quot;</span>), <span class="dt">model =</span> <span class="st">&quot;lasso&quot;</span>),</a>
<a class="sourceLine" id="cb109-4" data-line-number="4">          <span class="kw">mutate</span>(<span class="kw">map_df</span>(coefpath_hs, <span class="st">&quot;summary&quot;</span>), <span class="dt">model =</span> <span class="st">&quot;hs&quot;</span>))</a>
<a class="sourceLine" id="cb109-5" data-line-number="5"><span class="kw">ggplot</span>(all_coefpaths, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log2</span>(tau), <span class="dt">y =</span> mean, <span class="dt">colour =</span> model)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb109-6" data-line-number="6"><span class="st">  </span>modelr<span class="op">::</span><span class="kw">geom_ref_line</span>(<span class="dt">h =</span> <span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb109-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb109-8" data-line-number="8"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>parameter)</a></code></pre></div>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-45-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="shrinkage-parameters" class="section level2">
<h2><span class="header-section-number">12.7</span> Shrinkage Parameters</h2>
<p>Given the linear Gaussian regression model
<span class="math display">\[
y_i \sim \dnorm(\vec{\beta}\T \vec{x}, \sigma^2)
\]</span>
for <span class="math inline">\(i = 1, \dots, n\)</span>, where <span class="math inline">\(\vec{x}\)</span> is the <span class="math inline">\(K\)</span> dimensional vector of predictors.
Suppose a prior
<span class="math display">\[
\begin{aligned}[t]
\beta_j | \lambda_j, \tau &amp;\sim \dnorm(0, \lambda_j^2 \tau^2)
\end{aligned}
\]</span>
The <span class="math inline">\(\lambda_j\)</span> are local scales - it allows some weights to escape the shrinkage.
The global parameter <span class="math inline">\(\tau\)</span> pulls all weights towards zero, and effectively controls the sparsity.</p>
<p>The posterior distribution is
<span class="math display">\[
\begin{aligned}[t]
p(\vec{\beta} | \mat{\Lambda}, \tau, \sigma^2, \mat{X}, \vec{y}) &amp;= \dnorm(\vec{\beta}, \bar{\vec{\beta}}, \mat{\Sigma}) \\
\bar{\vec{\beta}} &amp;= \tau^2 \mat{\Lambda}(\tau^2 \mat{\Lambda} + \sigma^2 (\mat{X}\T \mat{X})^{-1})^{-1} \hat{\vec{\beta}} \\
\mat{\Sigma} &amp;= (\tau^{-2} \mat{\Lambda}^{-1} + \frac{1}{\sigma^2} \mat{X}\T \mat{X})^{-1},
\end{aligned}
\]</span>
where
<span class="math display">\[
\mat{\Lambda} = \diag(\lambda_1^2, \dots, \lambda_K^2) 
\]</span>
and
<span class="math display">\[
\hat{\vec{\beta}} = (\mat{X}\T \mat{X})^{-1} \mat{X}\T \vec{y}
\]</span>
is the MLE solution if <span class="math inline">\((\mat{X}\T \mat{X})^{-1}\)</span> exists.</p>
<p>It the predictors are uncorrelated with zero mean and unit variance, then <span class="math inline">\(\mat{X}\T \mat{X} \approx n \mat{I}\)</span>, and approximate
<span class="math display">\[
\bar{\beta}_j = (1 - \kappa_j) \hat{\beta}_j
\]</span>
where <span class="math inline">\(\kappa_j\)</span> is the shrinkage factor for coefficient <span class="math inline">\(j\)</span>,
<span class="math display">\[
\kappa_j = \frac{1}{1 + n \sigma^{-2} \tau^2 \lambda^2_j}
\]</span>
When <span class="math inline">\(\kappa = 1\)</span>, it is complete shrinkage, and the coefficient is zero.
When <span class="math inline">\(\kappa = 0\)</span>, then there is no shrinkage, and the coefficient is equal to the MLE solution.
As <span class="math inline">\(\tau \to 0\)</span>, then <span class="math inline">\(\bar{\beta} \to 0\)</span>, and as <span class="math inline">\(\tau \to \infty\)</span>, then <span class="math inline">\(\bar{\beta} \to \hat{\beta}\)</span>.</p>
<p><img src="shrinkage_files/figure-html/unnamed-chunk-46-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Note that for these distributions:</p>
<ul>
<li>Normal: prior puts weight only on a single point</li>
<li>HS for df = 0: prior on shrinkage parameter puts weight on either completely shrunk (<span class="math inline">\(\kappa = 1\)</span>) or unshrunk (<span class="math inline">\(\kappa = 0\)</span>)</li>
<li>HS for df = 3: prior on shrinkage parameter puts a lo of weight on it being completely shrunk (<span class="math inline">\(\kappa = 1\)</span>), but truncates the density for completely unshrunk.</li>
</ul>
</div>
<div id="choice-of-hyperparameter-on-tau" class="section level2">
<h2><span class="header-section-number">12.8</span> Choice of Hyperparameter on <span class="math inline">\(\tau\)</span></h2>
<p>The value of <span class="math inline">\(\tau\)</span> and the choice of its hyper-parameter has a big influence on the sparsity of the coefficients.</p>
<p><span class="citation">Carvalho, Polson, and Scott (2009)</span> suggest
<span class="math display">\[
\tau \sim \dhalfcauchy(0, \sigma),
\]</span>
while <span class="citation">Polson and Scott (2011)</span> suggest,
<span class="math display">\[
\tau \sim \dhalfcauchy(0, 1) .
\]</span></p>
<p><span class="citation">Pas, Kleijn, and Vaart (2014)</span> suggest
<span class="math display">\[
\tau \sim \dhalfcauchy(0, p^* / n)
\]</span>
where <span class="math inline">\(p^*\)</span> is the true number of non-zero parameters,
and <span class="math inline">\(n\)</span> is the number of observations.
They suggest <span class="math inline">\(\tau = p^* / n\)</span> or <span class="math inline">\(\tau p^* / n \sqrt{log(n / p^*)}\)</span>.
Additionally, they suggest restricting <span class="math inline">\(\tau\)</span> to <span class="math inline">\([0, 1]\)</span>.</p>
<p><span class="citation">Piironen and Vehtari (2016b)</span> understand the choice of the prior on <span class="math inline">\(\tau\)</span> as the implied prior on the number of effective parameters.
The shrinkage can be understood as its influence on the number of effective parameters, <span class="math inline">\(m_{eff}\)</span>,
<span class="math display">\[
m_{eff} = \sum_{j = 1}^K (1 - \kappa_j) .
\]</span>
This is a measure of effective model size.</p>
<p>The mean and variance of <span class="math inline">\(m_{eff}\)</span> given <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\sigma\)</span> are,
<span class="math display">\[
\begin{aligned}[t]
\E[m_{eff} | \tau, \sigma] &amp;= \frac{\sigma^{-1} \tau \sqrt{n}}{1 + \sigma^{-1} \tau \sqrt{n}} K , \\
\Var[m_{eff} | \tau, \sigma] &amp;= \frac{\sigma^{-1} \tau \sqrt{n}}{2 (1 + \sigma^{-1} \tau \sqrt{n})2} K .
\end{aligned}
\]</span></p>
<p>Based on this, a prior should be chosen so that the prior mass is located near,
<span class="math display">\[
\tau_0 = \frac{p_0}{K - p_0}\frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>Densities of the shrinkage parameter, <span class="math inline">\(\kappa\)</span>, for various shrinkage distributions where <span class="math inline">\(\sigma^2 = 1\)</span>, <span class="math inline">\(\tau = 1\)</span>, for <span class="math inline">\(n = 1\)</span>.</p>
<p><span class="citation">Datta and Ghosh (2013)</span> warn against empirical Bayes estimators of <span class="math inline">\(\tau\)</span> for the horseshoe prior as it can collapse to 0.
<span class="citation">Scott and Berger (2010)</span> consider marginal maximum likelihood estimates of <span class="math inline">\(\tau\)</span>.
<span class="citation">Pas, Kleijn, and Vaart (2014)</span> suggest that an empirical Bayes estimator truncated below at <span class="math inline">\(1 / n\)</span>.</p>
</div>
<div id="r-implementations" class="section level2">
<h2><span class="header-section-number">12.9</span> R Implementations</h2>
<p>See</p>
<ul>
<li><strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong>: estimates GLM regressions with various priors</li>
<li><strong><a href="https://cran.r-project.org/package=rmonomvn">rmonomvn</a></strong>: estimates Bayesian ridge, lasso, horseshoe, and ridge regression.</li>
<li><strong><a href="https://cran.r-project.org/package=bayesreg">bayesreg</a></strong>: See <span class="citation">Makalic and Schmidt (2016)</span> for documentation and a good review of Bayesian regularized regression.</li>
<li><a href="http://jingyuhe.com/fastHorseshoe.html">fastHorseshoe</a></li>
</ul>
</div>
<div id="bayesian-model-averaging" class="section level2">
<h2><span class="header-section-number">12.10</span> Bayesian Model Averaging</h2>
<p><em>Bayesian model averaging (BMA)</em> is method that calculates a posterior distribution of parameters by averaging over a discrete set of models, weighting them by their model evidence.</p>
<p>Suppose there are <span class="math inline">\(K\)</span> models, <span class="math inline">\(M_k\)</span>, <span class="math inline">\(k = 1, \dots, K\)</span> with the likelihood function <span class="math inline">\(L(y | \theta_k, M_k)\)</span> for observed data <span class="math inline">\(y\)</span>.
The posterior distribution of parameters <span class="math inline">\(\theta\)</span>, conditional on each model is,
<span class="math display">\[
p(\theta_k | y, M_k) = \frac{L(y | \theta_k | M_k) p(\theta_k | M_k)}{\int L(y | \theta_k, M_k) p(\theta_k | M_k) d\,\theta_k}
\]</span></p>
<p>The essential quality for BMA applications is the denominator of this equation is the the <em>marginal likelihood</em> or <em>model evidence</em>,
<span class="math display">\[
p(y | M_k) = \int L(y | \theta_k, M_k) p(\theta_k | M_k) d\,\theta_k .
\]</span></p>
<p>From this, derive the posterior probability of models given the data,
<span class="math display">\[
p(M_k | y) = \frac{p(y | M_k) p(M_k)}{\sum_{m = 1}^K p(y | M_m) p(M_m)}
\]</span>
The posterior probability of a model requires specifying a prior <span class="math inline">\(p(M_k)\)</span> for each model.</p>
<p>Bayes Factors can be used to calculate model probabilities for BMA and vice-versa.
The Bayes Factor for models <span class="math inline">\(l\)</span> and <span class="math inline">\(m\)</span> is
<span class="math display">\[
BF_{lm} = \frac{p(M_l | y)}{p(M_m | y)} .
\]</span>
Given a baseline model, <span class="math inline">\(M_1\)</span>, the model evidence can be written in terms of Bayes Factors relative to that model,
<span class="math display">\[
p(M_l|y) = \frac{BF_{1l} p(M_l)}{\sum_{m = 1}^K BF_{m1} p(M_m)} .
\]</span></p>
<p><strong>marginal probabilities of a parameter:</strong> The marginal probability of a parameter (<span class="math inline">\(\theta\)</span>), averaged across all models is,
<span class="math display">\[
p(\theta | y) = \sum_{k = 1}^K p(\theta | y, M_k) p(M_k | y) .
\]</span>
The posterior distribution of <span class="math inline">\(\Delta\)</span> averaged across all models is the average of <span class="math inline">\(\Delta\)</span> weighted by each posterior model probability.
The mean and variance of the posterior models are,
<span class="math display">\[
\begin{aligned}[t]
\E[\theta | y] &amp;= \sum_{k = 1}^K \bar{\theta} p(M_k | y) \\
\Var[\theta | y] &amp;= \sum_{k = 1}^K 
(\Var(\theta | y, M_k) + \bar{\theta}_k^2) p(M_k | y) - \E(\theta | y)^2
\end{aligned}
\]</span></p>
<p>Why is BMA difficult?</p>
<ul>
<li>The posterior is sensitive to the model prior, <span class="math inline">\(p(M_k)\)</span>.</li>
<li>Calculating the model evidence, <span class="math inline">\(p(y | M_k)\)</span>, is computationally difficult, except in special cases</li>
<li>The model space can be very large. In regression, it is <span class="math inline">\(2^K\)</span>. This means that it may be impossible to compute model probabilities for the full set of models. Thus, it may require sampling from the (discrete) model space.</li>
</ul>
<p>Uses of BMA:</p>
<ol style="list-style-type: decimal">
<li>model selection or choice: select the most likely model</li>
<li>average posterior estimates</li>
<li>average prediction. Generally predictions from models using BMA have lower risk (Raftery)</li>
</ol>
<p>For the common case of linear regression,
<span class="math display">\[
\begin{aligned}[t]
y &amp;= \alpha + X \beta + \epsilon &amp; \epsilon &amp;\sim \dnorm(0, \sigma^2 I)
\end{aligned}
\]</span>
where <span class="math inline">\(X\)</span> is a <span class="math inline">\(N \times K\)</span> matrix and <span class="math inline">\(\beta\)</span> is a <span class="math inline">\(K \times 1\)</span> vector.
The model selection problem in this case is the choice of the <span class="math inline">\(K\)</span> variables to include in the regression model.
Thus, there are <span class="math inline">\(2^K\)</span> models to consider.
Very quickly,</p>
<p>See <span class="citation">Fragoso and Neto (2015)</span> for a recent review. See <span class="citation">Volinsky et al. (1999)</span> for an earlier review.</p>
<p>There are several R packages that implement BMA. See <span class="citation">Amini Shahram and Parmeter Christopher (2011)</span> for a review of R packages.</p>
<ul>
<li><strong><a href="https://cran.r-project.org/package=BAS">BAS</a></strong> See its vignette <span class="citation">Zeugner (2011)</span>.</li>
<li><strong><a href="https://cran.r-project.org/package=BMA">BMA</a></strong> See its vignette <span class="citation">Raftery et al. (2017)</span>.</li>
<li><strong><a href="https://cran.r-project.org/package=BMS">BMS</a></strong> See its vignette <span class="citation">Clyde (2017)</span>.</li>
<li><strong><a href="https://cran.r-project.org/package=ensembleBMA">ensembleBMA</a></strong> uses <em>BMA</em> to generates ensemble BMA forecasts</li>
</ul>
<div id="zellners-g-prior" class="section level3">
<h3><span class="header-section-number">12.10.1</span> Zellner’s g-prior</h3>
<p>An alternative prior is the Zellner’s g-prior.
Consider the regression,
<span class="math display">\[
y_i | \alpha, \vec{\beta}, \sigma \sim \dnorm(\alpha + \mat{X} \vec{\beta}, \sigma^2)
\]</span>
The <span class="math inline">\(g\)</span>-prior is a non-informative, data-dependent prior,
<span class="math display">\[
\vec{\beta} \sim \dnorm(0, \sigma^2 g \mat{X}\T \mat{X})
\]</span>
It depends on only a single parameter <span class="math inline">\(g\)</span>.
The prior for <span class="math inline">\(g\)</span> must be proper. Some common choices include,
<span class="math display">\[
\begin{aligned}
g &amp;= n \\
g &amp;= k^2 \\
g &amp;= \max(n, k^2)
\end{aligned}
\]</span>
or putting a hyperprior on <span class="math inline">\(g\)</span>.</p>
<p>See <span class="citation">Ley and Steel (2012)</span> for a recent overview of g-priors.</p>
</div>
</div>
<div id="slab-and-spike-priors" class="section level2">
<h2><span class="header-section-number">12.11</span> Slab and Spike Priors</h2>
<p>In the case of the linear regression, an alternative to BMA is to use a spike-and-slab prior <span class="citation">(Mitchell and Beauchamp 1988, <span class="citation">@GeorgeMcCulloch1993a</span>, <span class="citation">@IshwaranRao2005a</span>)</span>, which is a prior that is a discrete mixture of a point mass at 0 and a non-informative distribution. The weight over these who alternatives is similar to a</p>
<p>The spike and slab prior is a “two-group” solution</p>
<p><span class="math display">\[
p(\beta_k) = (1 - w) \delta_0 + w \pi(\beta_k)
\]</span>
where <span class="math inline">\(\delta_0\)</span> is a Dirac delta function putting a point mass at 0, and <span class="math inline">\(\pi(\beta_k)\)</span> is an uninformative distribution, e.g. <span class="math inline">\(\pi(\beta_k) = \dnorm(\beta_k | 0, \sigma^2)\)</span> where <span class="math inline">\(\sigma\)</span> is large.</p>
<p>The posterior distribution of <span class="math inline">\(w\)</span> is the probability that <span class="math inline">\(\beta_k \neq 0\)</span>, and the conditional posterior distribution <span class="math inline">\(p(\beta_k | y, w = 1)\)</span> is the distribution of <span class="math inline">\(\beta_k\)</span> given that <span class="math inline">\(\beta_k \neq 0\)</span>.</p>
<p>See the R package <strong><a href="https://cran.r-project.org/package=spikeslab">spikeslab</a></strong> and he accompanying article <span class="citation">(Ishwaran, Kogalur, and Rao 2010)</span> for an implementation and review of spike-and-slab regressions.</p>
</div>
<div id="technical-notes" class="section level2">
<h2><span class="header-section-number">12.12</span> Technical Notes</h2>
<p>Marginal density of the horseshoe+ prior <span class="citation">Carvalho, Polson, and Scott (2010)</span> has no closed form but some bounds
are available.
If <span class="math inline">\(\tau^2 = 1\)</span>, then the marginal density of the horseshoe+ prior has the following properties:
<span class="math display">\[
\begin{aligned}[t]
\frac{K}{2} \log \left(1 + \frac{4}{\theta^2} \right) &lt; p_{HS}(\theta) \leq K \log \left(1 + \frac{2}{\theta^2} \right) \\
\lim_{|\theta| \to 0} p_{HS}(\theta) = \infty
\end{aligned}
\]</span>
where <span class="math inline">\(K = 1 / \sqrt{2 \pi^3}\)</span>.</p>
<p>Marginal density of the horseshoe+ prior <span class="citation">Bhadra et al. (2015)</span>:
If <span class="math inline">\(\tau^2 = 1\)</span>, then the marginal density of the horseshoe+ prior has the following properties:
<span class="math display">\[
\begin{aligned}[t]
\frac{1}{\pi^2 \sqrt{2 \pi}} \log \left(1 + \frac{4}{\theta^2} \right) &lt; p_{HS+}(\theta) \leq \frac{1}{\pi^2 |\theta|} \\
\lim_{|\theta| \to 0} p_{HS+}(\theta) = \infty
\end{aligned}
\]</span></p>
<p><strong>rstanarm</strong> uses a slightly different parameterization for the Bayeian lasso<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>
<span class="math display">\[
\begin{aligned}[t]
\beta_k &amp;\sim b + s \frac{1}{\lambda} \sqrt{2 \omega} \beta_k^*  \\
\frac{1}{\lambda} &amp;\sim \dchisq(df) \\
\omega &amp;\sim \dexp(1) \\
\beta^*_k &amp;\sim \dnorm(0, 1)
\end{aligned}
\]</span>
Apart from the decomponsition into a scale-location family, this is simply putting a <span class="math inline">\(\chi^2\)</span> prior on the penalization parameter, <span class="math inline">\(\frac{1}{\lambda}\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="left">Prior for <span class="math inline">\(\theta_i\)</span></th>
<th align="left">Density for <span class="math inline">\(\lambda_i\)</span></th>
<th align="left">Density for <span class="math inline">\(\kappa_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Double-exponential</td>
<td align="left">$_i (_i^2 / 2)</td>
<td align="left"><span class="math inline">\(\kappa_i^{-2} \exp\left( \frac{- 1}{2 \kappa_i} \right)\)</span></td>
</tr>
<tr class="even">
<td align="left">Cauchy</td>
<td align="left"><span class="math inline">\(\lambda_i^{-2} \exp(-1 / \lambda_i^2)\)</span></td>
<td align="left"><span class="math inline">\(\kappa_i^{-\frac{1}{2}} (1 - \kappa_i)^{- \frac{3}{2}} \exp \left(\frac{\kappa_i}{2 (1 - \kappa_i)}\right)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Strawderman-Berger</td>
<td align="left"><span class="math inline">\(\lambda_i (1 + \lambda_i^2)^{-\frac{3}{2}}\)</span></td>
<td align="left"><span class="math inline">\(\kappa_i^{-\frac{1}{2}}\)</span></td>
</tr>
<tr class="even">
<td align="left">Normal-exponential-gamma</td>
<td align="left"><span class="math inline">\(\lambda_i (1 + \lambda_i^2)^{-(c + 1)}\)</span></td>
<td align="left"><span class="math inline">\(\kappa_i^{c - 1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Normal-Jeffreys</td>
<td align="left"><span class="math inline">\(1 / \lambda_i\)</span></td>
<td align="left"><span class="math inline">\(\kappa_i^{-1} (1 - \kappa_i)^{-1}\)</span></td>
</tr>
<tr class="even">
<td align="left">Horseshoe</td>
<td align="left"><span class="math inline">\((1 + \lambda_i^2)^{-1}\)</span></td>
<td align="left"><span class="math inline">\(\kappa_i^{-1/2} (1 - \kappa_i)^{-1/2}\)</span></td>
</tr>
</tbody>
</table>
<p>Thresh-holding. The horseshoe has an implicit threshold of <span class="math inline">\(|T_\tau(y) - y| &lt; \sqrt{2 \sigma ^ 2 \log (1 / \tau))\)</span> <span class="citation">(Pas, Kleijn, and Vaart 2014)</span>.</p>
</div>
<div id="multiple-comparisons-and-thresholding-rules" class="section level2">
<h2><span class="header-section-number">12.13</span> Multiple Comparisons and Thresholding rules</h2>
<p>Multiple comparisons, family-wise error rate, and false discovery rates are frequentist
concepts. There are some attempts to bridge these two worlds - see Efron in particular. However, even if methodologically different, shrinkage addresses some of broadest
concerns about making multiple comparisons.</p>
<p>Although discussing hierarchical models, <span class="citation">Gelman, Hill, and Yajima (2012)</span> compares the shrinkage in hierarchical models to multiple comparisons, also see this <a href="http://andrewgelman.com/2013/08/20/correcting-for-multiple-comparisons-in-a-bayesian-regression-model/">post</a>.</p>
<p>Another (related) issue is sparsification. The decision rule as to whether a variable
is 0 (included), or not.</p>
<ul>
<li>The sparse-shrinkage priors from <span class="citation">Carvalho, Polson, and Scott (2010)</span> are motivated by a two-group
model (either <span class="math inline">\(\beta = 0\)</span> or <span class="math inline">\(\beta \neq 0\)</span>). They suggest a decision rule of considering
<span class="math inline">\(\beta \neq 0\)</span> when <span class="math inline">\(E(\kappa_j) &lt; 0.5\)</span> where <span class="math inline">\(\kappa_j\)</span> is a shrinkage parameter described in the paper.</li>
<li><span class="citation">Hahn and Carvalho (2015)</span> propose estimating the posterior distribution via shrinkage, and then summarizing the posterior distribution.</li>
<li><span class="citation">Piironen and Vehtari (2015)</span> propose something similar in spirit, in which a second step projects the initial shrinkage model to a sparse model</li>
</ul>
</div>
<div id="examples-of-applications-of-sensitivity-analysis" class="section level2">
<h2><span class="header-section-number">12.14</span> Examples of Applications of Sensitivity Analysis</h2>
<p>The memorably titled “Let’s Take the Con Out of Econometrics” <span class="citation">(Leamer 1983)</span> argues that economic models fail to account for model uncertainty. It prposes using an ensemble-like method called extreme-bounds. On economic growth: (confidence bounds) <span class="citation">Sala-I-Martin (1997)</span>, (Bayesian model averaging) <span class="citation">Fernández, Ley, and Steel (2001)</span>, <span class="citation">Ley and Steel (2009)</span>, <span class="citation">Eicher, Papageorgiou, and Raftery (2009)</span>, <span class="citation">Brock, Durlauf, and West (2003)</span>. Wars: <span class="citation">Hegre and Sambanis (2006)</span> use extreme bounds for civil war onset. <span class="citation">Ward, Greenhill, and Bakke (2010)</span> use model comparison and a step-wise method, but are focused on the difference between p-values and prediction; <span class="citation">Goenner (2004)</span> use BMA for inter-state wars (democratic peace). <span class="citation">Montgomery, Hollenbach, and Ward (2012)</span> and <span class="citation">Montgomery and Nyhan (2010)</span> apply BMA to multiple political science issues including voting, presidential elections, and civil war onset. <span class="citation">Tobias and Li (2004)</span> use BMA with returns to schooling. See <span class="citation">Fragoso and Neto (2015)</span> for a recent(ish) and comprehensive review of BMA applications across a variety of domains.</p>
<p>Also, not that many of these analyses are slightly older as empirical research in economics and political science has been moving to place less emphasis on model-based inference
(all-cause regressions) and more on design-based (causal) inference methods. As noted earlier, regularization techniques are also applicable in these cases, but is different.</p>
<p><strong>Variable selection:</strong> See <span class="citation">Piironen and Vehtari (2016a)</span> and <span class="citation">Bayarri et al. (2012)</span>.</p>
<!--chapter:end:shrinkage.Rmd-->
</div>
</div>
<div id="hierarchical-models" class="section level1">
<h1><span class="header-section-number">13</span> Hierarchical Models</h1>
<ul>
<li><em>Hierarchical models:</em> often groups of parameters, <span class="math inline">\(\{\theta_1, \dots, \theta_J\}\)</span>, are related.</li>
<li>E.g. countries, states, counties, years, etc. Even the regression coefficients, <span class="math inline">\(\beta_1, \dots, \beta_k\)</span> seen the in the <a href="#shrinkage-regularization">Shrinkage and Regularization</a> chapter.</li>
<li>We can treat those <span class="math inline">\(\theta_j\)</span> as drawn from a <em>population distribution</em>, <span class="math inline">\(\theta_j \sim p(\theta)\)</span>.</li>
<li>The prior distribution <span class="math inline">\(p(\theta)\)</span> is called a <em>hyperprior</em> and its parameters are <em>hyperparameters</em></li>
</ul>
<p><em>Exchangeability:</em></p>
<ul>
<li>parameters <span class="math inline">\((\theta_1, \dots, \theta_J)\)</span> are <em>exchangeable</em> if <span class="math inline">\(p(\theta_1, \dots, \theta_J)\)</span> don’t depend on the indexes.</li>
<li>i.i.d. models are a special case of exchangeability.</li>
</ul>
<div id="example-baseball-hits" class="section level2">
<h2><span class="header-section-number">13.1</span> Example: Baseball Hits</h2>
<p><span class="citation">Efron and Morris (1975)</span> analyzed data from 18 players in the 1970 season.
The goal was to predict the batting average of these 18 players from their first 45 at-bats for the remainder of the 1970 season.</p>
<p>The following example is based on <span class="citation">Carpenter, Gabry, and Goodrich (2017)</span> and the <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> vignette <a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/pooling.html">Hierarchical Partial Pooling for Repeated Binary Trials</a>.</p>
<p>The hitting data used in <span class="citation">Efron and Morris (1975)</span> is included in <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> as <a href="https://www.rdocumentation.org/packages/rstanarm/topics/bball1970">rstanarm</a>:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;bball1970&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rstanarm&quot;</span>)</a>
<a class="sourceLine" id="cb110-2" data-line-number="2">bball1970 &lt;-</a>
<a class="sourceLine" id="cb110-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(bball1970,</a>
<a class="sourceLine" id="cb110-4" data-line-number="4">         <span class="dt">BatAvg1 =</span> Hits <span class="op">/</span><span class="st"> </span>AB,</a>
<a class="sourceLine" id="cb110-5" data-line-number="5">         <span class="dt">BatAvg2 =</span> RemainingHits <span class="op">/</span><span class="st"> </span>RemainingAB)</a>
<a class="sourceLine" id="cb110-6" data-line-number="6">bball1970</a>
<a class="sourceLine" id="cb110-7" data-line-number="7"><span class="co">#&gt;        Player AB Hits RemainingAB RemainingHits BatAvg1 BatAvg2</span></a>
<a class="sourceLine" id="cb110-8" data-line-number="8"><span class="co">#&gt; 1    Clemente 45   18         367           127   0.400   0.346</span></a>
<a class="sourceLine" id="cb110-9" data-line-number="9"><span class="co">#&gt; 2    Robinson 45   17         426           127   0.378   0.298</span></a>
<a class="sourceLine" id="cb110-10" data-line-number="10"><span class="co">#&gt; 3      Howard 45   16         521           144   0.356   0.276</span></a>
<a class="sourceLine" id="cb110-11" data-line-number="11"><span class="co">#&gt; 4   Johnstone 45   15         275            61   0.333   0.222</span></a>
<a class="sourceLine" id="cb110-12" data-line-number="12"><span class="co">#&gt; 5       Berry 45   14         418           114   0.311   0.273</span></a>
<a class="sourceLine" id="cb110-13" data-line-number="13"><span class="co">#&gt; 6     Spencer 45   14         466           126   0.311   0.270</span></a>
<a class="sourceLine" id="cb110-14" data-line-number="14"><span class="co">#&gt; 7   Kessinger 45   13         586           155   0.289   0.265</span></a>
<a class="sourceLine" id="cb110-15" data-line-number="15"><span class="co">#&gt; 8    Alvarado 45   12         138            29   0.267   0.210</span></a>
<a class="sourceLine" id="cb110-16" data-line-number="16"><span class="co">#&gt; 9       Santo 45   11         510           137   0.244   0.269</span></a>
<a class="sourceLine" id="cb110-17" data-line-number="17"><span class="co">#&gt; 10    Swaboda 45   11         200            46   0.244   0.230</span></a>
<a class="sourceLine" id="cb110-18" data-line-number="18"><span class="co">#&gt; 11 Petrocelli 45   10         538           142   0.222   0.264</span></a>
<a class="sourceLine" id="cb110-19" data-line-number="19"><span class="co">#&gt; 12  Rodriguez 45   10         186            42   0.222   0.226</span></a>
<a class="sourceLine" id="cb110-20" data-line-number="20"><span class="co">#&gt; 13      Scott 45   10         435           132   0.222   0.303</span></a>
<a class="sourceLine" id="cb110-21" data-line-number="21"><span class="co">#&gt; 14      Unser 45   10         277            73   0.222   0.264</span></a>
<a class="sourceLine" id="cb110-22" data-line-number="22"><span class="co">#&gt; 15   Williams 45   10         591           195   0.222   0.330</span></a>
<a class="sourceLine" id="cb110-23" data-line-number="23"><span class="co">#&gt; 16 Campaneris 45    9         558           159   0.200   0.285</span></a>
<a class="sourceLine" id="cb110-24" data-line-number="24"><span class="co">#&gt; 17     Munson 45    8         408           129   0.178   0.316</span></a>
<a class="sourceLine" id="cb110-25" data-line-number="25"><span class="co">#&gt; 18      Alvis 45    7          70            14   0.156   0.200</span></a></code></pre></div>
<p>Let <span class="math inline">\(y_i\)</span> be the number of hits in the first 45 at bats for player <span class="math inline">\(i\)</span>,
<span class="math display">\[
\begin{aligned}[t]
y_i &amp; \sim \dbin(45, \mu_i),
\end{aligned}
\]</span>
where <span class="math inline">\(\mu_i \in (0, 1)\)</span> is the player-specific batting average.
Priors will be placed on the log-odds parameter, <span class="math inline">\(\eta \in \R\)</span>,
<span class="math display">\[
\begin{aligned}[t]
\mu_i &amp;\sim \frac{1}{1 + \exp(-\eta_i)} . \\
\end{aligned}
\]</span></p>
<p>This example considers three ways of modeling <span class="math inline">\(\mu_i\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Complete Pooling:</strong> All players have the same batting average parameter.
<span class="math display">\[
 \eta_i = \eta .
 \]</span>
The common (log-odds) batting average is given a weakly informative prior,
<span class="math display">\[
 \eta \sim \dnorm(0, 2.5)
 \]</span>
On the log odds scale, this places 95% of the probability mass between 0.7 and 99.3 on the proportion scale.</p></li>
<li><p><strong>Non-pooled:</strong> Each players (log-odds) batting average is independent, with each assigned a separate weak prior.
<span class="math display">\[
 \begin{aligned}[t]
 \eta_i &amp;\sim \dnorm(0, 2.5)
 \end{aligned}
 \]</span></p></li>
<li><p><strong>Partial-pooling:</strong> Each player has a separate (log-odds) batting average, but these batting average parameters are drawn from a common normal distribution.
<span class="math display">\[
 \begin{aligned}[t]
 \eta_i &amp;\sim \dnorm(0, \tau) \\
 \tau &amp;\sim \dnorm(0, 1)
 \end{aligned}
 \]</span></p></li>
</ol>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb111-1" data-line-number="1">bball1970_data &lt;-<span class="st"> </span><span class="kw">list</span>(</a>
<a class="sourceLine" id="cb111-2" data-line-number="2">  <span class="dt">N =</span> <span class="kw">nrow</span>(bball1970),</a>
<a class="sourceLine" id="cb111-3" data-line-number="3">  <span class="dt">k =</span> bball1970<span class="op">$</span>AB,</a>
<a class="sourceLine" id="cb111-4" data-line-number="4">  <span class="dt">y =</span> bball1970<span class="op">$</span>Hits,</a>
<a class="sourceLine" id="cb111-5" data-line-number="5">  <span class="dt">k_new =</span> bball1970<span class="op">$</span>RemainingAB,</a>
<a class="sourceLine" id="cb111-6" data-line-number="6">  <span class="dt">y_new =</span> bball1970<span class="op">$</span>RemainingHits</a>
<a class="sourceLine" id="cb111-7" data-line-number="7">)</a></code></pre></div>
<p>Create a list to store models:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1">models &lt;-<span class="st"> </span><span class="kw">list</span>()</a></code></pre></div>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" data-line-number="1">models[[<span class="st">&quot;nopool&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-no-pooling.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1">models[[<span class="st">&quot;nopool&quot;</span>]]</a></code></pre></div>
<pre>
  <code class="stan">/* Binomial Model (No pooling)

  A binomial model for $i = 1, \dots, N$, no pooling:
  $$
  p(y_i | n_i, \mu_i) &\sim \mathsf{Binomial}(y_i | n_i, \mu_i) \\
  \mu_i &= \logit^{-1}(\eta_i) \\
  p(\eta_i) &\sim \mathsf{Normal}^+(0, 10)
  $$

*/
data {
  int N;
  int y[N];
  int k[N];
  // new data
  int y_new[N];
  int k_new[N];
}
parameters {
  vector[N] eta;
}
model {
  eta ~ normal(0., 10.);
  y ~ binomial_logit(k, eta);
}
generated quantities {
  int y_rep[N];
  vector[N] log_lik;
  vector[N] log_lik_new;
  vector<lower = 0., upper = 1.>[N] mu;
  mu = inv_logit(eta);
  for (n in 1:N) {
    y_rep[n] = binomial_rng(k[n], mu[n]);
    log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]);
    log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]);
  }
}</code>
</pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" data-line-number="1">models[[<span class="st">&quot;pool&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-complete-pooling.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1">models[[<span class="st">&quot;pool&quot;</span>]]</a></code></pre></div>
<pre>
  <code class="stan">/* Binomial Model

  A binomial model for $i = 1, \dots, N$, with complete pooling
  $$
  \begin{aligned}[t]
  p(y_i | n_i, \mu) &\sim \mathsf{Binomial}(n_i, \mu) \\
  \mu &= \logit^{-1}(\eta) \\
  p(\eta) &\sim \mathsf{Normal}^+(0, 10)
  \end{aligned}
  $$

*/
data {
  int N;
  int y[N];
  int k[N];
  // new data
  int y_new[N];
  int k_new[N];
}
parameters {
  real eta;
}
model {
  eta ~ normal(0., 10.);
  y ~ binomial_logit(k, eta);
}
generated quantities {
  int y_rep[N];
  vector[N] log_lik;
  vector[N] log_lik_new;
  real<lower = 0., upper = 1.> mu;
  mu = inv_logit(eta);
  for (n in 1:N) { //
    y_rep[n] = binomial_rng(k[n], mu);
    log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta);
    log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta);
  }
}</code>
</pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" data-line-number="1">models[[<span class="st">&quot;partial&quot;</span>]] &lt;-<span class="st"> </span><span class="kw">stan_model</span>(<span class="st">&quot;stan/binomial-partial-pooling-t.stan&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1">models[[<span class="st">&quot;partial&quot;</span>]]</a></code></pre></div>
<pre>
  <code class="stan">/* Binomial Model

  A binomial model for $i = 1, \dots, N$, with partial pooling
  $$
  \begin{aligned}[t]
  p(y_i | n_i, \mu_i) &\sim \mathsf{Binomial}(y_i | n_i, \mu_i) \\
  \mu_i &= \logit^{-1}(\eta_i) \\
  p(\eta_i | \tau) &\sim \mathsf{Normal}(alpha, \tau) \\
  p(\tau) &\sim \mathsf{Normal}^+(0, 1) \\
  p(alpha) & \sim \mathsf{Normal}(0, 2.5) \\
  \end{aligned}
  $$

*/
data {
  int N;
  int y[N];
  int k[N];
  // new data
  int y_new[N];
  int k_new[N];
}
parameters {
  vector[N] eta;
  real alpha;
  real<lower = 0.> tau;
}
model {
  alpha ~ normal(0., 10.);
  tau ~ normal(0., 1);
  eta ~ normal(alpha, tau);
  y ~ binomial_logit(k, eta);
}
generated quantities {
  int y_rep[N];
  vector[N] log_lik;
  vector[N] log_lik_new;
  vector<lower = 0., upper = 1.>[N] mu;
  mu = inv_logit(eta);
  for (n in 1:N) { //
    y_rep[n] = binomial_rng(k[n], mu[n]);
    log_lik[n] = binomial_logit_lpmf(y[n] | k[n], eta[n]);
    log_lik_new[n] = binomial_logit_lpmf(y_new[n] | k_new[n], eta[n]);
  }
}</code>
</pre>
<p>Sample from all three models a</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" data-line-number="1">fits &lt;-<span class="st"> </span><span class="kw">map</span>(models, sampling, <span class="dt">data =</span> bball1970_data,</a>
<a class="sourceLine" id="cb119-2" data-line-number="2">            <span class="dt">refresh =</span> <span class="dv">-1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb119-3" data-line-number="3"><span class="st">  </span><span class="kw">set_names</span>(<span class="kw">names</span>(models))</a>
<a class="sourceLine" id="cb119-4" data-line-number="4"><span class="co">#&gt; Warning: There were 2 divergent transitions after warmup. Increasing adapt_delta above 0.8 may help. See</span></a>
<a class="sourceLine" id="cb119-5" data-line-number="5"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup</span></a>
<a class="sourceLine" id="cb119-6" data-line-number="6"><span class="co">#&gt; Warning: There were 4 chains where the estimated Bayesian Fraction of Missing Information was low. See</span></a>
<a class="sourceLine" id="cb119-7" data-line-number="7"><span class="co">#&gt; http://mc-stan.org/misc/warnings.html#bfmi-low</span></a>
<a class="sourceLine" id="cb119-8" data-line-number="8"><span class="co">#&gt; Warning: Examine the pairs() plot to diagnose sampling problems</span></a></code></pre></div>
<p>For each model calculate the posterior mean of <span class="math inline">\(\mu\)</span> for each player:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1">bball1970 &lt;-</a>
<a class="sourceLine" id="cb120-2" data-line-number="2"><span class="st">  </span><span class="kw">map2_df</span>(<span class="kw">names</span>(fits), fits, </a>
<a class="sourceLine" id="cb120-3" data-line-number="3">     <span class="cf">function</span>(nm, fit) {</a>
<a class="sourceLine" id="cb120-4" data-line-number="4">      mu &lt;-<span class="st"> </span>broom<span class="op">::</span><span class="kw">tidy</span>(fit) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(term, <span class="st">&quot;^mu&quot;</span>))</a>
<a class="sourceLine" id="cb120-5" data-line-number="5">      <span class="cf">if</span> (<span class="kw">nrow</span>(mu) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {</a>
<a class="sourceLine" id="cb120-6" data-line-number="6">        out &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">estimate =</span> <span class="kw">rep</span>(mu<span class="op">$</span>estimate, 18L))</a>
<a class="sourceLine" id="cb120-7" data-line-number="7">      } <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb120-8" data-line-number="8">        out &lt;-<span class="st"> </span><span class="kw">select</span>(mu, estimate)</a>
<a class="sourceLine" id="cb120-9" data-line-number="9">      }</a>
<a class="sourceLine" id="cb120-10" data-line-number="10">      out<span class="op">$</span>model &lt;-<span class="st"> </span>nm</a>
<a class="sourceLine" id="cb120-11" data-line-number="11">      out<span class="op">$</span>.id &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw">nrow</span>(out))</a>
<a class="sourceLine" id="cb120-12" data-line-number="12">      out</a>
<a class="sourceLine" id="cb120-13" data-line-number="13">     }) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb120-14" data-line-number="14"><span class="st">  </span><span class="kw">spread</span>(model, estimate) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb120-15" data-line-number="15"><span class="st">  </span><span class="kw">bind_cols</span>(bball1970)</a></code></pre></div>
<p>The partially pooled estiamtes are shrunk towards the overall average, and are between the no-pooling and pooled estimates.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb121-1" data-line-number="1"><span class="kw">select</span>(bball1970,</a>
<a class="sourceLine" id="cb121-2" data-line-number="2">       Player, nopool, partial, pool) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb121-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb121-4" data-line-number="4"><span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb121-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">x =</span> <span class="kw">factor</span>(variable), <span class="dt">group =</span> Player)) <span class="op">+</span></a>
<a class="sourceLine" id="cb121-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb121-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb121-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="kw">expression</span>(mu))</a></code></pre></div>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" />
We can plot the actual batting averages (<code>BatAvg1</code> and <code>BatAvg2</code>) and the model estimates:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="kw">select</span>(bball1970,</a>
<a class="sourceLine" id="cb122-2" data-line-number="2">       Player, nopool, partial, pool, BatAvg1, BatAvg2) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb122-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb122-4" data-line-number="4"><span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb122-5" data-line-number="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> Player, <span class="dt">x =</span> value, <span class="dt">colour =</span> variable)) <span class="op">+</span></a>
<a class="sourceLine" id="cb122-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb122-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu), <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" />
The estimates of the no-pooling model is almost exactly the same as <code>BatAvg1</code>.
The out-of-sample batting averages <code>BatAvg2</code> show regression to the mean.</p>
<p>For these models, compare the overall out-of-sample performance by calculating the actual average out-of-sample log-pointwise predictive density (lppd), and the expected lppd using LOO-PSIS.
The LOO-PSIS estimates of the out-of-sample lppd are optimistic.
However, they still show the pooling and partial estimates as superior to the no-pooling estimates.
The actual out-of-sample average lppd for the partial pooled model is the best fitting.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb123-1" data-line-number="1"><span class="kw">map2_df</span>(<span class="kw">names</span>(fits), fits, </a>
<a class="sourceLine" id="cb123-2" data-line-number="2">     <span class="cf">function</span>(nm, fit) {</a>
<a class="sourceLine" id="cb123-3" data-line-number="3">      loo &lt;-<span class="st"> </span><span class="kw">loo</span>(<span class="kw">extract_log_lik</span>(fit, <span class="st">&quot;log_lik&quot;</span>))</a>
<a class="sourceLine" id="cb123-4" data-line-number="4">      ll_new &lt;-<span class="st"> </span>rstan<span class="op">::</span><span class="kw">extract</span>(fit)[[<span class="st">&quot;log_lik_new&quot;</span>]]</a>
<a class="sourceLine" id="cb123-5" data-line-number="5">      <span class="kw">tibble</span>(<span class="dt">model =</span> nm,</a>
<a class="sourceLine" id="cb123-6" data-line-number="6">             <span class="dt">loo =</span> loo<span class="op">$</span>elpd_loo <span class="op">/</span><span class="st"> </span>bball1970_data<span class="op">$</span>N,</a>
<a class="sourceLine" id="cb123-7" data-line-number="7">             <span class="dt">ll_out =</span> <span class="kw">mean</span>(<span class="kw">log</span>(<span class="kw">colMeans</span>(<span class="kw">exp</span>(ll_new)))))</a>
<a class="sourceLine" id="cb123-8" data-line-number="8">     })</a>
<a class="sourceLine" id="cb123-9" data-line-number="9"><span class="co">#&gt; # A tibble: 3 × 3</span></a>
<a class="sourceLine" id="cb123-10" data-line-number="10"><span class="co">#&gt;     model   loo ll_out</span></a>
<a class="sourceLine" id="cb123-11" data-line-number="11"><span class="co">#&gt;     &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb123-12" data-line-number="12"><span class="co">#&gt; 1  nopool -3.20  -4.60</span></a>
<a class="sourceLine" id="cb123-13" data-line-number="13"><span class="co">#&gt; 2    pool -2.58  -4.05</span></a>
<a class="sourceLine" id="cb123-14" data-line-number="14"><span class="co">#&gt; 3 partial -2.59  -3.99</span></a></code></pre></div>
<p>To see why this is the case, plot the average errors for each observation in- and out-of-sample.
In-sample for the no-pooling model is zero, but it over-estimates (under-estimates) the players with the highest (lowest) batting averages in their first 45 at bats—this is regression to the mean.
In sample, the partially pooling model shrinks the estimates towards the mean and
reducing error.
Out of sample, the errors of the partially pooled model are not much different than the no-pooling model, except that the extreme observations have lower errors.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1"><span class="kw">select</span>(bball1970,</a>
<a class="sourceLine" id="cb124-2" data-line-number="2">       Player, nopool, partial, pool, BatAvg1, BatAvg2) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb124-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Player =</span> <span class="kw">as.integer</span>(<span class="kw">factor</span>(Player, <span class="dt">levels =</span> Player))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-4" data-line-number="4"><span class="st">  </span><span class="kw">gather</span>(variable, value, <span class="op">-</span>Player, <span class="op">-</span><span class="kw">matches</span>(<span class="st">&quot;BatAvg&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">In-sample Errors</span><span class="st">`</span> =<span class="st"> </span>value <span class="op">-</span><span class="st"> </span>BatAvg1,</a>
<a class="sourceLine" id="cb124-6" data-line-number="6">         <span class="st">`</span><span class="dt">Out-of-sample Errors</span><span class="st">`</span> =<span class="st"> </span>value <span class="op">-</span><span class="st"> </span>BatAvg2) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-7" data-line-number="7"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">matches</span>(<span class="st">&quot;BatAvg&quot;</span>), <span class="op">-</span>value) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-8" data-line-number="8"><span class="st">  </span><span class="kw">gather</span>(sample, error, <span class="op">-</span>variable, <span class="op">-</span>Player) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-9" data-line-number="9"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> error, <span class="dt">x =</span> Player, <span class="dt">colour =</span> variable)) <span class="op">+</span></a>
<a class="sourceLine" id="cb124-10" data-line-number="10"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb124-11" data-line-number="11"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb124-12" data-line-number="12"><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb124-13" data-line-number="13"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sample, <span class="dt">ncol =</span> <span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb124-14" data-line-number="14"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</a></code></pre></div>
<p><img src="hierarchical_files/figure-html/unnamed-chunk-16-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Extensions:</p>
<ul>
<li>Redo this analysis with the <a href="https://www.rdocumentation.org/packages/rstanarm/topics/bball2006">rstanarm</a> dataset with hits and at-bats for the entire 2006 AL season of MLB.</li>
<li>Use a beta distribution for the prior of <span class="math inline">\(\mu_i\)</span>. How would you specify the prior beta distribution so that it is uniformative?</li>
<li>If you used the beta distribution, how would you specify the beta distribution as a function of the mean?</li>
<li>The lowest batting average of the modern era is approximately 0.16 and the highest is approximately 0.4. Use this information for an informative prior distribuiton.</li>
<li>There may be some truly exceptional players. Model this by replacing the normal prior for <span class="math inline">\(\eta\)</span> with a wide tailed distribution.</li>
<li>The distribution of batting averages may be asymmetric - since there may be a few great players, but a player can only be so bad before they are relegated to the minor league. Find a skewed distribution to use as a prior.</li>
</ul>
<p>References:</p>
<ul>
<li>Albert, Jim. <a href="https://baseballwithr.wordpress.com/2016/02/15/revisiting-efron-and-morriss-baseball-study/">Revisiting Efron and Morris’s Baseball Study</a> Feb 15, 2016</li>
<li>Bob Carpenter. <a href="https://lingpipe-blog.com/2009/11/04/hierarchicalbayesian-batting-ability-with-multiple-comparisons/">Hierarchical Bayesian Batting Ability, with Multiple Comparisons</a>. November 4, 2009.</li>
<li>John Kruschke. <a href="http://doingbayesiandataanalysis.blogspot.com/2012/11/shrinkage-in-multi-level-hierarchical.html">Shrinkage in multi-level hierarchical models</a>. November 27, 2012.</li>
<li>See <span class="citation">Jensen, McShane, and Wyner (2009)</span> for an updated hierarchical model of baseball hitting</li>
</ul>
<div id="other-examples" class="section level3">
<h3><span class="header-section-number">13.1.1</span> Other Examples</h3>
<ul>
<li>Rat Tumors - BDA</li>
<li>Eight Schools - BDA</li>
</ul>
<!--chapter:end:hierarchical.Rmd-->
</div>
</div>
</div>
<div id="multilevel-models" class="section level1">
<h1><span class="header-section-number">14</span> Multilevel Models</h1>
<p>Multilevel models are commonly used hierarchical model.
They extend (generalized) linear models to include coefficients that vary by discrete groups.</p>
<p>Suppose that there are <span class="math inline">\(i = 1, dots, n\)</span> observations, and each observation is in one of <span class="math inline">\(j = 1, \dots, J\)</span> groups.
Let <span class="math inline">\(j[i]\)</span> be the group for
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha_{j[i]} + \beta_{j[i]} x_i, \sigma^2) \\
  \begin{bmatrix}
  \alpha_j \\
  \beta_j
  \end{bmatrix} 
&amp; \sim
\dnorm
\left(
  \begin{bmatrix}
  \mu_\alpha \\
  \mu_\beta
  \end{bmatrix},
\Omega
\right)
\end{aligned} .
\]</span></p>
<p><em>Pooled model</em>: All coefficients are common between groups. This is equivalent to a linear model.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta x_i, \sigma^2) \\
\begin{bmatrix}
\alpha \\
\beta
\end{bmatrix} 
&amp;\sim
\dnorm
\left(
  \begin{bmatrix}
  \mu_{\alpha} \\
  \mu_{\beta}
  \end{bmatrix},
  \Omega
\right)
\end{aligned}
\]</span></p>
<p><em>Pooled model</em>: All coefficients are common between groups. This is equivalent to a linear model.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta x_i, \sigma^2) \\
\end{aligned}
\]</span>
<em>Varying-intercept</em>: The slope coefficients (<span class="math inline">\(\beta\)</span>) are common between groups, but the intercepts (<span class="math inline">\(\alpha_j\)</span>) vary by group.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha_{j[i]} + \beta x_i, \sigma^2) \\
\end{aligned}
\]</span>
<em>Varying-slope model</em>: The groups share a common intercept, <span class="math inline">\(\alpha\)</span>, but the slope coefficient (<span class="math inline">\(\beta\)</span>), varies between groups. This is less common since it is hard to think of cases when it is appropriate.
<span class="math display">\[
\begin{aligned}[t]
y_i &amp;\sim \dnorm(\alpha + \beta_{j[i]} x_i, \sigma^2) \\
\end{aligned}
\]</span>
These models go by different names in different literatures: <em>hierarchical (generalized) linear models</em>, <em>nested data models</em>, <em>mixed models</em>, <em>random coefficients</em>, <em>random-effects</em>, <em>random parameter models</em>, <em>split-plot designs</em>.<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>
<p>The model can be extended to other cases:</p>
<ul>
<li>generalized linear models</li>
<li>multiple parameters</li>
</ul>
<p>One of the difficulties in these models is the prior to the covariance matrix, <span class="math inline">\(\Omega\)</span>.</p>
<div class="figure" style="text-align: center">
<img src="multilevel_files/figure-html/unnamed-chunk-2-1.png" alt="Visual representation of hierarchical models" width="70%" />
<p class="caption">
(#fig:unnamed-chunk-2)Visual representation of hierarchical models
</p>
</div>
<div id="example-radon" class="section level2">
<h2><span class="header-section-number">14.1</span> Example: Radon</h2>
<p>This example models the presence of radon in houses in Minnesota which appears in <span class="citation">Gelman and Hill (2007)</span> and <span class="citation">Gelman et al. (2013)</span>.
This is partly derived from a <a href="http://mc-stan.org/documentation/case-studies/radon.html">Stan Case Study</a>, which uses <code>PyStan</code> instead of <strong>rstan</strong>.</p>
<div id="data" class="section level3">
<h3><span class="header-section-number">14.1.1</span> Data</h3>
<p>The <a href="https://www.rdocumentation.org/packages/rstanarm/topics/radon">rstanarm</a> data is included in the <strong><a href="https://cran.r-project.org/package=rstanarm">rstanarm</a></strong> package.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;radon&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;rstanarm&quot;</span>)</a>
<a class="sourceLine" id="cb125-2" data-line-number="2">radon</a>
<a class="sourceLine" id="cb125-3" data-line-number="3"><span class="co">#&gt;     floor         county log_radon log_uranium</span></a>
<a class="sourceLine" id="cb125-4" data-line-number="4"><span class="co">#&gt; 1       1         AITKIN    0.8329     -0.6890</span></a>
<a class="sourceLine" id="cb125-5" data-line-number="5"><span class="co">#&gt; 2       0         AITKIN    0.8329     -0.6890</span></a>
<a class="sourceLine" id="cb125-6" data-line-number="6"><span class="co">#&gt; 3       0         AITKIN    1.0986     -0.6890</span></a>
<a class="sourceLine" id="cb125-7" data-line-number="7"><span class="co">#&gt; 4       0         AITKIN    0.0953     -0.6890</span></a>
<a class="sourceLine" id="cb125-8" data-line-number="8"><span class="co">#&gt; 5       0          ANOKA    1.1632     -0.8473</span></a>
<a class="sourceLine" id="cb125-9" data-line-number="9"><span class="co">#&gt; 6       0          ANOKA    0.9555     -0.8473</span></a>
<a class="sourceLine" id="cb125-10" data-line-number="10"><span class="co">#&gt; 7       0          ANOKA    0.4700     -0.8473</span></a>
<a class="sourceLine" id="cb125-11" data-line-number="11"><span class="co">#&gt; 8       0          ANOKA    0.0953     -0.8473</span></a>
<a class="sourceLine" id="cb125-12" data-line-number="12"><span class="co">#&gt; 9       0          ANOKA   -0.2231     -0.8473</span></a>
<a class="sourceLine" id="cb125-13" data-line-number="13"><span class="co">#&gt; 10      0          ANOKA    0.2624     -0.8473</span></a>
<a class="sourceLine" id="cb125-14" data-line-number="14"><span class="co">#&gt; 11      0          ANOKA    0.2624     -0.8473</span></a>
<a class="sourceLine" id="cb125-15" data-line-number="15"><span class="co">#&gt; 12      0          ANOKA    0.3365     -0.8473</span></a>
<a class="sourceLine" id="cb125-16" data-line-number="16"><span class="co">#&gt; 13      0          ANOKA    0.4055     -0.8473</span></a>
<a class="sourceLine" id="cb125-17" data-line-number="17"><span class="co">#&gt; 14      0          ANOKA   -0.6931     -0.8473</span></a>
<a class="sourceLine" id="cb125-18" data-line-number="18"><span class="co">#&gt; 15      0          ANOKA    0.1823     -0.8473</span></a>
<a class="sourceLine" id="cb125-19" data-line-number="19"><span class="co">#&gt; 16      0          ANOKA    1.5261     -0.8473</span></a>
<a class="sourceLine" id="cb125-20" data-line-number="20"><span class="co">#&gt; 17      0          ANOKA    0.3365     -0.8473</span></a>
<a class="sourceLine" id="cb125-21" data-line-number="21"><span class="co">#&gt; 18      0          ANOKA    0.7885     -0.8473</span></a>
<a class="sourceLine" id="cb125-22" data-line-number="22"><span class="co">#&gt; 19      0          ANOKA    1.7918     -0.8473</span></a>
<a class="sourceLine" id="cb125-23" data-line-number="23"><span class="co">#&gt; 20      0          ANOKA    1.2238     -0.8473</span></a>
<a class="sourceLine" id="cb125-24" data-line-number="24"><span class="co">#&gt; 21      0          ANOKA    0.6419     -0.8473</span></a>
<a class="sourceLine" id="cb125-25" data-line-number="25"><span class="co">#&gt; 22      0          ANOKA    1.7047     -0.8473</span></a>
<a class="sourceLine" id="cb125-26" data-line-number="26"><span class="co">#&gt; 23      0          ANOKA    1.8563     -0.8473</span></a>
<a class="sourceLine" id="cb125-27" data-line-number="27"><span class="co">#&gt; 24      0          ANOKA    0.6931     -0.8473</span></a>
<a class="sourceLine" id="cb125-28" data-line-number="28"><span class="co">#&gt; 25      0          ANOKA    1.9021     -0.8473</span></a>
<a class="sourceLine" id="cb125-29" data-line-number="29"><span class="co">#&gt; 26      0          ANOKA    1.1632     -0.8473</span></a>
<a class="sourceLine" id="cb125-30" data-line-number="30"><span class="co">#&gt; 27      0          ANOKA    1.9315     -0.8473</span></a>
<a class="sourceLine" id="cb125-31" data-line-number="31"><span class="co">#&gt; 28      0          ANOKA    1.9601     -0.8473</span></a>
<a class="sourceLine" id="cb125-32" data-line-number="32"><span class="co">#&gt; 29      0          ANOKA    2.0541     -0.8473</span></a>
<a class="sourceLine" id="cb125-33" data-line-number="33"><span class="co">#&gt; 30      0          ANOKA    1.6677     -0.8473</span></a>
<a class="sourceLine" id="cb125-34" data-line-number="34"><span class="co">#&gt; 31      0          ANOKA    1.5261     -0.8473</span></a>
<a class="sourceLine" id="cb125-35" data-line-number="35"><span class="co">#&gt; 32      0          ANOKA    1.5041     -0.8473</span></a>
<a class="sourceLine" id="cb125-36" data-line-number="36"><span class="co">#&gt; 33      0          ANOKA    1.0647     -0.8473</span></a>
<a class="sourceLine" id="cb125-37" data-line-number="37"><span class="co">#&gt; 34      0          ANOKA    2.1041     -0.8473</span></a>
<a class="sourceLine" id="cb125-38" data-line-number="38"><span class="co">#&gt; 35      0          ANOKA    0.5306     -0.8473</span></a>
<a class="sourceLine" id="cb125-39" data-line-number="39"><span class="co">#&gt; 36      0          ANOKA    1.4586     -0.8473</span></a>
<a class="sourceLine" id="cb125-40" data-line-number="40"><span class="co">#&gt; 37      0          ANOKA    1.7047     -0.8473</span></a>
<a class="sourceLine" id="cb125-41" data-line-number="41"><span class="co">#&gt; 38      0          ANOKA    1.4110     -0.8473</span></a>
<a class="sourceLine" id="cb125-42" data-line-number="42"><span class="co">#&gt; 39      0          ANOKA    0.8755     -0.8473</span></a>
<a class="sourceLine" id="cb125-43" data-line-number="43"><span class="co">#&gt; 40      0          ANOKA    1.0986     -0.8473</span></a>
<a class="sourceLine" id="cb125-44" data-line-number="44"><span class="co">#&gt; 41      0          ANOKA    0.4055     -0.8473</span></a>
<a class="sourceLine" id="cb125-45" data-line-number="45"><span class="co">#&gt; 42      0          ANOKA    1.2238     -0.8473</span></a>
<a class="sourceLine" id="cb125-46" data-line-number="46"><span class="co">#&gt; 43      0          ANOKA    1.0986     -0.8473</span></a>
<a class="sourceLine" id="cb125-47" data-line-number="47"><span class="co">#&gt; 44      1          ANOKA    0.6419     -0.8473</span></a>
<a class="sourceLine" id="cb125-48" data-line-number="48"><span class="co">#&gt; 45      1          ANOKA   -1.2040     -0.8473</span></a>
<a class="sourceLine" id="cb125-49" data-line-number="49"><span class="co">#&gt; 46      0          ANOKA    0.9163     -0.8473</span></a>
<a class="sourceLine" id="cb125-50" data-line-number="50"><span class="co">#&gt; 47      1          ANOKA    0.1823     -0.8473</span></a>
<a class="sourceLine" id="cb125-51" data-line-number="51"><span class="co">#&gt; 48      0          ANOKA    0.8329     -0.8473</span></a>
<a class="sourceLine" id="cb125-52" data-line-number="52"><span class="co">#&gt; 49      0          ANOKA   -0.3567     -0.8473</span></a>
<a class="sourceLine" id="cb125-53" data-line-number="53"><span class="co">#&gt; 50      0          ANOKA    0.5878     -0.8473</span></a>
<a class="sourceLine" id="cb125-54" data-line-number="54"><span class="co">#&gt; 51      0          ANOKA    1.0986     -0.8473</span></a>
<a class="sourceLine" id="cb125-55" data-line-number="55"><span class="co">#&gt; 52      0          ANOKA    0.8329     -0.8473</span></a>
<a class="sourceLine" id="cb125-56" data-line-number="56"><span class="co">#&gt; 53      0          ANOKA    0.5878     -0.8473</span></a>
<a class="sourceLine" id="cb125-57" data-line-number="57"><span class="co">#&gt; 54      0          ANOKA    0.4055     -0.8473</span></a>
<a class="sourceLine" id="cb125-58" data-line-number="58"><span class="co">#&gt; 55      0          ANOKA    0.6931     -0.8473</span></a>
<a class="sourceLine" id="cb125-59" data-line-number="59"><span class="co">#&gt; 56      0          ANOKA    0.6419     -0.8473</span></a>
<a class="sourceLine" id="cb125-60" data-line-number="60"><span class="co">#&gt; 57      1         BECKER    0.2624     -0.1135</span></a>
<a class="sourceLine" id="cb125-61" data-line-number="61"><span class="co">#&gt; 58      0         BECKER    1.4816     -0.1135</span></a>
<a class="sourceLine" id="cb125-62" data-line-number="62"><span class="co">#&gt; 59      1         BECKER    1.5261     -0.1135</span></a>
<a class="sourceLine" id="cb125-63" data-line-number="63"><span class="co">#&gt; 60      0       BELTRAMI    1.8563     -0.5934</span></a>
<a class="sourceLine" id="cb125-64" data-line-number="64"><span class="co">#&gt; 61      0       BELTRAMI    1.5476     -0.5934</span></a>
<a class="sourceLine" id="cb125-65" data-line-number="65"><span class="co">#&gt; 62      0       BELTRAMI    1.7579     -0.5934</span></a>
<a class="sourceLine" id="cb125-66" data-line-number="66"><span class="co">#&gt; 63      1       BELTRAMI    0.8329     -0.5934</span></a>
<a class="sourceLine" id="cb125-67" data-line-number="67"><span class="co">#&gt; 64      1       BELTRAMI   -0.6931     -0.5934</span></a>
<a class="sourceLine" id="cb125-68" data-line-number="68"><span class="co">#&gt; 65      1       BELTRAMI    1.5476     -0.5934</span></a>
<a class="sourceLine" id="cb125-69" data-line-number="69"><span class="co">#&gt; 66      1       BELTRAMI    1.5041     -0.5934</span></a>
<a class="sourceLine" id="cb125-70" data-line-number="70"><span class="co">#&gt; 67      0         BENTON    1.9021     -0.1429</span></a>
<a class="sourceLine" id="cb125-71" data-line-number="71"><span class="co">#&gt; 68      0         BENTON    1.0296     -0.1429</span></a>
<a class="sourceLine" id="cb125-72" data-line-number="72"><span class="co">#&gt; 69      1         BENTON    1.0986     -0.1429</span></a>
<a class="sourceLine" id="cb125-73" data-line-number="73"><span class="co">#&gt; 70      0         BENTON    1.0986     -0.1429</span></a>
<a class="sourceLine" id="cb125-74" data-line-number="74"><span class="co">#&gt; 71      0       BIGSTONE    1.9879      0.3871</span></a>
<a class="sourceLine" id="cb125-75" data-line-number="75"><span class="co">#&gt; 72      0       BIGSTONE    1.6292      0.3871</span></a>
<a class="sourceLine" id="cb125-76" data-line-number="76"><span class="co">#&gt; 73      0       BIGSTONE    0.9933      0.3871</span></a>
<a class="sourceLine" id="cb125-77" data-line-number="77"><span class="co">#&gt; 74      0      BLUEEARTH    1.6292      0.2716</span></a>
<a class="sourceLine" id="cb125-78" data-line-number="78"><span class="co">#&gt; 75      0      BLUEEARTH    2.5726      0.2716</span></a>
<a class="sourceLine" id="cb125-79" data-line-number="79"><span class="co">#&gt; 76      0      BLUEEARTH    1.9879      0.2716</span></a>
<a class="sourceLine" id="cb125-80" data-line-number="80"><span class="co">#&gt; 77      0      BLUEEARTH    1.9315      0.2716</span></a>
<a class="sourceLine" id="cb125-81" data-line-number="81"><span class="co">#&gt; 78      0      BLUEEARTH    2.5572      0.2716</span></a>
<a class="sourceLine" id="cb125-82" data-line-number="82"><span class="co">#&gt; 79      1      BLUEEARTH    1.7750      0.2716</span></a>
<a class="sourceLine" id="cb125-83" data-line-number="83"><span class="co">#&gt; 80      0      BLUEEARTH    2.2618      0.2716</span></a>
<a class="sourceLine" id="cb125-84" data-line-number="84"><span class="co">#&gt; 81      0      BLUEEARTH    1.8083      0.2716</span></a>
<a class="sourceLine" id="cb125-85" data-line-number="85"><span class="co">#&gt; 82      0      BLUEEARTH    1.3610      0.2716</span></a>
<a class="sourceLine" id="cb125-86" data-line-number="86"><span class="co">#&gt; 83      1      BLUEEARTH    2.6672      0.2716</span></a>
<a class="sourceLine" id="cb125-87" data-line-number="87"><span class="co">#&gt; 84      0      BLUEEARTH    0.6419      0.2716</span></a>
<a class="sourceLine" id="cb125-88" data-line-number="88"><span class="co">#&gt; 85      0      BLUEEARTH    1.9459      0.2716</span></a>
<a class="sourceLine" id="cb125-89" data-line-number="89"><span class="co">#&gt; 86      0      BLUEEARTH    1.5686      0.2716</span></a>
<a class="sourceLine" id="cb125-90" data-line-number="90"><span class="co">#&gt; 87      0      BLUEEARTH    2.2618      0.2716</span></a>
<a class="sourceLine" id="cb125-91" data-line-number="91"><span class="co">#&gt; 88      1          BROWN    0.9555      0.2776</span></a>
<a class="sourceLine" id="cb125-92" data-line-number="92"><span class="co">#&gt; 89      0          BROWN    1.9169      0.2776</span></a>
<a class="sourceLine" id="cb125-93" data-line-number="93"><span class="co">#&gt; 90      1          BROWN    1.4110      0.2776</span></a>
<a class="sourceLine" id="cb125-94" data-line-number="94"><span class="co">#&gt; 91      0          BROWN    2.3224      0.2776</span></a>
<a class="sourceLine" id="cb125-95" data-line-number="95"><span class="co">#&gt; 92      0        CARLTON    0.8329     -0.3323</span></a>
<a class="sourceLine" id="cb125-96" data-line-number="96"><span class="co">#&gt; 93      0        CARLTON    0.6419     -0.3323</span></a>
<a class="sourceLine" id="cb125-97" data-line-number="97"><span class="co">#&gt; 94      0        CARLTON    1.2528     -0.3323</span></a>
<a class="sourceLine" id="cb125-98" data-line-number="98"><span class="co">#&gt; 95      1        CARLTON    1.7405     -0.3323</span></a>
<a class="sourceLine" id="cb125-99" data-line-number="99"><span class="co">#&gt; 96      0        CARLTON    1.4816     -0.3323</span></a>
<a class="sourceLine" id="cb125-100" data-line-number="100"><span class="co">#&gt; 97      0        CARLTON    1.3863     -0.3323</span></a>
<a class="sourceLine" id="cb125-101" data-line-number="101"><span class="co">#&gt; 98      0        CARLTON    0.3365     -0.3323</span></a>
<a class="sourceLine" id="cb125-102" data-line-number="102"><span class="co">#&gt; 99      0        CARLTON    1.4586     -0.3323</span></a>
<a class="sourceLine" id="cb125-103" data-line-number="103"><span class="co">#&gt; 100     0        CARLTON   -0.1054     -0.3323</span></a>
<a class="sourceLine" id="cb125-104" data-line-number="104"><span class="co">#&gt; 101     0        CARLTON    0.7419     -0.3323</span></a>
<a class="sourceLine" id="cb125-105" data-line-number="105"><span class="co">#&gt; 102     0         CARVER    0.5306      0.0959</span></a>
<a class="sourceLine" id="cb125-106" data-line-number="106"><span class="co">#&gt; 104     0         CARVER    2.5649      0.0959</span></a>
<a class="sourceLine" id="cb125-107" data-line-number="107"><span class="co">#&gt; 106     1         CARVER    2.6946      0.0959</span></a>
<a class="sourceLine" id="cb125-108" data-line-number="108"><span class="co">#&gt; 108     1         CARVER    1.5686      0.0959</span></a>
<a class="sourceLine" id="cb125-109" data-line-number="109"><span class="co">#&gt; 110     0         CARVER    2.2721      0.0959</span></a>
<a class="sourceLine" id="cb125-110" data-line-number="110"><span class="co">#&gt; 112     1         CARVER   -2.3026      0.0959</span></a>
<a class="sourceLine" id="cb125-111" data-line-number="111"><span class="co">#&gt; 114     0           CASS    1.3350     -0.6082</span></a>
<a class="sourceLine" id="cb125-112" data-line-number="112"><span class="co">#&gt; 115     0           CASS    2.0149     -0.6082</span></a>
<a class="sourceLine" id="cb125-113" data-line-number="113"><span class="co">#&gt; 116     0           CASS    0.6931     -0.6082</span></a>
<a class="sourceLine" id="cb125-114" data-line-number="114"><span class="co">#&gt; 117     0           CASS    1.6864     -0.6082</span></a>
<a class="sourceLine" id="cb125-115" data-line-number="115"><span class="co">#&gt; 118     0           CASS    1.4110     -0.6082</span></a>
<a class="sourceLine" id="cb125-116" data-line-number="116"><span class="co">#&gt; 119     0       CHIPPEWA    2.0541      0.2737</span></a>
<a class="sourceLine" id="cb125-117" data-line-number="117"><span class="co">#&gt; 120     0       CHIPPEWA    0.4055      0.2737</span></a>
<a class="sourceLine" id="cb125-118" data-line-number="118"><span class="co">#&gt; 121     0       CHIPPEWA    2.3125      0.2737</span></a>
<a class="sourceLine" id="cb125-119" data-line-number="119"><span class="co">#&gt; 122     0       CHIPPEWA    2.2513      0.2737</span></a>
<a class="sourceLine" id="cb125-120" data-line-number="120"><span class="co">#&gt; 123     0        CHISAGO   -0.1054     -0.7353</span></a>
<a class="sourceLine" id="cb125-121" data-line-number="121"><span class="co">#&gt; 124     0        CHISAGO    1.5041     -0.7353</span></a>
<a class="sourceLine" id="cb125-122" data-line-number="122"><span class="co">#&gt; 125     0        CHISAGO    1.6292     -0.7353</span></a>
<a class="sourceLine" id="cb125-123" data-line-number="123"><span class="co">#&gt; 126     0        CHISAGO    0.7885     -0.7353</span></a>
<a class="sourceLine" id="cb125-124" data-line-number="124"><span class="co">#&gt; 127     0        CHISAGO    0.5878     -0.7353</span></a>
<a class="sourceLine" id="cb125-125" data-line-number="125"><span class="co">#&gt; 128     0        CHISAGO    2.1041     -0.7353</span></a>
<a class="sourceLine" id="cb125-126" data-line-number="126"><span class="co">#&gt; 129     1           CLAY    0.0000      0.3438</span></a>
<a class="sourceLine" id="cb125-127" data-line-number="127"><span class="co">#&gt; 130     0           CLAY    2.5649      0.3438</span></a>
<a class="sourceLine" id="cb125-128" data-line-number="128"><span class="co">#&gt; 131     0           CLAY    0.9933      0.3438</span></a>
<a class="sourceLine" id="cb125-129" data-line-number="129"><span class="co">#&gt; 132     1           CLAY    1.2809      0.3438</span></a>
<a class="sourceLine" id="cb125-130" data-line-number="130"><span class="co">#&gt; 133     0           CLAY    3.2847      0.3438</span></a>
<a class="sourceLine" id="cb125-131" data-line-number="131"><span class="co">#&gt; 134     0           CLAY    0.4700      0.3438</span></a>
<a class="sourceLine" id="cb125-132" data-line-number="132"><span class="co">#&gt; 135     0           CLAY    2.5726      0.3438</span></a>
<a class="sourceLine" id="cb125-133" data-line-number="133"><span class="co">#&gt; 136     0           CLAY    2.1861      0.3438</span></a>
<a class="sourceLine" id="cb125-134" data-line-number="134"><span class="co">#&gt; 137     0           CLAY    2.9755      0.3438</span></a>
<a class="sourceLine" id="cb125-135" data-line-number="135"><span class="co">#&gt; 138     1           CLAY    0.9555      0.3438</span></a>
<a class="sourceLine" id="cb125-136" data-line-number="136"><span class="co">#&gt; 139     0           CLAY    2.2083      0.3438</span></a>
<a class="sourceLine" id="cb125-137" data-line-number="137"><span class="co">#&gt; 140     0           CLAY    2.5802      0.3438</span></a>
<a class="sourceLine" id="cb125-138" data-line-number="138"><span class="co">#&gt; 141     0           CLAY    1.3083      0.3438</span></a>
<a class="sourceLine" id="cb125-139" data-line-number="139"><span class="co">#&gt; 142     1           CLAY    1.9459      0.3438</span></a>
<a class="sourceLine" id="cb125-140" data-line-number="140"><span class="co">#&gt; 143     1     CLEARWATER    1.5892     -0.0599</span></a>
<a class="sourceLine" id="cb125-141" data-line-number="141"><span class="co">#&gt; 144     0     CLEARWATER    1.2528     -0.0599</span></a>
<a class="sourceLine" id="cb125-142" data-line-number="142"><span class="co">#&gt; 145     1     CLEARWATER    0.0000     -0.0599</span></a>
<a class="sourceLine" id="cb125-143" data-line-number="143"><span class="co">#&gt; 146     0     CLEARWATER    1.2528     -0.0599</span></a>
<a class="sourceLine" id="cb125-144" data-line-number="144"><span class="co">#&gt; 147     0           COOK    1.0296     -0.5050</span></a>
<a class="sourceLine" id="cb125-145" data-line-number="145"><span class="co">#&gt; 148     0           COOK    0.4055     -0.5050</span></a>
<a class="sourceLine" id="cb125-146" data-line-number="146"><span class="co">#&gt; 149     0     COTTONWOOD    1.9315      0.3396</span></a>
<a class="sourceLine" id="cb125-147" data-line-number="147"><span class="co">#&gt; 150     1     COTTONWOOD    2.4159      0.3396</span></a>
<a class="sourceLine" id="cb125-148" data-line-number="148"><span class="co">#&gt; 151     1     COTTONWOOD   -2.3026      0.3396</span></a>
<a class="sourceLine" id="cb125-149" data-line-number="149"><span class="co">#&gt; 152     1     COTTONWOOD    0.9555      0.3396</span></a>
<a class="sourceLine" id="cb125-150" data-line-number="150"><span class="co">#&gt; 153     0       CROWWING    0.6419     -0.6334</span></a>
<a class="sourceLine" id="cb125-151" data-line-number="151"><span class="co">#&gt; 154     0       CROWWING    0.5306     -0.6334</span></a>
<a class="sourceLine" id="cb125-152" data-line-number="152"><span class="co">#&gt; 155     1       CROWWING    0.0953     -0.6334</span></a>
<a class="sourceLine" id="cb125-153" data-line-number="153"><span class="co">#&gt; 156     0       CROWWING    0.0000     -0.6334</span></a>
<a class="sourceLine" id="cb125-154" data-line-number="154"><span class="co">#&gt; 157     0       CROWWING    1.0986     -0.6334</span></a>
<a class="sourceLine" id="cb125-155" data-line-number="155"><span class="co">#&gt; 158     0       CROWWING    1.5041     -0.6334</span></a>
<a class="sourceLine" id="cb125-156" data-line-number="156"><span class="co">#&gt; 159     0       CROWWING    0.4700     -0.6334</span></a>
<a class="sourceLine" id="cb125-157" data-line-number="157"><span class="co">#&gt; 160     0       CROWWING    1.4351     -0.6334</span></a>
<a class="sourceLine" id="cb125-158" data-line-number="158"><span class="co">#&gt; 161     1       CROWWING    0.9555     -0.6334</span></a>
<a class="sourceLine" id="cb125-159" data-line-number="159"><span class="co">#&gt; 162     1       CROWWING    1.9169     -0.6334</span></a>
<a class="sourceLine" id="cb125-160" data-line-number="160"><span class="co">#&gt; 163     0       CROWWING    1.4816     -0.6334</span></a>
<a class="sourceLine" id="cb125-161" data-line-number="161"><span class="co">#&gt; 164     0       CROWWING    1.7228     -0.6334</span></a>
<a class="sourceLine" id="cb125-162" data-line-number="162"><span class="co">#&gt; 165     0         DAKOTA    1.3083     -0.0241</span></a>
<a class="sourceLine" id="cb125-163" data-line-number="163"><span class="co">#&gt; 166     0         DAKOTA    1.0647     -0.0241</span></a>
<a class="sourceLine" id="cb125-164" data-line-number="164"><span class="co">#&gt; 167     0         DAKOTA    2.6878     -0.0241</span></a>
<a class="sourceLine" id="cb125-165" data-line-number="165"><span class="co">#&gt; 168     0         DAKOTA    1.9169     -0.0241</span></a>
<a class="sourceLine" id="cb125-166" data-line-number="166"><span class="co">#&gt; 169     0         DAKOTA    2.0919     -0.0241</span></a>
<a class="sourceLine" id="cb125-167" data-line-number="167"><span class="co">#&gt; 170     0         DAKOTA    0.9933     -0.0241</span></a>
<a class="sourceLine" id="cb125-168" data-line-number="168"><span class="co">#&gt; 171     1         DAKOTA    1.0647     -0.0241</span></a>
<a class="sourceLine" id="cb125-169" data-line-number="169"><span class="co">#&gt; 172     0         DAKOTA    1.5041     -0.0241</span></a>
<a class="sourceLine" id="cb125-170" data-line-number="170"><span class="co">#&gt; 173     1         DAKOTA    0.5878     -0.0241</span></a>
<a class="sourceLine" id="cb125-171" data-line-number="171"><span class="co">#&gt; 174     0         DAKOTA    0.7419     -0.0241</span></a>
<a class="sourceLine" id="cb125-172" data-line-number="172"><span class="co">#&gt; 175     0         DAKOTA    0.7419     -0.0241</span></a>
<a class="sourceLine" id="cb125-173" data-line-number="173"><span class="co">#&gt; 176     0         DAKOTA    0.4700     -0.0241</span></a>
<a class="sourceLine" id="cb125-174" data-line-number="174"><span class="co">#&gt; 177     0         DAKOTA    2.2721     -0.0241</span></a>
<a class="sourceLine" id="cb125-175" data-line-number="175"><span class="co">#&gt; 178     0         DAKOTA    2.1041     -0.0241</span></a>
<a class="sourceLine" id="cb125-176" data-line-number="176"><span class="co">#&gt; 179     0         DAKOTA    1.2809     -0.0241</span></a>
<a class="sourceLine" id="cb125-177" data-line-number="177"><span class="co">#&gt; 180     1         DAKOTA   -0.1054     -0.0241</span></a>
<a class="sourceLine" id="cb125-178" data-line-number="178"><span class="co">#&gt; 181     0         DAKOTA    1.6487     -0.0241</span></a>
<a class="sourceLine" id="cb125-179" data-line-number="179"><span class="co">#&gt; 182     0         DAKOTA    1.1939     -0.0241</span></a>
<a class="sourceLine" id="cb125-180" data-line-number="180"><span class="co">#&gt; 183     0         DAKOTA    2.3888     -0.0241</span></a>
<a class="sourceLine" id="cb125-181" data-line-number="181"><span class="co">#&gt; 184     0         DAKOTA    2.1163     -0.0241</span></a>
<a class="sourceLine" id="cb125-182" data-line-number="182"><span class="co">#&gt; 185     0         DAKOTA    1.8563     -0.0241</span></a>
<a class="sourceLine" id="cb125-183" data-line-number="183"><span class="co">#&gt; 186     0         DAKOTA    1.5892     -0.0241</span></a>
<a class="sourceLine" id="cb125-184" data-line-number="184"><span class="co">#&gt; 187     0         DAKOTA    1.8083     -0.0241</span></a>
<a class="sourceLine" id="cb125-185" data-line-number="185"><span class="co">#&gt; 188     0         DAKOTA    0.1823     -0.0241</span></a>
<a class="sourceLine" id="cb125-186" data-line-number="186"><span class="co">#&gt; 189     0         DAKOTA    2.1748     -0.0241</span></a>
<a class="sourceLine" id="cb125-187" data-line-number="187"><span class="co">#&gt; 190     0         DAKOTA    2.1861     -0.0241</span></a>
<a class="sourceLine" id="cb125-188" data-line-number="188"><span class="co">#&gt; 191     0         DAKOTA    1.9315     -0.0241</span></a>
<a class="sourceLine" id="cb125-189" data-line-number="189"><span class="co">#&gt; 192     0         DAKOTA    0.8755     -0.0241</span></a>
<a class="sourceLine" id="cb125-190" data-line-number="190"><span class="co">#&gt; 193     0         DAKOTA    0.5306     -0.0241</span></a>
<a class="sourceLine" id="cb125-191" data-line-number="191"><span class="co">#&gt; 194     0         DAKOTA    1.0647     -0.0241</span></a>
<a class="sourceLine" id="cb125-192" data-line-number="192"><span class="co">#&gt; 195     0         DAKOTA    1.8871     -0.0241</span></a>
<a class="sourceLine" id="cb125-193" data-line-number="193"><span class="co">#&gt; 196     0         DAKOTA    0.5878     -0.0241</span></a>
<a class="sourceLine" id="cb125-194" data-line-number="194"><span class="co">#&gt; 197     0         DAKOTA    1.5476     -0.0241</span></a>
<a class="sourceLine" id="cb125-195" data-line-number="195"><span class="co">#&gt; 198     0         DAKOTA    1.2238     -0.0241</span></a>
<a class="sourceLine" id="cb125-196" data-line-number="196"><span class="co">#&gt; 199     0         DAKOTA    1.5041     -0.0241</span></a>
<a class="sourceLine" id="cb125-197" data-line-number="197"><span class="co">#&gt; 200     0         DAKOTA    3.0587     -0.0241</span></a>
<a class="sourceLine" id="cb125-198" data-line-number="198"><span class="co">#&gt; 201     0         DAKOTA    2.2192     -0.0241</span></a>
<a class="sourceLine" id="cb125-199" data-line-number="199"><span class="co">#&gt; 202     0         DAKOTA    0.0000     -0.0241</span></a>
<a class="sourceLine" id="cb125-200" data-line-number="200"><span class="co">#&gt; 203     0         DAKOTA    1.6094     -0.0241</span></a>
<a class="sourceLine" id="cb125-201" data-line-number="201"><span class="co">#&gt; 204     0         DAKOTA    1.6292     -0.0241</span></a>
<a class="sourceLine" id="cb125-202" data-line-number="202"><span class="co">#&gt; 205     0         DAKOTA    0.1823     -0.0241</span></a>
<a class="sourceLine" id="cb125-203" data-line-number="203"><span class="co">#&gt; 206     0         DAKOTA    2.0412     -0.0241</span></a>
<a class="sourceLine" id="cb125-204" data-line-number="204"><span class="co">#&gt; 207     0         DAKOTA    1.7047     -0.0241</span></a>
<a class="sourceLine" id="cb125-205" data-line-number="205"><span class="co">#&gt; 208     0         DAKOTA    1.3083     -0.0241</span></a>
<a class="sourceLine" id="cb125-206" data-line-number="206"><span class="co">#&gt; 209     0         DAKOTA    1.6094     -0.0241</span></a>
<a class="sourceLine" id="cb125-207" data-line-number="207"><span class="co">#&gt; 210     0         DAKOTA    1.5686     -0.0241</span></a>
<a class="sourceLine" id="cb125-208" data-line-number="208"><span class="co">#&gt; 211     0         DAKOTA    0.4055     -0.0241</span></a>
<a class="sourceLine" id="cb125-209" data-line-number="209"><span class="co">#&gt; 212     0         DAKOTA    1.2528     -0.0241</span></a>
<a class="sourceLine" id="cb125-210" data-line-number="210"><span class="co">#&gt; 213     0         DAKOTA    1.4586     -0.0241</span></a>
<a class="sourceLine" id="cb125-211" data-line-number="211"><span class="co">#&gt; 214     0         DAKOTA    0.9555     -0.0241</span></a>
<a class="sourceLine" id="cb125-212" data-line-number="212"><span class="co">#&gt; 215     0         DAKOTA    0.4055     -0.0241</span></a>
<a class="sourceLine" id="cb125-213" data-line-number="213"><span class="co">#&gt; 216     0         DAKOTA    0.4055     -0.0241</span></a>
<a class="sourceLine" id="cb125-214" data-line-number="214"><span class="co">#&gt; 217     0         DAKOTA    0.6931     -0.0241</span></a>
<a class="sourceLine" id="cb125-215" data-line-number="215"><span class="co">#&gt; 218     0         DAKOTA    1.5892     -0.0241</span></a>
<a class="sourceLine" id="cb125-216" data-line-number="216"><span class="co">#&gt; 219     1         DAKOTA    0.4055     -0.0241</span></a>
<a class="sourceLine" id="cb125-217" data-line-number="217"><span class="co">#&gt; 220     0         DAKOTA    1.3610     -0.0241</span></a>
<a class="sourceLine" id="cb125-218" data-line-number="218"><span class="co">#&gt; 221     0         DAKOTA    2.1861     -0.0241</span></a>
<a class="sourceLine" id="cb125-219" data-line-number="219"><span class="co">#&gt; 222     0         DAKOTA    1.4816     -0.0241</span></a>
<a class="sourceLine" id="cb125-220" data-line-number="220"><span class="co">#&gt; 223     0         DAKOTA    1.5041     -0.0241</span></a>
<a class="sourceLine" id="cb125-221" data-line-number="221"><span class="co">#&gt; 224     0         DAKOTA    1.5261     -0.0241</span></a>
<a class="sourceLine" id="cb125-222" data-line-number="222"><span class="co">#&gt; 225     0         DAKOTA    0.8329     -0.0241</span></a>
<a class="sourceLine" id="cb125-223" data-line-number="223"><span class="co">#&gt; 226     0         DAKOTA   -0.5108     -0.0241</span></a>
<a class="sourceLine" id="cb125-224" data-line-number="224"><span class="co">#&gt; 227     0         DAKOTA    1.7750     -0.0241</span></a>
<a class="sourceLine" id="cb125-225" data-line-number="225"><span class="co">#&gt; 228     0          DODGE    1.7047      0.2639</span></a>
<a class="sourceLine" id="cb125-226" data-line-number="226"><span class="co">#&gt; 229     0          DODGE    1.9879      0.2639</span></a>
<a class="sourceLine" id="cb125-227" data-line-number="227"><span class="co">#&gt; 230     0          DODGE    1.7579      0.2639</span></a>
<a class="sourceLine" id="cb125-228" data-line-number="228"><span class="co">#&gt; 231     0        DOUGLAS    2.0149      0.1557</span></a>
<a class="sourceLine" id="cb125-229" data-line-number="229"><span class="co">#&gt; 232     0        DOUGLAS    1.5892      0.1557</span></a>
<a class="sourceLine" id="cb125-230" data-line-number="230"><span class="co">#&gt; 233     0        DOUGLAS    1.9315      0.1557</span></a>
<a class="sourceLine" id="cb125-231" data-line-number="231"><span class="co">#&gt; 234     0        DOUGLAS    1.8718      0.1557</span></a>
<a class="sourceLine" id="cb125-232" data-line-number="232"><span class="co">#&gt; 235     1        DOUGLAS    1.3350      0.1557</span></a>
<a class="sourceLine" id="cb125-233" data-line-number="233"><span class="co">#&gt; 236     0        DOUGLAS    1.7228      0.1557</span></a>
<a class="sourceLine" id="cb125-234" data-line-number="234"><span class="co">#&gt; 237     0        DOUGLAS    2.0669      0.1557</span></a>
<a class="sourceLine" id="cb125-235" data-line-number="235"><span class="co">#&gt; 238     0        DOUGLAS    1.5041      0.1557</span></a>
<a class="sourceLine" id="cb125-236" data-line-number="236"><span class="co">#&gt; 239     0        DOUGLAS    1.0296      0.1557</span></a>
<a class="sourceLine" id="cb125-237" data-line-number="237"><span class="co">#&gt; 240     0      FARIBAULT    1.2528      0.2950</span></a>
<a class="sourceLine" id="cb125-238" data-line-number="238"><span class="co">#&gt; 241     0      FARIBAULT    1.4586      0.2950</span></a>
<a class="sourceLine" id="cb125-239" data-line-number="239"><span class="co">#&gt; 242     0      FARIBAULT    0.8755      0.2950</span></a>
<a class="sourceLine" id="cb125-240" data-line-number="240"><span class="co">#&gt; 243     1      FARIBAULT    0.3365      0.2950</span></a>
<a class="sourceLine" id="cb125-241" data-line-number="241"><span class="co">#&gt; 244     0      FARIBAULT    1.6677      0.2950</span></a>
<a class="sourceLine" id="cb125-242" data-line-number="242"><span class="co">#&gt; 245     0      FARIBAULT   -1.6094      0.2950</span></a>
<a class="sourceLine" id="cb125-243" data-line-number="243"><span class="co">#&gt; 246     1       FILLMORE    0.9555      0.4149</span></a>
<a class="sourceLine" id="cb125-244" data-line-number="244"><span class="co">#&gt; 247     0       FILLMORE    1.1939      0.4149</span></a>
<a class="sourceLine" id="cb125-245" data-line-number="245"><span class="co">#&gt; 248     0       FREEBORN    1.1939      0.2242</span></a>
<a class="sourceLine" id="cb125-246" data-line-number="246"><span class="co">#&gt; 249     0       FREEBORN    2.2721      0.2242</span></a>
<a class="sourceLine" id="cb125-247" data-line-number="247"><span class="co">#&gt; 250     0       FREEBORN    1.4586      0.2242</span></a>
<a class="sourceLine" id="cb125-248" data-line-number="248"><span class="co">#&gt; 251     0       FREEBORN    2.2083      0.2242</span></a>
<a class="sourceLine" id="cb125-249" data-line-number="249"><span class="co">#&gt; 252     0       FREEBORN    1.8563      0.2242</span></a>
<a class="sourceLine" id="cb125-250" data-line-number="250"><span class="co">#&gt; 253     0       FREEBORN    3.4874      0.2242</span></a>
<a class="sourceLine" id="cb125-251" data-line-number="251"><span class="co">#&gt; 254     0       FREEBORN    2.5878      0.2242</span></a>
<a class="sourceLine" id="cb125-252" data-line-number="252"><span class="co">#&gt; 255     1       FREEBORN    0.8329      0.2242</span></a>
<a class="sourceLine" id="cb125-253" data-line-number="253"><span class="co">#&gt; 256     1       FREEBORN    1.7405      0.2242</span></a>
<a class="sourceLine" id="cb125-254" data-line-number="254"><span class="co">#&gt; 257     0        GOODHUE    2.6672      0.1966</span></a>
<a class="sourceLine" id="cb125-255" data-line-number="255"><span class="co">#&gt; 258     1        GOODHUE    1.9459      0.1966</span></a>
<a class="sourceLine" id="cb125-256" data-line-number="256"><span class="co">#&gt; 259     0        GOODHUE    2.0412      0.1966</span></a>
<a class="sourceLine" id="cb125-257" data-line-number="257"><span class="co">#&gt; 260     1        GOODHUE    2.2925      0.1966</span></a>
<a class="sourceLine" id="cb125-258" data-line-number="258"><span class="co">#&gt; 261     0        GOODHUE    0.9933      0.1966</span></a>
<a class="sourceLine" id="cb125-259" data-line-number="259"><span class="co">#&gt; 262     0        GOODHUE    3.7751      0.1966</span></a>
<a class="sourceLine" id="cb125-260" data-line-number="260"><span class="co">#&gt; 263     0        GOODHUE    1.6094      0.1966</span></a>
<a class="sourceLine" id="cb125-261" data-line-number="261"><span class="co">#&gt; 264     0        GOODHUE    1.6094      0.1966</span></a>
<a class="sourceLine" id="cb125-262" data-line-number="262"><span class="co">#&gt; 265     0        GOODHUE    1.2809      0.1966</span></a>
<a class="sourceLine" id="cb125-263" data-line-number="263"><span class="co">#&gt; 266     0        GOODHUE    1.5892      0.1966</span></a>
<a class="sourceLine" id="cb125-264" data-line-number="264"><span class="co">#&gt; 267     0        GOODHUE    1.7405      0.1966</span></a>
<a class="sourceLine" id="cb125-265" data-line-number="265"><span class="co">#&gt; 268     0        GOODHUE    1.2809      0.1966</span></a>
<a class="sourceLine" id="cb125-266" data-line-number="266"><span class="co">#&gt; 269     0        GOODHUE    1.3863      0.1966</span></a>
<a class="sourceLine" id="cb125-267" data-line-number="267"><span class="co">#&gt; 270     0        GOODHUE    1.9169      0.1966</span></a>
<a class="sourceLine" id="cb125-268" data-line-number="268"><span class="co">#&gt; 271     0       HENNEPIN    2.0794     -0.0965</span></a>
<a class="sourceLine" id="cb125-269" data-line-number="269"><span class="co">#&gt; 272     0       HENNEPIN    1.2238     -0.0965</span></a>
<a class="sourceLine" id="cb125-270" data-line-number="270"><span class="co">#&gt; 273     1       HENNEPIN    0.7885     -0.0965</span></a>
<a class="sourceLine" id="cb125-271" data-line-number="271"><span class="co">#&gt; 274     0       HENNEPIN    0.5306     -0.0965</span></a>
<a class="sourceLine" id="cb125-272" data-line-number="272"><span class="co">#&gt; 275     0       HENNEPIN    1.4110     -0.0965</span></a>
<a class="sourceLine" id="cb125-273" data-line-number="273"><span class="co">#&gt; 276     0       HENNEPIN    0.6419     -0.0965</span></a>
<a class="sourceLine" id="cb125-274" data-line-number="274"><span class="co">#&gt; 277     0       HENNEPIN    0.9555     -0.0965</span></a>
<a class="sourceLine" id="cb125-275" data-line-number="275"><span class="co">#&gt; 278     0       HENNEPIN    2.4248     -0.0965</span></a>
<a class="sourceLine" id="cb125-276" data-line-number="276"><span class="co">#&gt; 279     0       HENNEPIN    0.9933     -0.0965</span></a>
<a class="sourceLine" id="cb125-277" data-line-number="277"><span class="co">#&gt; 280     0       HENNEPIN    1.3863     -0.0965</span></a>
<a class="sourceLine" id="cb125-278" data-line-number="278"><span class="co">#&gt; 281     0       HENNEPIN    2.0149     -0.0965</span></a>
<a class="sourceLine" id="cb125-279" data-line-number="279"><span class="co">#&gt; 282     0       HENNEPIN    0.3365     -0.0965</span></a>
<a class="sourceLine" id="cb125-280" data-line-number="280"><span class="co">#&gt; 283     0       HENNEPIN    0.0000     -0.0965</span></a>
<a class="sourceLine" id="cb125-281" data-line-number="281"><span class="co">#&gt; 284     0       HENNEPIN   -0.6931     -0.0965</span></a>
<a class="sourceLine" id="cb125-282" data-line-number="282"><span class="co">#&gt; 285     1       HENNEPIN    0.9555     -0.0965</span></a>
<a class="sourceLine" id="cb125-283" data-line-number="283"><span class="co">#&gt; 286     0       HENNEPIN    1.8083     -0.0965</span></a>
<a class="sourceLine" id="cb125-284" data-line-number="284"><span class="co">#&gt; 287     0       HENNEPIN    0.7419     -0.0965</span></a>
<a class="sourceLine" id="cb125-285" data-line-number="285"><span class="co">#&gt; 288     0       HENNEPIN    1.7047     -0.0965</span></a>
<a class="sourceLine" id="cb125-286" data-line-number="286"><span class="co">#&gt; 289     0       HENNEPIN    1.1314     -0.0965</span></a>
<a class="sourceLine" id="cb125-287" data-line-number="287"><span class="co">#&gt; 290     0       HENNEPIN    1.0986     -0.0965</span></a>
<a class="sourceLine" id="cb125-288" data-line-number="288"><span class="co">#&gt; 291     0       HENNEPIN    1.7228     -0.0965</span></a>
<a class="sourceLine" id="cb125-289" data-line-number="289"><span class="co">#&gt; 292     0       HENNEPIN    1.4351     -0.0965</span></a>
<a class="sourceLine" id="cb125-290" data-line-number="290"><span class="co">#&gt; 293     0       HENNEPIN    1.3863     -0.0965</span></a>
<a class="sourceLine" id="cb125-291" data-line-number="291"><span class="co">#&gt; 294     0       HENNEPIN    2.7081     -0.0965</span></a>
<a class="sourceLine" id="cb125-292" data-line-number="292"><span class="co">#&gt; 295     0       HENNEPIN    1.9879     -0.0965</span></a>
<a class="sourceLine" id="cb125-293" data-line-number="293"><span class="co">#&gt; 296     0       HENNEPIN    0.8755     -0.0965</span></a>
<a class="sourceLine" id="cb125-294" data-line-number="294"><span class="co">#&gt; 297     1       HENNEPIN    1.0647     -0.0965</span></a>
<a class="sourceLine" id="cb125-295" data-line-number="295"><span class="co">#&gt; 298     0       HENNEPIN    1.5041     -0.0965</span></a>
<a class="sourceLine" id="cb125-296" data-line-number="296"><span class="co">#&gt; 299     0       HENNEPIN    0.4700     -0.0965</span></a>
<a class="sourceLine" id="cb125-297" data-line-number="297"><span class="co">#&gt; 300     0       HENNEPIN    2.1633     -0.0965</span></a>
<a class="sourceLine" id="cb125-298" data-line-number="298"><span class="co">#&gt; 301     0       HENNEPIN    1.7405     -0.0965</span></a>
<a class="sourceLine" id="cb125-299" data-line-number="299"><span class="co">#&gt; 302     0       HENNEPIN    2.1633     -0.0965</span></a>
<a class="sourceLine" id="cb125-300" data-line-number="300"><span class="co">#&gt; 303     0       HENNEPIN    1.3610     -0.0965</span></a>
<a class="sourceLine" id="cb125-301" data-line-number="301"><span class="co">#&gt; 304     0       HENNEPIN    0.6419     -0.0965</span></a>
<a class="sourceLine" id="cb125-302" data-line-number="302"><span class="co">#&gt; 305     0       HENNEPIN    0.6931     -0.0965</span></a>
<a class="sourceLine" id="cb125-303" data-line-number="303"><span class="co">#&gt; 306     0       HENNEPIN    1.7228     -0.0965</span></a>
<a class="sourceLine" id="cb125-304" data-line-number="304"><span class="co">#&gt; 307     0       HENNEPIN    0.9555     -0.0965</span></a>
<a class="sourceLine" id="cb125-305" data-line-number="305"><span class="co">#&gt; 308     1       HENNEPIN   -0.1054     -0.0965</span></a>
<a class="sourceLine" id="cb125-306" data-line-number="306"><span class="co">#&gt; 309     0       HENNEPIN    0.7885     -0.0965</span></a>
<a class="sourceLine" id="cb125-307" data-line-number="307"><span class="co">#&gt; 310     0       HENNEPIN    1.0647     -0.0965</span></a>
<a class="sourceLine" id="cb125-308" data-line-number="308"><span class="co">#&gt; 311     0       HENNEPIN    1.3863     -0.0965</span></a>
<a class="sourceLine" id="cb125-309" data-line-number="309"><span class="co">#&gt; 312     0       HENNEPIN    1.4816     -0.0965</span></a>
<a class="sourceLine" id="cb125-310" data-line-number="310"><span class="co">#&gt; 313     0       HENNEPIN    1.5686     -0.0965</span></a>
<a class="sourceLine" id="cb125-311" data-line-number="311"><span class="co">#&gt; 314     0       HENNEPIN    1.0647     -0.0965</span></a>
<a class="sourceLine" id="cb125-312" data-line-number="312"><span class="co">#&gt; 315     0       HENNEPIN    1.4351     -0.0965</span></a>
<a class="sourceLine" id="cb125-313" data-line-number="313"><span class="co">#&gt; 316     0       HENNEPIN    0.5306     -0.0965</span></a>
<a class="sourceLine" id="cb125-314" data-line-number="314"><span class="co">#&gt; 317     0       HENNEPIN    1.4816     -0.0965</span></a>
<a class="sourceLine" id="cb125-315" data-line-number="315"><span class="co">#&gt; 318     1       HENNEPIN   -0.2231     -0.0965</span></a>
<a class="sourceLine" id="cb125-316" data-line-number="316"><span class="co">#&gt; 319     0       HENNEPIN    1.7228     -0.0965</span></a>
<a class="sourceLine" id="cb125-317" data-line-number="317"><span class="co">#&gt; 320     1       HENNEPIN    1.2238     -0.0965</span></a>
<a class="sourceLine" id="cb125-318" data-line-number="318"><span class="co">#&gt; 321     0       HENNEPIN    1.7228     -0.0965</span></a>
<a class="sourceLine" id="cb125-319" data-line-number="319"><span class="co">#&gt; 322     0       HENNEPIN    0.9555     -0.0965</span></a>
<a class="sourceLine" id="cb125-320" data-line-number="320"><span class="co">#&gt; 323     0       HENNEPIN    1.0296     -0.0965</span></a>
<a class="sourceLine" id="cb125-321" data-line-number="321"><span class="co">#&gt; 324     0       HENNEPIN    2.1401     -0.0965</span></a>
<a class="sourceLine" id="cb125-322" data-line-number="322"><span class="co">#&gt; 325     0       HENNEPIN    1.2238     -0.0965</span></a>
<a class="sourceLine" id="cb125-323" data-line-number="323"><span class="co">#&gt; 326     0       HENNEPIN    1.1939     -0.0965</span></a>
<a class="sourceLine" id="cb125-324" data-line-number="324"><span class="co">#&gt; 327     0       HENNEPIN    2.1633     -0.0965</span></a>
<a class="sourceLine" id="cb125-325" data-line-number="325"><span class="co">#&gt; 328     0       HENNEPIN    0.5878     -0.0965</span></a>
<a class="sourceLine" id="cb125-326" data-line-number="326"><span class="co">#&gt; 329     0       HENNEPIN    1.7579     -0.0965</span></a>
<a class="sourceLine" id="cb125-327" data-line-number="327"><span class="co">#&gt; 330     0       HENNEPIN    2.5726     -0.0965</span></a>
<a class="sourceLine" id="cb125-328" data-line-number="328"><span class="co">#&gt; 331     0       HENNEPIN    1.0296     -0.0965</span></a>
<a class="sourceLine" id="cb125-329" data-line-number="329"><span class="co">#&gt; 332     0       HENNEPIN    1.5686     -0.0965</span></a>
<a class="sourceLine" id="cb125-330" data-line-number="330"><span class="co">#&gt; 333     0       HENNEPIN    1.7405     -0.0965</span></a>
<a class="sourceLine" id="cb125-331" data-line-number="331"><span class="co">#&gt; 334     0       HENNEPIN    2.6319     -0.0965</span></a>
<a class="sourceLine" id="cb125-332" data-line-number="332"><span class="co">#&gt; 335     1       HENNEPIN    2.0412     -0.0965</span></a>
<a class="sourceLine" id="cb125-333" data-line-number="333"><span class="co">#&gt; 336     0       HENNEPIN    1.7579     -0.0965</span></a>
<a class="sourceLine" id="cb125-334" data-line-number="334"><span class="co">#&gt; 337     0       HENNEPIN    1.5476     -0.0965</span></a>
<a class="sourceLine" id="cb125-335" data-line-number="335"><span class="co">#&gt; 338     0       HENNEPIN    2.0412     -0.0965</span></a>
<a class="sourceLine" id="cb125-336" data-line-number="336"><span class="co">#&gt; 339     0       HENNEPIN    0.9933     -0.0965</span></a>
<a class="sourceLine" id="cb125-337" data-line-number="337"><span class="co">#&gt; 340     0       HENNEPIN    1.5261     -0.0965</span></a>
<a class="sourceLine" id="cb125-338" data-line-number="338"><span class="co">#&gt; 341     0       HENNEPIN    1.7918     -0.0965</span></a>
<a class="sourceLine" id="cb125-339" data-line-number="339"><span class="co">#&gt; 342     0       HENNEPIN    0.8329     -0.0965</span></a>
<a class="sourceLine" id="cb125-340" data-line-number="340"><span class="co">#&gt; 343     0       HENNEPIN    0.9163     -0.0965</span></a>
<a class="sourceLine" id="cb125-341" data-line-number="341"><span class="co">#&gt; 344     0       HENNEPIN    1.4110     -0.0965</span></a>
<a class="sourceLine" id="cb125-342" data-line-number="342"><span class="co">#&gt; 345     0       HENNEPIN    1.5476     -0.0965</span></a>
<a class="sourceLine" id="cb125-343" data-line-number="343"><span class="co">#&gt; 346     0       HENNEPIN    1.5476     -0.0965</span></a>
<a class="sourceLine" id="cb125-344" data-line-number="344"><span class="co">#&gt; 347     0       HENNEPIN    2.3979     -0.0965</span></a>
<a class="sourceLine" id="cb125-345" data-line-number="345"><span class="co">#&gt; 348     0       HENNEPIN    2.0412     -0.0965</span></a>
<a class="sourceLine" id="cb125-346" data-line-number="346"><span class="co">#&gt; 349     0       HENNEPIN    1.1314     -0.0965</span></a>
<a class="sourceLine" id="cb125-347" data-line-number="347"><span class="co">#&gt; 350     0       HENNEPIN    0.4700     -0.0965</span></a>
<a class="sourceLine" id="cb125-348" data-line-number="348"><span class="co">#&gt; 351     1       HENNEPIN    0.5306     -0.0965</span></a>
<a class="sourceLine" id="cb125-349" data-line-number="349"><span class="co">#&gt; 352     0       HENNEPIN    2.8094     -0.0965</span></a>
<a class="sourceLine" id="cb125-350" data-line-number="350"><span class="co">#&gt; 353     0       HENNEPIN    1.1632     -0.0965</span></a>
<a class="sourceLine" id="cb125-351" data-line-number="351"><span class="co">#&gt; 354     0       HENNEPIN    1.6487     -0.0965</span></a>
<a class="sourceLine" id="cb125-352" data-line-number="352"><span class="co">#&gt; 355     0       HENNEPIN    1.6094     -0.0965</span></a>
<a class="sourceLine" id="cb125-353" data-line-number="353"><span class="co">#&gt; 356     0       HENNEPIN    1.8083     -0.0965</span></a>
<a class="sourceLine" id="cb125-354" data-line-number="354"><span class="co">#&gt; 357     1       HENNEPIN    0.0000     -0.0965</span></a>
<a class="sourceLine" id="cb125-355" data-line-number="355"><span class="co">#&gt; 358     0       HENNEPIN    0.6419     -0.0965</span></a>
<a class="sourceLine" id="cb125-356" data-line-number="356"><span class="co">#&gt; 359     0       HENNEPIN    1.3863     -0.0965</span></a>
<a class="sourceLine" id="cb125-357" data-line-number="357"><span class="co">#&gt; 360     0       HENNEPIN    1.7405     -0.0965</span></a>
<a class="sourceLine" id="cb125-358" data-line-number="358"><span class="co">#&gt; 361     1       HENNEPIN   -0.6931     -0.0965</span></a>
<a class="sourceLine" id="cb125-359" data-line-number="359"><span class="co">#&gt; 362     0       HENNEPIN    0.9933     -0.0965</span></a>
<a class="sourceLine" id="cb125-360" data-line-number="360"><span class="co">#&gt; 363     0       HENNEPIN    1.3083     -0.0965</span></a>
<a class="sourceLine" id="cb125-361" data-line-number="361"><span class="co">#&gt; 364     0       HENNEPIN    1.8405     -0.0965</span></a>
<a class="sourceLine" id="cb125-362" data-line-number="362"><span class="co">#&gt; 365     0       HENNEPIN    3.1655     -0.0965</span></a>
<a class="sourceLine" id="cb125-363" data-line-number="363"><span class="co">#&gt; 366     0       HENNEPIN    1.3863     -0.0965</span></a>
<a class="sourceLine" id="cb125-364" data-line-number="364"><span class="co">#&gt; 367     0       HENNEPIN    1.0986     -0.0965</span></a>
<a class="sourceLine" id="cb125-365" data-line-number="365"><span class="co">#&gt; 368     0       HENNEPIN    1.1314     -0.0965</span></a>
<a class="sourceLine" id="cb125-366" data-line-number="366"><span class="co">#&gt; 369     0       HENNEPIN    1.5686     -0.0965</span></a>
<a class="sourceLine" id="cb125-367" data-line-number="367"><span class="co">#&gt; 370     0       HENNEPIN    1.1314     -0.0965</span></a>
<a class="sourceLine" id="cb125-368" data-line-number="368"><span class="co">#&gt; 371     0       HENNEPIN    1.4586     -0.0965</span></a>
<a class="sourceLine" id="cb125-369" data-line-number="369"><span class="co">#&gt; 372     0       HENNEPIN    1.3610     -0.0965</span></a>
<a class="sourceLine" id="cb125-370" data-line-number="370"><span class="co">#&gt; 373     0       HENNEPIN    1.1314     -0.0965</span></a>
<a class="sourceLine" id="cb125-371" data-line-number="371"><span class="co">#&gt; 374     0       HENNEPIN    1.4816     -0.0965</span></a>
<a class="sourceLine" id="cb125-372" data-line-number="372"><span class="co">#&gt; 375     1       HENNEPIN    1.0986     -0.0965</span></a>
<a class="sourceLine" id="cb125-373" data-line-number="373"><span class="co">#&gt; 376     0        HOUSTON    1.2528      0.5035</span></a>
<a class="sourceLine" id="cb125-374" data-line-number="374"><span class="co">#&gt; 377     0        HOUSTON    2.1518      0.5035</span></a>
<a class="sourceLine" id="cb125-375" data-line-number="375"><span class="co">#&gt; 378     0        HOUSTON    2.2083      0.5035</span></a>
<a class="sourceLine" id="cb125-376" data-line-number="376"><span class="co">#&gt; 379     1        HOUSTON    1.5892      0.5035</span></a>
<a class="sourceLine" id="cb125-377" data-line-number="377"><span class="co">#&gt; 380     0        HOUSTON    1.3083      0.5035</span></a>
<a class="sourceLine" id="cb125-378" data-line-number="378"><span class="co">#&gt; 381     1        HOUSTON    0.8329      0.5035</span></a>
<a class="sourceLine" id="cb125-379" data-line-number="379"><span class="co">#&gt; 382     1        HUBBARD    1.0647     -0.4006</span></a>
<a class="sourceLine" id="cb125-380" data-line-number="380"><span class="co">#&gt; 383     1        HUBBARD   -0.1054     -0.4006</span></a>
<a class="sourceLine" id="cb125-381" data-line-number="381"><span class="co">#&gt; 384     0        HUBBARD    0.4700     -0.4006</span></a>
<a class="sourceLine" id="cb125-382" data-line-number="382"><span class="co">#&gt; 385     0        HUBBARD    1.5476     -0.4006</span></a>
<a class="sourceLine" id="cb125-383" data-line-number="383"><span class="co">#&gt; 386     1        HUBBARD    1.3350     -0.4006</span></a>
<a class="sourceLine" id="cb125-384" data-line-number="384"><span class="co">#&gt; 387     0         ISANTI    1.3083     -0.7519</span></a>
<a class="sourceLine" id="cb125-385" data-line-number="385"><span class="co">#&gt; 388     0         ISANTI    1.1314     -0.7519</span></a>
<a class="sourceLine" id="cb125-386" data-line-number="386"><span class="co">#&gt; 389     0         ISANTI    0.8329     -0.7519</span></a>
<a class="sourceLine" id="cb125-387" data-line-number="387"><span class="co">#&gt; 390     0         ITASCA    0.6931     -0.6633</span></a>
<a class="sourceLine" id="cb125-388" data-line-number="388"><span class="co">#&gt; 391     0         ITASCA    0.9933     -0.6633</span></a>
<a class="sourceLine" id="cb125-389" data-line-number="389"><span class="co">#&gt; 392     0         ITASCA    0.6419     -0.6633</span></a>
<a class="sourceLine" id="cb125-390" data-line-number="390"><span class="co">#&gt; 393     0         ITASCA    0.9163     -0.6633</span></a>
<a class="sourceLine" id="cb125-391" data-line-number="391"><span class="co">#&gt; 394     0         ITASCA    1.4816     -0.6633</span></a>
<a class="sourceLine" id="cb125-392" data-line-number="392"><span class="co">#&gt; 395     0         ITASCA    0.9933     -0.6633</span></a>
<a class="sourceLine" id="cb125-393" data-line-number="393"><span class="co">#&gt; 396     0         ITASCA    0.1823     -0.6633</span></a>
<a class="sourceLine" id="cb125-394" data-line-number="394"><span class="co">#&gt; 397     0         ITASCA    1.2238     -0.6633</span></a>
<a class="sourceLine" id="cb125-395" data-line-number="395"><span class="co">#&gt; 398     0         ITASCA    0.9555     -0.6633</span></a>
<a class="sourceLine" id="cb125-396" data-line-number="396"><span class="co">#&gt; 399     0         ITASCA    2.2513     -0.6633</span></a>
<a class="sourceLine" id="cb125-397" data-line-number="397"><span class="co">#&gt; 400     0         ITASCA    0.3365     -0.6633</span></a>
<a class="sourceLine" id="cb125-398" data-line-number="398"><span class="co">#&gt; 401     0        JACKSON    2.1401      0.3090</span></a>
<a class="sourceLine" id="cb125-399" data-line-number="399"><span class="co">#&gt; 402     0        JACKSON    1.6292      0.3090</span></a>
<a class="sourceLine" id="cb125-400" data-line-number="400"><span class="co">#&gt; 403     0        JACKSON    1.0986      0.3090</span></a>
<a class="sourceLine" id="cb125-401" data-line-number="401"><span class="co">#&gt; 404     0        JACKSON    2.5802      0.3090</span></a>
<a class="sourceLine" id="cb125-402" data-line-number="402"><span class="co">#&gt; 405     0        JACKSON    2.7344      0.3090</span></a>
<a class="sourceLine" id="cb125-403" data-line-number="403"><span class="co">#&gt; 406     0        KANABEC    0.6419     -0.0534</span></a>
<a class="sourceLine" id="cb125-404" data-line-number="404"><span class="co">#&gt; 407     0        KANABEC    1.3610     -0.0534</span></a>
<a class="sourceLine" id="cb125-405" data-line-number="405"><span class="co">#&gt; 408     0        KANABEC    2.0794     -0.0534</span></a>
<a class="sourceLine" id="cb125-406" data-line-number="406"><span class="co">#&gt; 409     0        KANABEC    0.9933     -0.0534</span></a>
<a class="sourceLine" id="cb125-407" data-line-number="407"><span class="co">#&gt; 410     0      KANDIYOHI    2.4336      0.1097</span></a>
<a class="sourceLine" id="cb125-408" data-line-number="408"><span class="co">#&gt; 411     0      KANDIYOHI    1.4351      0.1097</span></a>
<a class="sourceLine" id="cb125-409" data-line-number="409"><span class="co">#&gt; 412     0      KANDIYOHI    2.5177      0.1097</span></a>
<a class="sourceLine" id="cb125-410" data-line-number="410"><span class="co">#&gt; 413     0      KANDIYOHI    1.9169      0.1097</span></a>
<a class="sourceLine" id="cb125-411" data-line-number="411"><span class="co">#&gt; 414     0        KITTSON    1.9459     -0.0078</span></a>
<a class="sourceLine" id="cb125-412" data-line-number="412"><span class="co">#&gt; 415     1        KITTSON    1.5261     -0.0078</span></a>
<a class="sourceLine" id="cb125-413" data-line-number="413"><span class="co">#&gt; 416     1        KITTSON    0.0000     -0.0078</span></a>
<a class="sourceLine" id="cb125-414" data-line-number="414"><span class="co">#&gt; 417     0    KOOCHICHING    0.5878     -0.8818</span></a>
<a class="sourceLine" id="cb125-415" data-line-number="415"><span class="co">#&gt; 418     0    KOOCHICHING    0.4055     -0.8818</span></a>
<a class="sourceLine" id="cb125-416" data-line-number="416"><span class="co">#&gt; 419     1    KOOCHICHING    0.7419     -0.8818</span></a>
<a class="sourceLine" id="cb125-417" data-line-number="417"><span class="co">#&gt; 420     1    KOOCHICHING    0.0953     -0.8818</span></a>
<a class="sourceLine" id="cb125-418" data-line-number="418"><span class="co">#&gt; 421     0    KOOCHICHING    0.0953     -0.8818</span></a>
<a class="sourceLine" id="cb125-419" data-line-number="419"><span class="co">#&gt; 422     1    KOOCHICHING    1.0647     -0.8818</span></a>
<a class="sourceLine" id="cb125-420" data-line-number="420"><span class="co">#&gt; 423     1    KOOCHICHING    0.3365     -0.8818</span></a>
<a class="sourceLine" id="cb125-421" data-line-number="421"><span class="co">#&gt; 424     1    LACQUIPARLE    2.4336      0.3110</span></a>
<a class="sourceLine" id="cb125-422" data-line-number="422"><span class="co">#&gt; 426     0    LACQUIPARLE    2.7788      0.3110</span></a>
<a class="sourceLine" id="cb125-423" data-line-number="423"><span class="co">#&gt; 428     1           LAKE    0.3365     -0.6916</span></a>
<a class="sourceLine" id="cb125-424" data-line-number="424"><span class="co">#&gt; 429     0           LAKE    0.3365     -0.6916</span></a>
<a class="sourceLine" id="cb125-425" data-line-number="425"><span class="co">#&gt; 430     0           LAKE    0.5306     -0.6916</span></a>
<a class="sourceLine" id="cb125-426" data-line-number="426"><span class="co">#&gt; 431     0           LAKE    0.0000     -0.6916</span></a>
<a class="sourceLine" id="cb125-427" data-line-number="427"><span class="co">#&gt; 432     0           LAKE    1.0647     -0.6916</span></a>
<a class="sourceLine" id="cb125-428" data-line-number="428"><span class="co">#&gt; 433     0           LAKE   -0.5108     -0.6916</span></a>
<a class="sourceLine" id="cb125-429" data-line-number="429"><span class="co">#&gt; 434     0           LAKE    0.4700     -0.6916</span></a>
<a class="sourceLine" id="cb125-430" data-line-number="430"><span class="co">#&gt; 435     0           LAKE    1.9741     -0.6916</span></a>
<a class="sourceLine" id="cb125-431" data-line-number="431"><span class="co">#&gt; 436     0           LAKE   -0.5108     -0.6916</span></a>
<a class="sourceLine" id="cb125-432" data-line-number="432"><span class="co">#&gt; 437     0 LAKEOFTHEWOODS    2.3224     -0.6817</span></a>
<a class="sourceLine" id="cb125-433" data-line-number="433"><span class="co">#&gt; 438     1 LAKEOFTHEWOODS    1.4816     -0.6817</span></a>
<a class="sourceLine" id="cb125-434" data-line-number="434"><span class="co">#&gt; 439     0 LAKEOFTHEWOODS    1.2238     -0.6817</span></a>
<a class="sourceLine" id="cb125-435" data-line-number="435"><span class="co">#&gt; 440     1 LAKEOFTHEWOODS    1.0986     -0.6817</span></a>
<a class="sourceLine" id="cb125-436" data-line-number="436"><span class="co">#&gt; 441     0        LESUEUR    2.5337      0.1944</span></a>
<a class="sourceLine" id="cb125-437" data-line-number="437"><span class="co">#&gt; 442     1        LESUEUR    1.4586      0.1944</span></a>
<a class="sourceLine" id="cb125-438" data-line-number="438"><span class="co">#&gt; 443     0        LESUEUR    1.5261      0.1944</span></a>
<a class="sourceLine" id="cb125-439" data-line-number="439"><span class="co">#&gt; 444     0        LESUEUR    1.3863      0.1944</span></a>
<a class="sourceLine" id="cb125-440" data-line-number="440"><span class="co">#&gt; 445     0        LESUEUR    1.2238      0.1944</span></a>
<a class="sourceLine" id="cb125-441" data-line-number="441"><span class="co">#&gt; 446     0        LINCOLN    2.8679      0.4449</span></a>
<a class="sourceLine" id="cb125-442" data-line-number="442"><span class="co">#&gt; 447     0        LINCOLN    2.3702      0.4449</span></a>
<a class="sourceLine" id="cb125-443" data-line-number="443"><span class="co">#&gt; 448     0        LINCOLN    2.0794      0.4449</span></a>
<a class="sourceLine" id="cb125-444" data-line-number="444"><span class="co">#&gt; 449     1        LINCOLN    1.2809      0.4449</span></a>
<a class="sourceLine" id="cb125-445" data-line-number="445"><span class="co">#&gt; 450     0           LYON    1.8871      0.3947</span></a>
<a class="sourceLine" id="cb125-446" data-line-number="446"><span class="co">#&gt; 451     1           LYON    1.9459      0.3947</span></a>
<a class="sourceLine" id="cb125-447" data-line-number="447"><span class="co">#&gt; 452     0           LYON    1.6487      0.3947</span></a>
<a class="sourceLine" id="cb125-448" data-line-number="448"><span class="co">#&gt; 453     0           LYON    2.4932      0.3947</span></a>
<a class="sourceLine" id="cb125-449" data-line-number="449"><span class="co">#&gt; 454     0           LYON    1.6487      0.3947</span></a>
<a class="sourceLine" id="cb125-450" data-line-number="450"><span class="co">#&gt; 455     0           LYON    2.1972      0.3947</span></a>
<a class="sourceLine" id="cb125-451" data-line-number="451"><span class="co">#&gt; 456     0           LYON    1.7750      0.3947</span></a>
<a class="sourceLine" id="cb125-452" data-line-number="452"><span class="co">#&gt; 457     0           LYON    1.5476      0.3947</span></a>
<a class="sourceLine" id="cb125-453" data-line-number="453"><span class="co">#&gt; 458     0         MCLEOD    2.3418      0.1404</span></a>
<a class="sourceLine" id="cb125-454" data-line-number="454"><span class="co">#&gt; 459     0         MCLEOD    1.3863      0.1404</span></a>
<a class="sourceLine" id="cb125-455" data-line-number="455"><span class="co">#&gt; 460     0         MCLEOD    0.6419      0.1404</span></a>
<a class="sourceLine" id="cb125-456" data-line-number="456"><span class="co">#&gt; 461     0         MCLEOD    2.3026      0.1404</span></a>
<a class="sourceLine" id="cb125-457" data-line-number="457"><span class="co">#&gt; 462     0         MCLEOD    0.8755      0.1404</span></a>
<a class="sourceLine" id="cb125-458" data-line-number="458"><span class="co">#&gt; 463     0         MCLEOD    1.5041      0.1404</span></a>
<a class="sourceLine" id="cb125-459" data-line-number="459"><span class="co">#&gt; 464     0         MCLEOD    1.0647      0.1404</span></a>
<a class="sourceLine" id="cb125-460" data-line-number="460"><span class="co">#&gt; 465     1         MCLEOD    0.1823      0.1404</span></a>
<a class="sourceLine" id="cb125-461" data-line-number="461"><span class="co">#&gt; 466     0         MCLEOD    0.2624      0.1404</span></a>
<a class="sourceLine" id="cb125-462" data-line-number="462"><span class="co">#&gt; 467     1         MCLEOD    0.5306      0.1404</span></a>
<a class="sourceLine" id="cb125-463" data-line-number="463"><span class="co">#&gt; 468     1         MCLEOD    3.2387      0.1404</span></a>
<a class="sourceLine" id="cb125-464" data-line-number="464"><span class="co">#&gt; 469     1         MCLEOD   -2.3026      0.1404</span></a>
<a class="sourceLine" id="cb125-465" data-line-number="465"><span class="co">#&gt; 470     0         MCLEOD    2.3702      0.1404</span></a>
<a class="sourceLine" id="cb125-466" data-line-number="466"><span class="co">#&gt; 471     0       MAHNOMEN    1.3863      0.1496</span></a>
<a class="sourceLine" id="cb125-467" data-line-number="467"><span class="co">#&gt; 472     1       MARSHALL    0.4700      0.0138</span></a>
<a class="sourceLine" id="cb125-468" data-line-number="468"><span class="co">#&gt; 473     0       MARSHALL    3.1739      0.0138</span></a>
<a class="sourceLine" id="cb125-469" data-line-number="469"><span class="co">#&gt; 474     1       MARSHALL    0.0000      0.0138</span></a>
<a class="sourceLine" id="cb125-470" data-line-number="470"><span class="co">#&gt; 475     1       MARSHALL    0.4055      0.0138</span></a>
<a class="sourceLine" id="cb125-471" data-line-number="471"><span class="co">#&gt; 476     1       MARSHALL    0.1823      0.0138</span></a>
<a class="sourceLine" id="cb125-472" data-line-number="472"><span class="co">#&gt; 477     0       MARSHALL    1.0647      0.0138</span></a>
<a class="sourceLine" id="cb125-473" data-line-number="473"><span class="co">#&gt; 478     0       MARSHALL    3.8774      0.0138</span></a>
<a class="sourceLine" id="cb125-474" data-line-number="474"><span class="co">#&gt; 479     1       MARSHALL    0.0000      0.0138</span></a>
<a class="sourceLine" id="cb125-475" data-line-number="475"><span class="co">#&gt; 480     0       MARSHALL    2.1282      0.0138</span></a>
<a class="sourceLine" id="cb125-476" data-line-number="476"><span class="co">#&gt; 481     0         MARTIN    1.4351      0.1659</span></a>
<a class="sourceLine" id="cb125-477" data-line-number="477"><span class="co">#&gt; 482     1         MARTIN   -0.5108      0.1659</span></a>
<a class="sourceLine" id="cb125-478" data-line-number="478"><span class="co">#&gt; 483     0         MARTIN    1.9169      0.1659</span></a>
<a class="sourceLine" id="cb125-479" data-line-number="479"><span class="co">#&gt; 484     0         MARTIN    2.0281      0.1659</span></a>
<a class="sourceLine" id="cb125-480" data-line-number="480"><span class="co">#&gt; 485     0         MARTIN    2.2300      0.1659</span></a>
<a class="sourceLine" id="cb125-481" data-line-number="481"><span class="co">#&gt; 486     0         MARTIN   -0.5108      0.1659</span></a>
<a class="sourceLine" id="cb125-482" data-line-number="482"><span class="co">#&gt; 487     0         MARTIN    0.4700      0.1659</span></a>
<a class="sourceLine" id="cb125-483" data-line-number="483"><span class="co">#&gt; 488     0         MEEKER    0.8755      0.0240</span></a>
<a class="sourceLine" id="cb125-484" data-line-number="484"><span class="co">#&gt; 489     0         MEEKER    1.3863      0.0240</span></a>
<a class="sourceLine" id="cb125-485" data-line-number="485"><span class="co">#&gt; 490     0         MEEKER    1.9879      0.0240</span></a>
<a class="sourceLine" id="cb125-486" data-line-number="486"><span class="co">#&gt; 491     0         MEEKER    0.7885      0.0240</span></a>
<a class="sourceLine" id="cb125-487" data-line-number="487"><span class="co">#&gt; 492     0         MEEKER    1.1939      0.0240</span></a>
<a class="sourceLine" id="cb125-488" data-line-number="488"><span class="co">#&gt; 493     1      MILLELACS   -0.5108     -0.2101</span></a>
<a class="sourceLine" id="cb125-489" data-line-number="489"><span class="co">#&gt; 494     0      MILLELACS    1.7579     -0.2101</span></a>
<a class="sourceLine" id="cb125-490" data-line-number="490"><span class="co">#&gt; 495     0       MORRISON    0.4055     -0.0932</span></a>
<a class="sourceLine" id="cb125-491" data-line-number="491"><span class="co">#&gt; 496     0       MORRISON    0.7885     -0.0932</span></a>
<a class="sourceLine" id="cb125-492" data-line-number="492"><span class="co">#&gt; 497     0       MORRISON    1.5041     -0.0932</span></a>
<a class="sourceLine" id="cb125-493" data-line-number="493"><span class="co">#&gt; 498     0       MORRISON    0.9163     -0.0932</span></a>
<a class="sourceLine" id="cb125-494" data-line-number="494"><span class="co">#&gt; 499     0       MORRISON    1.6094     -0.0932</span></a>
<a class="sourceLine" id="cb125-495" data-line-number="495"><span class="co">#&gt; 500     1       MORRISON    1.1314     -0.0932</span></a>
<a class="sourceLine" id="cb125-496" data-line-number="496"><span class="co">#&gt; 501     0       MORRISON    1.1314     -0.0932</span></a>
<a class="sourceLine" id="cb125-497" data-line-number="497"><span class="co">#&gt; 502     0       MORRISON    1.0647     -0.0932</span></a>
<a class="sourceLine" id="cb125-498" data-line-number="498"><span class="co">#&gt; 503     0       MORRISON    1.3863     -0.0932</span></a>
<a class="sourceLine" id="cb125-499" data-line-number="499"><span class="co">#&gt; 504     0          MOWER    2.3979      0.2609</span></a>
<a class="sourceLine" id="cb125-500" data-line-number="500"><span class="co">#&gt; 505     0          MOWER    1.8718      0.2609</span></a>
<a class="sourceLine" id="cb125-501" data-line-number="501"><span class="co">#&gt; 506     0          MOWER    0.7419      0.2609</span></a>
<a class="sourceLine" id="cb125-502" data-line-number="502"><span class="co">#&gt; 507     0          MOWER    1.1314      0.2609</span></a>
<a class="sourceLine" id="cb125-503" data-line-number="503"><span class="co">#&gt; 508     0          MOWER    1.5261      0.2609</span></a>
<a class="sourceLine" id="cb125-504" data-line-number="504"><span class="co">#&gt; 509     0          MOWER    0.7885      0.2609</span></a>
<a class="sourceLine" id="cb125-505" data-line-number="505"><span class="co">#&gt; 510     0          MOWER    2.0919      0.2609</span></a>
<a class="sourceLine" id="cb125-506" data-line-number="506"><span class="co">#&gt; 511     1          MOWER    0.3365      0.2609</span></a>
<a class="sourceLine" id="cb125-507" data-line-number="507"><span class="co">#&gt; 512     0          MOWER    2.2300      0.2609</span></a>
<a class="sourceLine" id="cb125-508" data-line-number="508"><span class="co">#&gt; 513     1          MOWER    0.1823      0.2609</span></a>
<a class="sourceLine" id="cb125-509" data-line-number="509"><span class="co">#&gt; 514     0          MOWER    2.3702      0.2609</span></a>
<a class="sourceLine" id="cb125-510" data-line-number="510"><span class="co">#&gt; 515     0          MOWER    3.1822      0.2609</span></a>
<a class="sourceLine" id="cb125-511" data-line-number="511"><span class="co">#&gt; 516     0          MOWER    2.2192      0.2609</span></a>
<a class="sourceLine" id="cb125-512" data-line-number="512"><span class="co">#&gt; 517     0         MURRAY    2.5014      0.3988</span></a>
<a class="sourceLine" id="cb125-513" data-line-number="513"><span class="co">#&gt; 518     0       NICOLLET    2.1041      0.2480</span></a>
<a class="sourceLine" id="cb125-514" data-line-number="514"><span class="co">#&gt; 519     0       NICOLLET    2.3888      0.2480</span></a>
<a class="sourceLine" id="cb125-515" data-line-number="515"><span class="co">#&gt; 520     0       NICOLLET    1.4586      0.2480</span></a>
<a class="sourceLine" id="cb125-516" data-line-number="516"><span class="co">#&gt; 521     0       NICOLLET    2.7600      0.2480</span></a>
<a class="sourceLine" id="cb125-517" data-line-number="517"><span class="co">#&gt; 522     0         NOBLES    1.7047      0.4055</span></a>
<a class="sourceLine" id="cb125-518" data-line-number="518"><span class="co">#&gt; 523     0         NOBLES    1.8405      0.4055</span></a>
<a class="sourceLine" id="cb125-519" data-line-number="519"><span class="co">#&gt; 524     0         NOBLES    2.2824      0.4055</span></a>
<a class="sourceLine" id="cb125-520" data-line-number="520"><span class="co">#&gt; 525     0         NORMAN    2.1041      0.2652</span></a>
<a class="sourceLine" id="cb125-521" data-line-number="521"><span class="co">#&gt; 526     0         NORMAN    0.5306      0.2652</span></a>
<a class="sourceLine" id="cb125-522" data-line-number="522"><span class="co">#&gt; 527     1         NORMAN    0.5306      0.2652</span></a>
<a class="sourceLine" id="cb125-523" data-line-number="523"><span class="co">#&gt; 528     0        OLMSTED    1.8718      0.2432</span></a>
<a class="sourceLine" id="cb125-524" data-line-number="524"><span class="co">#&gt; 529     0        OLMSTED    1.5041      0.2432</span></a>
<a class="sourceLine" id="cb125-525" data-line-number="525"><span class="co">#&gt; 530     0        OLMSTED    2.4248      0.2432</span></a>
<a class="sourceLine" id="cb125-526" data-line-number="526"><span class="co">#&gt; 531     0        OLMSTED    2.3125      0.2432</span></a>
<a class="sourceLine" id="cb125-527" data-line-number="527"><span class="co">#&gt; 532     0        OLMSTED    1.5261      0.2432</span></a>
<a class="sourceLine" id="cb125-528" data-line-number="528"><span class="co">#&gt; 533     0        OLMSTED    2.0919      0.2432</span></a>
<a class="sourceLine" id="cb125-529" data-line-number="529"><span class="co">#&gt; 534     0        OLMSTED    0.8755      0.2432</span></a>
<a class="sourceLine" id="cb125-530" data-line-number="530"><span class="co">#&gt; 535     0        OLMSTED    1.1939      0.2432</span></a>
<a class="sourceLine" id="cb125-531" data-line-number="531"><span class="co">#&gt; 536     0        OLMSTED    1.6292      0.2432</span></a>
<a class="sourceLine" id="cb125-532" data-line-number="532"><span class="co">#&gt; 537     0        OLMSTED    1.4351      0.2432</span></a>
<a class="sourceLine" id="cb125-533" data-line-number="533"><span class="co">#&gt; 538     0        OLMSTED    0.1823      0.2432</span></a>
<a class="sourceLine" id="cb125-534" data-line-number="534"><span class="co">#&gt; 539     0        OLMSTED    0.7419      0.2432</span></a>
<a class="sourceLine" id="cb125-535" data-line-number="535"><span class="co">#&gt; 540     1        OLMSTED    0.1823      0.2432</span></a>
<a class="sourceLine" id="cb125-536" data-line-number="536"><span class="co">#&gt; 541     0        OLMSTED    1.0986      0.2432</span></a>
<a class="sourceLine" id="cb125-537" data-line-number="537"><span class="co">#&gt; 542     0        OLMSTED    0.7885      0.2432</span></a>
<a class="sourceLine" id="cb125-538" data-line-number="538"><span class="co">#&gt; 543     0        OLMSTED    2.0669      0.2432</span></a>
<a class="sourceLine" id="cb125-539" data-line-number="539"><span class="co">#&gt; 544     0        OLMSTED    1.3610      0.2432</span></a>
<a class="sourceLine" id="cb125-540" data-line-number="540"><span class="co">#&gt; 545     0        OLMSTED    0.9555      0.2432</span></a>
<a class="sourceLine" id="cb125-541" data-line-number="541"><span class="co">#&gt; 546     0        OLMSTED    1.0986      0.2432</span></a>
<a class="sourceLine" id="cb125-542" data-line-number="542"><span class="co">#&gt; 547     1        OLMSTED    0.5878      0.2432</span></a>
<a class="sourceLine" id="cb125-543" data-line-number="543"><span class="co">#&gt; 548     0        OLMSTED    0.9555      0.2432</span></a>
<a class="sourceLine" id="cb125-544" data-line-number="544"><span class="co">#&gt; 549     0        OLMSTED    2.2513      0.2432</span></a>
<a class="sourceLine" id="cb125-545" data-line-number="545"><span class="co">#&gt; 550     1        OLMSTED   -0.3567      0.2432</span></a>
<a class="sourceLine" id="cb125-546" data-line-number="546"><span class="co">#&gt; 551     0      OTTERTAIL    1.0296     -0.2047</span></a>
<a class="sourceLine" id="cb125-547" data-line-number="547"><span class="co">#&gt; 552     1      OTTERTAIL    0.1823     -0.2047</span></a>
<a class="sourceLine" id="cb125-548" data-line-number="548"><span class="co">#&gt; 553     1      OTTERTAIL    0.7885     -0.2047</span></a>
<a class="sourceLine" id="cb125-549" data-line-number="549"><span class="co">#&gt; 554     0      OTTERTAIL    2.4932     -0.2047</span></a>
<a class="sourceLine" id="cb125-550" data-line-number="550"><span class="co">#&gt; 555     1      OTTERTAIL    2.5416     -0.2047</span></a>
<a class="sourceLine" id="cb125-551" data-line-number="551"><span class="co">#&gt; 556     0      OTTERTAIL    1.1939     -0.2047</span></a>
<a class="sourceLine" id="cb125-552" data-line-number="552"><span class="co">#&gt; 557     0      OTTERTAIL    1.4586     -0.2047</span></a>
<a class="sourceLine" id="cb125-553" data-line-number="553"><span class="co">#&gt; 558     0      OTTERTAIL    1.3610     -0.2047</span></a>
<a class="sourceLine" id="cb125-554" data-line-number="554"><span class="co">#&gt; 559     1     PENNINGTON    1.3350     -0.0740</span></a>
<a class="sourceLine" id="cb125-555" data-line-number="555"><span class="co">#&gt; 560     0     PENNINGTON    1.7750     -0.0740</span></a>
<a class="sourceLine" id="cb125-556" data-line-number="556"><span class="co">#&gt; 561     1     PENNINGTON   -0.9163     -0.0740</span></a>
<a class="sourceLine" id="cb125-557" data-line-number="557"><span class="co">#&gt; 562     0           PINE    1.4351     -0.1633</span></a>
<a class="sourceLine" id="cb125-558" data-line-number="558"><span class="co">#&gt; 563     0           PINE    1.0647     -0.1633</span></a>
<a class="sourceLine" id="cb125-559" data-line-number="559"><span class="co">#&gt; 564     0           PINE    0.6931     -0.1633</span></a>
<a class="sourceLine" id="cb125-560" data-line-number="560"><span class="co">#&gt; 565     1           PINE    0.2624     -0.1633</span></a>
<a class="sourceLine" id="cb125-561" data-line-number="561"><span class="co">#&gt; 566     0           PINE    0.2624     -0.1633</span></a>
<a class="sourceLine" id="cb125-562" data-line-number="562"><span class="co">#&gt; 567     0           PINE    0.4700     -0.1633</span></a>
<a class="sourceLine" id="cb125-563" data-line-number="563"><span class="co">#&gt; 568     0      PIPESTONE    2.2513      0.4786</span></a>
<a class="sourceLine" id="cb125-564" data-line-number="564"><span class="co">#&gt; 569     0      PIPESTONE    0.5878      0.4786</span></a>
<a class="sourceLine" id="cb125-565" data-line-number="565"><span class="co">#&gt; 570     0      PIPESTONE    2.5014      0.4786</span></a>
<a class="sourceLine" id="cb125-566" data-line-number="566"><span class="co">#&gt; 571     1      PIPESTONE    1.4816      0.4786</span></a>
<a class="sourceLine" id="cb125-567" data-line-number="567"><span class="co">#&gt; 572     0           POLK    1.9459      0.2661</span></a>
<a class="sourceLine" id="cb125-568" data-line-number="568"><span class="co">#&gt; 573     1           POLK    0.4055      0.2661</span></a>
<a class="sourceLine" id="cb125-569" data-line-number="569"><span class="co">#&gt; 574     1           POLK    0.9555      0.2661</span></a>
<a class="sourceLine" id="cb125-570" data-line-number="570"><span class="co">#&gt; 575     0           POLK    2.2721      0.2661</span></a>
<a class="sourceLine" id="cb125-571" data-line-number="571"><span class="co">#&gt; 576     0           POPE    1.3610      0.2811</span></a>
<a class="sourceLine" id="cb125-572" data-line-number="572"><span class="co">#&gt; 577     0           POPE    1.2528      0.2811</span></a>
<a class="sourceLine" id="cb125-573" data-line-number="573"><span class="co">#&gt; 578     0         RAMSEY    1.9315     -0.4181</span></a>
<a class="sourceLine" id="cb125-574" data-line-number="574"><span class="co">#&gt; 579     0         RAMSEY    1.3083     -0.4181</span></a>
<a class="sourceLine" id="cb125-575" data-line-number="575"><span class="co">#&gt; 580     0         RAMSEY    0.8329     -0.4181</span></a>
<a class="sourceLine" id="cb125-576" data-line-number="576"><span class="co">#&gt; 581     0         RAMSEY    0.9933     -0.4181</span></a>
<a class="sourceLine" id="cb125-577" data-line-number="577"><span class="co">#&gt; 582     0         RAMSEY    0.7885     -0.4181</span></a>
<a class="sourceLine" id="cb125-578" data-line-number="578"><span class="co">#&gt; 583     0         RAMSEY    1.9601     -0.4181</span></a>
<a class="sourceLine" id="cb125-579" data-line-number="579"><span class="co">#&gt; 584     0         RAMSEY    0.2624     -0.4181</span></a>
<a class="sourceLine" id="cb125-580" data-line-number="580"><span class="co">#&gt; 585     0         RAMSEY    1.3610     -0.4181</span></a>
<a class="sourceLine" id="cb125-581" data-line-number="581"><span class="co">#&gt; 586     0         RAMSEY    1.2809     -0.4181</span></a>
<a class="sourceLine" id="cb125-582" data-line-number="582"><span class="co">#&gt; 587     0         RAMSEY    1.4586     -0.4181</span></a>
<a class="sourceLine" id="cb125-583" data-line-number="583"><span class="co">#&gt; 588     1         RAMSEY    0.5306     -0.4181</span></a>
<a class="sourceLine" id="cb125-584" data-line-number="584"><span class="co">#&gt; 589     1         RAMSEY    1.0647     -0.4181</span></a>
<a class="sourceLine" id="cb125-585" data-line-number="585"><span class="co">#&gt; 590     0         RAMSEY    2.1633     -0.4181</span></a>
<a class="sourceLine" id="cb125-586" data-line-number="586"><span class="co">#&gt; 591     0         RAMSEY    1.8405     -0.4181</span></a>
<a class="sourceLine" id="cb125-587" data-line-number="587"><span class="co">#&gt; 592     0         RAMSEY    1.6677     -0.4181</span></a>
<a class="sourceLine" id="cb125-588" data-line-number="588"><span class="co">#&gt; 593     0         RAMSEY    1.0296     -0.4181</span></a>
<a class="sourceLine" id="cb125-589" data-line-number="589"><span class="co">#&gt; 594     0         RAMSEY    0.2624     -0.4181</span></a>
<a class="sourceLine" id="cb125-590" data-line-number="590"><span class="co">#&gt; 595     0         RAMSEY    1.2809     -0.4181</span></a>
<a class="sourceLine" id="cb125-591" data-line-number="591"><span class="co">#&gt; 596     0         RAMSEY    1.7228     -0.4181</span></a>
<a class="sourceLine" id="cb125-592" data-line-number="592"><span class="co">#&gt; 597     1         RAMSEY    2.3224     -0.4181</span></a>
<a class="sourceLine" id="cb125-593" data-line-number="593"><span class="co">#&gt; 598     0         RAMSEY    1.7228     -0.4181</span></a>
<a class="sourceLine" id="cb125-594" data-line-number="594"><span class="co">#&gt; 599     0         RAMSEY    0.2624     -0.4181</span></a>
<a class="sourceLine" id="cb125-595" data-line-number="595"><span class="co">#&gt; 600     0         RAMSEY    1.6094     -0.4181</span></a>
<a class="sourceLine" id="cb125-596" data-line-number="596"><span class="co">#&gt; 601     0         RAMSEY    1.4110     -0.4181</span></a>
<a class="sourceLine" id="cb125-597" data-line-number="597"><span class="co">#&gt; 602     0         RAMSEY    1.2809     -0.4181</span></a>
<a class="sourceLine" id="cb125-598" data-line-number="598"><span class="co">#&gt; 603     0         RAMSEY    0.9555     -0.4181</span></a>
<a class="sourceLine" id="cb125-599" data-line-number="599"><span class="co">#&gt; 604     0         RAMSEY    0.2624     -0.4181</span></a>
<a class="sourceLine" id="cb125-600" data-line-number="600"><span class="co">#&gt; 605     0         RAMSEY    1.0296     -0.4181</span></a>
<a class="sourceLine" id="cb125-601" data-line-number="601"><span class="co">#&gt; 606     0         RAMSEY    0.5878     -0.4181</span></a>
<a class="sourceLine" id="cb125-602" data-line-number="602"><span class="co">#&gt; 607     0         RAMSEY    1.1632     -0.4181</span></a>
<a class="sourceLine" id="cb125-603" data-line-number="603"><span class="co">#&gt; 608     0         RAMSEY   -0.2231     -0.4181</span></a>
<a class="sourceLine" id="cb125-604" data-line-number="604"><span class="co">#&gt; 609     0         RAMSEY    0.0953     -0.4181</span></a>
<a class="sourceLine" id="cb125-605" data-line-number="605"><span class="co">#&gt; 610     0        REDWOOD    0.6931      0.3663</span></a>
<a class="sourceLine" id="cb125-606" data-line-number="606"><span class="co">#&gt; 611     0        REDWOOD    1.3610      0.3663</span></a>
<a class="sourceLine" id="cb125-607" data-line-number="607"><span class="co">#&gt; 612     0        REDWOOD    2.1972      0.3663</span></a>
<a class="sourceLine" id="cb125-608" data-line-number="608"><span class="co">#&gt; 613     0        REDWOOD    2.0149      0.3663</span></a>
<a class="sourceLine" id="cb125-609" data-line-number="609"><span class="co">#&gt; 614     1        REDWOOD    3.0350      0.3663</span></a>
<a class="sourceLine" id="cb125-610" data-line-number="610"><span class="co">#&gt; 615     0       RENVILLE    1.8083      0.3806</span></a>
<a class="sourceLine" id="cb125-611" data-line-number="611"><span class="co">#&gt; 616     0       RENVILLE    0.7885      0.3806</span></a>
<a class="sourceLine" id="cb125-612" data-line-number="612"><span class="co">#&gt; 617     1       RENVILLE    1.7750      0.3806</span></a>
<a class="sourceLine" id="cb125-613" data-line-number="613"><span class="co">#&gt; 618     0           RICE    2.2824      0.1931</span></a>
<a class="sourceLine" id="cb125-614" data-line-number="614"><span class="co">#&gt; 619     0           RICE    1.8718      0.1931</span></a>
<a class="sourceLine" id="cb125-615" data-line-number="615"><span class="co">#&gt; 620     0           RICE    1.5476      0.1931</span></a>
<a class="sourceLine" id="cb125-616" data-line-number="616"><span class="co">#&gt; 621     0           RICE    1.7405      0.1931</span></a>
<a class="sourceLine" id="cb125-617" data-line-number="617"><span class="co">#&gt; 622     0           RICE    2.9497      0.1931</span></a>
<a class="sourceLine" id="cb125-618" data-line-number="618"><span class="co">#&gt; 623     1           RICE    0.9163      0.1931</span></a>
<a class="sourceLine" id="cb125-619" data-line-number="619"><span class="co">#&gt; 624     0           RICE    1.1314      0.1931</span></a>
<a class="sourceLine" id="cb125-620" data-line-number="620"><span class="co">#&gt; 625     0           RICE    1.6487      0.1931</span></a>
<a class="sourceLine" id="cb125-621" data-line-number="621"><span class="co">#&gt; 626     0           RICE    2.0541      0.1931</span></a>
<a class="sourceLine" id="cb125-622" data-line-number="622"><span class="co">#&gt; 627     0           RICE    2.1041      0.1931</span></a>
<a class="sourceLine" id="cb125-623" data-line-number="623"><span class="co">#&gt; 628     0           RICE    1.5686      0.1931</span></a>
<a class="sourceLine" id="cb125-624" data-line-number="624"><span class="co">#&gt; 629     0           ROCK    2.1401      0.5280</span></a>
<a class="sourceLine" id="cb125-625" data-line-number="625"><span class="co">#&gt; 630     0           ROCK    0.5306      0.5280</span></a>
<a class="sourceLine" id="cb125-626" data-line-number="626"><span class="co">#&gt; 631     1         ROSEAU    1.8083     -0.2120</span></a>
<a class="sourceLine" id="cb125-627" data-line-number="627"><span class="co">#&gt; 632     1         ROSEAU    0.1823     -0.2120</span></a>
<a class="sourceLine" id="cb125-628" data-line-number="628"><span class="co">#&gt; 633     0         ROSEAU    2.4423     -0.2120</span></a>
<a class="sourceLine" id="cb125-629" data-line-number="629"><span class="co">#&gt; 634     1         ROSEAU    1.4816     -0.2120</span></a>
<a class="sourceLine" id="cb125-630" data-line-number="630"><span class="co">#&gt; 635     1         ROSEAU    1.3083     -0.2120</span></a>
<a class="sourceLine" id="cb125-631" data-line-number="631"><span class="co">#&gt; 636     0         ROSEAU    2.3418     -0.2120</span></a>
<a class="sourceLine" id="cb125-632" data-line-number="632"><span class="co">#&gt; 637     1         ROSEAU    1.2528     -0.2120</span></a>
<a class="sourceLine" id="cb125-633" data-line-number="633"><span class="co">#&gt; 638     0         ROSEAU    1.1632     -0.2120</span></a>
<a class="sourceLine" id="cb125-634" data-line-number="634"><span class="co">#&gt; 639     0         ROSEAU    1.3083     -0.2120</span></a>
<a class="sourceLine" id="cb125-635" data-line-number="635"><span class="co">#&gt; 640     0         ROSEAU    1.0296     -0.2120</span></a>
<a class="sourceLine" id="cb125-636" data-line-number="636"><span class="co">#&gt; 641     0         ROSEAU    1.4110     -0.2120</span></a>
<a class="sourceLine" id="cb125-637" data-line-number="637"><span class="co">#&gt; 642     1         ROSEAU    0.2624     -0.2120</span></a>
<a class="sourceLine" id="cb125-638" data-line-number="638"><span class="co">#&gt; 643     1         ROSEAU    0.5878     -0.2120</span></a>
<a class="sourceLine" id="cb125-639" data-line-number="639"><span class="co">#&gt; 644     1         ROSEAU    1.4586     -0.2120</span></a>
<a class="sourceLine" id="cb125-640" data-line-number="640"><span class="co">#&gt; 645     0        STLOUIS   -0.1054     -0.4747</span></a>
<a class="sourceLine" id="cb125-641" data-line-number="641"><span class="co">#&gt; 646     1        STLOUIS   -0.5108     -0.4747</span></a>
<a class="sourceLine" id="cb125-642" data-line-number="642"><span class="co">#&gt; 647     0        STLOUIS    0.9163     -0.4747</span></a>
<a class="sourceLine" id="cb125-643" data-line-number="643"><span class="co">#&gt; 648     0        STLOUIS    0.8755     -0.4747</span></a>
<a class="sourceLine" id="cb125-644" data-line-number="644"><span class="co">#&gt; 649     0        STLOUIS    1.5476     -0.4747</span></a>
<a class="sourceLine" id="cb125-645" data-line-number="645"><span class="co">#&gt; 650     0        STLOUIS    2.4069     -0.4747</span></a>
<a class="sourceLine" id="cb125-646" data-line-number="646"><span class="co">#&gt; 651     0        STLOUIS    2.7081     -0.4747</span></a>
<a class="sourceLine" id="cb125-647" data-line-number="647"><span class="co">#&gt; 652     0        STLOUIS    2.1633     -0.4747</span></a>
<a class="sourceLine" id="cb125-648" data-line-number="648"><span class="co">#&gt; 653     0        STLOUIS    1.5261     -0.4747</span></a>
<a class="sourceLine" id="cb125-649" data-line-number="649"><span class="co">#&gt; 654     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-650" data-line-number="650"><span class="co">#&gt; 655     0        STLOUIS    1.3863     -0.4747</span></a>
<a class="sourceLine" id="cb125-651" data-line-number="651"><span class="co">#&gt; 656     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-652" data-line-number="652"><span class="co">#&gt; 657     0        STLOUIS    0.5306     -0.4747</span></a>
<a class="sourceLine" id="cb125-653" data-line-number="653"><span class="co">#&gt; 658     0        STLOUIS   -0.5108     -0.4747</span></a>
<a class="sourceLine" id="cb125-654" data-line-number="654"><span class="co">#&gt; 659     1        STLOUIS   -0.6931     -0.4747</span></a>
<a class="sourceLine" id="cb125-655" data-line-number="655"><span class="co">#&gt; 660     1        STLOUIS   -0.5108     -0.4747</span></a>
<a class="sourceLine" id="cb125-656" data-line-number="656"><span class="co">#&gt; 661     0        STLOUIS    2.1748     -0.4747</span></a>
<a class="sourceLine" id="cb125-657" data-line-number="657"><span class="co">#&gt; 662     1        STLOUIS    0.5306     -0.4747</span></a>
<a class="sourceLine" id="cb125-658" data-line-number="658"><span class="co">#&gt; 663     0        STLOUIS    0.4055     -0.4747</span></a>
<a class="sourceLine" id="cb125-659" data-line-number="659"><span class="co">#&gt; 664     0        STLOUIS    2.1748     -0.4747</span></a>
<a class="sourceLine" id="cb125-660" data-line-number="660"><span class="co">#&gt; 665     0        STLOUIS    2.4159     -0.4747</span></a>
<a class="sourceLine" id="cb125-661" data-line-number="661"><span class="co">#&gt; 666     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-662" data-line-number="662"><span class="co">#&gt; 667     0        STLOUIS    0.1823     -0.4747</span></a>
<a class="sourceLine" id="cb125-663" data-line-number="663"><span class="co">#&gt; 668     1        STLOUIS    0.0000     -0.4747</span></a>
<a class="sourceLine" id="cb125-664" data-line-number="664"><span class="co">#&gt; 669     0        STLOUIS   -0.2231     -0.4747</span></a>
<a class="sourceLine" id="cb125-665" data-line-number="665"><span class="co">#&gt; 670     0        STLOUIS    1.4586     -0.4747</span></a>
<a class="sourceLine" id="cb125-666" data-line-number="666"><span class="co">#&gt; 671     0        STLOUIS    1.2528     -0.4747</span></a>
<a class="sourceLine" id="cb125-667" data-line-number="667"><span class="co">#&gt; 672     1        STLOUIS    0.7885     -0.4747</span></a>
<a class="sourceLine" id="cb125-668" data-line-number="668"><span class="co">#&gt; 673     0        STLOUIS    1.0986     -0.4747</span></a>
<a class="sourceLine" id="cb125-669" data-line-number="669"><span class="co">#&gt; 674     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-670" data-line-number="670"><span class="co">#&gt; 675     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-671" data-line-number="671"><span class="co">#&gt; 676     0        STLOUIS    0.9163     -0.4747</span></a>
<a class="sourceLine" id="cb125-672" data-line-number="672"><span class="co">#&gt; 677     0        STLOUIS    0.5878     -0.4747</span></a>
<a class="sourceLine" id="cb125-673" data-line-number="673"><span class="co">#&gt; 678     1        STLOUIS   -0.1054     -0.4747</span></a>
<a class="sourceLine" id="cb125-674" data-line-number="674"><span class="co">#&gt; 679     0        STLOUIS    2.4681     -0.4747</span></a>
<a class="sourceLine" id="cb125-675" data-line-number="675"><span class="co">#&gt; 680     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-676" data-line-number="676"><span class="co">#&gt; 681     0        STLOUIS    1.0647     -0.4747</span></a>
<a class="sourceLine" id="cb125-677" data-line-number="677"><span class="co">#&gt; 682     1        STLOUIS    1.2809     -0.4747</span></a>
<a class="sourceLine" id="cb125-678" data-line-number="678"><span class="co">#&gt; 683     0        STLOUIS    1.3083     -0.4747</span></a>
<a class="sourceLine" id="cb125-679" data-line-number="679"><span class="co">#&gt; 684     0        STLOUIS    1.2809     -0.4747</span></a>
<a class="sourceLine" id="cb125-680" data-line-number="680"><span class="co">#&gt; 685     0        STLOUIS    1.1314     -0.4747</span></a>
<a class="sourceLine" id="cb125-681" data-line-number="681"><span class="co">#&gt; 686     1        STLOUIS    1.1939     -0.4747</span></a>
<a class="sourceLine" id="cb125-682" data-line-number="682"><span class="co">#&gt; 687     0        STLOUIS    1.1632     -0.4747</span></a>
<a class="sourceLine" id="cb125-683" data-line-number="683"><span class="co">#&gt; 688     0        STLOUIS    1.2238     -0.4747</span></a>
<a class="sourceLine" id="cb125-684" data-line-number="684"><span class="co">#&gt; 689     1        STLOUIS    0.5878     -0.4747</span></a>
<a class="sourceLine" id="cb125-685" data-line-number="685"><span class="co">#&gt; 690     0        STLOUIS    1.7405     -0.4747</span></a>
<a class="sourceLine" id="cb125-686" data-line-number="686"><span class="co">#&gt; 691     0        STLOUIS    1.2528     -0.4747</span></a>
<a class="sourceLine" id="cb125-687" data-line-number="687"><span class="co">#&gt; 692     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-688" data-line-number="688"><span class="co">#&gt; 693     0        STLOUIS    3.4751     -0.4747</span></a>
<a class="sourceLine" id="cb125-689" data-line-number="689"><span class="co">#&gt; 694     0        STLOUIS    0.1823     -0.4747</span></a>
<a class="sourceLine" id="cb125-690" data-line-number="690"><span class="co">#&gt; 695     0        STLOUIS    0.7885     -0.4747</span></a>
<a class="sourceLine" id="cb125-691" data-line-number="691"><span class="co">#&gt; 696     0        STLOUIS   -0.1054     -0.4747</span></a>
<a class="sourceLine" id="cb125-692" data-line-number="692"><span class="co">#&gt; 697     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-693" data-line-number="693"><span class="co">#&gt; 698     0        STLOUIS    0.3365     -0.4747</span></a>
<a class="sourceLine" id="cb125-694" data-line-number="694"><span class="co">#&gt; 699     0        STLOUIS    1.1632     -0.4747</span></a>
<a class="sourceLine" id="cb125-695" data-line-number="695"><span class="co">#&gt; 700     0        STLOUIS    1.9879     -0.4747</span></a>
<a class="sourceLine" id="cb125-696" data-line-number="696"><span class="co">#&gt; 701     0        STLOUIS    0.4055     -0.4747</span></a>
<a class="sourceLine" id="cb125-697" data-line-number="697"><span class="co">#&gt; 702     0        STLOUIS    0.3365     -0.4747</span></a>
<a class="sourceLine" id="cb125-698" data-line-number="698"><span class="co">#&gt; 703     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-699" data-line-number="699"><span class="co">#&gt; 704     0        STLOUIS    1.6292     -0.4747</span></a>
<a class="sourceLine" id="cb125-700" data-line-number="700"><span class="co">#&gt; 705     0        STLOUIS    0.8755     -0.4747</span></a>
<a class="sourceLine" id="cb125-701" data-line-number="701"><span class="co">#&gt; 706     0        STLOUIS    0.9163     -0.4747</span></a>
<a class="sourceLine" id="cb125-702" data-line-number="702"><span class="co">#&gt; 707     0        STLOUIS    0.2624     -0.4747</span></a>
<a class="sourceLine" id="cb125-703" data-line-number="703"><span class="co">#&gt; 708     0        STLOUIS    1.7047     -0.4747</span></a>
<a class="sourceLine" id="cb125-704" data-line-number="704"><span class="co">#&gt; 709     0        STLOUIS    0.1823     -0.4747</span></a>
<a class="sourceLine" id="cb125-705" data-line-number="705"><span class="co">#&gt; 710     0        STLOUIS    0.4055     -0.4747</span></a>
<a class="sourceLine" id="cb125-706" data-line-number="706"><span class="co">#&gt; 711     1        STLOUIS    1.9879     -0.4747</span></a>
<a class="sourceLine" id="cb125-707" data-line-number="707"><span class="co">#&gt; 712     0        STLOUIS    0.1823     -0.4747</span></a>
<a class="sourceLine" id="cb125-708" data-line-number="708"><span class="co">#&gt; 713     0        STLOUIS    1.2238     -0.4747</span></a>
<a class="sourceLine" id="cb125-709" data-line-number="709"><span class="co">#&gt; 714     0        STLOUIS    1.1939     -0.4747</span></a>
<a class="sourceLine" id="cb125-710" data-line-number="710"><span class="co">#&gt; 715     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-711" data-line-number="711"><span class="co">#&gt; 716     0        STLOUIS    1.3083     -0.4747</span></a>
<a class="sourceLine" id="cb125-712" data-line-number="712"><span class="co">#&gt; 717     0        STLOUIS   -0.1054     -0.4747</span></a>
<a class="sourceLine" id="cb125-713" data-line-number="713"><span class="co">#&gt; 718     0        STLOUIS    0.5306     -0.4747</span></a>
<a class="sourceLine" id="cb125-714" data-line-number="714"><span class="co">#&gt; 719     0        STLOUIS    0.4055     -0.4747</span></a>
<a class="sourceLine" id="cb125-715" data-line-number="715"><span class="co">#&gt; 720     0        STLOUIS    1.0296     -0.4747</span></a>
<a class="sourceLine" id="cb125-716" data-line-number="716"><span class="co">#&gt; 721     0        STLOUIS    1.2238     -0.4747</span></a>
<a class="sourceLine" id="cb125-717" data-line-number="717"><span class="co">#&gt; 722     0        STLOUIS    0.0000     -0.4747</span></a>
<a class="sourceLine" id="cb125-718" data-line-number="718"><span class="co">#&gt; 723     0        STLOUIS   -0.3567     -0.4747</span></a>
<a class="sourceLine" id="cb125-719" data-line-number="719"><span class="co">#&gt; 724     0        STLOUIS    0.7419     -0.4747</span></a>
<a class="sourceLine" id="cb125-720" data-line-number="720"><span class="co">#&gt; 725     0        STLOUIS    0.6931     -0.4747</span></a>
<a class="sourceLine" id="cb125-721" data-line-number="721"><span class="co">#&gt; 726     0        STLOUIS    0.0000     -0.4747</span></a>
<a class="sourceLine" id="cb125-722" data-line-number="722"><span class="co">#&gt; 727     0        STLOUIS    1.7047     -0.4747</span></a>
<a class="sourceLine" id="cb125-723" data-line-number="723"><span class="co">#&gt; 728     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-724" data-line-number="724"><span class="co">#&gt; 729     0        STLOUIS    1.1632     -0.4747</span></a>
<a class="sourceLine" id="cb125-725" data-line-number="725"><span class="co">#&gt; 730     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-726" data-line-number="726"><span class="co">#&gt; 731     1        STLOUIS    0.0000     -0.4747</span></a>
<a class="sourceLine" id="cb125-727" data-line-number="727"><span class="co">#&gt; 732     0        STLOUIS    1.2238     -0.4747</span></a>
<a class="sourceLine" id="cb125-728" data-line-number="728"><span class="co">#&gt; 733     0        STLOUIS    0.5878     -0.4747</span></a>
<a class="sourceLine" id="cb125-729" data-line-number="729"><span class="co">#&gt; 734     0        STLOUIS    1.1632     -0.4747</span></a>
<a class="sourceLine" id="cb125-730" data-line-number="730"><span class="co">#&gt; 735     1        STLOUIS   -0.2231     -0.4747</span></a>
<a class="sourceLine" id="cb125-731" data-line-number="731"><span class="co">#&gt; 736     0        STLOUIS    1.4816     -0.4747</span></a>
<a class="sourceLine" id="cb125-732" data-line-number="732"><span class="co">#&gt; 737     0        STLOUIS    0.4055     -0.4747</span></a>
<a class="sourceLine" id="cb125-733" data-line-number="733"><span class="co">#&gt; 738     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-734" data-line-number="734"><span class="co">#&gt; 739     0        STLOUIS    0.4700     -0.4747</span></a>
<a class="sourceLine" id="cb125-735" data-line-number="735"><span class="co">#&gt; 740     1        STLOUIS    0.8329     -0.4747</span></a>
<a class="sourceLine" id="cb125-736" data-line-number="736"><span class="co">#&gt; 741     0        STLOUIS    0.9163     -0.4747</span></a>
<a class="sourceLine" id="cb125-737" data-line-number="737"><span class="co">#&gt; 742     0        STLOUIS    1.0296     -0.4747</span></a>
<a class="sourceLine" id="cb125-738" data-line-number="738"><span class="co">#&gt; 743     0        STLOUIS    0.5878     -0.4747</span></a>
<a class="sourceLine" id="cb125-739" data-line-number="739"><span class="co">#&gt; 744     1        STLOUIS    0.1823     -0.4747</span></a>
<a class="sourceLine" id="cb125-740" data-line-number="740"><span class="co">#&gt; 745     1        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-741" data-line-number="741"><span class="co">#&gt; 746     0        STLOUIS   -1.2040     -0.4747</span></a>
<a class="sourceLine" id="cb125-742" data-line-number="742"><span class="co">#&gt; 747     0        STLOUIS    0.8329     -0.4747</span></a>
<a class="sourceLine" id="cb125-743" data-line-number="743"><span class="co">#&gt; 748     0        STLOUIS    1.5476     -0.4747</span></a>
<a class="sourceLine" id="cb125-744" data-line-number="744"><span class="co">#&gt; 749     0        STLOUIS    0.7885     -0.4747</span></a>
<a class="sourceLine" id="cb125-745" data-line-number="745"><span class="co">#&gt; 750     0        STLOUIS    0.7419     -0.4747</span></a>
<a class="sourceLine" id="cb125-746" data-line-number="746"><span class="co">#&gt; 751     0        STLOUIS   -0.2231     -0.4747</span></a>
<a class="sourceLine" id="cb125-747" data-line-number="747"><span class="co">#&gt; 752     0        STLOUIS    1.8718     -0.4747</span></a>
<a class="sourceLine" id="cb125-748" data-line-number="748"><span class="co">#&gt; 753     0        STLOUIS    1.1314     -0.4747</span></a>
<a class="sourceLine" id="cb125-749" data-line-number="749"><span class="co">#&gt; 754     0        STLOUIS    0.7419     -0.4747</span></a>
<a class="sourceLine" id="cb125-750" data-line-number="750"><span class="co">#&gt; 755     0        STLOUIS    0.0000     -0.4747</span></a>
<a class="sourceLine" id="cb125-751" data-line-number="751"><span class="co">#&gt; 756     0        STLOUIS    1.2238     -0.4747</span></a>
<a class="sourceLine" id="cb125-752" data-line-number="752"><span class="co">#&gt; 757     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-753" data-line-number="753"><span class="co">#&gt; 758     0        STLOUIS    0.6419     -0.4747</span></a>
<a class="sourceLine" id="cb125-754" data-line-number="754"><span class="co">#&gt; 759     0        STLOUIS    0.8329     -0.4747</span></a>
<a class="sourceLine" id="cb125-755" data-line-number="755"><span class="co">#&gt; 760     0        STLOUIS    1.4816     -0.4747</span></a>
<a class="sourceLine" id="cb125-756" data-line-number="756"><span class="co">#&gt; 761     1          SCOTT    2.9653      0.0631</span></a>
<a class="sourceLine" id="cb125-757" data-line-number="757"><span class="co">#&gt; 762     1          SCOTT    2.2192      0.0631</span></a>
<a class="sourceLine" id="cb125-758" data-line-number="758"><span class="co">#&gt; 763     0          SCOTT    0.7419      0.0631</span></a>
<a class="sourceLine" id="cb125-759" data-line-number="759"><span class="co">#&gt; 764     0          SCOTT    2.4423      0.0631</span></a>
<a class="sourceLine" id="cb125-760" data-line-number="760"><span class="co">#&gt; 765     0          SCOTT    2.3321      0.0631</span></a>
<a class="sourceLine" id="cb125-761" data-line-number="761"><span class="co">#&gt; 766     1          SCOTT    0.7885      0.0631</span></a>
<a class="sourceLine" id="cb125-762" data-line-number="762"><span class="co">#&gt; 767     0          SCOTT    0.2624      0.0631</span></a>
<a class="sourceLine" id="cb125-763" data-line-number="763"><span class="co">#&gt; 768     0          SCOTT    1.1939      0.0631</span></a>
<a class="sourceLine" id="cb125-764" data-line-number="764"><span class="co">#&gt; 769     1          SCOTT    0.7419      0.0631</span></a>
<a class="sourceLine" id="cb125-765" data-line-number="765"><span class="co">#&gt; 770     0          SCOTT    1.4816      0.0631</span></a>
<a class="sourceLine" id="cb125-766" data-line-number="766"><span class="co">#&gt; 771     0          SCOTT    0.8329      0.0631</span></a>
<a class="sourceLine" id="cb125-767" data-line-number="767"><span class="co">#&gt; 772     0          SCOTT    1.7047      0.0631</span></a>
<a class="sourceLine" id="cb125-768" data-line-number="768"><span class="co">#&gt; 773     0          SCOTT    3.2308      0.0631</span></a>
<a class="sourceLine" id="cb125-769" data-line-number="769"><span class="co">#&gt; 774     0      SHERBURNE    1.6487     -0.6834</span></a>
<a class="sourceLine" id="cb125-770" data-line-number="770"><span class="co">#&gt; 775     0      SHERBURNE    0.8755     -0.6834</span></a>
<a class="sourceLine" id="cb125-771" data-line-number="771"><span class="co">#&gt; 776     0      SHERBURNE    1.1939     -0.6834</span></a>
<a class="sourceLine" id="cb125-772" data-line-number="772"><span class="co">#&gt; 777     0      SHERBURNE    0.9555     -0.6834</span></a>
<a class="sourceLine" id="cb125-773" data-line-number="773"><span class="co">#&gt; 778     0      SHERBURNE    1.0647     -0.6834</span></a>
<a class="sourceLine" id="cb125-774" data-line-number="774"><span class="co">#&gt; 779     0      SHERBURNE    1.1632     -0.6834</span></a>
<a class="sourceLine" id="cb125-775" data-line-number="775"><span class="co">#&gt; 780     0      SHERBURNE    0.5306     -0.6834</span></a>
<a class="sourceLine" id="cb125-776" data-line-number="776"><span class="co">#&gt; 781     0      SHERBURNE    1.5686     -0.6834</span></a>
<a class="sourceLine" id="cb125-777" data-line-number="777"><span class="co">#&gt; 782     0         SIBLEY    1.4110      0.2372</span></a>
<a class="sourceLine" id="cb125-778" data-line-number="778"><span class="co">#&gt; 783     0         SIBLEY    1.6292      0.2372</span></a>
<a class="sourceLine" id="cb125-779" data-line-number="779"><span class="co">#&gt; 784     0         SIBLEY    0.4700      0.2372</span></a>
<a class="sourceLine" id="cb125-780" data-line-number="780"><span class="co">#&gt; 785     0         SIBLEY    1.5892      0.2372</span></a>
<a class="sourceLine" id="cb125-781" data-line-number="781"><span class="co">#&gt; 786     0        STEARNS    2.0281      0.1164</span></a>
<a class="sourceLine" id="cb125-782" data-line-number="782"><span class="co">#&gt; 787     0        STEARNS    1.8718      0.1164</span></a>
<a class="sourceLine" id="cb125-783" data-line-number="783"><span class="co">#&gt; 788     0        STEARNS    2.1282      0.1164</span></a>
<a class="sourceLine" id="cb125-784" data-line-number="784"><span class="co">#&gt; 789     0        STEARNS    0.7885      0.1164</span></a>
<a class="sourceLine" id="cb125-785" data-line-number="785"><span class="co">#&gt; 790     0        STEARNS    1.2238      0.1164</span></a>
<a class="sourceLine" id="cb125-786" data-line-number="786"><span class="co">#&gt; 791     0        STEARNS    0.3365      0.1164</span></a>
<a class="sourceLine" id="cb125-787" data-line-number="787"><span class="co">#&gt; 792     0        STEARNS    1.6292      0.1164</span></a>
<a class="sourceLine" id="cb125-788" data-line-number="788"><span class="co">#&gt; 793     1        STEARNS    0.0953      0.1164</span></a>
<a class="sourceLine" id="cb125-789" data-line-number="789"><span class="co">#&gt; 794     0        STEARNS    1.9601      0.1164</span></a>
<a class="sourceLine" id="cb125-790" data-line-number="790"><span class="co">#&gt; 795     0        STEARNS    1.7579      0.1164</span></a>
<a class="sourceLine" id="cb125-791" data-line-number="791"><span class="co">#&gt; 796     0        STEARNS    2.3224      0.1164</span></a>
<a class="sourceLine" id="cb125-792" data-line-number="792"><span class="co">#&gt; 797     0        STEARNS    1.9021      0.1164</span></a>
<a class="sourceLine" id="cb125-793" data-line-number="793"><span class="co">#&gt; 798     1        STEARNS    0.9933      0.1164</span></a>
<a class="sourceLine" id="cb125-794" data-line-number="794"><span class="co">#&gt; 799     0        STEARNS    1.2238      0.1164</span></a>
<a class="sourceLine" id="cb125-795" data-line-number="795"><span class="co">#&gt; 800     1        STEARNS    0.4700      0.1164</span></a>
<a class="sourceLine" id="cb125-796" data-line-number="796"><span class="co">#&gt; 801     0        STEARNS    1.6292      0.1164</span></a>
<a class="sourceLine" id="cb125-797" data-line-number="797"><span class="co">#&gt; 802     0        STEARNS    2.0149      0.1164</span></a>
<a class="sourceLine" id="cb125-798" data-line-number="798"><span class="co">#&gt; 803     0        STEARNS    2.6810      0.1164</span></a>
<a class="sourceLine" id="cb125-799" data-line-number="799"><span class="co">#&gt; 804     0        STEARNS    0.6419      0.1164</span></a>
<a class="sourceLine" id="cb125-800" data-line-number="800"><span class="co">#&gt; 805     0        STEARNS    2.0149      0.1164</span></a>
<a class="sourceLine" id="cb125-801" data-line-number="801"><span class="co">#&gt; 806     0        STEARNS    0.9933      0.1164</span></a>
<a class="sourceLine" id="cb125-802" data-line-number="802"><span class="co">#&gt; 807     0        STEARNS    1.3350      0.1164</span></a>
<a class="sourceLine" id="cb125-803" data-line-number="803"><span class="co">#&gt; 808     0        STEARNS    0.6931      0.1164</span></a>
<a class="sourceLine" id="cb125-804" data-line-number="804"><span class="co">#&gt; 809     1        STEARNS    0.8329      0.1164</span></a>
<a class="sourceLine" id="cb125-805" data-line-number="805"><span class="co">#&gt; 810     0        STEARNS    1.6292      0.1164</span></a>
<a class="sourceLine" id="cb125-806" data-line-number="806"><span class="co">#&gt; 811     0         STEELE    2.0015      0.2698</span></a>
<a class="sourceLine" id="cb125-807" data-line-number="807"><span class="co">#&gt; 812     0         STEELE    1.3350      0.2698</span></a>
<a class="sourceLine" id="cb125-808" data-line-number="808"><span class="co">#&gt; 813     0         STEELE    1.0986      0.2698</span></a>
<a class="sourceLine" id="cb125-809" data-line-number="809"><span class="co">#&gt; 814     0         STEELE    1.5041      0.2698</span></a>
<a class="sourceLine" id="cb125-810" data-line-number="810"><span class="co">#&gt; 815     0         STEELE    2.1401      0.2698</span></a>
<a class="sourceLine" id="cb125-811" data-line-number="811"><span class="co">#&gt; 816     0         STEELE    1.6487      0.2698</span></a>
<a class="sourceLine" id="cb125-812" data-line-number="812"><span class="co">#&gt; 817     0         STEELE    1.3083      0.2698</span></a>
<a class="sourceLine" id="cb125-813" data-line-number="813"><span class="co">#&gt; 818     0         STEELE    0.4700      0.2698</span></a>
<a class="sourceLine" id="cb125-814" data-line-number="814"><span class="co">#&gt; 819     0         STEELE    2.1633      0.2698</span></a>
<a class="sourceLine" id="cb125-815" data-line-number="815"><span class="co">#&gt; 820     0         STEELE    2.3702      0.2698</span></a>
<a class="sourceLine" id="cb125-816" data-line-number="816"><span class="co">#&gt; 821     0        STEVENS    2.0919      0.4708</span></a>
<a class="sourceLine" id="cb125-817" data-line-number="817"><span class="co">#&gt; 822     0        STEVENS    1.5261      0.4708</span></a>
<a class="sourceLine" id="cb125-818" data-line-number="818"><span class="co">#&gt; 823     0          SWIFT    1.1314      0.3160</span></a>
<a class="sourceLine" id="cb125-819" data-line-number="819"><span class="co">#&gt; 824     0          SWIFT    0.9163      0.3160</span></a>
<a class="sourceLine" id="cb125-820" data-line-number="820"><span class="co">#&gt; 825     0          SWIFT    0.4700      0.3160</span></a>
<a class="sourceLine" id="cb125-821" data-line-number="821"><span class="co">#&gt; 826     0          SWIFT    1.5892      0.3160</span></a>
<a class="sourceLine" id="cb125-822" data-line-number="822"><span class="co">#&gt; 827     0           TODD    1.9315     -0.0468</span></a>
<a class="sourceLine" id="cb125-823" data-line-number="823"><span class="co">#&gt; 828     0           TODD    0.7885     -0.0468</span></a>
<a class="sourceLine" id="cb125-824" data-line-number="824"><span class="co">#&gt; 829     1           TODD    1.8083     -0.0468</span></a>
<a class="sourceLine" id="cb125-825" data-line-number="825"><span class="co">#&gt; 830     1       TRAVERSE    1.0986      0.4976</span></a>
<a class="sourceLine" id="cb125-826" data-line-number="826"><span class="co">#&gt; 831     0       TRAVERSE    1.9169      0.4976</span></a>
<a class="sourceLine" id="cb125-827" data-line-number="827"><span class="co">#&gt; 832     0       TRAVERSE    2.9653      0.4976</span></a>
<a class="sourceLine" id="cb125-828" data-line-number="828"><span class="co">#&gt; 833     0       TRAVERSE    1.4110      0.4976</span></a>
<a class="sourceLine" id="cb125-829" data-line-number="829"><span class="co">#&gt; 834     0        WABASHA    1.7918      0.1501</span></a>
<a class="sourceLine" id="cb125-830" data-line-number="830"><span class="co">#&gt; 835     0        WABASHA    2.2083      0.1501</span></a>
<a class="sourceLine" id="cb125-831" data-line-number="831"><span class="co">#&gt; 836     0        WABASHA    2.1401      0.1501</span></a>
<a class="sourceLine" id="cb125-832" data-line-number="832"><span class="co">#&gt; 837     1        WABASHA    0.1823      0.1501</span></a>
<a class="sourceLine" id="cb125-833" data-line-number="833"><span class="co">#&gt; 838     0        WABASHA    1.1632      0.1501</span></a>
<a class="sourceLine" id="cb125-834" data-line-number="834"><span class="co">#&gt; 839     0        WABASHA    2.4510      0.1501</span></a>
<a class="sourceLine" id="cb125-835" data-line-number="835"><span class="co">#&gt; 840     0        WABASHA    2.2721      0.1501</span></a>
<a class="sourceLine" id="cb125-836" data-line-number="836"><span class="co">#&gt; 841     0         WADENA    1.0986     -0.6720</span></a>
<a class="sourceLine" id="cb125-837" data-line-number="837"><span class="co">#&gt; 842     1         WADENA   -0.2231     -0.6720</span></a>
<a class="sourceLine" id="cb125-838" data-line-number="838"><span class="co">#&gt; 843     1         WADENA    1.1939     -0.6720</span></a>
<a class="sourceLine" id="cb125-839" data-line-number="839"><span class="co">#&gt; 844     0         WADENA    1.5686     -0.6720</span></a>
<a class="sourceLine" id="cb125-840" data-line-number="840"><span class="co">#&gt; 845     0         WADENA    1.5892     -0.6720</span></a>
<a class="sourceLine" id="cb125-841" data-line-number="841"><span class="co">#&gt; 846     0         WASECA   -0.6931      0.2124</span></a>
<a class="sourceLine" id="cb125-842" data-line-number="842"><span class="co">#&gt; 847     0         WASECA    2.2407      0.2124</span></a>
<a class="sourceLine" id="cb125-843" data-line-number="843"><span class="co">#&gt; 848     0         WASECA    0.5878      0.2124</span></a>
<a class="sourceLine" id="cb125-844" data-line-number="844"><span class="co">#&gt; 849     1         WASECA    0.0000      0.2124</span></a>
<a class="sourceLine" id="cb125-845" data-line-number="845"><span class="co">#&gt; 850     0     WASHINGTON    2.3321     -0.1475</span></a>
<a class="sourceLine" id="cb125-846" data-line-number="846"><span class="co">#&gt; 851     0     WASHINGTON    2.0541     -0.1475</span></a>
<a class="sourceLine" id="cb125-847" data-line-number="847"><span class="co">#&gt; 852     0     WASHINGTON    0.8329     -0.1475</span></a>
<a class="sourceLine" id="cb125-848" data-line-number="848"><span class="co">#&gt; 853     0     WASHINGTON    1.8871     -0.1475</span></a>
<a class="sourceLine" id="cb125-849" data-line-number="849"><span class="co">#&gt; 854     0     WASHINGTON    2.5096     -0.1475</span></a>
<a class="sourceLine" id="cb125-850" data-line-number="850"><span class="co">#&gt; 855     0     WASHINGTON    1.5476     -0.1475</span></a>
<a class="sourceLine" id="cb125-851" data-line-number="851"><span class="co">#&gt; 856     0     WASHINGTON    1.8405     -0.1475</span></a>
<a class="sourceLine" id="cb125-852" data-line-number="852"><span class="co">#&gt; 857     0     WASHINGTON    1.8871     -0.1475</span></a>
<a class="sourceLine" id="cb125-853" data-line-number="853"><span class="co">#&gt; 858     0     WASHINGTON    1.0647     -0.1475</span></a>
<a class="sourceLine" id="cb125-854" data-line-number="854"><span class="co">#&gt; 859     0     WASHINGTON    0.6931     -0.1475</span></a>
<a class="sourceLine" id="cb125-855" data-line-number="855"><span class="co">#&gt; 860     1     WASHINGTON    0.2624     -0.1475</span></a>
<a class="sourceLine" id="cb125-856" data-line-number="856"><span class="co">#&gt; 861     0     WASHINGTON    0.9163     -0.1475</span></a>
<a class="sourceLine" id="cb125-857" data-line-number="857"><span class="co">#&gt; 862     0     WASHINGTON    0.0953     -0.1475</span></a>
<a class="sourceLine" id="cb125-858" data-line-number="858"><span class="co">#&gt; 863     1     WASHINGTON    0.2624     -0.1475</span></a>
<a class="sourceLine" id="cb125-859" data-line-number="859"><span class="co">#&gt; 864     0     WASHINGTON    0.5306     -0.1475</span></a>
<a class="sourceLine" id="cb125-860" data-line-number="860"><span class="co">#&gt; 865     0     WASHINGTON   -0.1054     -0.1475</span></a>
<a class="sourceLine" id="cb125-861" data-line-number="861"><span class="co">#&gt; 866     0     WASHINGTON    0.5878     -0.1475</span></a>
<a class="sourceLine" id="cb125-862" data-line-number="862"><span class="co">#&gt; 867     0     WASHINGTON    1.5686     -0.1475</span></a>
<a class="sourceLine" id="cb125-863" data-line-number="863"><span class="co">#&gt; 868     1     WASHINGTON    0.5878     -0.1475</span></a>
<a class="sourceLine" id="cb125-864" data-line-number="864"><span class="co">#&gt; 869     0     WASHINGTON    1.2238     -0.1475</span></a>
<a class="sourceLine" id="cb125-865" data-line-number="865"><span class="co">#&gt; 870     1     WASHINGTON   -0.1054     -0.1475</span></a>
<a class="sourceLine" id="cb125-866" data-line-number="866"><span class="co">#&gt; 871     0     WASHINGTON    2.2925     -0.1475</span></a>
<a class="sourceLine" id="cb125-867" data-line-number="867"><span class="co">#&gt; 872     0     WASHINGTON    1.6864     -0.1475</span></a>
<a class="sourceLine" id="cb125-868" data-line-number="868"><span class="co">#&gt; 873     0     WASHINGTON    2.1518     -0.1475</span></a>
<a class="sourceLine" id="cb125-869" data-line-number="869"><span class="co">#&gt; 874     0     WASHINGTON    0.6931     -0.1475</span></a>
<a class="sourceLine" id="cb125-870" data-line-number="870"><span class="co">#&gt; 875     0     WASHINGTON    1.9021     -0.1475</span></a>
<a class="sourceLine" id="cb125-871" data-line-number="871"><span class="co">#&gt; 876     0     WASHINGTON    1.3610     -0.1475</span></a>
<a class="sourceLine" id="cb125-872" data-line-number="872"><span class="co">#&gt; 877     0     WASHINGTON    1.7918     -0.1475</span></a>
<a class="sourceLine" id="cb125-873" data-line-number="873"><span class="co">#&gt; 878     0     WASHINGTON    1.6094     -0.1475</span></a>
<a class="sourceLine" id="cb125-874" data-line-number="874"><span class="co">#&gt; 879     1     WASHINGTON    0.9555     -0.1475</span></a>
<a class="sourceLine" id="cb125-875" data-line-number="875"><span class="co">#&gt; 880     0     WASHINGTON    2.3795     -0.1475</span></a>
<a class="sourceLine" id="cb125-876" data-line-number="876"><span class="co">#&gt; 881     0     WASHINGTON    0.9163     -0.1475</span></a>
<a class="sourceLine" id="cb125-877" data-line-number="877"><span class="co">#&gt; 882     0     WASHINGTON    0.7885     -0.1475</span></a>
<a class="sourceLine" id="cb125-878" data-line-number="878"><span class="co">#&gt; 883     0     WASHINGTON    1.5686     -0.1475</span></a>
<a class="sourceLine" id="cb125-879" data-line-number="879"><span class="co">#&gt; 884     0     WASHINGTON    1.3350     -0.1475</span></a>
<a class="sourceLine" id="cb125-880" data-line-number="880"><span class="co">#&gt; 885     0     WASHINGTON    2.6027     -0.1475</span></a>
<a class="sourceLine" id="cb125-881" data-line-number="881"><span class="co">#&gt; 886     0     WASHINGTON    1.0986     -0.1475</span></a>
<a class="sourceLine" id="cb125-882" data-line-number="882"><span class="co">#&gt; 887     0     WASHINGTON    1.4816     -0.1475</span></a>
<a class="sourceLine" id="cb125-883" data-line-number="883"><span class="co">#&gt; 888     0     WASHINGTON    1.3610     -0.1475</span></a>
<a class="sourceLine" id="cb125-884" data-line-number="884"><span class="co">#&gt; 889     0     WASHINGTON    0.6419     -0.1475</span></a>
<a class="sourceLine" id="cb125-885" data-line-number="885"><span class="co">#&gt; 890     0     WASHINGTON    0.4700     -0.1475</span></a>
<a class="sourceLine" id="cb125-886" data-line-number="886"><span class="co">#&gt; 891     0     WASHINGTON    0.6419     -0.1475</span></a>
<a class="sourceLine" id="cb125-887" data-line-number="887"><span class="co">#&gt; 892     0     WASHINGTON    0.3365     -0.1475</span></a>
<a class="sourceLine" id="cb125-888" data-line-number="888"><span class="co">#&gt; 893     0     WASHINGTON    1.9021     -0.1475</span></a>
<a class="sourceLine" id="cb125-889" data-line-number="889"><span class="co">#&gt; 894     0     WASHINGTON    3.0204     -0.1475</span></a>
<a class="sourceLine" id="cb125-890" data-line-number="890"><span class="co">#&gt; 895     0     WASHINGTON    1.8083     -0.1475</span></a>
<a class="sourceLine" id="cb125-891" data-line-number="891"><span class="co">#&gt; 896     0       WATONWAN    2.6319      0.1832</span></a>
<a class="sourceLine" id="cb125-892" data-line-number="892"><span class="co">#&gt; 897     1       WATONWAN    2.3321      0.1832</span></a>
<a class="sourceLine" id="cb125-893" data-line-number="893"><span class="co">#&gt; 898     1       WATONWAN    1.7579      0.1832</span></a>
<a class="sourceLine" id="cb125-894" data-line-number="894"><span class="co">#&gt; 899     0         WILKIN    2.2407      0.2360</span></a>
<a class="sourceLine" id="cb125-895" data-line-number="895"><span class="co">#&gt; 900     0         WINONA    1.2528      0.4632</span></a>
<a class="sourceLine" id="cb125-896" data-line-number="896"><span class="co">#&gt; 901     0         WINONA    1.4351      0.4632</span></a>
<a class="sourceLine" id="cb125-897" data-line-number="897"><span class="co">#&gt; 902     0         WINONA    2.4596      0.4632</span></a>
<a class="sourceLine" id="cb125-898" data-line-number="898"><span class="co">#&gt; 903     0         WINONA    1.9879      0.4632</span></a>
<a class="sourceLine" id="cb125-899" data-line-number="899"><span class="co">#&gt; 904     0         WINONA    1.5686      0.4632</span></a>
<a class="sourceLine" id="cb125-900" data-line-number="900"><span class="co">#&gt; 905     1         WINONA    0.6419      0.4632</span></a>
<a class="sourceLine" id="cb125-901" data-line-number="901"><span class="co">#&gt; 906     1         WINONA   -0.2231      0.4632</span></a>
<a class="sourceLine" id="cb125-902" data-line-number="902"><span class="co">#&gt; 907     0         WINONA    1.5686      0.4632</span></a>
<a class="sourceLine" id="cb125-903" data-line-number="903"><span class="co">#&gt; 908     0         WINONA    2.3321      0.4632</span></a>
<a class="sourceLine" id="cb125-904" data-line-number="904"><span class="co">#&gt; 909     0         WINONA    2.4336      0.4632</span></a>
<a class="sourceLine" id="cb125-905" data-line-number="905"><span class="co">#&gt; 910     0         WINONA    2.0412      0.4632</span></a>
<a class="sourceLine" id="cb125-906" data-line-number="906"><span class="co">#&gt; 911     0         WINONA    2.4765      0.4632</span></a>
<a class="sourceLine" id="cb125-907" data-line-number="907"><span class="co">#&gt; 912     1         WINONA   -0.5108      0.4632</span></a>
<a class="sourceLine" id="cb125-908" data-line-number="908"><span class="co">#&gt; 913     0         WRIGHT    1.9169     -0.0900</span></a>
<a class="sourceLine" id="cb125-909" data-line-number="909"><span class="co">#&gt; 914     0         WRIGHT    1.6864     -0.0900</span></a>
<a class="sourceLine" id="cb125-910" data-line-number="910"><span class="co">#&gt; 915     0         WRIGHT    1.1632     -0.0900</span></a>
<a class="sourceLine" id="cb125-911" data-line-number="911"><span class="co">#&gt; 916     0         WRIGHT    0.7885     -0.0900</span></a>
<a class="sourceLine" id="cb125-912" data-line-number="912"><span class="co">#&gt; 917     0         WRIGHT    2.0015     -0.0900</span></a>
<a class="sourceLine" id="cb125-913" data-line-number="913"><span class="co">#&gt; 918     0         WRIGHT    1.6487     -0.0900</span></a>
<a class="sourceLine" id="cb125-914" data-line-number="914"><span class="co">#&gt; 919     0         WRIGHT    0.8329     -0.0900</span></a>
<a class="sourceLine" id="cb125-915" data-line-number="915"><span class="co">#&gt; 920     1         WRIGHT    0.8755     -0.0900</span></a>
<a class="sourceLine" id="cb125-916" data-line-number="916"><span class="co">#&gt; 921     0         WRIGHT    2.7726     -0.0900</span></a>
<a class="sourceLine" id="cb125-917" data-line-number="917"><span class="co">#&gt; 922     0         WRIGHT    2.2618     -0.0900</span></a>
<a class="sourceLine" id="cb125-918" data-line-number="918"><span class="co">#&gt; 923     0         WRIGHT    1.8718     -0.0900</span></a>
<a class="sourceLine" id="cb125-919" data-line-number="919"><span class="co">#&gt; 924     0         WRIGHT    1.5261     -0.0900</span></a>
<a class="sourceLine" id="cb125-920" data-line-number="920"><span class="co">#&gt; 925     0         WRIGHT    1.6292     -0.0900</span></a>
<a class="sourceLine" id="cb125-921" data-line-number="921"><span class="co">#&gt; 926     0 YELLOWMEDICINE    1.3350      0.3553</span></a>
<a class="sourceLine" id="cb125-922" data-line-number="922"><span class="co">#&gt; 927     0 YELLOWMEDICINE    1.0986      0.3553</span></a></code></pre></div>
<p>The data consist of 919 observations of radon levels of houses from 85 counties.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1">radon_county &lt;-<span class="st"> </span>radon <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb126-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(county) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb126-3" data-line-number="3"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">log_radon_mean =</span> <span class="kw">mean</span>(log_radon),</a>
<a class="sourceLine" id="cb126-4" data-line-number="4">            <span class="dt">log_radon_sd =</span> <span class="kw">sd</span>(log_radon), </a>
<a class="sourceLine" id="cb126-5" data-line-number="5">            <span class="dt">log_uranium =</span> <span class="kw">mean</span>(log_uranium),</a>
<a class="sourceLine" id="cb126-6" data-line-number="6">            <span class="dt">n =</span> <span class="kw">length</span>(county))</a></code></pre></div>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" data-line-number="1"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb127-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> radon,</a>
<a class="sourceLine" id="cb127-3" data-line-number="3">             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> log_radon, <span class="dt">x =</span> <span class="kw">fct_reorder</span>(county, log_radon, mean))) <span class="op">+</span></a>
<a class="sourceLine" id="cb127-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> radon_county,</a>
<a class="sourceLine" id="cb127-5" data-line-number="5">             <span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">fct_reorder</span>(county, log_radon_mean), <span class="dt">y =</span> log_radon_mean),</a>
<a class="sourceLine" id="cb127-6" data-line-number="6">             <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb127-7" data-line-number="7"><span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb127-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;log(radon)&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<p><img src="multilevel_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Relationship between mean and sample size</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1"><span class="kw">ggplot</span>(radon_county, <span class="kw">aes</span>(<span class="dt">y =</span> log_radon_mean, <span class="dt">x =</span> <span class="kw">log2</span>(n))) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb128-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>()</a></code></pre></div>
<p><img src="multilevel_files/figure-html/unnamed-chunk-6-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="varying-intercepts-models" class="section level3">
<h3><span class="header-section-number">14.1.2</span> Varying Intercepts Models</h3>
<p>Consider the general model with an intercept for each county representing the baseline average of the county:
<span class="math display">\[
\begin{aligned}
y_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta x_i
\end{aligned}
\]</span>
where <span class="math inline">\(j[i]\)</span> means that observation <span class="math inline">\(i\)</span> is in county <span class="math inline">\(j \in (1, \dots, 85)\)</span>.</p>
<p>In this particular example, <span class="math inline">\(y = \mathtt{log_radon}\)</span> and <span class="math inline">\(x = \mathtt{basement}\)</span>.
<span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta~\mathtt{basement}_i
\end{aligned}
\]</span></p>
<p>We can put a prior distribution on <span class="math inline">\(\alpha_{j[i]}\)</span>,
<span class="math display">\[
\begin{aligned}[t]
\alpha_{j} &amp;\sim N(\gamma, \tau) &amp; \text{for $i \in (1, \dots, 85)}
\end{aligned}
\]</span>
This parameterization nests common cases,</p>
<p><em>Complete pooling:</em> When <span class="math inline">\(\tau \to 0\)</span>, the intercepts are the same,
<span class="math display">\[
\begin{aligned}[t]
\alpha_j &amp;= \gamma  &amp; \text{for all $j$.}
\end{aligned}
\]</span></p>
<p><em>No pooling:</em> When <span class="math inline">\(\tau \to \infty\)</span>, prior distribution on the intercepts is equivalent to an improper normal distribution, and there is no shrinkage,
<span class="math display">\[
p(\alpha_j) \propto 1,
\]</span>
for all <span class="math inline">\(j\)</span>.</p>
<p><em>Partial pooling:</em> When <span class="math inline">\(\tau\)</span> is a parameter, the amount of shrinkage can be estimated from the data.</p>
</div>
<div id="varying-intercept-model" class="section level3">
<h3><span class="header-section-number">14.1.3</span> Varying Intercept Model</h3>
</div>
<div id="varying-slope-model" class="section level3">
<h3><span class="header-section-number">14.1.4</span> Varying Slope Model</h3>
<p><span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i
\end{aligned}
\]</span></p>
</div>
<div id="group-level-predictors" class="section level3">
<h3><span class="header-section-number">14.1.5</span> Group Level Predictors</h3>
<p>The <code>radon</code> dataset also contains the county-level measurements of <code>uranium</code>.</p>
<p>One way to include county level measurements is to model the county-level intercepts.
The values of each county intercept is a function of the county-level uranium.
<span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i
\alpha_{j} \sim  N(\gamma_0 + \gamma_1~\mathtt{log\_uranium}_j, \tau)
\end{aligned}
\]</span></p>
<p>Alternatively, we can model model the county-level intercepts.
The values of each county intercept is a function of the county-level uranium.
<span class="math display">\[
\begin{aligned}
\mathtt{log\_radon}_i &amp;\sim  N(\mu_i, \sigma^2) \\
\mu_i &amp;= \alpha_{j[i]} + \beta_{j[i]}~\mathtt{basement}_i \\
\alpha_{j} &amp;\sim  N(\gamma_0 + \gamma_1~\mathtt{log\_uranium}_j, \tau)
\end{aligned}
\]</span></p>
</div>
<div id="lme4" class="section level3">
<h3><span class="header-section-number">14.1.6</span> lme4</h3>
<p>In R, the most widely used package to estimate mixed-effects models is <strong>lme4</strong>.
This estimates models using maximum likelihood or restricted maximum likelihood methods (REML).
This will be faster than using full-Bayesian methods but also underestimate the uncertainty, as well as being a worse approximation of the posterior.
Additionally, in frequentist inference, the meaning of the random effects is different; they are nuisance parameters and not given standard errors.</p>
<p>See <span class="citation">Bates (2010)</span> and <span class="citation">Bates et al. (2014)</span> for introductions to mixed-effects models with <strong>lme4</strong>.
These are also good introductions to classical approaches to mixed effects models.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;lme4&quot;</span>)</a>
<a class="sourceLine" id="cb129-2" data-line-number="2"><span class="co">#&gt; Loading required package: Matrix</span></a>
<a class="sourceLine" id="cb129-3" data-line-number="3"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb129-4" data-line-number="4"><span class="co">#&gt; Attaching package: &#39;Matrix&#39;</span></a>
<a class="sourceLine" id="cb129-5" data-line-number="5"><span class="co">#&gt; The following object is masked from &#39;package:tidyr&#39;:</span></a>
<a class="sourceLine" id="cb129-6" data-line-number="6"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb129-7" data-line-number="7"><span class="co">#&gt;     expand</span></a></code></pre></div>
<p>Complete pooling</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb130-1" data-line-number="1">fit_pooled &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>County-varying intercepts with no-pooling</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" data-line-number="1">fit_intercept_nopool &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>County-varying intercepts with partial-pooling</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb132-1" data-line-number="1">fit_intercept_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>Varying slopes with no pooling:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" data-line-number="1">fit_slope_nopool &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">*</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>Varying slopes with partial pooling:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county), <span class="dt">data =</span> radon)</a></code></pre></div>
<p>Including a county-level variable (<code>log_uranium</code>) in various models:</p>
<p>With no-pooling,</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>With varying-intercepts</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>With varying-intercepts and slopes,</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">lmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st">  </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
</div>
<div id="rstanarm" class="section level3">
<h3><span class="header-section-number">14.1.7</span> rstanarm</h3>
<p>Some multilevel models can also be estimated using the <strong>rstanarm</strong> functions <code>stan_glmer</code> and <code>stan_lmer</code>.
These functions have syntax similar to <strong>lme4</strong> functions, but estimate the mixed models using Bayesian methods with Stan.</p>
<p>Complete pooling</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1">fit_pooled &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>County-varying intercepts with no-pooling</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb139-1" data-line-number="1">fit_intercept_nopool &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>County-varying intercepts with partial-pooling</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb140-1" data-line-number="1">fit_intercept_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>Varying slopes with no pooling. <em>There is an error estimating this</em></p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb141-1" data-line-number="1">fit_slope_nopool &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span><span class="dv">-1</span> <span class="op">+</span><span class="st"> </span>county <span class="op">+</span><span class="st"> </span>county<span class="op">:</span>floor, <span class="dt">data =</span> radon,</a>
<a class="sourceLine" id="cb141-2" data-line-number="2">                             <span class="dt">prior =</span> <span class="kw">normal</span>(<span class="dt">scale =</span> <span class="dv">1</span>))</a></code></pre></div>
<p>Varying slopes with partial pooling:</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb142-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county), <span class="dt">data =</span> radon)</a></code></pre></div>
<p>Including a county-level variable (<code>log_uranium</code>) in various models:</p>
<p>With no-pooling,</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb143-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(log_radon <span class="op">~</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>With varying-intercepts</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb144-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
<p>With varying-intercepts and slopes,</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb145-1" data-line-number="1">fit_slope_partial &lt;-<span class="st"> </span><span class="kw">stan_glmer</span>(log_radon <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>floor <span class="op">|</span><span class="st"> </span>county) <span class="op">+</span><span class="st">  </span>log_uranium, <span class="dt">data =</span> radon)</a></code></pre></div>
</div>
</div>
<div id="pooling-of-hierarchical-parameters" class="section level2">
<h2><span class="header-section-number">14.2</span> Pooling of Hierarchical Parameters</h2>
<p>This is easiest understood in the case of a model of group means,
<span class="math display">\[
\begin{aligned}[t]
y &amp;\sim \dnorm(\mu_{j[i]}, \sigma^2) \\
\mu_{j} &amp;\sim \dnorm(\gamma, \tau^2) .
\end{aligned}
\]</span>
Each group has size <span class="math inline">\(n_j\)</span>.</p>
<table>
<thead>
<tr class="header">
<th align="left">Sample size, <span class="math inline">\(n_j\)</span></th>
<th align="left">Estimate of <span class="math inline">\(\hat{\mu}_j\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = 0\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \gamma\)</span> (complete pooling)</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(n_j &lt; \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j\)</span> closer to <span class="math inline">\(\gamma\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \frac{1}{2} \bar{y}_j + \frac{1}{2} \gamma\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(n_j &gt; \frac{\sigma^2}{\tau^2}\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j\)</span> closer to <span class="math inline">\(\bar{y}_j\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(n_j = \infty\)</span></td>
<td align="left"><span class="math inline">\(\hat{\mu}_j = \bar{y}_j\)</span> (no pooling)</td>
</tr>
</tbody>
</table>
<p>If the hyperparameters were known, the posterior of <span class="math inline">\(\mu_j\)</span> is
<span class="math display">\[
\mu_j | y, \gamma, \sigma, \tau \sim \dnorm(\hat{\mu}_j, V_j)
\]</span>
where
<span class="math display">\[
\begin{aligned}[t]
\hat{\mu}_j &amp;= \frac{\frac{n_j}{\sigma^2} \bar{y}_j + \frac{1}{\tau^2} \gamma}{\frac{n_j}{\sigma^2} + \frac{1}{\tau^2}} \\
V_j &amp;= \frac{1}{\frac{n_j}{\sigma^2} + \frac{1}{\tau^2}}
\end{aligned}
\]</span></p>
<p>Some crude estimates given <span class="math inline">\(\mu_j\)</span>.</p>
<p>The <em>data variance</em>, <span class="math inline">\(\sigma^2\)</span>, is the residual variance,
<span class="math display">\[
\E(\sigma^2 | y, \mu)  = \frac{1}{n} \sum_{i = 1}^n (y - \mu_{j[i]})^2 .
\]</span>
The global mean is approximately the average of the group-level means,
<span class="math display">\[
\begin{aligned}[t]
\E(\gamma | y, \mu) &amp;= \frac{1}{J} \sum_{i = 1}^n \mu_j \\
\Var(\gamma | y, \mu) &amp;= \frac{1}{J} \tau^2
\end{aligned}
\]</span>
The group level variance is <span class="math inline">\(\tau^2\)</span> is,
<span class="math display">\[
\E(\tau^ | y, \mu) = \frac{1}{J} \sum_{j = 1}^J (\mu_j - \gamma)^2
\]</span></p>
</div>
<div id="anova" class="section level2">
<h2><span class="header-section-number">14.3</span> ANOVA</h2>
<p><strong>TODO</strong></p>
</div>
<div id="time-series-cross-section" class="section level2">
<h2><span class="header-section-number">14.4</span> Time-Series Cross Section</h2>
<p><strong>TODO</strong></p>
<p>A common application for these models are Time-Series Cross-Section (TSCS) or panel models.
In this case, both the time and units can be modeled.</p>
</div>
<div id="extensions" class="section level2">
<h2><span class="header-section-number">14.5</span> Extensions</h2>
<ul>
<li>Including group-level covariates</li>
<li>Prior distributions</li>
<li><p>Prediction</p>
<ul>
<li>new obs in existing groups</li>
<li>new group</li>
<li>new obs in new group</li>
</ul></li>
<li>Modeling correlation between intercept and slopes</li>
<li><p>Non-nested models</p></li>
</ul>
</div>
<div id="miscellaneous" class="section level2">
<h2><span class="header-section-number">14.6</span> Miscellaneous</h2>
<div id="how-many-groups" class="section level3">
<h3><span class="header-section-number">14.6.1</span> How many groups?</h3>
<p>In classical discussions of multi-level or hierarchical models,
a common question is how many groups are required to be able to use random effects vs. fixed effects.</p>
<p>As noted earlier, random effects estimates the variance between group means. If there are few groups, there is not much information available to estimate this variance.
As such, random effects is not much different than fixed effects.</p>
<p>This literature provides many different rules of thumb for the number of groups necessary to be able to use random effects: 8, 10, 30, 50, or 100 <span class="citation">(Stegmueller 2013, 749)</span>.</p>
<p><span class="citation">Stegmueller (2013)</span> finds that Bayesian method produces better multi-level-models than maximum likelihood methods for all numbers of groups.
ML methods do not suffer severe bias above 10-15 groups.
Bayesian point estimates are biased for smaller numbers of groups, but less than the ML.
Additionally, the Bayesian methods have better frequentist coverage than ML methods.</p>
<p><span class="citation">Beck and Katz (2007)</span> show that ML random coefficient models are superior in terms of efficiency to many types of pooled and unpooled estimators in small samples.</p>
</div>
<div id="correlation-between-predictors-and-errors" class="section level3">
<h3><span class="header-section-number">14.6.2</span> Correlation between Predictors and Errors</h3>
<p><span class="citation">Bafumi and Gelman (2006)</span> analyze this case.</p>
<p>The standard suggestion in frequentist literature is to use a Hausman test where the null hypothesis is that random effects are consistent. However, <span class="citation">Clark and Linzer (2014)</span> note that in small samples this is likely to fail to reject random effects; and in large samples, random effects behave like fixed effects anyways.</p>
</div>
</div>
<div id="references-9" class="section level2">
<h2><span class="header-section-number">14.7</span> References</h2>
<p>Texts and chapters on multi-level analysis:</p>
<ul>
<li><p>Bayesian</p>
<ul>
<li><span class="citation">Gelman and Hill (2007 Ch. 11-17)</span>.</li>
<li><span class="citation">Gelman et al. (2013 Ch 5)</span> “Hierarchical Models”</li>
<li><span class="citation">Gelman et al. (2013 Ch 15)</span> “Hierarchical Linear Models”</li>
<li><span class="citation">Jackman (2009 CHh. 7)</span></li>
<li><span class="citation">Draper (2008)</span></li>
</ul></li>
<li><p>Frequentist</p>
<ul>
<li><span class="citation">Goldstein (2011)</span></li>
<li><span class="citation">Snijders and Bosker (2011)</span></li>
<li><span class="citation">Rabe-Hesketh and Skrondal (2012)</span></li>
<li><span class="citation">Jiang (2007)</span></li>
</ul></li>
</ul>
<p>Stan model examples:</p>
<ul>
<li>Stan models for <a href="https://github.com/stan-dev/example-models/wiki/ARM-Models">ARM</a></li>
<li><a href="http://mc-stan.org/documentation/case-studies/radon.html" class="uri">http://mc-stan.org/documentation/case-studies/radon.html</a></li>
<li><a href="https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/" class="uri">https://biologyforfun.wordpress.com/2016/12/08/crossed-and-nested-hierarchical-models-with-stan-and-r/</a></li>
</ul>
<p>Examples of multilevel models</p>
<ul>
<li><span class="citation">Western (1998)</span>: economic growth for OECD countries</li>
<li><span class="citation">Gelman and King (1993)</span>: US election polling</li>
<li><span class="citation">Park, Gelman, and Bafumi (2004)</span>: multi-level models of opinion polls combined with post-stratification to extrapolate national opinion surveys to regions.</li>
<li><span class="citation">Steenbergen and Jones (2002)</span>: mostly an intro/review of MLM, but uses the cross-country Eurobarometer to model support for the EU</li>
<li><span class="citation">Gelman et al. (2007)</span>: state-level opinion polls</li>
<li><span class="citation">Raudenbush and Bryk (2001)</span>: student performance with student and school-level indicators</li>
<li><span class="citation">Gilardi (2010)</span>: policy diffusion</li>
<li><span class="citation">O’Rourke and Sinnott (2006)</span>: attitudes toward immigration</li>
<li><span class="citation">Andersen and Fetner (2008)</span>: ethnic and social tolerance</li>
<li><span class="citation">Weldon (2006)</span>: ethnic and social tolerance</li>
<li><span class="citation">Arzheimer (2009)</span>: right-wing voting</li>
<li><span class="citation">Hooghe et al. (2009)</span>: social and political trust</li>
<li><span class="citation">Anderson and Singer (2008)</span>: satisfaction with democracy</li>
<li><span class="citation">Meer, Deth, and Scheepers (2009)</span>: political participation</li>
<li><span class="citation">Iversen and Rosenbluth (2006)</span>: political economy of the gender wage gap</li>
<li><span class="citation">Hooghe and Marks (2004)</span>: support for European integration</li>
<li><span class="citation">Lax and Phillips (2009)</span>: American politics using states and neighborhoods</li>
<li><span class="citation">Voeten (2008)</span>: judicial decision making</li>
<li><span class="citation">Franchino and Høyland (2009)</span>: legislative politics</li>
<li><span class="citation">Denisova et al. (2009)</span>: politics of economic reforms</li>
<li><span class="citation">Aitkin and Longford (1986)</span>, <span class="citation">Goldstein et al. (2000)</span>, <span class="citation">Goldstein et al. (1993)</span>: education</li>
<li><span class="citation">Goldstein et al. (2000)</span>: medicine</li>
</ul>
<!--chapter:end:multilevel.Rmd-->
</div>
</div>
<div id="part-appendix" class="section level1 unnumbered">
<h1>(PART) Appendix</h1>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb146-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;stringr&quot;</span>)</a></code></pre></div>
<div id="parameters" class="section level2">
<h2><span class="header-section-number">14.8</span> Parameters</h2>
<table>
<thead>
<tr class="header">
<th align="left">Category</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">modeled data</td>
<td align="left">Data, assigned distribution</td>
</tr>
<tr class="even">
<td align="left">unmodeled data</td>
<td align="left">Data not given a distribution</td>
</tr>
<tr class="odd">
<td align="left">modeled parameters</td>
<td align="left">Parameters with an informative prior distribution</td>
</tr>
<tr class="even">
<td align="left">unmodeled parameters</td>
<td align="left">Parameters with non-informative prior distribution</td>
</tr>
<tr class="odd">
<td align="left">derived quantities</td>
<td align="left">Variables defined deterministicically</td>
</tr>
</tbody>
</table>
<p>See <span class="citation">Gelman and Hill (2007, 366)</span></p>
</div>
<div id="miscellaneous-mathematical-background" class="section level2">
<h2><span class="header-section-number">14.9</span> Miscellaneous Mathematical Background</h2>
<div id="location-scale-families" class="section level3">
<h3><span class="header-section-number">14.9.1</span> Location-Scale Families</h3>
<p>In a <a href="https://en.wikipedia.org/wiki/Location%E2%80%93scale_family">location-scale family</a> of distributions, if the random variable <span class="math inline">\(X\)</span> is distributed with mean 0 and standard deviation 1, then the random variable <span class="math inline">\(Y\)</span>,
<span class="math display">\[
Y = \mu + \sigma X ,
\]</span>
has mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p><strong>Normal distribution:</strong> Suppose <span class="math inline">\(X \sim \dnorm(0, 1)\)</span>, then
<span class="math display">\[
Y = \mu + \sigma X,
\]</span>
is equivalent to <span class="math inline">\(Y \sim \dnorm(\mu, \sigma)\)</span> (normal with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>).</p>
<p>** Student-t distribution** (including Cauchy):
<span class="math display">\[
\begin{aligned}[t]
X &amp;\sim \dt{\nu}(0, 1) \\
Y &amp;= \mu + \sigma X 
\end{aligned}
\]</span>
implies
<span class="math display">\[
Y \sim \dt{\nu}(\mu, \sigma),
\]</span>
i.e. <span class="math inline">\(Y\)</span> is distributed Student-<span class="math inline">\(t\)</span> with location <span class="math inline">\(\mu\)</span> and scale <span class="math inline">\(\sigma\)</span>.</p>
<p>In Stan, it can be useful parameterize distributions in terms of a mean 0, scale 1 parameters, and separate parameters for the locations and scales. E.g. with normal distributions,</p>
<pre><code>parameters {
  real mu;
  real&lt;lower = 0.0&gt; sigma;
  vector[n] eps;
}
transformed parameters {
  vector[n] y;
  y = mu + sigma * eps;
}
model {
  eps ~ normal(0.0, 1.0);
}</code></pre>
</div>
<div id="scale-mixtures-of-normal-distributions" class="section level3">
<h3><span class="header-section-number">14.9.2</span> Scale Mixtures of Normal Distributions</h3>
<p>Some commonly used distributions can be represented as scale mixtures of normal distributions.
For formal details of scale mixtures of normal distributions see <span class="citation">West (1987)</span>.
Distributions that are scale-mixtures of normal distributions can be written as,
<span class="math display">\[
Y \sim \dnorm(\mu, \sigma_i^2) \\
\sigma_i \sim \pi(\sigma_i)
\]</span>
As its name suggests, the individual variances (scales) themselves, have a distribution.</p>
<p>Some examples:</p>
<ul>
<li>Student-t</li>
<li>Double Exponential</li>
<li>Horseshoe or Hierarchical Shrinkage (HS)</li>
<li>Horseshoe Plus or Hierarchical Shrinkage Plus (HS+)</li>
</ul>
<p>Even when analytic forms of the distribution are available, representing them as scale mixtures of normal distributions may be convenient in modeling.
In particular, it may allow for drawing samples from the distribution easily.
And in HMC, it may induce a more tractable posterior density.</p>
</div>
<div id="covariance-correlation-matrix-decomposition" class="section level3">
<h3><span class="header-section-number">14.9.3</span> Covariance-Correlation Matrix Decomposition</h3>
<p>The suggested method for modeling covariance matrices in Stan is the separation strategy which decomposes a covariance matrix <span class="math inline">\(\Sigma\)</span> can be decomposed into a standard deviation vector <span class="math inline">\(\sigma\)</span>, and a correlation matrix <span class="math inline">\(R\)</span> <span class="citation">(Barnard, McCulloch, and Meng 2000)</span>,
<span class="math display">\[
\Sigma = \diag(\sigma) R \diag(\sigma) .
\]</span>
This is useful for setting priors on covariance because separate priors can be set
for the scales of the variables via <span class="math inline">\(\sigma\)</span>, and the correlation between them,
via <span class="math inline">\(R\)</span>.</p>
<p>The <a href="https://github.com/stan-dev/rstanarm/wiki/Prior-distributions">rstanarm</a> <code>decov</code> prior goes further and decomposes the covariance matrix into a correlation matrix, <span class="math inline">\(\mat{R}\)</span>,
a diagonal variance matrix <span class="math inline">\(\mat{\Omega}\)</span> with trace <span class="math inline">\(n \sigma^2\)</span>, a scalar global variance <span class="math inline">\(\sigma^2\)</span>, and a simplex <span class="math inline">\(\vec{\pi}\)</span> (proportion of total variance for each variable):
<span class="math display">\[
\begin{aligned}[t]
\mat{\Sigma} &amp;= \mat{\Omega} \mat{R}  \\
\diag(\mat{\Omega}) &amp;= n \vec{\pi} \sigma^2
\end{aligned}
\]</span>
Separate and interpretable priors can be put on <span class="math inline">\(\mat{R}\)</span>, <span class="math inline">\(\vec{\pi}\)</span>, and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The LKJ (Lewandowski, ) distribution is a distribution over correlation coefficients,
<span class="math display">\[
R \sim \dlkjcorr(\eta) ,
\]</span>
where
<span class="math display">\[
\dlkjcorr(\Sigma | \eta) \propto \det(\Sigma)^{(\eta - 1)} .
\]</span></p>
<p>This distribution has the following properties:</p>
<ul>
<li><span class="math inline">\(\eta = 1\)</span>: uniform correlations</li>
<li><span class="math inline">\(\eta \to \infty\)</span>: approaches the identity matrix</li>
<li><span class="math inline">\(0 &lt; \eta &lt; 1\)</span>: there is a trough at the identity matrix with higher probabilities placed on non-zero correlations.</li>
<li>For all positive <span class="math inline">\(\eta\)</span> (<span class="math inline">\(\eta &gt; 0\)</span>), <span class="math inline">\(\E(R) = \mat{I}\)</span>.</li>
</ul>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb148-1" data-line-number="1">lkjcorr_df &lt;-<span class="st"> </span><span class="cf">function</span>(eta, <span class="dt">n =</span> <span class="dv">2</span>) {</a>
<a class="sourceLine" id="cb148-2" data-line-number="2">  out &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rlkjcorr</span>(n, eta))</a>
<a class="sourceLine" id="cb148-3" data-line-number="3">  out<span class="op">$</span>.row &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="kw">nrow</span>(out))</a>
<a class="sourceLine" id="cb148-4" data-line-number="4">  out &lt;-<span class="st"> </span><span class="kw">gather</span>(out, .col, value, <span class="op">-</span>.row)</a>
<a class="sourceLine" id="cb148-5" data-line-number="5">  out<span class="op">$</span>.col &lt;-<span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">str_replace</span>(out<span class="op">$</span>.col, <span class="st">&quot;^V&quot;</span>, <span class="st">&quot;&quot;</span>))</a>
<a class="sourceLine" id="cb148-6" data-line-number="6">  out<span class="op">$</span>eta &lt;-<span class="st"> </span>eta</a>
<a class="sourceLine" id="cb148-7" data-line-number="7">  out  </a>
<a class="sourceLine" id="cb148-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb148-9" data-line-number="9"></a>
<a class="sourceLine" id="cb148-10" data-line-number="10">lkjsims &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map_df</span>(<span class="kw">c</span>(<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">50</span>, <span class="dv">1000</span>), lkjcorr_df, <span class="dt">n =</span> <span class="dv">50</span>)</a></code></pre></div>
<p>This simulates a single matrix from the LKJ distribution with different values of <span class="math inline">\(\eta\)</span>.
As <span class="math inline">\(\eta \to \infty\)</span>, the off-diagonal correlations tend towards 0, and the correlation matrix to the identity matrix.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" data-line-number="1"><span class="kw">ggplot</span>(lkjsims,</a>
<a class="sourceLine" id="cb149-2" data-line-number="2">       <span class="kw">aes</span>(<span class="dt">x =</span> .row, <span class="dt">y =</span> .col, <span class="dt">fill =</span> value)) <span class="op">+</span></a>
<a class="sourceLine" id="cb149-3" data-line-number="3"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>eta, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb149-4" data-line-number="4"><span class="st">  </span><span class="kw">scale_fill_distiller</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">type =</span> <span class="st">&quot;div&quot;</span>, <span class="dt">palette =</span> <span class="st">&quot;RdYlBu&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb149-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_raster</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb149-6" data-line-number="6"><span class="st">  </span><span class="kw">theme_minimal</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb149-7" data-line-number="7"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(), <span class="dt">axis.text =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></a>
<a class="sourceLine" id="cb149-8" data-line-number="8"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</a></code></pre></div>
<p><img src="appendix_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The density of the off-diagonal correlations.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" data-line-number="1">lkjsims <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb150-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(.row <span class="op">&lt;</span><span class="st"> </span>.col) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb150-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">colour =</span> <span class="kw">factor</span>(eta))) <span class="op">+</span></a>
<a class="sourceLine" id="cb150-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_density</span>()</a></code></pre></div>
<p><img src="appendix_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>For other discussions of the LKJ correlation distribution, see these:</p>
<ul>
<li><a href="https://stats.stackexchange.com/questions/2746/how-to-efficiently-generate-random-positive-semidefinite-correlation-matrices/125017#125017" class="uri">https://stats.stackexchange.com/questions/2746/how-to-efficiently-generate-random-positive-semidefinite-correlation-matrices/125017#125017</a></li>
<li><a href="http://www.zinkov.com/posts/2015-06-09-where-priors-come-from/" class="uri">http://www.zinkov.com/posts/2015-06-09-where-priors-come-from/</a></li>
<li><a href="http://www.psychstatistics.com/2014/12/27/d-lkj-priors/" class="uri">http://www.psychstatistics.com/2014/12/27/d-lkj-priors/</a></li>
</ul>
</div>
<div id="qr-factorization" class="section level3">
<h3><span class="header-section-number">14.9.4</span> QR Factorization</h3>
<p>For a full-rank <span class="math inline">\(N \times K\)</span> matrix, the QR factorization is
<span class="math display">\[
\mat{X} = \mat{Q} \mat{R} 
\]</span>
where <span class="math inline">\(\mat{Q}\)</span> is an orthonormal matrix such that <span class="math inline">\(\mat{Q}\T \mat{Q}\)</span> and
<span class="math inline">\(\mat{R}\)</span> is an upper triangular matrix.</p>
<p>Stan function
<span class="citation">Stan Development Team (2016)</span> suggest writing it is
<span class="math display">\[
\begin{aligned}[t]
\mat{Q}^* = \mat{Q} \times \sqrt{N - 1} \\
\mat{R}^* = \frac{1}{\sqrt{N - 1}} \mat{R}
\end{aligned}
\]</span></p>
<p>This is used for solving linear model.</p>
<p>Suppose <span class="math inline">\(\vec{\beta}\)</span> is a <span class="math inline">\(K \times 1\)</span> vector, then
<span class="math display">\[
\vec{eta} = \mat{x} \vec{\beta} = \mat{Q} \mat{R} \vec{\beta} = \mat{Q}^* \mat{R}^* \vec{\beta} .
\]</span>
Suppose <span class="math inline">\(\mat{theta} = \mat{R}^* \vec{\beta}\)</span>, then <span class="math inline">\(\vec{eta} = \mat{Q}^* \mat{\theta}\)</span> and <span class="math inline">\(\vec{beta} = {\mat{R}^*}^{-1} \mat{\theta}\)</span>.</p>
<p><a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/lm.html">rstanarm</a> provides a prior for a normal linear model which uses the QR decomposition to parameterize a prior in terms of <span class="math inline">\(R^2\)</span>.</p>
<p>Stan functions:</p>
<ul>
<li><code>qr_Q(matrix A)</code></li>
<li><code>qr_R(matrix A)</code></li>
</ul>
<p>See <span class="citation">Stan Development Team (2016 Sec 8.2)</span></p>
</div>
<div id="cholesky-decomposition" class="section level3">
<h3><span class="header-section-number">14.9.5</span> Cholesky Decomposition</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition">Cholesky decomposition</a> of a
positive definite matrix <span class="math inline">\(A\)</span> is,
<span class="math display">\[
\mat{A} = \mat{L} \mat{L}\T ,
\]</span>
where <span class="math inline">\(\mat{L}\)</span> is a lower-triangular matrix.</p>
<ul>
<li>It is similar to a square root for a matrix.</li>
<li><p>It often more numerically stable or efficient to work with the Cholesky decomposition, than with
a covariance matrix. When working with the covariance matrix, numerical precision can
result in a non positive definite matrix. However, working with <span class="math inline">\(\mat{L}\)</span> will ensure
that <span class="math inline">\(\mat{A} = \mat{L} \mat{L}\T\)</span> will be positive definite.</p></li>
<li><p>In Stan</p>
<ul>
<li>Types types <code>cholesky_factor_cov</code>, and <code>cholesky_factor_corr</code> represent the Cholesky factor
of covariance and correlation matrices, respectively.</li>
<li>Cholesky decomposition function is <code>cholesky_decompose(matrix A)</code></li>
</ul></li>
<li><p>Multiple functions in Stan are parameterized with Cholesky decompositions instead of or in addition
to covariance matrices. Use them if possible; they are more numerically stable.</p>
<ul>
<li><code>lkj_corr_chol_lpdf</code></li>
<li><code>multi_normal_cholesky_lpdf</code></li>
</ul></li>
</ul>
<p>The Cholesky factor is used for sampling from a multivariate normal distribution using i.i.d. standard normal distributions.
Suppose <span class="math inline">\(X_1, \dots, X_N\)</span> are <span class="math inline">\(N\)</span> i.i.d. standard normal distributions, <span class="math inline">\(\mat{\Omega}\)</span> is an <span class="math inline">\(N \times N\)</span> lower-triangular matrix such that <span class="math inline">\(\mat{\Omega} \mat{Omega}\T = \mat{\Sigma}\)</span>, and <span class="math inline">\(\mu\)</span> is an <span class="math inline">\(N \times 1\)</span> vector, then
<span class="math display">\[
\vec{\mu} + \mat{\Omega} X \sim \dnorm(\vec{\mu}, \mat{\Sigma})
\]</span></p>
<p>See <span class="citation">Stan Development Team (2016, 40, 147, 241, 246)</span></p>
</div>
</div>
</div>
<div id="scaled-and-unscaled-variables" class="section level1">
<h1><span class="header-section-number">15</span> Scaled and Unscaled Variables</h1>
<p>Though priors shouldn’t depend on the data itself, many priors depends</p>
<p>Suppose <span class="math inline">\(\tilde{Y}\)</span>, <span class="math inline">\(\tilde{X}\)</span>, <span class="math inline">\(\tilde{\alpha}\)</span>, <span class="math inline">\(\tilde{\beta}\)</span>, and <span class="math inline">\(\epsilon\)</span> are random variables, such that
<span class="math display">\[
\tilde{Y} = \tilde{\alpha} + \tilde{\beta} \tilde{X} + \epsilon .
\]</span>
These random variables have the following properties:
<span class="math display">\[
\begin{aligned}
\tilde{Y} &amp;= \frac{Y - \bar{Y}}{\sigma_Y}, &amp; \E\[\tilde{Y}\] &amp;= 0, &amp; \sigma_Y^2 &amp;= \V\[\tilde{Y}\] = 1 \\
\tilde{X} &amp;= \frac{X - \bar{X}}{\sigma_X}, &amp;  \E\[\tilde{X}\] &amp;= 0, &amp; \sigma_X^2 &amp;= \V\[\tilde{X}\] = 1 , \\
&amp;&amp; \E\[\epsilon\] &amp;= 0 &amp; \sigma_{\tilde{\epsilon}}^2 &amp;= \V\[\tilde{\epsilon}\]
\end{aligned}
\]</span>
where
<span class="math display">\[
\begin{aligned}[t]
\bar{X} &amp;= \E\[X\] , &amp; s_X^2 &amp;= \V\[X\] , \\
\bar{Y} &amp;= \E\[Y\] , &amp; s_Y^2 &amp;= \V\[Y\] . 
\end{aligned}
\]</span></p>
<p>Then via some algebra,
<span class="math display">\[
\begin{aligned}
Y &amp;= \underbrace{\sigma_{Y} \tilde{\alpha} + \bar{Y} - \frac{\sigma_Y }{\sigma_X} \tilde{\beta} \bar{X}}_{\alpha} + 
\underbrace{\frac{\sigma_Y}{\sigma_X} \tilde{\beta}}_{\beta} X + \underbrace{\sigma_Y \tilde{\epsilon}}_{\epsilon} \\ 
  &amp;= \alpha + \beta X + \epsilon .
\end{aligned}
\]</span>
The primary relationships of interest are those between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\tilde{\alpha}\)</span>, <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\tilde{\beta}\)</span>, and <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\tilde{\epsilon}\)</span>.
These can be used to convert between coefficients estimated with standardized data to the coefficients on the data scale, or to adjust scale-free weakly informative priors to the data scale.
<span class="math display">\[
\begin{aligned}[t]
\tilde{\alpha} &amp;= \sigma_Y^{-1}\left(\alpha - \bar{Y} + \beta \bar{X} \right) \\
&amp;= \sigma_Y^{-1}\left(\alpha - \bar{Y} + \frac{\sigma_Y}{\sigma_X} \tilde{\beta} \bar{X} \right), \\
\alpha &amp;= \sigma_Y \tilde{\alpha} + \bar{Y} - \frac{\sigma_Y}{\sigma_X} \tilde{\beta} \bar{X} \\
       &amp;= \sigma_Y \tilde{\alpha} + \bar{Y} - \beta \bar{X} ,  \\
\tilde{\beta} &amp;= \frac{\sigma_X}{\sigma_Y} \beta , \\
\beta &amp;= \frac{\sigma_Y}{\sigma_X} \tilde{\beta} , \\
\tilde{\epsilon} &amp;= \epsilon / \sigma_Y , \\
\epsilon &amp;= \sigma_Y \tilde{\epsilon} .
\end{aligned}
\]</span>
This implies the following relationships between their means and variances,
<span class="math display">\[
\begin{aligned}[t]
E(\alpha) &amp;= \sigma_{Y} E(\tilde{\alpha}) + \bar{Y} - \frac{\sigma_Y}{\sigma_X} \tilde{\beta} \bar{X} , \\
E(\tilde{\alpha}) &amp;= \frac{E(\alpha) - \bar{Y} + \beta \bar{X} }{\sigma_Y}
\end{aligned}
\]</span>
For example, a weakly informative prior on <span class="math inline">\(\tilde{\alpha}\)</span> implies a prior on <span class="math inline">\(\alpha\)</span>,
<span class="math display">\[
\tilde{\alpha} \sim N(0, 10^2) \to \alpha \sim N \left( \frac{\beta \bar{X} - \bar{Y}}{\sigma_Y}, \sigma_Y^2 10^2 \right) .
\]</span></p>
<p><span class="math display">\[
\begin{aligned}[t]
E(\beta) &amp;= \frac{\sigma_Y}{\sigma_X} E(\tilde{\beta})  , &amp;
V(\beta) &amp;= \frac{\sigma_Y^2}{\sigma_X^2} V(\tilde{\beta})  , \\
E(\tilde{\beta}) &amp;= \frac{\sigma_X}{\sigma_Y} E(\beta)  , &amp;
V(\tilde{\beta}) &amp;= \frac{\sigma_X^2}{\sigma_Y^2} V(\beta) . 
\end{aligned}
\]</span></p>
<p>For example, a weakly informative prior on <span class="math inline">\(\tilde{\beta}\)</span> implies the following prior on <span class="math inline">\(\beta\)</span>,
<span class="math display">\[
\tilde{\beta} \sim N(0, 2.5^2) \to \beta \sim N\left(0, \frac{\sigma_Y^2}{\sigma_X^2} 2.5^2 \right) .
\]</span></p>
<p><span class="math display">\[
\begin{aligned}[t]
E(\epsilon) &amp;= 0 , &amp; V(\epsilon) &amp;= \sigma_Y^2 V(\tilde{\epsilon}), \\
E(\tilde{\epsilon}) &amp;= 0 , &amp; V(\tilde{\epsilon}) &amp;= \sigma_Y^{-2}  V(\epsilon) .
\end{aligned}
\]</span>
For example, a weakly informative prior on the variance of <span class="math inline">\(\tilde{\epsilon}}\)</span> implies a weakly informative prior on the variance of <span class="math inline">\(\epsilon\)</span>,
<span class="math display">\[
\sigma_{\tilde{\epsilon}} \sim C^{+}\left(0, 5 \right) \to 
\sigma_{\epsilon} \sim C^{+}\left(0, \sigma_Y 5 \right) .
\]</span></p>
<p>All of the above calculations are a little sloppy since I’m treating the other random variables as constants when deriving these (basically assuming <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are independent).</p>
<p><strong>TODO</strong> handle multivariate case, with whitening transformation
<span class="math display">\[
\tilde{Y} = \beta&#39; \tilde{X} + \epsilon
\]</span>
where
<span class="math display">\[
\begin{aligned}[t]
E(\tilde{Y}) &amp;= 0, &amp; V(\tilde{Y}) &amp;= 1, \\
E(\tilde{X}) &amp;= 0_k, &amp; V(\tilde{Y}) &amp;= I_k .
\end{aligned}
\]</span>
and
<span class="math display">\[
\begin{aligned}[t]
\tilde{Y} &amp;= \sigma_Y^{-1}(Y - \bar{Y}) &amp;, Y &amp;= \sigma_{\tilde{Y}} Y + \bar{Y} \\
\tilde{X} &amp;= L (X - \bar{X}), &amp; X &amp;= L^{-1} \tilde{X} + \bar{X}
\end{aligned}
\]</span>
where <span class="math inline">\(L\)</span> is a <span class="math inline">\(k \times k\)</span> whitening matrix.
This is a matrix such that <span class="math inline">\(L&#39; L = V(X)^{-1}\)</span>.
With a sample, <span class="math inline">\(L = chol(X&#39; X)\)</span>.</p>
<!--chapter:end:appendix.Rmd-->
</div>
<div id="annotated-bibliography" class="section level1">
<h1><span class="header-section-number">16</span> Annotated Bibliography</h1>
<div id="textbooks" class="section level3">
<h3><span class="header-section-number">16.0.1</span> Textbooks</h3>
<ul>
<li>Gelman and Hill (2006) <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em></li>
<li>Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin (2013) <em>Bayesian Data Analysis</em> 3rd ed. CRC Press.</li>
<li>Jackman, Simon. 2009. <em>Bayesian Analysis for the Social Sciences</em></li>
<li>Lynch, Scott M. 2007. <em>Introduction to Applied Bayesian Statistics and Estimation for Social Scientists</em> New York: Springer.</li>
<li><p>McElreath, Richard. 2016. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan.</em></p>
<ul>
<li>github page for Statistical Rethinking <a href="https://github.com/rmcelreath/rethinking" class="uri">https://github.com/rmcelreath/rethinking</a></li>
<li><a href="http://xcelab.net/rm/statistical-rethinking/" class="uri">http://xcelab.net/rm/statistical-rethinking/</a></li>
</ul></li>
<li>Lunn, David, Chris Jackson, Nicky Best, Andrew Thomas, and David Spiegelhalter. 2012. <em>The BUGS Book: A Practical Introduction to Bayesian Analysis</em> Boca Raton, FL: Chapman; Hall/CRC.</li>
<li>Peter Hoff. 2009. <em>A First Course in Bayesian Statistical Methods</em></li>
<li>Congdon. 2014. Applied Bayesian Modeling.</li>
<li>Casella and Roberts. 2004 <em>Monte Carlo Statistical Methods</em></li>
<li>Marin and Roberts. 2014. <em>Bayesian Essentials with R.</em> <a href="http://www.springer.com/us/book/9781461486862" class="uri">http://www.springer.com/us/book/9781461486862</a></li>
<li><p>Robert and Casella. <em>Introducing Monte Carlo Methods with R</em></p></li>
</ul>
</div>
<div id="syllabi" class="section level2">
<h2><span class="header-section-number">16.1</span> Syllabi</h2>
<ul>
<li>Ryan Bakker and Johannes Karreth, “Introduction to Applied Bayesian Modeling” ICPSR. Summer 2016. <a href="http://www.jkarreth.net/files/bayes2016.pdf">Syllabus</a>; <a href="https://github.com/jkarreth/Bayes">code</a></li>
<li>Justin Esarey. “Advanced Topics in Political Methodology: Bayesian Statistics” Winter 2015. <a href="http://jee3.web.rice.edu/POLS506-syllabus-2015.pdf">Syllabus</a>; <a href="http://jee3.web.rice.edu/teaching.htm">Lectures</a>.</li>
<li>Kruschke. <a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis site</a>.</li>
<li>Nick Beauchamp. “Bayesian Methods.” NYU. <a href="http://www.democraticwriting.com/work/Beauchamp_bayesian_syllabus.pdf">syllabus</a>.</li>
<li>Alex Tanhk. “Bayesian Methods for the Social Sciences” U of Wisconsin. Spring 2017. <a href="https://polisci.wisc.edu/sites/polisci.wisc.edu/files/documents/syllabi/PS%20919%20.pdf">syllabus</a>.</li>
<li>MTH225 Statistics for Science Spring 2016. <a href="https://github.com/equinn1/MTH225_Spring2016">github website</a>.</li>
<li>Ben Goodrich, “Bayesian Statistics for Social Sciences” Columbia University. Spring 2016.</li>
<li>Bakker. “Introduction to Applied Bayesian Analysis” University of Georgia. <a href="http://spia.uga.edu/faculty_pages/rbakker/bayes/bayes2016_maymester.pdf">syllabus</a>; <a href="http://spia.uga.edu/faculty_pages/rbakker/bayes/POLS%20Bayes.htm">site</a></li>
<li>Myimoto. “Advances in Quantitative Psychology: Bayesian Statistics, Modeling &amp; Reasoning” U of Washington. Winter 2017. <a href="http://faculty.washington.edu/jmiyamot/p548/p548-set.htm">site</a></li>
<li>Neil Frazer. Bayesian Data Analysis. Hawaii. Spring 2017. <a href="http://www.soest.hawaii.edu/GG/resources/syllabi-S17/gg695-s17-syl.pdf">syllabus</a></li>
<li>Lopes. 2016. Bayesian Statistical Learning: Readings in Statistics and Econometrics. <a href="http://hedibert.org/current-teaching/">syllabus</a>.</li>
<li>Lopes. 2012 <a href="http://hedibert.org/simulation-based-approaches-to-modern-bayesian-econometrics/">Simulation-based approaches to modern Bayesian econometrics</a>. Short course.</li>
<li>Lopes. 2015. Bayesian Econometrics. <a href="http://hedibert.org/current-teaching/">syllabus</a>.</li>
</ul>
</div>
<div id="topics" class="section level2">
<h2><span class="header-section-number">16.2</span> Topics</h2>
</div>
<div id="bayes-theorem" class="section level2">
<h2><span class="header-section-number">16.3</span> Bayes’ Theorem</h2>
<ul>
<li>Puga, Kryzwinski, and Altman (2015) “<a href="https://dx.doi.org/10.1038/nmeth.3335">Points of significance: Bayes’ theorem</a>” <em>Nature Methods</em></li>
</ul>
</div>
<div id="article-length-introductions-to-bayesian-statistics" class="section level2">
<h2><span class="header-section-number">16.4</span> Article Length Introductions to Bayesian Statistics</h2>
<ul>
<li>Stan Modeling 2.17. Ch. 29. “Bayesian Inference”</li>
<li>Michael Clarke <a href="https://m-clark.github.io/docs/IntroBayes.html">Bayesian Basics</a>.</li>
<li>Eddy (2004) “<a href="https://dx.doi.org/10.1038/nbt0904-1177">What is Bayesian Statistics</a>” <em>Nature Biotechnology</em></li>
<li>Jackman. 2004. Bayesian Analysis for Political Research. <em>Annual Review of Political Science</em> DOI: 10.1146/annurev.polisci.7.012003.104706.</li>
<li>Kruschke, J.K. &amp; Liddell, T.M. Psychon Bull Rev (2017). <a href="doi:10.3758/s13423-016-1221-4" class="uri">doi:10.3758/s13423-016-1221-4</a> - Kruschke and Liddell (2017) “<a href="https://dx.doi.org/10.3758/s13423-016-1221-4">Bayesian new statistics: hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</a>”</li>
</ul>
<div id="why-bayesian" class="section level3">
<h3><span class="header-section-number">16.4.1</span> Why Bayesian</h3>
<ul>
<li>Jim Savage. <a href="http://modernstatisticalworkflow.blogspot.com/2017/04/why-learn-bayesian-modeling.html">Why learn Bayesian Modeling?</a> April 10, 2017.</li>
</ul>
</div>
<div id="modern-statistical-workflow" class="section level3">
<h3><span class="header-section-number">16.4.2</span> Modern Statistical Workflow</h3>
<ul>
<li><p>Savage, Jaim. 2017. <a href="https://khakieconomics.github.io/half_day_course/msw.html">A Brief Introduction to Econometrics in Stan</a></p></li>
<li>Betancourt, Michael. <a href="http://mc-stan.org/users/documentation/case-studies/rstan_workflow.html">Robust Staistical Workflow with RStan</a></li>
<li>Stan Modeling 2.17. “Model Building as Software Development”</li>
<li><p>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., Gelman, A. (2018). Visualization in Bayesian workflow. Journal of the Royal Statistical Society Series A, accepted for publication. arXiv preprint: <a href="https://arxiv.org/abs/1709.01449" class="uri">https://arxiv.org/abs/1709.01449</a></p></li>
</ul>
</div>
<div id="bayesian-philosophy" class="section level3">
<h3><span class="header-section-number">16.4.3</span> Bayesian Philosophy</h3>
<ul>
<li>Gelman (2008) “<a href="https://dx.doi.org/10.1214/08-ba318">Objections to Bayesian Statistics</a>” <em>Bayesian Analysis</em></li>
<li>Gelman and Shalizi (2012) “<a href="https://dx.doi.org/10.1111/j.2044-8317.2011.02037.x">Philosophy and the practice of Bayesian statistics</a>” <em>British Journal of Mathematical and Statistical Psychology</em></li>
<li>Borsboom and Haig (2012) “<a href="10.1111/j.2044-8317.2012.02062.x">How to practise Bayesian statistics outside the Bayesian church: What philosophy for Bayesian statistical modelling?</a>” <em>British Journal of Mathematical and Statistical Psychology</em>
journaltitle = {</li>
<li>Berger and Berry (1988) “<a href="http://www.jstor.org/stable/27855070">Statistical Analysis and the Illusion of Objectivity</a>” <em>American Scientist</em>
American Scientist 1988</li>
<li><p>Efron (2010) “<a href="https://dx.doi.org/10.1214/09-STS308">The Future of Indirect Evidence</a>”</p></li>
<li><p>Efron (1986) “<a href="https://dx.doi.org/10.1080/00031305.1986.10475342">Why Isn’t Everyone a Bayesian?</a>” <em>American Statistician</em> <span class="citation">(B. Efron 1986b)</span>. See comments <span class="citation">Chernoff (1986)</span>, <span class="citation">Lindley (1986)</span>, <span class="citation">Morris (1986)</span>, <span class="citation">Smith (1986)</span>, <span class="citation">Press (1986)</span>, <span class="citation">B. Efron (1986a)</span>.</p></li>
<li>Philosophy and the practice of Bayesian statistics in the social sciences. tp://www.stat.columbia.edu/~gelman/research/published/philosophy_chapter.pdf</li>
<li>Rubin (1984) Rubin, Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician. Ann. Statist. 12 (1984), no. 4, 1151–1172. <a href="doi:10.1214/aos/1176346785" class="uri">doi:10.1214/aos/1176346785</a>. <a href="http://projecteuclid.org/euclid.aos/1176346785" class="uri">http://projecteuclid.org/euclid.aos/1176346785</a>.</li>
<li>Andrew Gelman Induction and Deduction in Bayesian Data Analysis</li>
<li><p>Berger (2013) “<a href="https://dx.doi.org/10.1214/ss/1056397485">Could Fisher, Jeffreys and Neyman Have Agreed on Testing?</a> <em>Statistical Science</em></p></li>
</ul>
</div>
<div id="bayesian-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">16.4.4</span> Bayesian Hypothesis Testing</h3>
<ul>
<li>Gross, J. H. (2015) “<a href="https://dx.doi.org/10.1111/ajps.12149">Testing What Matters (If You Must Test at All): A Context-Driven Approach to Substantive and Statistical Significance</a>” <em>American Journal of Political Science</em> <span class="citation">(Gross 2014)</span></li>
</ul>
</div>
<div id="bayesian-frequentist-debates" class="section level3">
<h3><span class="header-section-number">16.4.5</span> Bayesian Frequentist Debates</h3>
<ul>
<li><a href="http://www.stat.ufl.edu/archived/casella/Talks/BayesRefresher.pdf">Bayesians and Frequentists : Models, Assumptions, and Inference</a> slides</li>
<li>Kass Statitsical Inference: The Big Picture <a href="https://arxiv.org/pdf/1106.2895v2.pdf" class="uri">https://arxiv.org/pdf/1106.2895v2.pdf</a></li>
<li>Noah Smith <a href="http://noahpinionblog.blogspot.com/2013/01/bayesian-vs-frequentist-is-there-any.html">Bayesian vs. Frequentist: Is there any “there” there?</a></li>
<li>Kass <a href="http://www.stat.cmu.edu/~kass/papers/kinds.pdf">Kinds of Bayesians</a></li>
<li>Anthony O’Hagan. Science, Subjectivity and Software (Comments on the articles by Berger and Goldstein)</li>
</ul>
</div>
<div id="categorical" class="section level3">
<h3><span class="header-section-number">16.4.6</span> Categorical</h3>
<ul>
<li><p>Agresti. Bayesian Inference for Categorical Data Analysis. <a href="http://www.stat.ufl.edu/~aa/cda2/bayes.pdf" class="uri">http://www.stat.ufl.edu/~aa/cda2/bayes.pdf</a></p></li>
<li><p><strong>Perfect Separation</strong></p>
<ul>
<li>Gelman. 2008. “A weakly informative default prior distribution for logistic and other regression models” <em>Ann Applied Stat</em> <a href="doi:10.1214/08-AOAS191" class="uri">doi:10.1214/08-AOAS191</a></li>
</ul></li>
<li>Rainey. 2016. “Dealing with Separation in Logistic Regression Models” <em>Political Analysis</em></li>
<li><p><span class="citation">Wechsler, Izbicki, and Esteves (2013)</span> “A Bayesian look at nonidentifiability: a simple example”&quot;</p></li>
</ul>
</div>
<div id="variable-selection" class="section level3">
<h3><span class="header-section-number">16.4.7</span> Variable Selection</h3>
<ul>
<li><span class="citation">J. Ghosh and Ghattas (2015)</span> Ghosh and Ghattas (2015) “Bayesian Variable Selection Under Colinearity” <em>American Statistician</em></li>
<li>Scott and Berger (2011) “<a href="https://dx.doi.org/10.1214/10-Aos792">Bayes and empirical-Bayes multiplicity adjustment in the variable-selection problem</a>” <em>Annals of Statistics</em> <span class="citation">(Scott and Berger 2010)</span></li>
<li>Ishwaran and Rao (2005) “<a href="https://dx.doi.org/10.1214/009053604000001147">Spike and slab variable selection: Frequentist and Bayesian strategies</a>” <em>Annalsb of Statistics</em></li>
<li>Ishwaran, Kogalur, and Rao (2010) “<a href="ttps://journal.r-project.org/archive/2010-2/RJournal_2010-2_Ishwaran~et~al.pdf">spikeslab: prediction and variable selection using spike and slab regression</a>” <em>R Journal</em></li>
<li>Piironen and Vehtari (2015) “<a href="http://arxiv.org/pdf/1508.02502v1:PDF">Projection predictive variable selection using {Stan}+{R}</a>”</li>
<li>Polson and Scott. “<a href="https://dx.doi.org/10.1093/acprof:oso/9780199694587.003.0017">Shrink globally, act locally: sparse Bayesian regularization and prediction</a>” <em>Bayesian Statistics</em></li>
<li>Projection predictive variable selection using Stan+R <a href="https://arxiv.org/abs/1508.02502" class="uri">https://arxiv.org/abs/1508.02502</a></li>
<li>Lasso Meets Horseshoe. <a href="https://arxiv.org/pdf/1706.10179.pdf" class="uri">https://arxiv.org/pdf/1706.10179.pdf</a></li>
<li>Piironen and Vehtari. Sparsity information and regularization in the horseshoe and other shrinkage priors <a href="https://arxiv.org/pdf/1706.10179.pdf" class="uri">https://arxiv.org/pdf/1706.10179.pdf</a></li>
<li>DECOUPLING SHRINKAGE AND SELECTION IN BAYESIAN
LINEAR MODELS: A POSTERIOR SUMMARY PERSPECTIVE. By P. Richard Hahn and Carlos M. Carvalho. <a href="https://arxiv.org/pdf/1408.0464.pdf" class="uri">https://arxiv.org/pdf/1408.0464.pdf</a></li>
<li>Michael Betancourt <a href="https://betanalpha.github.io/assets/case_studies/bayes_sparse_regression.html">Bayes Sparse Regression</a></li>
</ul>
</div>
<div id="multiple-testing" class="section level3">
<h3><span class="header-section-number">16.4.8</span> Multiple Testing</h3>
<ul>
<li>Gelman, Hill, and Yajima (2012) “<a href="https://dx.doi.org/10.1080/19345747.2011.618213">Why we (Usually) don’t have to worry about multiple comparisons</a>” <em>Journal of Research on Educational Effectiveness</em></li>
</ul>
</div>
<div id="rare-events" class="section level3">
<h3><span class="header-section-number">16.4.9</span> Rare Events</h3>
<ul>
<li>King and Zheng. 2001. “Explaining Rare Events in International Relations” <em>Int Org</em> <a href="https://doi.org/10.1162/00208180152507597" class="uri">https://doi.org/10.1162/00208180152507597</a></li>
<li>King, Gary, and Langche Zeng. 2001. “Logistic Regression in Rare Events Data.” <em>Political Analysis</em> <a href="http://www.jstor.org/stable/25791637" class="uri">http://www.jstor.org/stable/25791637</a>.</li>
</ul>
</div>
<div id="identifiability" class="section level3">
<h3><span class="header-section-number">16.4.10</span> Identifiability</h3>
<ul>
<li>Weschler et al. 2013. A. Bayesian Look at Nonidentifiability: A Simple Example. <em>Am stat</em> <a href="http://dx.doi.org/10.1080/00031305.2013.778787" class="uri">http://dx.doi.org/10.1080/00031305.2013.778787</a></li>
</ul>
</div>
<div id="shrinkage" class="section level3">
<h3><span class="header-section-number">16.4.11</span> Shrinkage</h3>
<ul>
<li>Efron and Morris (1975) “<a href="https://dx.doi.org/10.1080/01621459.1975.10479864">Data Analysis Using Stein’s Estimator and its Generalizations</a>” <em>JASA</em> <span class="citation">(Efron and Morris 1975)</span></li>
</ul>
</div>
<div id="inference" class="section level3">
<h3><span class="header-section-number">16.4.12</span> Inference</h3>
<div id="gibbs" class="section level4">
<h4><span class="header-section-number">16.4.12.1</span> Gibbs</h4>
<ul>
<li><span class="citation">(Allison and Dunkley 2013)</span> <a href="https://arxiv.org/pdf/1308.2675.pdf">Comparison of sampling techniques for Bayesian parameter estimation</a></li>
<li>Gelfand et al. (1990) “<a href="https://dx.doi.org/10.1080/01621459.1990.10474968">Illustration of Bayesian Inference in Normal Data Models Using Gibbs Sampling</a>” <em>JASA</em></li>
<li>Chib and Greenberg “<a href="https://dx.doi.org/10.1080/00031305.1995.10476177">Understanding the Metropolis-Hastings Algorithm</a>”</li>
<li>Geyer. MCMC: Does it work? How can we tell?<a href="http://users.stat.umn.edu/~geyer/jsm09.pdf" class="uri">http://users.stat.umn.edu/~geyer/jsm09.pdf</a></li>
</ul>
</div>
<div id="hmc" class="section level4">
<h4><span class="header-section-number">16.4.12.2</span> HMC</h4>
<ul>
<li>Neal (2011) <a href="https://arxiv.org/pdf/1206.1901.pdf">MCMC using Hamiltonian dynamics</a> in <em>Handbook of Markov Chain Monte Carlo</em>.</li>
<li>Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte Carlo. <a href="https://arxiv.org/abs/1701.02434" class="uri">https://arxiv.org/abs/1701.02434</a></li>
</ul>
</div>
</div>
<div id="convergence" class="section level3">
<h3><span class="header-section-number">16.4.13</span> Convergence</h3>
<ul>
<li>Gelman, A. and Rubin, D. B. (1992) “<a href="http://www.jstor.org/stable/2246093">Inference from iterative simulation using multiple sequences</a>” <em>Statistical Science</em></li>
<li>Stan Modeling Language, Ch 30. Markov Chain Monte Carlo Sampling</li>
<li>Gabry, Jonah. <a href="http://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html">Visual MCMC diagnostics using the bayesplot plackage</a></li>
<li>Gabyr, Jonah. <a href="http://mc-stan.org/bayesplot/articles/plotting-mcmc-draws.html">Plotting MCMC draws using the bayesplot package</a></li>
</ul>
<div id="variational" class="section level4">
<h4><span class="header-section-number">16.4.13.1</span> Variational</h4>
<ul>
<li>Grimmer (2011) “<a href="https://dx.doi.org/10.1093/pan/mpq027">An Introduction to Bayesian Inference via Variational Approximations</a>” <em>Political Analysis</em> <span class="citation">(Grimmer 2011)</span></li>
<li>Raganath et al. (2015) “<a href="https://arxiv.org/abs/1401.0118">Black Box Variational Inference</a>” <span class="citation">(Ranganath, Gerrish, and Blei 2014)</span></li>
</ul>
</div>
<div id="expectation-propogation" class="section level4">
<h4><span class="header-section-number">16.4.13.2</span> Expectation Propogation</h4>
<ul>
<li>Gelman et. al. 2017. “<a href="https://arxiv.org/pdf/1412.4869.pdf">Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data</a>”</li>
</ul>
</div>
<div id="importance-resampling" class="section level4">
<h4><span class="header-section-number">16.4.13.3</span> Importance Resampling</h4>
<ul>
<li>Smith and Gelfand (1992) “<a href="https://dx.doi.or/10.1080/00031305.1992.10475856">Bayesian Statistics without Tears: A Sampling–Resampling Perspective</a>” <em>American Statistician</em> <span class="citation">(Smith and Gelfand 1992)</span></li>
<li>Gelfand and Smith. “<a href="https://dx.doi.org/10.1080/01621459.1990.10476213">Sampling-Based Approaches to Calculating Marginal Densities</a>” <em>JASA</em></li>
<li>Lopes, Polson, and Carvalho. “<a href="http://www.jstor.org/stable/43601224">Bayesian Statistics with a Smile: A Resampling-sampling Perspective</a>” <em>Brazilian Journal of Probability and Statistics</em> []</li>
</ul>
</div>
</div>
<div id="software" class="section level3">
<h3><span class="header-section-number">16.4.14</span> Software</h3>
<p>Sofware for general purpose Bayesian computation is called <a href="https://en.wikipedia.org/wiki/Probabilistic_programming_language">probablistic programming</a>, though the term is used in CS and not so much in stats, or social science.</p>
<ul>
<li><p><a href="http://mc-stan.org/">Stan</a></p>
<ul>
<li>Joseph Rickert. 2016. <a href="https://www.r-bloggers.com/r-stan-and-bayesian-statistics/">R Stan and Statistics</a></li>
</ul></li>
<li><p>BUGS modeling language. Models are specified in a different language.</p>
<ul>
<li><a href="https://r-nimble.org/">NIMBLE</a> A very new BUGS-like lanugage that works with R.</li>
<li><a href="http://mcmc-jags.sourceforge.net/">JAGS</a> Gibbs/MCMC based</li>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/">WinBUGS</a> Gibbs and MCMC based software. It was
one of the first but is now obsolete and unmaintained. Use JAGS or Stan instead.</li>
<li><a href="http://www.openbugs.net/w/FrontPage">OpenBUGS</a> The continuation of the WinBUGS project. Also no longer well maintained.
Use JAGS or Stan instead.</li>
</ul></li>
<li><p>R has multiple packages that implement some Bayesian methods. See the <a href="https://cran.r-project.org/web/views/Bayesian.html">Bayesian Task View</a></p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/LearnBayes/index.html">LearnBayes</a></li>
<li><a href="https://cran.r-project.org/web/packages/TeachBayes/index.html">TeachBayes</a></li>
</ul></li>
<li><p>Python</p>
<ul>
<li><a href="https://pymc-devs.github.io/pymc3/">PyMC</a> Very complete general-purpose Python package for Bayesian Analysis</li>
<li>The various Machine learning packages like [SciKit]</li>
</ul></li>
<li><a href="https://github.com/blei-lab/edward">Edward</a>. By David Blei. Deep generative models, variational inference. Runs
on Tensorflow. Implements variational and HMC methods, as well as optimization.</li>
<li>Church and others. Lisp-based inference programs. These are from the CS side.</li>
<li><p>Stata: Since <a href="http://www.stata.com/new-in-stata/bayesian-analysis/">Stata 14</a> it has some Bayesian capabilities. It mostly uses Metropolis-Hastings with Gibbs for a few models.</p></li>
<li><p>Julia</p>
<ul>
<li><a href="https://mambajl.readthedocs.io/en/latest/">Mamba</a> MCMC supporting multiple methods including Gibbs, MH, HMC, slice</li>
</ul></li>
</ul>
</div>
<div id="stan-3" class="section level3">
<h3><span class="header-section-number">16.4.15</span> Stan</h3>
<p>Some R packages.</p>
<p>Official <code>stan-dev</code> packages:</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/rstan/index.html">rstan</a></li>
<li><a href="https://cran.r-project.org/web/packages/rstanarm/index.html">rstanarm</a></li>
<li><a href="https://cran.r-project.org/web/packages/bayesplot/index.html">bayesplot</a></li>
<li><a href="https://cran.r-project.org/web/packages/shinystan/index.html">ShinyStan</a></li>
<li><a href="https://github.com/stan-dev/loo">loo</a></li>
</ul>
<p>Others:</p>
<ul>
<li><a href="https://github.com/paul-buerkner/brms">brms</a> Bayesian generalized non-linear multilevel models using Stan</li>
<li><a href="https://cran.r-project.org/web/packages/ggmcmc/index.html">ggmcmc</a></li>
</ul>
</div>
<div id="diagrams" class="section level3">
<h3><span class="header-section-number">16.4.16</span> Diagrams</h3>
<div id="dags-and-plate-notation" class="section level4">
<h4><span class="header-section-number">16.4.16.1</span> DAGs and Plate Notation</h4>
<p>See <a href="https://en.wikipedia.org/wiki/Plate_notation">Plate notation</a></p>
<ul>
<li><a href="https://github.com/jluttine/tikz-bayesnet">tikz-bayesnet</a> A TiKZ library for drawing Bayesian networks</li>
<li><a href="http://daft-pgm.org/">Daf</a> A python package to draw DAGs</li>
<li><p>Relevant Stackoverflow questions:</p>
<ul>
<li>[Software for drawing bayesian networks (graphical models)] (<a href="http://stats.stackexchange.com/questions/16750/software-for-drawing-bayesian-networks-graphical-models" class="uri">http://stats.stackexchange.com/questions/16750/software-for-drawing-bayesian-networks-graphical-models</a>) Stackoverflow.</li>
<li><a href="http://www.texample.net/tikz/examples/bayes/">Tikz Example</a></li>
<li><a href="http://tex.stackexchange.com/questions/199734/how-to-draw-plate-indices-in-graphical-model-by-tikz">how to draw plate indices in graphical model by tikz</a> Stackexchange</li>
<li><a href="http://tex.stackexchange.com/questions/11751/can-i-have-automatically-adjusted-plates-in-a-graphical-model?rq=1">Can I have automatically adjusted plates in a graphical model?</a></li>
</ul></li>
</ul>
</div>
<div id="kruschke-diagrams" class="section level4">
<h4><span class="header-section-number">16.4.16.2</span> Kruschke Diagrams</h4>
<p>Diagrams in the style of Kruschke’s <em>Doing Bayesian Analysis</em></p>
<ul>
<li>LibreOffice Draw Templates: <a href="http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/" class="uri">http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/</a></li>
<li><p>Blog posts</p>
<ul>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2012/05/graphical-model-diagrams-in-doing.html</a></li>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2012/05/hierarchical-diagrams-read-bottom-to.html</a></li>
<li><a href="http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html" class="uri">http://doingbayesiandataanalysis.blogspot.se/2013/10/diagrams-for-hierarchical-models-we.html</a></li>
</ul></li>
<li>R scripts: <a href="https://github.com/rasmusab/distribution_diagrams" class="uri">https://github.com/rasmusab/distribution_diagrams</a></li>
<li><p>Tikz scripts: <a href="https://github.com/yozw/bayesdiagram" class="uri">https://github.com/yozw/bayesdiagram</a></p></li>
</ul>
</div>
<div id="venn-diagramseikosograms" class="section level4">
<h4><span class="header-section-number">16.4.16.3</span> Venn Diagrams/Eikosograms</h4>
<ul>
<li>Oldford and W.H. Cherry. 2006. “Picturing Probability: the poverty of Venn diagrams, the richness of Eikosograms”</li>
</ul>
</div>
</div>
<div id="priors" class="section level3">
<h3><span class="header-section-number">16.4.17</span> Priors</h3>
<ul>
<li>Betancourt (2017) “<a href="http://mc-stan.org/documentation/case-studies/weakly_informative_shapes.html">How the shape of a weakly informative prior affects inferences</a>” <em>Stan Case Studies</em></li>
<li>Stan, <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Prior Choice Recommendations</a></li>
</ul>
</div>
</div>
<div id="bayesian-model-averaging-1" class="section level2">
<h2><span class="header-section-number">16.5</span> Bayesian Model Averaging</h2>
<ul>
<li>Montgomery, Hollenbach and Ward (2012) “<a href="https://dx.doi.org/10.1093/pan/mps002">Improving Predictions Using Ensemble Bayesian Model Averaging</a>” <em>Political Analysis</em></li>
<li>Montgomery and Nyhan (2011) <a href="https://dx.doi.org/10.1093/pan/mpq001">Bayesian Model Averaging: Theoretical Developments and Practical Applications</a></li>
<li><a href="https://CRAN.R-project.org/package=BMA">BMA Package</a></li>
<li><a href="https://CRAN.R-project.org/package=BMS">BMS Package</a></li>
<li><a href="https://CRAN.R-project.org/package=BAS">BAS Package</a></li>
<li>Amini and Parmeter (2011) “<a href="https://dx.doi.org/10.3233/JEM-2011-0350">Bayesian Model Averaging in R</a>” <em>Journal of Economic and Social Measurement</em></li>
<li>Fragoso and Neto (2015) <a href="http://arxiv.org/pdf/1509.08864v1:PDF">Bayesian model averaging: A systematic review and conceptual classification</a> <span class="citation">(Fragoso and Neto 2015)</span></li>
<li>Ley and Steel (2012) “<a href="https://dx.doi.org/10.1016/j.jeconom.2012.06.009">Mixtures of g-priors for Bayesian model averaging with economic applications</a>” <em>Journal of Econometrics</em></li>
<li><p>Ley and Steel (2009) “<a href="https://dx.doi.org/10.1002/jae.1057">On the effect of prior assumptions in Bayesian model averaging with applications to growth regression</a>” <em>Journal of Applied Econometrics</em></p></li>
<li><p>Volinsky, Raftery, Madigan, and Hoeting (1999) “<a href="https://dx.doi.org/10.1214/ss/1009212519">Bayesian model averaging: A Tutorial</a>” <em>Statistical Science</em></p></li>
</ul>
</div>
<div id="multilevel-modeling" class="section level2">
<h2><span class="header-section-number">16.6</span> Multilevel Modeling</h2>
<ul>
<li>Stegmueller (2013), “<a href="https://dx.doi.org/10.1111n/ajps.12001">How Many Countries for Multilevel Modeling? A Comparison of Frequentist and Bayesian Approaches</a>” <em>American Journal of Political Science</em> <span class="citation">(Stegmueller 2013)</span></li>
<li>Shor, Bafumi, Keele, and Park (2007) “<a href="https://dx.doi.org/10.1093/pan/mpm006">A Bayesian multilevel modeling approach to time-series cross-sectional data</a>” <em>Political Analysis</em></li>
<li>Beck and Katz (2007) “<a href="https://dx.doi.org/10.1093/pan/mpl001">Random coefficient models for time-series—cross-section data: Monte Carlo experiments</a>” <em>Political Analysis</em> <span class="citation">(Beck and Katz 2007)</span></li>
<li>Western and Jackman (1994). “<a href="https://dx.doi.org/10.2307/2944713">Bayesian Inference for Comparative Research</a>” <em>American Political Science Review</em> <span class="citation">(Western and Jackman 1994)</span></li>
<li>Anderson and Fetner. 2008. “<a href="https://dx.doi.org/10.1111/j.1540-5907.2008.00352.x">Economic inequality and intolerance: attitudes toward homosexuality in 35 democracies</a>” <em>American Journal of Political Science</em></li>
</ul>
</div>
<div id="mixture-models" class="section level2">
<h2><span class="header-section-number">16.7</span> Mixture Models</h2>
<ul>
<li>ImaiTingley2011a: Imai, K. and Tingley, D. (2012) “<a href="https://dx.doi.org/10.1111/j.1540-5907.2011.00555.x">A Statistical Method for Empirical Testing of Competing Theories</a>” <em>American Journal of Political Science</em></li>
</ul>
</div>
<div id="inference-1" class="section level2">
<h2><span class="header-section-number">16.8</span> Inference</h2>
<div id="discussion-of-bayesian-inference" class="section level3">
<h3><span class="header-section-number">16.8.1</span> Discussion of Bayesian Inference</h3>
<ul>
<li>Lindley. The Analysis of Experimental Data: The Appreciation of Tea and Wine</li>
</ul>
</div>
</div>
<div id="model-checking-1" class="section level2">
<h2><span class="header-section-number">16.9</span> Model Checking</h2>
<div id="posterior-predictive-checks-1" class="section level3">
<h3><span class="header-section-number">16.9.1</span> Posterior Predictive Checks</h3>
<ul>
<li>Gelman, Andrew (2007) “<a href="10.1111/j.1751-5823.2003.tb00203.x">A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-fit Testing</a>” <em>International Statistical Review</em></li>
<li>Gelman, Meng, Stern. POSTERIOR PREDICTIVE ASSESSMENT OF MODEL
FITNESS VIA REALIZED DISCREPANCIES. 1996.</li>
<li>Krushke. Posterior predictive checks can and should be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the practice of Bayesian statistics</li>
<li><a href="http://andrewgelman.com/2009/02/07/confusions_abou/">Confusions about posterior predictive checks</a></li>
<li>Gabry, Jonah. <a href="https://cran.r-project.org/web/packages/bayesplot/vignettes/graphical-ppcs.html">Graphical posterior predictive checks using the bayesplot package</a></li>
</ul>
</div>
<div id="prediction-criteria" class="section level3">
<h3><span class="header-section-number">16.9.2</span> Prediction Criteria</h3>
<ul>
<li>Gelman, Andrew, Jessica Hwang, and Aki Vehtari. 2014. “Understanding Predictive Information Criteria for Bayesian Models.” Statistics and Computing 24 (6). Springer: 997–1016.</li>
<li>Vehtari, Gelman, and Gabry. Practical Bayesian model evaluation using leave-one-out cross-validation and
WAIC. 2016. <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf" class="uri">http://www.stat.columbia.edu/~gelman/research/unpublished/loo_stan.pdf</a></li>
<li>Vehtari and Lampinen (2002) <a href="https://doi.org/10.1162/08997660260293292">Bayesian model assessment and comparison using cross-validation predictive densities</a></li>
<li>Vehtari and Ojanen (2012) “<a href="https://dx.doi.org/10.1214/12-SS102">A survey of Bayesian predictive methods for model assessment, selection and comparison</a>”</li>
</ul>
</div>
<div id="software-validation" class="section level3">
<h3><span class="header-section-number">16.9.3</span> Software Validation</h3>
<ul>
<li>Cook, Gelman, and Rubin (2006) “<a href="https://dx.doi.org/10.1198/106186006X136976">Validation of Software for Bayesian Models Using Posterior Quantiles</a>” <em>J of Comp. and Graphical Stat</em></li>
<li>Gelman. Correction <a href="https://doi.org/10.1080/10618600.2017.1377082" class="uri">https://doi.org/10.1080/10618600.2017.1377082</a></li>
<li>Savage, Jim. <a href="http://modernstatisticalworkflow.blogspot.com/2017/04/an-easy-way-to-simulate-fake-data-from.html">An easy way to simulate fake data from your Stan model</a></li>
<li><a href="https://github.com/stan-dev/stan/wiki/Stan-Best-Practices">Stan Best Practices</a></li>
</ul>
</div>
</div>
<div id="hierarchical-modeling" class="section level2">
<h2><span class="header-section-number">16.10</span> Hierarchical Modeling</h2>
<ul>
<li>Kruschke and Vanpaeml “Bayesian Estimation in Hierarchical Models” <a href="http://www.indiana.edu/~kruschke/articles/KruschkeVanpaemel2015.pdf" class="uri">http://www.indiana.edu/~kruschke/articles/KruschkeVanpaemel2015.pdf</a></li>
<li>Park, Gelman, and Bafumi (2004) “<a href="https://dx.doi.org/10.1093/pan/mph024">Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls</a>” <em>Political Analysis</em></li>
<li>Lax and Phillips. 2009. “How Should We Estimate Public Opinion in the States?” <em>AJPS</em></li>
</ul>
</div>
<div id="shrinkageregularization" class="section level2">
<h2><span class="header-section-number">16.11</span> Shrinkage/Regularization</h2>
<ul>
<li>Piironen and Vehtari. 2016. <a href="https://arxiv.org/abs/1610.05559">On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior</a></li>
<li>Lopes. 2015. <a href="http://hedibert.org/wp-content/uploads/2015/12/BayesianRegularization.pdf">Bayesian Regularization</a> slides.</li>
</ul>
</div>
<div id="empirical-bayes" class="section level2">
<h2><span class="header-section-number">16.12</span> Empirical Bayes</h2>
<ul>
<li>Berger (2006) “<a href="https://dx.doi.org/10.1214/06-BA115">The case for objective Bayesian analysis</a>” <em>Bayesian Analysis</em></li>
<li>Efron (2014) “<a href="https://dx.doi.org/10.1111%2Frssb.12080">Frequentist accuracy of Bayesian estimates</a>” <em>JRSS B</em></li>
<li>Efron (2010) “<a href="https://dx.doi.org/10.1214/09-sts308">The Future of Indirect Evidence</a>” <em>Statistical Science</em></li>
</ul>
</div>
<div id="history-of-bayesian-statistics" class="section level2">
<h2><span class="header-section-number">16.13</span> History of Bayesian Statistics</h2>
<ul>
<li>Robert and Casella (2011) “<a href="http://dx.doi.org/10.1214/10-STS351">A Short History of Markov Chain Monte Carlo: Subjective Recollections from Incomplete Data</a>” <em>Statistical Science</em></li>
<li>Stigler (2018) “<a href="https://doi.org/10.1214/17-STS635">Richard Price, the first Bayesian</a>” <em>Statistical Science</em> <span class="citation">(Stigler 2018)</span></li>
<li>Stigler (1983) “<a href="http://www.jstor.org/stable/2682766">Who discovered Bayes’s theorem?</a>” <em>American Statistician</em> <span class="citation">(Stigler 1983)</span></li>
<li>Fienberg (2006) “<a href="https://doi.org/10.1214/06-BA101">When did Bayesian Inference Become “Bayesian”?</a>” <em>Bayesian Analysis</em> <span class="citation">(Fienberg 2006)</span></li>
</ul>
</div>
</div>
<div id="sampling-difficulties" class="section level1">
<h1><span class="header-section-number">17</span> Sampling Difficulties</h1>
<ul>
<li>Carpenter (2017) “<a href="http://mc-stan.org/users/documentation/case-studies/curse-dims.html">Typical sets and the curse of dimensionality</a>” <em>Stan Case Studies</em></li>
<li>Betancourt (2017) “<a href="http://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html">Diagnosing biased inference with divergences</a>” <em>Stan Case Studies</em></li>
<li>Betancourt (2016) “<a href="http://arxiv.org/pdf/1604.00695v1:PDF">Diagnosing suboptimal cotangent disintegrations in Hamiltonian Monte Carlo</a>”</li>
<li>Betancourt and Girolami (2013) “Hamiltonian Monte Carlo for Hierarchical Models”</li>
</ul>
<div id="complicated-estimation-and-testing" class="section level2">
<h2><span class="header-section-number">17.1</span> Complicated Estimation and Testing</h2>
<ul>
<li>King, Tomz, and Wittenberg (2000) “<a href="https://dx.doi.org/10.2307/2669316">Making the most of statistical analyses: improving interpretation and presentation</a>” Propose a pseudo-Bayesian method.</li>
<li>Golder “<a href="http://mattgolder.com/interactions">Interactions</a>”. See referenced papers.</li>
<li>Hanmer and Kalkan (2012) “<a href="https://dx.doi.org/10.1111/j.1540-5907.2012.00602.x">Behind the curve: clarifying the best approach to calculating predicted probabilities and marginal effects from limited dependent variable models</a>” <em>American Journal of Political Science</em></li>
</ul>
</div>
<div id="pooling-polls" class="section level2">
<h2><span class="header-section-number">17.2</span> Pooling Polls</h2>
<ul>
<li>Jackman (2000) “<a href="https://dx.doi.org/10.1080/10361140500302472">Pooling the Polls over an Election Campaign</a>” <em>Australian Journal of Political Science</em></li>
<li>Linzer (2013) “<a href="http://dx.doi.org/10.1080/01621459.2012.737735">Dynamic Bayesian forecasting of presidential elections in the States</a>” <em>JASA</em></li>
</ul>
</div>
<div id="numerical-analysis" class="section level2">
<h2><span class="header-section-number">17.3</span> Numerical Analysis</h2>
<ul>
<li>Goldberg (1991) “<a href="https://dx.doi.org/10.1145/103162.103163">What every computer scientist should know about floating-point arithmetic</a>”</li>
<li>Computerphile (2014) “<a href="ttps://www.youtube.com/watch?v=PZRI1IfStY0">Floating point numbers</a>” video.</li>
<li>Eisele (2016) “<a href="https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/">The log-sum-exp trick in Machine Learning</a>” blog.</li>
<li>Carpenter (2016) “<a href="http://andrewgelman.com/2016/06/11/log-sum-of-exponentials/">Log Sum of Exponentials for Robust Sums on the Log Scale</a>” <em>Statistical Modeling, Causal Inference, and Social Science</em> (blog)</li>
<li>Cook <a href="https://www.johndcook.com/blog/2012/07/26/avoiding-underflow-in-bayesian-computations/">Avoiding underflow in Bayesian computations</a></li>
</ul>
</div>
<div id="visualizing-mcmc-methods" class="section level2">
<h2><span class="header-section-number">17.4</span> Visualizing MCMC Methods</h2>
<ul>
<li><a href="https://chi-feng.github.io/mcmc-demo/" class="uri">https://chi-feng.github.io/mcmc-demo/</a></li>
<li><a href="https://mimno.infosci.cornell.edu/hmc/" class="uri">https://mimno.infosci.cornell.edu/hmc/</a> and <a href="http://www.mimno.org/articles/hmc/" class="uri">http://www.mimno.org/articles/hmc/</a></li>
<li><a href="http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/" class="uri">http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/</a></li>
<li><a href="https://ridlow.wordpress.com/category/animation/" class="uri">https://ridlow.wordpress.com/category/animation/</a></li>
<li><a href="http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf" class="uri">http://people.math.aau.dk/~kkb/Undervisning/Bayes14/sorenh/docs/sampling-notes.pdf</a></li>
<li><a href="https://rpubs.com/mv2521/mcmc-animation" class="uri">https://rpubs.com/mv2521/mcmc-animation</a></li>
<li><a href="http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html" class="uri">http://blog.revolutionanalytics.com/2013/09/an-animated-peek-into-the-workings-of-bayesian-statistics.html</a></li>
<li><a href="https://people.duke.edu/~ccc14/sta-663/Animation.html" class="uri">https://people.duke.edu/~ccc14/sta-663/Animation.html</a></li>
<li><a href="https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html" class="uri">https://artax.karlin.mff.cuni.cz/r-help/library/asbio/html/anm.mc.bvn.html</a></li>
<li><a href="https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE" class="uri">https://groups.google.com/forum/#!topic/stan-users/nOk80xTlSyE</a></li>
<li><a href="https://www.youtube.com/watch?v=Vv3f0QNWvWQ" class="uri">https://www.youtube.com/watch?v=Vv3f0QNWvWQ</a></li>
<li><a href="https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltnonian-monte-carlo-a-k-a-hybrid-monte-carlo/" class="uri">https://theclevermachine.wordpress.com/2012/11/18/mcmc-hamiltnonian-monte-carlo-a-k-a-hybrid-monte-carlo/</a></li>
<li><a href="https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11" class="uri">https://www.youtube.com/watch?v=pHsuIaPbNbY&amp;list=PLqdbxUnkqOw2nKn7VxYqIrKWcqRkQYOsF&amp;index=11</a></li>
<li><a href="http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html" class="uri">http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html</a></li>
</ul>
</div>
<div id="bayesian-point-estimation-decision" class="section level2">
<h2><span class="header-section-number">17.5</span> Bayesian point estimation / Decision</h2>
<ul>
<li>Stan Modeling Language. Ch 32. Bayesian Point Estimation.</li>
<li><a href="http://www.johnmyleswhite.com/notebook/2013/03/22/modes-medians-and-means-an-unifying-perspective/">Modes, Medians and Means: A Unifying Perspective</a>. Not explicitly motivated with Bayesian decision theory; nevertheless, it is a good intuitive explanation of these estimators.</li>
<li>The Impact of Reparameterization on Point Estimates. <a href="http://mc-stan.org/users/documentation/case-studies/mle-params.html" class="uri">http://mc-stan.org/users/documentation/case-studies/mle-params.html</a></li>
<li>Rainey. <a href="https://github.com/carlislerainey/transformation-induced-bias" class="uri">https://github.com/carlislerainey/transformation-induced-bias</a></li>
</ul>
</div>
</div>
<div id="information-theory" class="section level1">
<h1><span class="header-section-number">18</span> Information Theory</h1>
<ul>
<li>Information Theory, Inference, and Learning Algorithms
David J.C. MacKay. <a href="http://www.inference.org.uk/itprnn/book.pdf" class="uri">http://www.inference.org.uk/itprnn/book.pdf</a></li>
</ul>
</div>
<div id="stan-modeling-language" class="section level1">
<h1><span class="header-section-number">19</span> Stan Modeling Language</h1>
<ul>
<li>Ch 1–8 Introduction.</li>
<li><p>pay attention to Ch 1, 8. skim the rest. know where to look for help.</p></li>
<li><p>Ch 28. Optimizing Stan Code for Efficiency (Neal’s funnel, reparameterization, vectorization)</p></li>
<li>Ch 22. Reparameterization and change of variables</li>
<li>Ch 23. Customized</li>
<li>Ch 24. User-defined functions</li>
<li><p>Ch 25. problematic posteriors</p></li>
<li>Ch 29. Bayesian Data Analysis</li>
<li>Ch 30. Markov Chain Monte Carlo Sampling (R hat, ESS, convergence, thinning)</li>
<li>Ch 31. Penalized MLE</li>
<li>Ch 32. Bayesin Point Estimation</li>
<li>Ch 34. Hamiltonian Monte Carlo Sampling</li>
<li><p>Ch 35. Transofrmations of Constrained Variables - changes of variables.</p></li>
</ul>
<div id="lists-of-distributions" class="section level3">
<h3><span class="header-section-number">19.0.1</span> Lists of Distributions</h3>
<ul>
<li>The list on <a href="https://en.wikipedia.org/wiki/Probability_distribution">Probability Distribution</a> is sufficient for most purposes</li>
<li>Refence at end of BDA 3</li>
<li><a href="https://www.johndcook.com/blog/distribution_chart/">Diagram of distribution relationships</a></li>
</ul>
<!--chapter:end:annotated.Rmd-->
</div>
</div>
<div id="references-10" class="section level1 unnumbered">
<h1>References</h1>
<!--chapter:end:references.Rmd-->
<div id="refs" class="references">
<div id="ref-AitkinLongford1986a">
<p>Aitkin, M., and N. Longford. 1986. “Statistical Modelling Issues in School Effectiveness Studies.” <em>Journal of the Royal Statistical Society. Series A (General)</em> 149 (1). [Royal Statistical Society, Wiley]:1–43. <a href="http://www.jstor.org/stable/2981882" class="uri">http://www.jstor.org/stable/2981882</a>.</p>
</div>
<div id="ref-Alexseev2006a">
<p>Alexseev, Mikhail A. 2006. “Ballot-Box Vigilantism? Ethnic Population Shifts and Xenophobic Voting in Post-Soviet Russia.” <em>Political Behavior</em> 28 (3). Springer Nature:211–40. <a href="https://doi.org/10.1007/s11109-006-9009-2" class="uri">https://doi.org/10.1007/s11109-006-9009-2</a>.</p>
</div>
<div id="ref-AllisonDunkley2013a">
<p>Allison, Rupert, and Joanna Dunkley. 2013. “Comparison of Sampling Techniques for Bayesian Parameter Estimation,” August. <a href="https://doi.org/10.1093/mnras/stt2190" class="uri">https://doi.org/10.1093/mnras/stt2190</a>.</p>
</div>
<div id="ref-AminiShahramParmeterChristopher2011a">
<p>Amini Shahram, M., and F. Parmeter Christopher. 2011. “Bayesian Model Averaging in R.” <em>Journal of Economic and Social Measurement</em> 36 (4). IOS Press:253–87. <a href="https://doi.org/10.3233/JEM-2011-0350" class="uri">https://doi.org/10.3233/JEM-2011-0350</a>.</p>
</div>
<div id="ref-AndersenFetner2008a">
<p>Andersen, Robert, and Tina Fetner. 2008. “Economic Inequality and Intolerance: Attitudes Toward Homosexuality in 35 Democracies.” <em>American Journal of Political Science</em> 52 (4). Wiley-Blackwell:942–58. <a href="https://doi.org/10.1111/j.1540-5907.2008.00352.x" class="uri">https://doi.org/10.1111/j.1540-5907.2008.00352.x</a>.</p>
</div>
<div id="ref-AndersonSinger2008a">
<p>Anderson, C. J., and M. M. Singer. 2008. “The Sensitive Left and the Impervious Right: Multilevel Models and the Politics of Inequality, Ideology, and Legitimacy in Europe.” <em>Comparative Political Studies</em> 41 (4-5). SAGE Publications:564–99. <a href="https://doi.org/10.1177/0010414007313113" class="uri">https://doi.org/10.1177/0010414007313113</a>.</p>
</div>
<div id="ref-Arzheimer2009a">
<p>Arzheimer, Kai. 2009. “Contextual Factors and the Extreme Right Vote in Western Europe, 1980-2002.” <em>American Journal of Political Science</em> 53 (2). Wiley-Blackwell:259–75. <a href="https://doi.org/10.1111/j.1540-5907.2009.00369.x" class="uri">https://doi.org/10.1111/j.1540-5907.2009.00369.x</a>.</p>
</div>
<div id="ref-BafumiGelman2006a">
<p>Bafumi, Joseph, and Andrew Gelman. 2006. “Fitting Multilevel Models When Predictors and Group Effects Correlate.” <em>SSRN Electronic Journal</em>. Elsevier BV. <a href="https://doi.org/10.2139/ssrn.1010095" class="uri">https://doi.org/10.2139/ssrn.1010095</a>.</p>
</div>
<div id="ref-BarnardMcCullochMeng2000a">
<p>Barnard, John, Robert McCulloch, and Xiao-Li Meng. 2000. “Modeling Covariance Matrices in Terms of Standard Deviations and Correlations, with Application to Shrinkage.” <em>Statistica Sinica</em> 10 (4). Institute of Statistical Science, Academia Sinica:1281–1311. <a href="http://www.jstor.org/stable/24306780" class="uri">http://www.jstor.org/stable/24306780</a>.</p>
</div>
<div id="ref-BarrilleauxRainey2014a">
<p>Barrilleaux, Charles, and Carlisle Rainey. 2014. “The Politics of Need.” <em>State Politics &amp; Policy Quarterly</em> 14 (4). SAGE Publications:437–60. <a href="https://doi.org/10.1177/1532440014561644" class="uri">https://doi.org/10.1177/1532440014561644</a>.</p>
</div>
<div id="ref-Bates2010a">
<p>Bates, Douglas M. 2010. <em>lme4: Mixed-Effects Modeling with R</em>. <a href="http://lme4.r-forge.r-project.org/book/front.pdf" class="uri">http://lme4.r-forge.r-project.org/book/front.pdf</a>.</p>
</div>
<div id="ref-BatesMaechlerBolkerEtAl2014a">
<p>Bates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2014. “Fitting Linear Mixed-Effects Models Using lme4,” June. <a href="http://arxiv.org/abs/1406.5823v1" class="uri">http://arxiv.org/abs/1406.5823v1</a>.</p>
</div>
<div id="ref-BayarriBergerForteEtAl2012a">
<p>Bayarri, M. J., J. O. Berger, A. Forte, and G. García-Donato. 2012. “Criteria for Bayesian Model Choice with Application to Variable Selection.” <em>The Annals of Statistics</em> 40 (3). Institute of Mathematical Statistics:1550–77. <a href="http://www.jstor.org/stable/41713685" class="uri">http://www.jstor.org/stable/41713685</a>.</p>
</div>
<div id="ref-BeckKatz2007a">
<p>Beck, Nathaniel, and Jonathan N. Katz. 2007. “Random Coefficient Models for Time-Series—Cross-Section Data: Monte Carlo Experiments.” <em>Political Analysis</em> 15 (02). Cambridge University Press (CUP):182–95. <a href="https://doi.org/10.1093/pan/mpl001" class="uri">https://doi.org/10.1093/pan/mpl001</a>.</p>
</div>
<div id="ref-BeckKatzTucker1998a">
<p>Beck, Nathaniel, Jonathan N. Katz, and Richard Tucker. 1998. “Taking Time Seriously: Time-Series-Cross-Section Analysis with a Binary Dependent Variable.” <em>American Journal of Political Science</em> 42 (4). [Midwest Political Science Association, Wiley]:1260–88. <a href="http://www.jstor.org/stable/2991857" class="uri">http://www.jstor.org/stable/2991857</a>.</p>
</div>
<div id="ref-BenoitPoel2017a">
<p>Benoit, Dries F., and Dirk Van den Poel. 2017. “bayesQR: A Bayesian Approach to Quantile Regression.” <em>Journal of Statistical Software</em> 76 (7). Foundation for Open Access Statistic. <a href="https://doi.org/10.18637/jss.v076.i07" class="uri">https://doi.org/10.18637/jss.v076.i07</a>.</p>
</div>
<div id="ref-BerryGolderMilton2012a">
<p>Berry, William D., Matt Golder, and Daniel Milton. 2012. “Improving Tests of Theories Positing Interaction.” <em>The Journal of Politics</em> 74 (3). University of Chicago Press:653–71. <a href="https://doi.org/10.1017/s0022381612000199" class="uri">https://doi.org/10.1017/s0022381612000199</a>.</p>
</div>
<div id="ref-Betancourt2016a">
<p>Betancourt, Michael. 2016. “Diagnosing Suboptimal Cotangent Disintegrations in Hamiltonian Monte Carlo,” April. <a href="http://arxiv.org/pdf/1604.00695v1:PDF" class="uri">http://arxiv.org/pdf/1604.00695v1:PDF</a>.</p>
</div>
<div id="ref-BhadraDattaPolsonEtAl2015a">
<p>Bhadra, Anindya, Jyotishka Datta, Nicholas G. Polson, and Brandon Willard. 2015. “The Horseshoe+ Estimator of Ultra-Sparse Signals,” February. <a href="http://arxiv.org/abs/1502.00560v2" class="uri">http://arxiv.org/abs/1502.00560v2</a>.</p>
</div>
<div id="ref-Box1976a">
<p>Box, George E. P. 1976. “Science and Statistics.” <em>Journal of the American Statistical Association</em> 71 (356):791–99. <a href="https://doi.org/10.1080/01621459.1976.10480949" class="uri">https://doi.org/10.1080/01621459.1976.10480949</a>.</p>
</div>
<div id="ref-BramborClarkGolder2006a">
<p>Brambor, Thomas, William Roberts Clark, and Matt Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” <em>Political Analysis</em> 14 (01). Cambridge University Press (CUP):63–82. <a href="https://doi.org/10.1093/pan/mpi014" class="uri">https://doi.org/10.1093/pan/mpi014</a>.</p>
</div>
<div id="ref-BrockDurlaufWest2003a">
<p>Brock, William, Steven Durlauf, and Kenneth West. 2003. “Policy Evaluation in Uncertain Economic Environments.” National Bureau of Economic Research. <a href="https://doi.org/10.3386/w10025" class="uri">https://doi.org/10.3386/w10025</a>.</p>
</div>
<div id="ref-Carpenter2016a">
<p>Carpenter, Bob. 2016. “The Impact of Reparameterization on Point Estimates.” <em>Stan Case Studies</em>, April. <a href="http://mc-stan.org/documentation/case-studies/mle-params.html" class="uri">http://mc-stan.org/documentation/case-studies/mle-params.html</a>.</p>
</div>
<div id="ref-CarpenterGabryGoodrich2017a">
<p>Carpenter, Bob, Jonah Gabry, and Ben Goodrich. 2017. “Hierarchical Partial Pooling for Repeated Binary Trials.” <em>Stan Case Studies</em>, January. <a href="http://mc-stan.org/documentation/case-studies/pool-binary-trials-rstanarm.html" class="uri">http://mc-stan.org/documentation/case-studies/pool-binary-trials-rstanarm.html</a>.</p>
</div>
<div id="ref-CarvalhoPolsonScott2009a">
<p>Carvalho, Carlos M., Nicholas G. Polson, and James G. Scott. 2009. “Handling Sparsity via the Horseshoe.” Edited by David van Dyk and Max Welling, Proceedings of machine learning research, 5. Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA: PMLR:73–80. <a href="http://proceedings.mlr.press/v5/carvalho09a.html" class="uri">http://proceedings.mlr.press/v5/carvalho09a.html</a>.</p>
</div>
<div id="ref-CarvalhoPolsonScott2010a">
<p>Carvalho, C. M., N. G. Polson, and J. G. Scott. 2010. “The Horseshoe Estimator for Sparse Signals.” <em>Biometrika</em> 97 (2). Oxford University Press (OUP):465–80. <a href="https://doi.org/10.1093/biomet/asq017" class="uri">https://doi.org/10.1093/biomet/asq017</a>.</p>
</div>
<div id="ref-Chernoff1986a">
<p>Chernoff, Herman. 1986. “Comment.” <em>The American Statistician</em> 40 (1). Informa UK Limited:5–6. <a href="https://doi.org/10.1080/00031305.1986.10475343" class="uri">https://doi.org/10.1080/00031305.1986.10475343</a>.</p>
</div>
<div id="ref-ClarkLinzer2014a">
<p>Clark, Tom S., and Drew A. Linzer. 2014. “Should I Use Fixed or Random Effects?” <em>Political Science Research and Methods</em> 3 (02). Cambridge University Press (CUP):399–408. <a href="https://doi.org/10.1017/psrm.2014.32" class="uri">https://doi.org/10.1017/psrm.2014.32</a>.</p>
</div>
<div id="ref-Clyde2017a">
<p>Clyde, Merlise A. 2017. “Using the Bayesian Adaptive Sampling (BAS) Package for Bayesian Model Averaging.” R package vignette. <a href="https://cran.r-project.org/web/packages/BAS/vignettes/BAS-vignette.html" class="uri">https://cran.r-project.org/web/packages/BAS/vignettes/BAS-vignette.html</a>.</p>
</div>
<div id="ref-Cribari-NetoZeileis2010a">
<p>Cribari-Neto, Francisco, and Achim Zeileis. 2010. “Beta Regression in R.” <em>Journal of Statistical Software</em> 34 (2). Foundation for Open Access Statistic. <a href="https://doi.org/10.18637/jss.v034.i02" class="uri">https://doi.org/10.18637/jss.v034.i02</a>.</p>
</div>
<div id="ref-DattaGhosh2013a">
<p>Datta, Jyotishka, and Jayanta. K. Ghosh. 2013. “Asymptotic Properties of Bayes Risk for the Horseshoe Prior.” <em>Bayesian Analysis</em> 8 (1). Institute of Mathematical Statistics:111–32. <a href="https://doi.org/10.1214/13-ba805" class="uri">https://doi.org/10.1214/13-ba805</a>.</p>
</div>
<div id="ref-DenisovaEllerFryeEtAl2009a">
<p>Denisova, Irina, Markus Eller, Timothy Frye, and Ekaterina Zhuravskaya. 2009. “Who Wants to Revise Privatization? The Complementarity of Market Skills and Institutions.” <em>American Political Science Review</em> 103 (02). Cambridge University Press (CUP):284–304. <a href="https://doi.org/10.1017/s0003055409090248" class="uri">https://doi.org/10.1017/s0003055409090248</a>.</p>
</div>
<div id="ref-Draper2008a">
<p>Draper, David. 2008. “Bayesian Multilevel Analysis and MCMC.” In <em>Handbook of Multilevel Analysis</em>, 77–139. Springer New York. <a href="https://doi.org/10.1007/978-0-387-73186-5_2" class="uri">https://doi.org/10.1007/978-0-387-73186-5_2</a>.</p>
</div>
<div id="ref-Duncan1961a">
<p>Duncan, O. D. 1961. “A Socioeconomic Index for All Occupations.” In <em>Occupations and Social Status</em>, edited by Jr. Reiss A. J. Frre Press.</p>
</div>
<div id="ref-Efron1986b">
<p>Efron, B. 1986a. “Reply.” <em>The American Statistician</em> 40 (1). Informa UK Limited:11–11. <a href="https://doi.org/10.1080/00031305.1986.10475348" class="uri">https://doi.org/10.1080/00031305.1986.10475348</a>.</p>
</div>
<div id="ref-Efron1986a">
<p>———. 1986b. “Why Isn’t Everyone a Bayesian?” <em>The American Statistician</em> 40 (1). Informa UK Limited:1–5. <a href="https://doi.org/10.1080/00031305.1986.10475342" class="uri">https://doi.org/10.1080/00031305.1986.10475342</a>.</p>
</div>
<div id="ref-EfronHastie2016a">
<p>Efron, Bradley, and Trevor Hastie. 2016. <em>Computer Age Statistical Inference</em>. Cambridge University Pr.</p>
</div>
<div id="ref-EfronMorris1975a">
<p>Efron, Bradley, and Carl Morris. 1975. “Data Analysis Using Stein’s Estimator and Its Generalizations.” <em>Journal of the American Statistical Association</em> 70 (350). Informa UK Limited:311–19. <a href="https://doi.org/10.1080/01621459.1975.10479864" class="uri">https://doi.org/10.1080/01621459.1975.10479864</a>.</p>
</div>
<div id="ref-EicherPapageorgiouRaftery2009a">
<p>Eicher, Theo S., Chris Papageorgiou, and Adrian E. Raftery. 2009. “Default Priors and Predictive Performance in Bayesian Model Averaging, with Application to Growth Determinants.” <em>Journal of Applied Econometrics</em> 26 (1). Wiley-Blackwell:30–55. <a href="https://doi.org/10.1002/jae.1112" class="uri">https://doi.org/10.1002/jae.1112</a>.</p>
</div>
<div id="ref-FernandezLeySteel2001a">
<p>Fernández, Carmen, Eduardo Ley, and Mark F. J. Steel. 2001. “Benchmark Priors for Bayesian Model Averaging.” <em>Journal of Econometrics</em> 100 (2). Elsevier BV:381–427. <a href="https://doi.org/10.1016/s0304-4076(00)00076-2" class="uri">https://doi.org/10.1016/s0304-4076(00)00076-2</a>.</p>
</div>
<div id="ref-FerrariCribari-Neto2004a">
<p>Ferrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta Regression for Modelling Rates and Proportions.” <em>Journal of Applied Statistics</em> 31 (7). Informa UK Limited:799–815. <a href="https://doi.org/10.1080/0266476042000214501" class="uri">https://doi.org/10.1080/0266476042000214501</a>.</p>
</div>
<div id="ref-Fienberg2006a">
<p>Fienberg, Stephen E. 2006. “When Did Bayesian Inference Become Bayesian?” <em>Bayesian Analysis</em> 1 (1). International Society for Bayesian Analysis:1–40. <a href="https://doi.org/10.1214/06-BA101" class="uri">https://doi.org/10.1214/06-BA101</a>.</p>
</div>
<div id="ref-Firth1993a">
<p>Firth, David. 1993. “Bias Reduction of Maximum Likelihood Estimates.” <em>Biometrika</em> 80 (1). Oxford University Press (OUP):27–38. <a href="https://doi.org/10.1093/biomet/80.1.27" class="uri">https://doi.org/10.1093/biomet/80.1.27</a>.</p>
</div>
<div id="ref-FlegalHaranJones2008a">
<p>Flegal, James M., Murali Haran, and Galin L. Jones. 2008. “Markov Chain Monte Carlo: Can We Trust the Third Significant Figure?” <em>Statistical Science</em> 23 (2). Institute of Mathematical Statistics:250–60. <a href="https://doi.org/10.1214/08-sts257" class="uri">https://doi.org/10.1214/08-sts257</a>.</p>
</div>
<div id="ref-Fox2016a">
<p>Fox, John. 2016. <em>Applied Regression Analysis &amp; Generalized Linear Models</em>. 3rd ed. Sage.</p>
</div>
<div id="ref-FragosoNeto2015a">
<p>Fragoso, Tiago M., and Francisco Louzada Neto. 2015. “Bayesian Model Averaging: A Systematic Review and Conceptual Classification,” September. <a href="http://arxiv.org/pdf/1509.08864v1:PDF" class="uri">http://arxiv.org/pdf/1509.08864v1:PDF</a>.</p>
</div>
<div id="ref-FranchinoHoeyland2009a">
<p>Franchino, Fabio, and Bjørn Høyland. 2009. “Legislative Involvement in Parliamentary Systems: Opportunities, Conflict, and Institutional Constraints.” <em>American Political Science Review</em> 103 (04). Cambridge University Press (CUP):607–21. <a href="https://doi.org/10.1017/s0003055409990177" class="uri">https://doi.org/10.1017/s0003055409990177</a>.</p>
</div>
<div id="ref-Gelman2007a">
<p>Gelman, Andrew. 2007. “A Bayesian Formulation of Exploratory Data Analysis and Goodness-of-Fit Testinga.” <em>International Statistical Review</em> 71 (2). Wiley-Blackwell:369–82. <a href="https://doi.org/10.1111/j.1751-5823.2003.tb00203.x" class="uri">https://doi.org/10.1111/j.1751-5823.2003.tb00203.x</a>.</p>
</div>
<div id="ref-Gelman2009a">
<p>———. 2009. “Confusions About Posterior Predictive Checks.” February 7, 2009. <a href="http://andrewgelman.com/2009/02/07/confusions_abou/" class="uri">http://andrewgelman.com/2009/02/07/confusions_abou/</a>.</p>
</div>
<div id="ref-Gelman2014a">
<p>———. 2014. “Discussion with Sander Greenland on Posterior Predictive Checks.” <em>Statistical Modeling, Causal Inference, and Social Science</em>, August. <a href="http://andrewgelman.com/2014/08/11/discussion-sander-greenland-posterior-predictive-checks/" class="uri">http://andrewgelman.com/2014/08/11/discussion-sander-greenland-posterior-predictive-checks/</a>.</p>
</div>
<div id="ref-BDA3">
<p>Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, and Aki Vehtari. 2013. <em>Bayesian Data Analysis</em>. Taylor &amp; Francis Ltd.</p>
</div>
<div id="ref-GelmanHill2007a">
<p>Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel / Hierarchical Models</em>. Cambridge University Pr.</p>
</div>
<div id="ref-GelmanHillYajima2012a">
<p>Gelman, Andrew, Jennifer Hill, and Masanao Yajima. 2012. “Why We (Usually) Don’t Have to Worry About Multiple Comparisons.” <em>Journal of Research on Educational Effectiveness</em> 5 (2). Informa UK Limited:189–211. <a href="https://doi.org/10.1080/19345747.2011.618213" class="uri">https://doi.org/10.1080/19345747.2011.618213</a>.</p>
</div>
<div id="ref-GelmanJakulinPittauEtAl2008a">
<p>Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” <em>The Annals of Applied Statistics</em> 2 (4). Institute of Mathematical Statistics:1360–83. <a href="https://doi.org/10.1214/08-aoas191" class="uri">https://doi.org/10.1214/08-aoas191</a>.</p>
</div>
<div id="ref-GelmanKing1993a">
<p>Gelman, Andrew, and Gary King. 1993. “Why Are American Presidential Election Campaign Polls so Variable When Votes Are so Predictable?” <em>British Journal of Political Science</em> 23 (04). Cambridge University Press (CUP):409. <a href="https://doi.org/10.1017/s0007123400006682" class="uri">https://doi.org/10.1017/s0007123400006682</a>.</p>
</div>
<div id="ref-GelmanMengStern1996a">
<p>Gelman, Andrew, Xiao-Li Meng, and Hal Stern. 1996. “Posterior Predictive Assessment of Model Fitness via Realized Discrepancies.” <em>Statistica Sinica</em> 6 (4). Institute of Statistical Science, Academia Sinica:733–60. <a href="http://www.jstor.org/stable/24306036" class="uri">http://www.jstor.org/stable/24306036</a>.</p>
</div>
<div id="ref-GelmanRubin1992a">
<p>Gelman, Andrew, and Donald B. Rubin. 1992. “Inference from Iterative Simulation Using Multiple Sequences.” <em>Statistical Science</em> 7 (4). Institute of Mathematical Statistics:457–72. <a href="http://www.jstor.org/stable/2246093" class="uri">http://www.jstor.org/stable/2246093</a>.</p>
</div>
<div id="ref-GelmanShalizi2012b">
<p>Gelman, Andrew, and Cosma Shalizi. 2012a. “Rejoinder to Discussion of ‘Philosophy and the Practice of Bayesian Statistics’.” <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1). Wiley-Blackwell:76–80. <a href="https://doi.org/10.1111/j.2044-8317.2012.02066.x" class="uri">https://doi.org/10.1111/j.2044-8317.2012.02066.x</a>.</p>
</div>
<div id="ref-GelmanShalizi2012a">
<p>Gelman, Andrew, and Cosma Rohilla Shalizi. 2012b. “Philosophy and the Practice of Bayesian Statistics.” <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1). Wiley-Blackwell:8–38. <a href="https://doi.org/10.1111/j.2044-8317.2011.02037.x" class="uri">https://doi.org/10.1111/j.2044-8317.2011.02037.x</a>.</p>
</div>
<div id="ref-GelmanShorBafumiEtAl2007a">
<p>Gelman, Andrew, Boris Shor, Joseph Bafumi, and David Park. 2007. “Rich State, Poor State, Red State, Blue State: What’s the Matter with Connecticut?” <em>Quarterly Journal of Political Science</em> 2 (4). Now Publishers:345–67. <a href="https://doi.org/10.1561/100.00006026" class="uri">https://doi.org/10.1561/100.00006026</a>.</p>
</div>
<div id="ref-GeorgeMcCulloch1993a">
<p>George, Edward I., and Robert E. McCulloch. 1993. “Variable Selection via Gibbs Sampling.” <em>Journal of the American Statistical Association</em> 88 (423). Informa UK Limited:881–89. <a href="https://doi.org/10.1080/01621459.1993.10476353" class="uri">https://doi.org/10.1080/01621459.1993.10476353</a>.</p>
</div>
<div id="ref-Geyer2011a">
<p>Geyer, C. J. 2011. “Introduction to Markov Chain Monte Carlo.” In <em>Handbook of Markov Chain Monte Carlo</em>, edited by S. Brooks, Gelman, A. G. L. Jones, and X.-L. Meng. Chapman; Hall/CRC.</p>
</div>
<div id="ref-GhoshGhattas2015a">
<p>Ghosh, Joyee, and Andrew E. Ghattas. 2015. “Bayesian Variable Selection Under Colinearity.” <em>The American Statistician</em> 69 (3). Informa UK Limited:165–73. <a href="https://doi.org/10.1080/00031305.2015.1031827" class="uri">https://doi.org/10.1080/00031305.2015.1031827</a>.</p>
</div>
<div id="ref-GhoshLiMitra2015a">
<p>Ghosh, Joyee, Yingbo Li, and Robin Mitra. 2015. “On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression,” July. <a href="http://arxiv.org/abs/1507.07170v2" class="uri">http://arxiv.org/abs/1507.07170v2</a>.</p>
</div>
<div id="ref-Gilardi2010a">
<p>Gilardi, Fabrizio. 2010. “Who Learns from What in Policy Diffusion Processes?” <em>American Journal of Political Science</em> 54 (3). [Midwest Political Science Association, Wiley]:650–66. <a href="http://www.jstor.org/stable/27821944" class="uri">http://www.jstor.org/stable/27821944</a>.</p>
</div>
<div id="ref-Goenner2004a">
<p>Goenner, Cullen F. 2004. “Uncertainty of the Liberal Peace.” <em>Journal of Peace Research</em> 41 (5). Sage Publications, Ltd.:589–605. <a href="http://www.jstor.org/stable/4149615" class="uri">http://www.jstor.org/stable/4149615</a>.</p>
</div>
<div id="ref-Goldera">
<p>Golder, Matthew. n.d. “Interactions.” Accessed March 21, 2017. <a href="http://mattgolder.com/interactions" class="uri">http://mattgolder.com/interactions</a>.</p>
</div>
<div id="ref-Goldstein2011a">
<p>Goldstein, H. 2011. <em>Multilevel Statistical Models</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-GoldsteinRasbashYangEtAl1993a">
<p>Goldstein, Harvey, Jon Rasbash, Min Yang, Geoffrey Woodhouse, Huiqi Pan, Desmond Nuttall, and Sally Thomas. 1993. “A Multilevel Analysis of School Examination Results.” <em>Oxford Review of Education</em> 19 (4). Informa UK Limited:425–33. <a href="https://doi.org/10.1080/0305498930190401" class="uri">https://doi.org/10.1080/0305498930190401</a>.</p>
</div>
<div id="ref-GoldsteinYangOmarEtAl2000a">
<p>Goldstein, Harvey, Min Yang, Rumana Omar, Rebecca Turner, and Simon Thompson. 2000. “Meta-Analysis Using Multilevel Models with an Application to the Study of Class Size Effects.” <em>Journal of the Royal Statistical Society: Series C (Applied Statistics)</em> 49 (3). Wiley-Blackwell:399–412. <a href="https://doi.org/10.1111/1467-9876.00200" class="uri">https://doi.org/10.1111/1467-9876.00200</a>.</p>
</div>
<div id="ref-GreenlandMansournia2015a">
<p>Greenland, Sander, and Mohammad Ali Mansournia. 2015. “Penalization, Bias Reduction, and Default Priors in Logistic and Related Categorical and Survival Regressions.” <em>Statistics in Medicine</em> 34 (23). Wiley-Blackwell:3133–43. <a href="https://doi.org/10.1002/sim.6537" class="uri">https://doi.org/10.1002/sim.6537</a>.</p>
</div>
<div id="ref-Grimmer2011a">
<p>Grimmer, Justin. 2011. “An Introduction to Bayesian Inference via Variational Approximations.” <em>Political Analysis</em> 19 (01). Cambridge University Press (CUP):32–47. <a href="https://doi.org/10.1093/pan/mpq027" class="uri">https://doi.org/10.1093/pan/mpq027</a>.</p>
</div>
<div id="ref-Gross2014a">
<p>Gross, Justin H. 2014. “Testing What Matters (If You Must Test at All): A Context-Driven Approach to Substantive and Statistical Significance.” <em>American Journal of Political Science</em> 59 (3). Wiley-Blackwell:775–88. <a href="https://doi.org/10.1111/ajps.12149" class="uri">https://doi.org/10.1111/ajps.12149</a>.</p>
</div>
<div id="ref-GruenKosmidisZeileis2012a">
<p>Grün, Bettina, Ioannis Kosmidis, and Achim Zeileis. 2012. “Extended Beta Regression in R: Shaken, Stirred, Mixed, and Partitioned.” <em>Journal of Statistical Software</em> 48 (11). Foundation for Open Access Statistic. <a href="https://doi.org/10.18637/jss.v048.i11" class="uri">https://doi.org/10.18637/jss.v048.i11</a>.</p>
</div>
<div id="ref-HahnCarvalho2015a">
<p>Hahn, P. Richard, and Carlos M. Carvalho. 2015. “Decoupling Shrinkage and Selection in Bayesian Linear Models: A Posterior Summary Perspective.” <em>Journal of the American Statistical Association</em> 110 (509). Informa UK Limited:435–48. <a href="https://doi.org/10.1080/01621459.2014.993077" class="uri">https://doi.org/10.1080/01621459.2014.993077</a>.</p>
</div>
<div id="ref-HegreSambanis2006a">
<p>Hegre, Håvard, and Nicholas Sambanis. 2006. “Sensitivity Analysis of Empirical Results on Civil War Onset.” <em>Journal of Conflict Resolution</em> 50 (4). SAGE Publications:508–35. <a href="https://doi.org/10.1177/0022002706289303" class="uri">https://doi.org/10.1177/0022002706289303</a>.</p>
</div>
<div id="ref-HoerlKennard1970a">
<p>Hoerl, Arthur E., and Robert W. Kennard. 1970. “Ridge Regression: Biased Estimation for Nonorthogonal Problems.” <em>Technometrics</em> 12 (1). Informa UK Limited:55–67. <a href="https://doi.org/10.1080/00401706.1970.10488634" class="uri">https://doi.org/10.1080/00401706.1970.10488634</a>.</p>
</div>
<div id="ref-HoogheMarks2004a">
<p>Hooghe, Liesbet, and Gary Marks. 2004. “Does Identity or Economic Rationality Drive Public Opinion on European Integration?” <em>PS: Political Science and Politics</em> 37 (3). [American Political Science Association, Cambridge University Press]:415–20. <a href="http://www.jstor.org/stable/4488854" class="uri">http://www.jstor.org/stable/4488854</a>.</p>
</div>
<div id="ref-HoogheReeskensStolleEtAl2009a">
<p>Hooghe, Marc, Tim Reeskens, Dietlind Stolle, and Ann Trappers. 2009. “Ethnic Diversity and Generalized Trust in Europe.” <em>Comparative Political Studies</em> 42 (2). SAGE Publications:198–223. <a href="https://doi.org/10.1177/0010414008325286" class="uri">https://doi.org/10.1177/0010414008325286</a>.</p>
</div>
<div id="ref-IshwaranKogalurRao2010a">
<p>Ishwaran, Hemant, Udaya B. Kogalur, and J. Sunil Rao. 2010. “spikeslab: Prediction and Variable Selection Using Spike and Slab Regression.” <em>R Journal</em>. <a href="https://journal.r-project.org/archive/2010-2/RJournal_2010-2_Ishwaran~et~al.pdf" class="uri">https://journal.r-project.org/archive/2010-2/RJournal_2010-2_Ishwaran~et~al.pdf</a>.</p>
</div>
<div id="ref-IshwaranRao2005a">
<p>Ishwaran, Hemant, and J. Sunil Rao. 2005. “Spike and Slab Variable Selection: Frequentist and Bayesian Strategies.” <em>The Annals of Statistics</em> 33 (2). Institute of Mathematical Statistics:730–73. <a href="https://doi.org/10.1214/009053604000001147" class="uri">https://doi.org/10.1214/009053604000001147</a>.</p>
</div>
<div id="ref-IversenRosenbluth2006a">
<p>Iversen, Torben, and Frances Rosenbluth. 2006. “The Political Economy of Gender: Explaining Cross-National Variation in the Gender Division of Labor and the Gender Voting Gap.” <em>American Journal of Political Science</em> 50 (1). Wiley-Blackwell:1–19. <a href="https://doi.org/10.1111/j.1540-5907.2006.00166.x" class="uri">https://doi.org/10.1111/j.1540-5907.2006.00166.x</a>.</p>
</div>
<div id="ref-Jackman2009a">
<p>Jackman, Simon. 2009. <em>Bayesian Analysis for the Social Sciences</em>. John Wiley; Sons Ltd.</p>
</div>
<div id="ref-JensenMcShaneWyner2009a">
<p>Jensen, Shane T., Blakeley B. McShane, and Abraham J. Wyner. 2009. “Hierarchical Bayesian Modeling of Hitting Performance in Baseball.” <em>Bayesian Analysis</em> 4 (4). Institute of Mathematical Statistics:631–52. <a href="https://doi.org/10.1214/09-ba424" class="uri">https://doi.org/10.1214/09-ba424</a>.</p>
</div>
<div id="ref-Jiang2007a">
<p>Jiang, Jiming. 2007. <em>Linear and Generalized Linear Mixed Models and Their Applications</em>. Springer New York.</p>
</div>
<div id="ref-King1998a">
<p>King, Gary. 1998. <em>Unifying Political Methodology: The Likelihood Theory of Statistical Inference</em>. UNIV OF MICHIGAN PR.</p>
</div>
<div id="ref-KingZeng2001b">
<p>King, Gary, and Langche Zeng. 2001a. “Logistic Regression in Rare Events Data.” <em>Political Analysis</em> 9 (2). [Oxford University Press, Society for Political Methodology]:137–63. <a href="http://www.jstor.org/stable/25791637" class="uri">http://www.jstor.org/stable/25791637</a>.</p>
</div>
<div id="ref-KingZeng2001a">
<p>———. 2001b. “Explaining Rare Events in International Relations.” <em>International Organization</em> 55 (3). Cambridge University Press (CUP):693–715. <a href="https://doi.org/10.1162/00208180152507597" class="uri">https://doi.org/10.1162/00208180152507597</a>.</p>
</div>
<div id="ref-Kruschke2013b">
<p>Kruschke, John K. 2013. “Posterior Predictive Checks Can and Should Be Bayesian: Comment on Gelman and Shalizi, ‘Philosophy and the Practice of Bayesian Statistics’.” <em>British Journal of Mathematical and Statistical Psychology</em> 66 (1):45–56. <a href="https://doi.org/10.1111/j.2044-8317.2012.02063.x" class="uri">https://doi.org/10.1111/j.2044-8317.2012.02063.x</a>.</p>
</div>
<div id="ref-LaxPhillips2009a">
<p>Lax, Jeffrey R., and Justin H. Phillips. 2009. “How Should We Estimate Public Opinion in the States?” <em>American Journal of Political Science</em> 53 (1). Wiley-Blackwell:107–21. <a href="https://doi.org/10.1111/j.1540-5907.2008.00360.x" class="uri">https://doi.org/10.1111/j.1540-5907.2008.00360.x</a>.</p>
</div>
<div id="ref-Leamer1983a">
<p>Leamer, Edward E. 1983. “Let’s Take the Con Out of Econometrics.” <em>The American Economic Review</em> 73 (1). American Economic Association:31–43. <a href="http://www.jstor.org/stable/1803924" class="uri">http://www.jstor.org/stable/1803924</a>.</p>
</div>
<div id="ref-LeySteel2009a">
<p>Ley, Eduardo, and Mark F. J. Steel. 2009. “On the Effect of Prior Assumptions in Bayesian Model Averaging with Applications to Growth Regression.” <em>Journal of Applied Econometrics</em> 24 (4). Wiley-Blackwell:651–74. <a href="https://doi.org/10.1002/jae.1057" class="uri">https://doi.org/10.1002/jae.1057</a>.</p>
</div>
<div id="ref-LeySteel2012a">
<p>———. 2012. “Mixtures of g-Priors for Bayesian Model Averaging with Economic Applications.” <em>Journal of Econometrics</em> 171 (2). Elsevier BV:251–66. <a href="https://doi.org/10.1016/j.jeconom.2012.06.009" class="uri">https://doi.org/10.1016/j.jeconom.2012.06.009</a>.</p>
</div>
<div id="ref-Lindley1986a">
<p>Lindley, D. V. 1986. “Comment.” <em>The American Statistician</em> 40 (1). Informa UK Limited:6–7. <a href="https://doi.org/10.1080/00031305.1986.10475344" class="uri">https://doi.org/10.1080/00031305.1986.10475344</a>.</p>
</div>
<div id="ref-MakalicSchmidt2016a">
<p>Makalic, Enes, and Daniel F. Schmidt. 2016. “High-Dimensional Bayesian Lregularised Regression with the BayesReg Package,” November. <a href="http://arxiv.org/abs/1611.06649v3" class="uri">http://arxiv.org/abs/1611.06649v3</a>.</p>
</div>
<div id="ref-Martin1992a">
<p>Martin, Lisa. 1992. <em>Coercive Cooperation: Explaining Multilateral Economic Sanctions</em>. Princeton University Press.</p>
</div>
<div id="ref-McElreath2016a">
<p>McElreath, Richard. 2016. <em>Statistical Rethinking</em>. Apple Academic Press Inc.</p>
</div>
<div id="ref-MeerDethScheepers2009a">
<p>Meer, T. W. G. van der, J. W. van Deth, and P. L. H. Scheepers. 2009. “The Politicized Participant: Ideology and Political Action in 20 Democracies.” <em>Comparative Political Studies</em> 42 (11). SAGE Publications:1426–57. <a href="https://doi.org/10.1177/0010414009332136" class="uri">https://doi.org/10.1177/0010414009332136</a>.</p>
</div>
<div id="ref-MitchellBeauchamp1988a">
<p>Mitchell, T. J., and J. J. Beauchamp. 1988. “Bayesian Variable Selection in Linear Regression.” <em>Journal of the American Statistical Association</em> 83 (404). Informa UK Limited:1023–32. <a href="https://doi.org/10.1080/01621459.1988.10478694" class="uri">https://doi.org/10.1080/01621459.1988.10478694</a>.</p>
</div>
<div id="ref-MontgomeryHollenbachWard2012a">
<p>Montgomery, Jacob M., Florian M. Hollenbach, and Michael D. Ward. 2012. “Improving Predictions Using Ensemble Bayesian Model Averaging.” <em>Political Analysis</em> 20 (03). Cambridge University Press (CUP):271–91. <a href="https://doi.org/10.1093/pan/mps002" class="uri">https://doi.org/10.1093/pan/mps002</a>.</p>
</div>
<div id="ref-MontgomeryNyhan2010a">
<p>Montgomery, Jacob M., and Brendan Nyhan. 2010. “Bayesian Model Averaging: Theoretical Developments and Practical Applications.” <em>Political Analysis</em> 18 (02). Cambridge University Press (CUP):245–70. <a href="https://doi.org/10.1093/pan/mpq001" class="uri">https://doi.org/10.1093/pan/mpq001</a>.</p>
</div>
<div id="ref-Morris1986a">
<p>Morris, C. N. 1986. “Comment.” <em>The American Statistician</em> 40 (1). Informa UK Limited:7–8. <a href="https://doi.org/10.1080/00031305.1986.10475345" class="uri">https://doi.org/10.1080/00031305.1986.10475345</a>.</p>
</div>
<div id="ref-ORourkeSinnott2006a">
<p>O’Rourke, Kevin H., and Richard Sinnott. 2006. “The Determinants of Individual Attitudes Towards Immigration.” <em>European Journal of Political Economy</em> 22 (4). Elsevier BV:838–61. <a href="https://doi.org/10.1016/j.ejpoleco.2005.10.005" class="uri">https://doi.org/10.1016/j.ejpoleco.2005.10.005</a>.</p>
</div>
<div id="ref-ParkGelmanBafumi2004a">
<p>Park, David K., Andrew Gelman, and Joseph Bafumi. 2004. “Bayesian Multilevel Estimation with Poststratification: State-Level Estimates from National Polls.” <em>Political Analysis</em> 12 (04). Cambridge University Press (CUP):375–85. <a href="https://doi.org/10.1093/pan/mph024" class="uri">https://doi.org/10.1093/pan/mph024</a>.</p>
</div>
<div id="ref-PasKleijnVaart2014a">
<p>Pas, S. L. van der, B. J. K. Kleijn, and A. W. van der Vaart. 2014. “The Horseshoe Estimator: Posterior Concentration Around Nearly Black Vectors.” <em>Electronic Journal of Statistics</em> 8 (2). Institute of Mathematical Statistics:2585–2618. <a href="https://doi.org/10.1214/14-ejs962" class="uri">https://doi.org/10.1214/14-ejs962</a>.</p>
</div>
<div id="ref-PiironenVehtari2015a">
<p>Piironen, Juho, and Aki Vehtari. 2015. “Projection Predictive Model Selection for Gaussian Processes,” October. <a href="https://doi.org/10.1109/MLSP.2016.7738829" class="uri">https://doi.org/10.1109/MLSP.2016.7738829</a>.</p>
</div>
<div id="ref-PiironenVehtari2016b">
<p>———. 2016a. “Comparison of Bayesian Predictive Methods for Model Selection.” <em>Statistics and Computing</em> 27 (3). Springer Nature:711–35. <a href="https://doi.org/10.1007/s11222-016-9649-y" class="uri">https://doi.org/10.1007/s11222-016-9649-y</a>.</p>
</div>
<div id="ref-PiironenVehtari2016a">
<p>———. 2016b. “On the Hyperprior Choice for the Global Shrinkage Parameter in the Horseshoe Prior,” October. <a href="http://arxiv.org/abs/1610.05559v1" class="uri">http://arxiv.org/abs/1610.05559v1</a>.</p>
</div>
<div id="ref-PolsonScott2011a">
<p>Polson, Nicholas G., and James G. Scott. 2011. “Shrink Globally, Act Locally: Sparse Bayesian Regularization and Prediction.” In <em>Bayesian Statistics</em>, 501–38. Oxford University Press. <a href="https://doi.org/10.1093/acprof:oso/9780199694587.003.0017" class="uri">https://doi.org/10.1093/acprof:oso/9780199694587.003.0017</a>.</p>
</div>
<div id="ref-Press1986a">
<p>Press, S. James. 1986. “Comment.” <em>The American Statistician</em> 40 (1). Informa UK Limited:9–10. <a href="https://doi.org/10.1080/00031305.1986.10475346" class="uri">https://doi.org/10.1080/00031305.1986.10475346</a>.</p>
</div>
<div id="ref-Rabe-HeskethSkrondal2012a">
<p>Rabe-Hesketh, Sophia, and Anders Skrondal. 2012. <em>Multilevel and Longitudinal Modeling Using Stata, Volumes I and II</em>. Stata Press. <a href="https://www.amazon.com/Multilevel-Longitudinal-Modeling-Using-Volumes-ebook/dp/B06XWHYLZT?SubscriptionId=0JYN1NVW651KCA56C102&amp;tag=techkie-20&amp;linkCode=xm2&amp;camp=2025&amp;creative=165953&amp;creativeASIN=B06XWHYLZT" class="uri">https://www.amazon.com/Multilevel-Longitudinal-Modeling-Using-Volumes-ebook/dp/B06XWHYLZT?SubscriptionId=0JYN1NVW651KCA56C102&amp;tag=techkie-20&amp;linkCode=xm2&amp;camp=2025&amp;creative=165953&amp;creativeASIN=B06XWHYLZT</a>.</p>
</div>
<div id="ref-RafteryHoetingVolinskyEtAl2017a">
<p>Raftery, Adrian, Jennifer Hoeting, Chris Volinsky, Ian Painter, and Ka Yee Yeung. 2017. “BMA: Bayesian Model Averaging.” <a href="https://CRAN.R-project.org/package=BMA" class="uri">https://CRAN.R-project.org/package=BMA</a>.</p>
</div>
<div id="ref-Rainey2016a">
<p>Rainey, Carlisle. 2016a. “Dealing with Separation in Logistic Regression Models.” <em>Political Analysis</em> 24 (03). Cambridge University Press (CUP):339–55. <a href="https://doi.org/10.1093/pan/mpw014" class="uri">https://doi.org/10.1093/pan/mpw014</a>.</p>
</div>
<div id="ref-Rainey2016b">
<p>———. 2016b. “Transformation-Induced Bias: Unbiased Coefficients Do Not Imply Unbiased Quantities of Interest.” <a href="http://www.carlislerainey.com/papers/bias.pdf" class="uri">http://www.carlislerainey.com/papers/bias.pdf</a>.</p>
</div>
<div id="ref-RanganathGerrishBlei2014a">
<p>Ranganath, R., S. Gerrish, and D. M. Blei. 2014. “Black box variational inference.” <em>ArXiv E-Prints</em>, December. <a href="https://arxiv.org/abs/1401.0118" class="uri">https://arxiv.org/abs/1401.0118</a>.</p>
</div>
<div id="ref-RaudenbushBryk2001a">
<p>Raudenbush, Stephen W., and Anthony S. Bryk. 2001. <em>Hierarchical Linear Models: Applications and Data Analysis Methods</em>. SAGE PUBN.</p>
</div>
<div id="ref-Sala-I-Martin1997a">
<p>Sala-I-Martin, Xavier X. 1997. “I Just Ran Two Million Regressions.” <em>The American Economic Review</em> 87 (2). American Economic Association:178–83. <a href="http://www.jstor.org/stable/2950909" class="uri">http://www.jstor.org/stable/2950909</a>.</p>
</div>
<div id="ref-ScottBerger2010a">
<p>Scott, James G., and James O. Berger. 2010. “Bayes and Empirical-Bayes Multiplicity Adjustment in the Variable-Selection Problem.” <em>The Annals of Statistics</em> 38 (5). Institute of Mathematical Statistics:2587–2619. <a href="https://doi.org/10.1214/10-Aos792" class="uri">https://doi.org/10.1214/10-Aos792</a>.</p>
</div>
<div id="ref-Smith1986a">
<p>Smith, Adrian F. M. 1986. “Comment.” <em>The American Statistician</em> 40 (1). Informa UK Limited:10–10. <a href="https://doi.org/10.1080/00031305.1986.10475347" class="uri">https://doi.org/10.1080/00031305.1986.10475347</a>.</p>
</div>
<div id="ref-SmithGelfand1992a">
<p>Smith, A. F. M., and A. E. Gelfand. 1992. “Bayesian Statistics Without Tears: A Sampling/Resampling Perspective.” <em>The American Statistician</em> 46 (2). Informa UK Limited:84–88. <a href="https://doi.org/10.1080/00031305.1992.10475856" class="uri">https://doi.org/10.1080/00031305.1992.10475856</a>.</p>
</div>
<div id="ref-SnijdersBosker2011a">
<p>Snijders, Tom A. B., and Roel Bosker. 2011. <em>Multilevel Analysis</em>. Sage Publications Ltd.</p>
</div>
<div id="ref-Stan2016a">
<p>Stan Development Team. 2016. <em>Stan Modeling Language Users Guide and Reference Manual, Version 2.14.0</em>. <a href="https://github.com/stan-dev/stan/releases/download/v2.14.0/stan-reference-2.14.0.pdf" class="uri">https://github.com/stan-dev/stan/releases/download/v2.14.0/stan-reference-2.14.0.pdf</a>.</p>
</div>
<div id="ref-SteenbergenJones2002a">
<p>Steenbergen, Marco R., and Bradford S. Jones. 2002. “Modeling Multilevel Data Structures.” <em>American Journal of Political Science</em> 46 (1). [Midwest Political Science Association, Wiley]:218–37. <a href="http://www.jstor.org/stable/3088424" class="uri">http://www.jstor.org/stable/3088424</a>.</p>
</div>
<div id="ref-Stegmueller2013a">
<p>Stegmueller, Daniel. 2013. “How Many Countries for Multilevel Modeling? A Comparison of Frequentist and Bayesian Approaches.” <em>American Journal of Political Science</em> 57 (3). Wiley-Blackwell:748–61. <a href="https://doi.org/10.1111/ajps.12001" class="uri">https://doi.org/10.1111/ajps.12001</a>.</p>
</div>
<div id="ref-Stigler1983a">
<p>Stigler, Stephen M. 1983. “Who Discovered Bayes’s Theorem?” <em>The American Statistician</em> 37 (4). [American Statistical Association, Taylor &amp; Francis, Ltd.]:290–96. <a href="http://www.jstor.org/stable/2682766" class="uri">http://www.jstor.org/stable/2682766</a>.</p>
</div>
<div id="ref-Stigler2018a">
<p>———. 2018. “Richard Price, the First Bayesian.” <em>Statistical Science</em> 33 (1). The Institute of Mathematical Statistics:117–25. <a href="https://doi.org/10.1214/17-STS635" class="uri">https://doi.org/10.1214/17-STS635</a>.</p>
</div>
<div id="ref-Tibshirani1996a">
<p>Tibshirani, Robert. 1996. “Regression Shrinkage and Selection via the Lasso.” <em>Journal of the Royal Statistical Society. Series B (Methodological)</em> 58 (1). [Royal Statistical Society, Wiley]:267–88. <a href="http://www.jstor.org/stable/2346178" class="uri">http://www.jstor.org/stable/2346178</a>.</p>
</div>
<div id="ref-TobiasLi2004a">
<p>Tobias, Justin L., and Mingliang Li. 2004. “Returns to Schooling and Bayesian Model Averaging: A Union of Two Literatures.” <em>Journal of Economic Surveys</em> 18 (2). Wiley-Blackwell:153–80. <a href="https://doi.org/10.1111/j.0950-0804.2004.00003.x" class="uri">https://doi.org/10.1111/j.0950-0804.2004.00003.x</a>.</p>
</div>
<div id="ref-Voeten2008a">
<p>Voeten, Erik. 2008. “The Impartiality of International Judges: Evidence from the European Court of Human Rights.” <em>American Political Science Review</em> 102 (04). Cambridge University Press (CUP):417–33. <a href="https://doi.org/10.1017/s0003055408080398" class="uri">https://doi.org/10.1017/s0003055408080398</a>.</p>
</div>
<div id="ref-VolinskyRafteryMadiganEtAl1999a">
<p>Volinsky, Chris T., Adrian E. Raftery, David Madigan, and Jennifer A. Hoeting. 1999. “Bayesian Model Averaging: A Tutorial (with Comments by M. Clyde, David Draper and E. I. George, and a Rejoinder by the Authors).” <em>Statistical Science</em> 14 (4). Institute of Mathematical Statistics:382–417. <a href="https://doi.org/10.1214/ss/1009212519" class="uri">https://doi.org/10.1214/ss/1009212519</a>.</p>
</div>
<div id="ref-WardGreenhillBakke2010a">
<p>Ward, Michael D., Brian D. Greenhill, and Kristin M. Bakke. 2010. “The Perils of Policy by p-Value: Predicting Civil Conflicts.” <em>Journal of Peace Research</em> 47 (4). SAGE Publications:363–75. <a href="https://doi.org/10.1177/0022343309356491" class="uri">https://doi.org/10.1177/0022343309356491</a>.</p>
</div>
<div id="ref-WechslerIzbickiEsteves2013a">
<p>Wechsler, Sergio, Rafael Izbicki, and Luìs Gustavo Esteves. 2013. “A Bayesian Look at Nonidentifiability: A Simple Example.” <em>The American Statistician</em> 67 (2). Informa UK Limited:90–93. <a href="https://doi.org/10.1080/00031305.2013.778787" class="uri">https://doi.org/10.1080/00031305.2013.778787</a>.</p>
</div>
<div id="ref-Weldon2006a">
<p>Weldon, Steven A. 2006. “The Institutional Context of Tolerance for Ethnic Minorities: A Comparative, Multilevel Analysis of Western Europe.” <em>American Journal of Political Science</em> 50 (2). Wiley-Blackwell:331–49. <a href="https://doi.org/10.1111/j.1540-5907.2006.00187.x" class="uri">https://doi.org/10.1111/j.1540-5907.2006.00187.x</a>.</p>
</div>
<div id="ref-West1987a">
<p>West, Mike. 1987. “On Scale Mixtures of Normal Distributions.” <em>Biometrika</em> 74 (3). Oxford University Press (OUP):646–48. <a href="https://doi.org/10.1093/biomet/74.3.646" class="uri">https://doi.org/10.1093/biomet/74.3.646</a>.</p>
</div>
<div id="ref-Western1998a">
<p>Western, Bruce. 1998. “Causal Heterogeneity in Comparative Research: A Bayesian Hierarchical Modelling Approach.” <em>American Journal of Political Science</em> 42 (4). [Midwest Political Science Association, Wiley]:1233–59. <a href="https://doi.org/10.2307/2991856" class="uri">https://doi.org/10.2307/2991856</a>.</p>
</div>
<div id="ref-WesternJackman1994a">
<p>Western, Bruce, and Simon Jackman. 1994. “Bayesian Inference for Comparative Research.” <em>American Political Science Review</em> 88 (02). Cambridge University Press (CUP):412–23. <a href="https://doi.org/10.2307/2944713" class="uri">https://doi.org/10.2307/2944713</a>.</p>
</div>
<div id="ref-WickhamCookHofmannEtAl2010a">
<p>Wickham, Hadley, Dianne Cook, Heike Hofmann, and Andreas Buja. 2010. “Graphical Inference for Infovis.” <em>IEEE Transactions on Visualization and Computer Graphics</em> 16 (6). Institute of Electrical; Electronics Engineers (IEEE):973–79. <a href="https://doi.org/10.1109/tvcg.2010.161" class="uri">https://doi.org/10.1109/tvcg.2010.161</a>.</p>
</div>
<div id="ref-YuZhang2005a">
<p>Yu, Keming, and Jin Zhang. 2005. “A Three-Parameter Asymmetric Laplace Distribution and Its Extension.” <em>Communications in Statistics - Theory and Methods</em> 34 (9-10). Informa UK Limited:1867–79. <a href="https://doi.org/10.1080/03610920500199018" class="uri">https://doi.org/10.1080/03610920500199018</a>.</p>
</div>
<div id="ref-Zeugner2011a">
<p>Zeugner, Stefan. 2011. “Bayesian Model Averaging with BMS for BMS Version 0.3.0.” R package vignette. <a href="https://cran.r-project.org/web/packages/BMS/vignettes/bms.pdf" class="uri">https://cran.r-project.org/web/packages/BMS/vignettes/bms.pdf</a>.</p>
</div>
<div id="ref-Zorn2005a">
<p>Zorn, Christopher. 2005. “A Solution to Separation in Binary Response Models.” <em>Political Analysis</em> 13 (2). [Oxford University Press, Society for Political Methodology]:157–70. <a href="https://doi.org/10.1093/pan/mpi009" class="uri">https://doi.org/10.1093/pan/mpi009</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This is also the case in optimization with non-convex objective functions.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>The original model used cluster robust standard errors, which will be ignored for now.<a href="#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>The Double Exponential distribution still has a thinner tail than the Student-t at higher values.<a href="#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>Since the cumulative distribution function of a distribution maps reals to <span class="math inline">\((0, 1)\)</span>, any CDF can be used as a link function.<a href="#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p><span class="citation">Beck, Katz, and Tucker (1998)</span> show that the cloglog link function can be derived from a grouped duration model with binary response variables.<a href="#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>Example from <a href="http://docs.zeligproject.org/en/latest/zelig-logit.html">Zelig-logit</a>.<a href="#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>See the source code <a href="https://github.com/stan-dev/rstanarm/blob/b78c2b5190db8b62da93f0c686d0c78da4e5bb9b/inst/chunks/tparameters_glm.stan#L22">here</a>
and <a href="https://github.com/stan-dev/rstanarm/blob/b78c2b5190db8b62da93f0c686d0c78da4e5bb9b/inst/chunks/priors_glm.stan#L25">here</a>.<a href="#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p><a href="https://en.wikipedia.org/wiki/Multilevel_model" class="uri">https://en.wikipedia.org/wiki/Multilevel_model</a><a href="#fnref8" class="footnote-back">↩</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
